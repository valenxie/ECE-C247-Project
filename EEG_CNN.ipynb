{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "5DT3YzDfAoJG",
    "outputId": "9c78dd0a-fe3a-4413-9417-50b123f54cd1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f7f03737fd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.layers.reshaping.flatten import Flatten\n",
    "from keras.layers.core.activation import Activation\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Reshape\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "X_test = np.load(\"X_test.npy\")\n",
    "y_test = np.load(\"y_test.npy\")\n",
    "person_train_valid = np.load(\"person_train_valid.npy\")\n",
    "X_train_valid = np.load(\"X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"y_train_valid.npy\")\n",
    "person_test = np.load(\"person_test.npy\")\n",
    "\n",
    "y_train_valid -= 769\n",
    "y_test -= 769\n",
    "\n",
    "## Visualizing the data\n",
    "\n",
    "ch_data = X_train_valid[:,8,:] # extracts the 9th channel from the data\n",
    "\n",
    "\n",
    "class_0_ind = np.where(y_train_valid == 0) # finds the indices where the label is 0\n",
    "ch_data_class_0 = ch_data[class_0_ind] # finds the data where label is 0\n",
    "avg_ch_data_class_0 = np.mean(ch_data_class_0,axis=0) # finds the average representation of the 9th channel when label is 0\n",
    "\n",
    "\n",
    "class_1_ind = np.where(y_train_valid == 1)\n",
    "ch_data_class_1 = ch_data[class_1_ind]\n",
    "avg_ch_data_class_1 = np.mean(ch_data_class_1,axis=0)\n",
    "\n",
    "class_2_ind = np.where(y_train_valid == 2)\n",
    "ch_data_class_2 = ch_data[class_2_ind]\n",
    "avg_ch_data_class_2 = np.mean(ch_data_class_2,axis=0)\n",
    "\n",
    "class_3_ind = np.where(y_train_valid == 3)\n",
    "ch_data_class_3 = ch_data[class_3_ind]\n",
    "avg_ch_data_class_3 = np.mean(ch_data_class_3,axis=0)\n",
    "\n",
    "\n",
    "plt.plot(np.arange(1000),avg_ch_data_class_0)\n",
    "plt.plot(np.arange(1000),avg_ch_data_class_1)\n",
    "plt.plot(np.arange(1000),avg_ch_data_class_2)\n",
    "plt.plot(np.arange(1000),avg_ch_data_class_3)\n",
    "plt.axvline(x=500, label='line at t=500',c='cyan')\n",
    "\n",
    "plt.legend([\"Cue Onset left\", \"Cue Onset right\", \"Cue onset foot\", \"Cue onset tongue\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "BvkwSOkwZCH2"
   },
   "outputs": [],
   "source": [
    "def data_prep(X,y,sub_sample,average,noise,period):\n",
    "    \n",
    "    total_X = None\n",
    "    total_y = None\n",
    "    \n",
    "    # Trimming the data (sample,22,1000) -> (sample,22,500)\n",
    "    X = X[:,:,0:period]\n",
    "\n",
    "    \n",
    "    # Maxpooling the data (sample,22,1000) -> (sample,22,500/sub_sample)\n",
    "    X_reshape = X.reshape(X.shape[0], X.shape[1], -1, sub_sample)\n",
    "    X_max = np.max(X_reshape, axis=3)\n",
    "    \n",
    "    total_X = X_max\n",
    "    total_y = y\n",
    "    \n",
    "    # Averaging + noise \n",
    "    X_average = np.mean(X.reshape(X.shape[0], X.shape[1], -1, average),axis=3)\n",
    "    if noise:\n",
    "      X_average = X_average + np.random.normal(0.0, 0.5, X_average.shape)\n",
    "    \n",
    "    total_X = np.vstack((total_X, X_average))\n",
    "    total_y = np.hstack((total_y, y))\n",
    "    \n",
    "    # Subsampling\n",
    "    \n",
    "    for i in range(sub_sample):\n",
    "        \n",
    "        X_subsample = X[:, :, i::sub_sample] + \\\n",
    "                            (np.random.normal(0.0, 0.5, X[:, :,i::sub_sample].shape) if noise else 0.0)\n",
    "            \n",
    "        total_X = np.vstack((total_X, X_subsample))\n",
    "        total_y = np.hstack((total_y, y))\n",
    "\n",
    "    return total_X,total_y\n",
    "        \n",
    "def data_finalize(period, total_number, takeout_sample, y_test=y_test): \n",
    "    ind_valid = np.random.choice(total_number, takeout_sample, replace=False)  # get 375 out of 2115 samples and no repetitation\n",
    "    ind_train = np.array(list(set(range(total_number)).difference(set(ind_valid)))) # a set(unordered) different with another set, set = set1 - set2\n",
    "\n",
    "    # Creating the training and validation sets using the generated indices\n",
    "    (X_train, X_valid) = X_train_valid[ind_train], X_train_valid[ind_valid] \n",
    "    (y_train, y_valid) = y_train_valid[ind_train], y_train_valid[ind_valid]\n",
    "    x_train,y_train = data_prep(X_train,y_train,2,2,True, period=period)\n",
    "    x_valid,y_valid = data_prep(X_valid,y_valid,2,2,True, period=period)\n",
    "    X_test_prep,y_test_prep = data_prep(X_test,y_test,2,2,True, period=period)\n",
    "\n",
    "    # Converting the labels to categorical variables for multiclass classification\n",
    "    y_train = to_categorical(y_train, 4)\n",
    "    y_valid = to_categorical(y_valid, 4)\n",
    "    y_test = to_categorical(y_test_prep, 4)\n",
    "\n",
    "    # Adding width of the segment to be 1\n",
    "    x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "    x_valid = x_valid.reshape(x_valid.shape[0], x_valid.shape[1], x_train.shape[2], 1)\n",
    "    x_test = X_test_prep.reshape(X_test_prep.shape[0], X_test_prep.shape[1], X_test_prep.shape[2], 1)\n",
    "\n",
    "\n",
    "    # Reshaping the training and validation dataset\n",
    "    x_train = np.swapaxes(x_train, 1,3)\n",
    "    x_train = np.swapaxes(x_train, 1,2)\n",
    "    x_valid = np.swapaxes(x_valid, 1,3)\n",
    "    x_valid = np.swapaxes(x_valid, 1,2)\n",
    "    x_test = np.swapaxes(x_test, 1,3)\n",
    "    x_test = np.swapaxes(x_test, 1,2)\n",
    "\n",
    "    return x_train, x_valid, x_test, y_train, y_valid, y_test\n",
    "\n",
    "\n",
    "\n",
    "X_train_valid_prep,y_train_valid_prep = data_prep(X_train_valid,y_train_valid,2,2,noise=True, period=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "73oNi5FjCAS2"
   },
   "source": [
    "# **Train the model on subject 1 data only and test it on both subject 1 test set and all subject test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XYDsW_1zCTPr",
    "outputId": "323c5539-98c7-4582-eea1-e6a4a29d6112"
   },
   "outputs": [],
   "source": [
    "# get subject 1 data for training and validation set\n",
    "person_train_valid = person_train_valid.flatten()\n",
    "X_train_valid=X_train_valid[np.where(person_train_valid==0)]\n",
    "y_train_valid=y_train_valid[np.where(person_train_valid==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v8NrEhQEFWWf",
    "outputId": "2b993fae-67c0-4708-e91f-250fb25ecbc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(237, 22, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_valid.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "RmMo3NY9Ghca"
   },
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "learning_rate = 7e-4\n",
    "epochs = 50\n",
    "cnn_optimizer = keras.optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8qr-vDpgzEAE",
    "outputId": "bc647a37-3334-4e57-f430-6c55f720b041"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 500, 1, 25)        5525      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 250, 1, 25)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 250, 1, 25)       100       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 250, 1, 25)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 250, 1, 50)        12550     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 125, 1, 50)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 125, 1, 50)       200       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 125, 1, 50)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 125, 1, 100)       50100     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 63, 1, 100)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 63, 1, 100)       400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 63, 1, 100)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6300)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 25204     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 94,079\n",
      "Trainable params: 93,729\n",
      "Non-trainable params: 350\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 15:20:09.756548: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "25/25 [==============================] - 2s 55ms/step - loss: 2.0430 - accuracy: 0.3551 - val_loss: 3.3001 - val_accuracy: 0.2083\n",
      "Epoch 2/50\n",
      "25/25 [==============================] - 1s 45ms/step - loss: 1.5570 - accuracy: 0.4795 - val_loss: 2.4562 - val_accuracy: 0.2560\n",
      "Epoch 3/50\n",
      "25/25 [==============================] - 1s 45ms/step - loss: 1.1444 - accuracy: 0.5846 - val_loss: 1.8634 - val_accuracy: 0.3036\n",
      "Epoch 4/50\n",
      "25/25 [==============================] - 1s 45ms/step - loss: 0.8899 - accuracy: 0.6962 - val_loss: 1.7051 - val_accuracy: 0.2857\n",
      "Epoch 5/50\n",
      "25/25 [==============================] - 1s 51ms/step - loss: 0.7932 - accuracy: 0.7205 - val_loss: 1.8448 - val_accuracy: 0.3333\n",
      "Epoch 6/50\n",
      "25/25 [==============================] - 1s 55ms/step - loss: 0.6138 - accuracy: 0.7782 - val_loss: 2.0967 - val_accuracy: 0.3512\n",
      "Epoch 7/50\n",
      "25/25 [==============================] - 1s 50ms/step - loss: 0.5176 - accuracy: 0.7974 - val_loss: 2.3738 - val_accuracy: 0.3810\n",
      "Epoch 8/50\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 0.4283 - accuracy: 0.8436 - val_loss: 2.4470 - val_accuracy: 0.3869\n",
      "Epoch 9/50\n",
      "25/25 [==============================] - 1s 52ms/step - loss: 0.3514 - accuracy: 0.8679 - val_loss: 2.8428 - val_accuracy: 0.3512\n",
      "Epoch 10/50\n",
      "25/25 [==============================] - 1s 56ms/step - loss: 0.3265 - accuracy: 0.8859 - val_loss: 2.8564 - val_accuracy: 0.3512\n",
      "Epoch 11/50\n",
      "25/25 [==============================] - 1s 57ms/step - loss: 0.2399 - accuracy: 0.9115 - val_loss: 2.9295 - val_accuracy: 0.3214\n",
      "Epoch 12/50\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.2197 - accuracy: 0.9244 - val_loss: 3.1171 - val_accuracy: 0.3333\n",
      "Epoch 13/50\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.1379 - accuracy: 0.9577 - val_loss: 2.9190 - val_accuracy: 0.3512\n",
      "Epoch 14/50\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.1770 - accuracy: 0.9372 - val_loss: 3.2044 - val_accuracy: 0.2857\n",
      "Epoch 15/50\n",
      "25/25 [==============================] - 1s 52ms/step - loss: 0.1622 - accuracy: 0.9462 - val_loss: 3.1246 - val_accuracy: 0.2857\n",
      "Epoch 16/50\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.1366 - accuracy: 0.9551 - val_loss: 3.0909 - val_accuracy: 0.3452\n",
      "Epoch 17/50\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.1265 - accuracy: 0.9577 - val_loss: 3.3216 - val_accuracy: 0.3095\n",
      "Epoch 18/50\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.1318 - accuracy: 0.9590 - val_loss: 3.0489 - val_accuracy: 0.3452\n",
      "Epoch 19/50\n",
      "25/25 [==============================] - 1s 55ms/step - loss: 0.0965 - accuracy: 0.9654 - val_loss: 3.3969 - val_accuracy: 0.2917\n",
      "Epoch 20/50\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.1290 - accuracy: 0.9577 - val_loss: 3.0424 - val_accuracy: 0.3571\n",
      "Epoch 21/50\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.1102 - accuracy: 0.9615 - val_loss: 3.3337 - val_accuracy: 0.3393\n",
      "Epoch 22/50\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.0631 - accuracy: 0.9846 - val_loss: 3.5307 - val_accuracy: 0.3155\n",
      "Epoch 23/50\n",
      "25/25 [==============================] - 1s 51ms/step - loss: 0.0819 - accuracy: 0.9718 - val_loss: 3.4415 - val_accuracy: 0.3214\n",
      "Epoch 24/50\n",
      "25/25 [==============================] - 1s 51ms/step - loss: 0.0815 - accuracy: 0.9679 - val_loss: 3.2295 - val_accuracy: 0.3333\n",
      "Epoch 25/50\n",
      "25/25 [==============================] - 1s 52ms/step - loss: 0.0720 - accuracy: 0.9808 - val_loss: 3.1902 - val_accuracy: 0.3929\n",
      "Epoch 26/50\n",
      "25/25 [==============================] - 1s 60ms/step - loss: 0.0554 - accuracy: 0.9808 - val_loss: 3.3245 - val_accuracy: 0.3869\n",
      "Epoch 27/50\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.0440 - accuracy: 0.9821 - val_loss: 3.4735 - val_accuracy: 0.3571\n",
      "Epoch 28/50\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.0487 - accuracy: 0.9859 - val_loss: 3.5735 - val_accuracy: 0.3452\n",
      "Epoch 29/50\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.0435 - accuracy: 0.9885 - val_loss: 3.6175 - val_accuracy: 0.3452\n",
      "Epoch 30/50\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.0407 - accuracy: 0.9885 - val_loss: 3.3634 - val_accuracy: 0.3393\n",
      "Epoch 31/50\n",
      "25/25 [==============================] - 1s 51ms/step - loss: 0.0374 - accuracy: 0.9910 - val_loss: 3.3940 - val_accuracy: 0.3333\n",
      "Epoch 32/50\n",
      "25/25 [==============================] - 1s 51ms/step - loss: 0.0397 - accuracy: 0.9859 - val_loss: 3.5049 - val_accuracy: 0.3631\n",
      "Epoch 33/50\n",
      "25/25 [==============================] - 1s 51ms/step - loss: 0.0473 - accuracy: 0.9872 - val_loss: 3.2519 - val_accuracy: 0.3631\n",
      "Epoch 34/50\n",
      "25/25 [==============================] - 1s 51ms/step - loss: 0.0569 - accuracy: 0.9833 - val_loss: 3.5977 - val_accuracy: 0.3512\n",
      "Epoch 35/50\n",
      "25/25 [==============================] - 1s 50ms/step - loss: 0.0246 - accuracy: 0.9936 - val_loss: 3.7547 - val_accuracy: 0.3333\n",
      "Epoch 36/50\n",
      "25/25 [==============================] - 1s 51ms/step - loss: 0.0415 - accuracy: 0.9821 - val_loss: 3.4450 - val_accuracy: 0.3631\n",
      "Epoch 37/50\n",
      "25/25 [==============================] - 1s 51ms/step - loss: 0.0376 - accuracy: 0.9885 - val_loss: 3.4454 - val_accuracy: 0.3512\n",
      "Epoch 38/50\n",
      "25/25 [==============================] - 1s 51ms/step - loss: 0.0384 - accuracy: 0.9885 - val_loss: 3.4343 - val_accuracy: 0.3631\n",
      "Epoch 39/50\n",
      "25/25 [==============================] - 1s 51ms/step - loss: 0.0367 - accuracy: 0.9897 - val_loss: 3.4081 - val_accuracy: 0.3393\n",
      "Epoch 40/50\n",
      "25/25 [==============================] - 1s 51ms/step - loss: 0.0281 - accuracy: 0.9949 - val_loss: 3.4724 - val_accuracy: 0.2857\n",
      "Epoch 41/50\n",
      "25/25 [==============================] - 1s 50ms/step - loss: 0.0213 - accuracy: 0.9949 - val_loss: 3.4622 - val_accuracy: 0.3512\n",
      "Epoch 42/50\n",
      "25/25 [==============================] - 1s 50ms/step - loss: 0.0190 - accuracy: 0.9962 - val_loss: 3.5009 - val_accuracy: 0.3393\n",
      "Epoch 43/50\n",
      "25/25 [==============================] - 1s 51ms/step - loss: 0.0227 - accuracy: 0.9936 - val_loss: 3.4780 - val_accuracy: 0.3274\n",
      "Epoch 44/50\n",
      "25/25 [==============================] - 1s 52ms/step - loss: 0.0397 - accuracy: 0.9872 - val_loss: 3.4303 - val_accuracy: 0.3452\n",
      "Epoch 45/50\n",
      "25/25 [==============================] - 1s 51ms/step - loss: 0.0209 - accuracy: 0.9949 - val_loss: 3.4589 - val_accuracy: 0.3452\n",
      "Epoch 46/50\n",
      "25/25 [==============================] - 1s 51ms/step - loss: 0.0259 - accuracy: 0.9910 - val_loss: 3.4956 - val_accuracy: 0.3274\n",
      "Epoch 47/50\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.0230 - accuracy: 0.9897 - val_loss: 3.6133 - val_accuracy: 0.3214\n",
      "Epoch 48/50\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.0262 - accuracy: 0.9923 - val_loss: 3.5434 - val_accuracy: 0.3036\n",
      "Epoch 49/50\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.0200 - accuracy: 0.9936 - val_loss: 3.6583 - val_accuracy: 0.3095\n",
      "Epoch 50/50\n",
      "25/25 [==============================] - 1s 52ms/step - loss: 0.0317 - accuracy: 0.9872 - val_loss: 3.5128 - val_accuracy: 0.3155\n"
     ]
    }
   ],
   "source": [
    "x_train, x_valid, x_test, y_train, y_valid, y_test = data_finalize(total_number=237, takeout_sample=42, period=1000, y_test=y_test)\n",
    "# get subject 1 data for test set\n",
    "person_test=person_test.flatten()\n",
    "X_test_sub1 = x_test[np.where(person_test==0)]\n",
    "y_test_sub1 = y_test[np.where(person_test==0)]\n",
    "\n",
    "model_sub1 = Sequential([\n",
    "\n",
    "      # Conv. block 1\n",
    "      keras.layers.Conv2D(filters=25, kernel_size=(10,1), padding='same', activation=tf.nn.gelu, input_shape=(x_train.shape[1],1,22)),\n",
    "      keras.layers.MaxPooling2D(pool_size=(2,1), padding='same'), # Read the keras documentation\n",
    "      keras.layers.BatchNormalization(),\n",
    "      keras.layers.Dropout(0.5),\n",
    "\n",
    "      # Conv. block 2\n",
    "      keras.layers.Conv2D(filters=50, kernel_size=(10,1), padding='same', activation=tf.nn.gelu),\n",
    "      keras.layers.MaxPooling2D(pool_size=(2,1), padding='same'),\n",
    "      keras.layers.BatchNormalization(),\n",
    "      keras.layers.Dropout(0.5),\n",
    "\n",
    "      # Conv. block 3\n",
    "      keras.layers.Conv2D(filters=100, kernel_size=(10,1), padding='same', activation=tf.nn.gelu),\n",
    "      keras.layers.MaxPooling2D(pool_size=(2,1), padding='same'),\n",
    "      keras.layers.BatchNormalization(),\n",
    "      keras.layers.Dropout(0.5),\n",
    "\n",
    "      # Output layer with Softmax activation\n",
    "      keras.layers.Flatten(), # Flattens the input\n",
    "      keras.layers.Dense(4, activation='softmax') # Output FC layer with softmax activation\n",
    "\n",
    "  ])\n",
    "\n",
    "  # Printing the model summary\n",
    "model_sub1.summary()\n",
    "\n",
    "  \n",
    "\n",
    "model_sub1.compile(loss='categorical_crossentropy',\n",
    "                 optimizer=cnn_optimizer,\n",
    "                 metrics=['accuracy'])\n",
    "  \n",
    "\n",
    "  # Training and validating the model\n",
    "model_sub1_results = model_sub1.fit(x_train,\n",
    "              y_train,\n",
    "              batch_size=32,\n",
    "              epochs=50,\n",
    "              validation_data=(x_valid, y_valid), verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8W33IzSUCpBs",
    "outputId": "5e83e080-eaba-4dc3-ff80-6a83c4d3c072"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of model_sub1: 0.3799999952316284\n"
     ]
    }
   ],
   "source": [
    "cnn_score = model_sub1.evaluate(X_test_sub1, y_test_sub1, verbose=0)\n",
    "print('Test accuracy of model_sub1:',cnn_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load(\"X_test.npy\")\n",
    "y_test = np.load(\"y_test.npy\")\n",
    "person_train_valid = np.load(\"person_train_valid.npy\")\n",
    "X_train_valid = np.load(\"X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"y_train_valid.npy\")\n",
    "person_test = np.load(\"person_test.npy\")\n",
    "y_train_valid -= 769\n",
    "y_test -= 769"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jeXROCIqUe_7",
    "outputId": "60049651-600e-4f2d-f333-6ed2eac0922f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6960, 500, 1, 22)\n",
      "(6960, 4)\n",
      "(1500, 500, 1, 22)\n",
      "(1500, 4)\n",
      "(1772, 500, 1, 22)\n",
      "(1772, 4)\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_24 (Conv2D)          (None, 500, 1, 25)        5525      \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPoolin  (None, 250, 1, 25)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_24 (Bat  (None, 250, 1, 25)       100       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 250, 1, 25)        0         \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 250, 1, 50)        12550     \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPoolin  (None, 125, 1, 50)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_25 (Bat  (None, 125, 1, 50)       200       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 125, 1, 50)        0         \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 125, 1, 100)       50100     \n",
      "                                                                 \n",
      " max_pooling2d_26 (MaxPoolin  (None, 63, 1, 100)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_26 (Bat  (None, 63, 1, 100)       400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 63, 1, 100)        0         \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 6300)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 4)                 25204     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 94,079\n",
      "Trainable params: 93,729\n",
      "Non-trainable params: 350\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "218/218 [==============================] - 12s 52ms/step - loss: 2.9413 - accuracy: 0.3713 - val_loss: 2.3924 - val_accuracy: 0.3593\n",
      "Epoch 2/50\n",
      "218/218 [==============================] - 12s 56ms/step - loss: 1.8674 - accuracy: 0.4770 - val_loss: 1.7829 - val_accuracy: 0.4060\n",
      "Epoch 3/50\n",
      "218/218 [==============================] - 12s 56ms/step - loss: 1.4289 - accuracy: 0.5496 - val_loss: 1.6449 - val_accuracy: 0.4240\n",
      "Epoch 4/50\n",
      "218/218 [==============================] - 12s 55ms/step - loss: 1.1883 - accuracy: 0.5986 - val_loss: 1.4800 - val_accuracy: 0.4747\n",
      "Epoch 5/50\n",
      "218/218 [==============================] - 13s 59ms/step - loss: 1.0060 - accuracy: 0.6391 - val_loss: 1.4780 - val_accuracy: 0.4767\n",
      "Epoch 6/50\n",
      "218/218 [==============================] - 13s 57ms/step - loss: 0.9054 - accuracy: 0.6636 - val_loss: 1.5322 - val_accuracy: 0.4973\n",
      "Epoch 7/50\n",
      "218/218 [==============================] - 13s 58ms/step - loss: 0.8069 - accuracy: 0.7000 - val_loss: 1.4484 - val_accuracy: 0.5113\n",
      "Epoch 8/50\n",
      "218/218 [==============================] - 13s 58ms/step - loss: 0.7616 - accuracy: 0.7093 - val_loss: 1.4361 - val_accuracy: 0.5073\n",
      "Epoch 9/50\n",
      "218/218 [==============================] - 13s 58ms/step - loss: 0.6976 - accuracy: 0.7345 - val_loss: 1.4636 - val_accuracy: 0.5160\n",
      "Epoch 10/50\n",
      "218/218 [==============================] - 12s 57ms/step - loss: 0.6628 - accuracy: 0.7530 - val_loss: 1.2981 - val_accuracy: 0.5640\n",
      "Epoch 11/50\n",
      "218/218 [==============================] - 12s 56ms/step - loss: 0.6003 - accuracy: 0.7648 - val_loss: 1.3156 - val_accuracy: 0.5633\n",
      "Epoch 12/50\n",
      "218/218 [==============================] - 12s 57ms/step - loss: 0.5732 - accuracy: 0.7858 - val_loss: 1.3706 - val_accuracy: 0.5533\n",
      "Epoch 13/50\n",
      "218/218 [==============================] - 12s 56ms/step - loss: 0.5406 - accuracy: 0.7954 - val_loss: 1.3239 - val_accuracy: 0.5620\n",
      "Epoch 14/50\n",
      "218/218 [==============================] - 12s 56ms/step - loss: 0.4968 - accuracy: 0.8065 - val_loss: 1.2671 - val_accuracy: 0.5933\n",
      "Epoch 15/50\n",
      "218/218 [==============================] - 12s 56ms/step - loss: 0.4918 - accuracy: 0.8116 - val_loss: 1.3276 - val_accuracy: 0.5647\n",
      "Epoch 16/50\n",
      "218/218 [==============================] - 12s 56ms/step - loss: 0.4670 - accuracy: 0.8157 - val_loss: 1.2426 - val_accuracy: 0.5867\n",
      "Epoch 17/50\n",
      "218/218 [==============================] - 12s 57ms/step - loss: 0.4336 - accuracy: 0.8376 - val_loss: 1.2415 - val_accuracy: 0.5853\n",
      "Epoch 18/50\n",
      "218/218 [==============================] - 13s 58ms/step - loss: 0.4226 - accuracy: 0.8430 - val_loss: 1.2663 - val_accuracy: 0.5733\n",
      "Epoch 19/50\n",
      "218/218 [==============================] - 13s 57ms/step - loss: 0.4083 - accuracy: 0.8399 - val_loss: 1.3026 - val_accuracy: 0.5700\n",
      "Epoch 20/50\n",
      "218/218 [==============================] - 12s 57ms/step - loss: 0.3802 - accuracy: 0.8562 - val_loss: 1.3790 - val_accuracy: 0.5780\n",
      "Epoch 21/50\n",
      "218/218 [==============================] - 12s 56ms/step - loss: 0.3883 - accuracy: 0.8540 - val_loss: 1.3485 - val_accuracy: 0.5960\n",
      "Epoch 22/50\n",
      "218/218 [==============================] - 12s 54ms/step - loss: 0.3684 - accuracy: 0.8626 - val_loss: 1.3356 - val_accuracy: 0.5753\n",
      "Epoch 23/50\n",
      "218/218 [==============================] - 12s 54ms/step - loss: 0.3327 - accuracy: 0.8761 - val_loss: 1.2813 - val_accuracy: 0.6107\n",
      "Epoch 24/50\n",
      "218/218 [==============================] - 12s 56ms/step - loss: 0.3312 - accuracy: 0.8750 - val_loss: 1.2716 - val_accuracy: 0.6073\n",
      "Epoch 25/50\n",
      "218/218 [==============================] - 12s 56ms/step - loss: 0.3122 - accuracy: 0.8809 - val_loss: 1.2708 - val_accuracy: 0.6073\n",
      "Epoch 26/50\n",
      "218/218 [==============================] - 12s 56ms/step - loss: 0.3082 - accuracy: 0.8858 - val_loss: 1.2707 - val_accuracy: 0.6113\n",
      "Epoch 27/50\n",
      "218/218 [==============================] - 12s 56ms/step - loss: 0.3019 - accuracy: 0.8897 - val_loss: 1.2718 - val_accuracy: 0.6273\n",
      "Epoch 28/50\n",
      "218/218 [==============================] - 12s 56ms/step - loss: 0.2847 - accuracy: 0.8934 - val_loss: 1.3530 - val_accuracy: 0.6033\n",
      "Epoch 29/50\n",
      "218/218 [==============================] - 12s 56ms/step - loss: 0.2820 - accuracy: 0.8927 - val_loss: 1.2584 - val_accuracy: 0.6253\n",
      "Epoch 30/50\n",
      "218/218 [==============================] - 12s 56ms/step - loss: 0.2666 - accuracy: 0.8991 - val_loss: 1.1895 - val_accuracy: 0.6353\n",
      "Epoch 31/50\n",
      "218/218 [==============================] - 12s 56ms/step - loss: 0.2668 - accuracy: 0.8976 - val_loss: 1.2316 - val_accuracy: 0.6313\n",
      "Epoch 32/50\n",
      "218/218 [==============================] - 12s 56ms/step - loss: 0.2470 - accuracy: 0.9101 - val_loss: 1.1847 - val_accuracy: 0.6400\n",
      "Epoch 33/50\n",
      "218/218 [==============================] - 12s 56ms/step - loss: 0.2576 - accuracy: 0.9052 - val_loss: 1.2416 - val_accuracy: 0.6367\n",
      "Epoch 34/50\n",
      "218/218 [==============================] - 12s 56ms/step - loss: 0.2511 - accuracy: 0.9101 - val_loss: 1.2706 - val_accuracy: 0.6320\n",
      "Epoch 35/50\n",
      "218/218 [==============================] - 12s 56ms/step - loss: 0.2434 - accuracy: 0.9116 - val_loss: 1.2916 - val_accuracy: 0.6133\n",
      "Epoch 36/50\n",
      "218/218 [==============================] - 12s 57ms/step - loss: 0.2253 - accuracy: 0.9132 - val_loss: 1.2730 - val_accuracy: 0.6453\n",
      "Epoch 37/50\n",
      "218/218 [==============================] - 12s 57ms/step - loss: 0.2228 - accuracy: 0.9167 - val_loss: 1.3548 - val_accuracy: 0.6267\n",
      "Epoch 38/50\n",
      "218/218 [==============================] - 12s 57ms/step - loss: 0.2066 - accuracy: 0.9259 - val_loss: 1.3540 - val_accuracy: 0.6173\n",
      "Epoch 39/50\n",
      "218/218 [==============================] - 12s 57ms/step - loss: 0.2204 - accuracy: 0.9177 - val_loss: 1.2696 - val_accuracy: 0.6400\n",
      "Epoch 40/50\n",
      "218/218 [==============================] - 12s 57ms/step - loss: 0.2153 - accuracy: 0.9207 - val_loss: 1.2446 - val_accuracy: 0.6373\n",
      "Epoch 41/50\n",
      "218/218 [==============================] - 12s 56ms/step - loss: 0.2153 - accuracy: 0.9220 - val_loss: 1.3504 - val_accuracy: 0.6313\n",
      "Epoch 42/50\n",
      "218/218 [==============================] - 12s 57ms/step - loss: 0.1929 - accuracy: 0.9319 - val_loss: 1.3334 - val_accuracy: 0.6213\n",
      "Epoch 43/50\n",
      "218/218 [==============================] - 12s 57ms/step - loss: 0.2085 - accuracy: 0.9247 - val_loss: 1.3486 - val_accuracy: 0.6173\n",
      "Epoch 44/50\n",
      "218/218 [==============================] - 12s 57ms/step - loss: 0.1940 - accuracy: 0.9312 - val_loss: 1.3177 - val_accuracy: 0.6280\n",
      "Epoch 45/50\n",
      "218/218 [==============================] - 13s 59ms/step - loss: 0.1894 - accuracy: 0.9300 - val_loss: 1.2940 - val_accuracy: 0.6493\n",
      "Epoch 46/50\n",
      "218/218 [==============================] - 13s 58ms/step - loss: 0.1988 - accuracy: 0.9272 - val_loss: 1.2627 - val_accuracy: 0.6267\n",
      "Epoch 47/50\n",
      "218/218 [==============================] - 13s 59ms/step - loss: 0.1991 - accuracy: 0.9277 - val_loss: 1.2984 - val_accuracy: 0.6273\n",
      "Epoch 48/50\n",
      "218/218 [==============================] - 13s 58ms/step - loss: 0.2017 - accuracy: 0.9283 - val_loss: 1.4854 - val_accuracy: 0.6060\n",
      "Epoch 49/50\n",
      "218/218 [==============================] - 12s 56ms/step - loss: 0.1846 - accuracy: 0.9338 - val_loss: 1.2479 - val_accuracy: 0.6533\n",
      "Epoch 50/50\n",
      "218/218 [==============================] - 12s 56ms/step - loss: 0.1836 - accuracy: 0.9325 - val_loss: 1.2697 - val_accuracy: 0.6527\n",
      "{'1000': 0.6526666879653931}\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000, 1100, 100):\n",
    "    x_train, x_valid, x_test, y_train, y_valid, y_test = data_finalize(total_number=2115, takeout_sample=375, period=i, y_test=y_test)\n",
    "    print(x_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(x_valid.shape)\n",
    "    print(y_valid.shape)\n",
    "    print(x_test.shape)\n",
    "    print(y_test.shape)\n",
    "    model_all_subs = Sequential([\n",
    "\n",
    "      # Conv. block 1\n",
    "      keras.layers.Conv2D(filters=25, kernel_size=(10,1), padding='same', activation=tf.nn.gelu, input_shape=(x_train.shape[1],1,22)),\n",
    "      keras.layers.MaxPooling2D(pool_size=(2,1), padding='same'), \n",
    "      keras.layers.BatchNormalization(),\n",
    "      keras.layers.Dropout(0.5),\n",
    "\n",
    "      # Conv. block 2\n",
    "      keras.layers.Conv2D(filters=50, kernel_size=(10,1), padding='same', activation=tf.nn.gelu),\n",
    "      keras.layers.MaxPooling2D(pool_size=(2,1), padding='same'),\n",
    "      keras.layers.BatchNormalization(),\n",
    "      keras.layers.Dropout(0.5),\n",
    "\n",
    "      # Conv. block 3\n",
    "      keras.layers.Conv2D(filters=100, kernel_size=(10,1), padding='same', activation=tf.nn.gelu),\n",
    "      keras.layers.MaxPooling2D(pool_size=(2,1), padding='same'),\n",
    "      keras.layers.BatchNormalization(),\n",
    "      keras.layers.Dropout(0.5),\n",
    "\n",
    "      # Output layer with Softmax activation\n",
    "      keras.layers.Flatten(), # Flattens the input\n",
    "      keras.layers.Dense(4, activation='softmax') # Output FC layer with softmax activation\n",
    "\n",
    "  ])\n",
    "\n",
    "  # Printing the model summary\n",
    "    model_all_subs.summary()\n",
    "\n",
    "  \n",
    "\n",
    "    model_all_subs.compile(loss='categorical_crossentropy',\n",
    "                 optimizer=cnn_optimizer,\n",
    "                 metrics=['accuracy'])\n",
    "  \n",
    "\n",
    "  # Training and validating the model\n",
    "    model_all_subs_results = model_all_subs.fit(x_train,\n",
    "              y_train,\n",
    "              batch_size=32,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_valid, y_valid), verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on one subjects: 0.5799999833106995\n"
     ]
    }
   ],
   "source": [
    "cnn_score = model_all_subs.evaluate(X_test_sub1, y_test_sub1, verbose=0)\n",
    "print('Test accuracy on one subjects:',cnn_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "WqMPuChAH1va"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on all subjects: 0.6450338363647461\n"
     ]
    }
   ],
   "source": [
    "cnn_score = model_all_subs.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test accuracy on all subjects:',cnn_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 500, 1, 22)\n",
      "(50, 4)\n"
     ]
    }
   ],
   "source": [
    "print (X_test_sub1.shape)\n",
    "print (y_test_sub1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train data based on time periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2115,)\n",
      "(443,)\n"
     ]
    }
   ],
   "source": [
    "X_test = np.load(\"X_test.npy\")\n",
    "y_test = np.load(\"y_test.npy\")\n",
    "person_train_valid = np.load(\"person_train_valid.npy\")\n",
    "X_train_valid = np.load(\"X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"y_train_valid.npy\")\n",
    "person_test = np.load(\"person_test.npy\")\n",
    "y_train_valid -= 769\n",
    "y_test -= 769\n",
    "print(y_train_valid.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== period: 50  ==========\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_36 (Conv2D)          (None, 25, 1, 25)         5525      \n",
      "                                                                 \n",
      " max_pooling2d_36 (MaxPoolin  (None, 13, 1, 25)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_36 (Bat  (None, 13, 1, 25)        100       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 13, 1, 25)         0         \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 13, 1, 50)         12550     \n",
      "                                                                 \n",
      " max_pooling2d_37 (MaxPoolin  (None, 7, 1, 50)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_37 (Bat  (None, 7, 1, 50)         200       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 7, 1, 50)          0         \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 7, 1, 100)         50100     \n",
      "                                                                 \n",
      " max_pooling2d_38 (MaxPoolin  (None, 4, 1, 100)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_38 (Bat  (None, 4, 1, 100)        400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_38 (Dropout)        (None, 4, 1, 100)         0         \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 400)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 4)                 1604      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,479\n",
      "Trainable params: 70,129\n",
      "Non-trainable params: 350\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 1.7406 - accuracy: 0.2830 - val_loss: 1.3814 - val_accuracy: 0.3127\n",
      "Epoch 2/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 1.4285 - accuracy: 0.3223 - val_loss: 1.3555 - val_accuracy: 0.3247\n",
      "Epoch 3/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 1.3703 - accuracy: 0.3427 - val_loss: 1.3450 - val_accuracy: 0.3493\n",
      "Epoch 4/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.3300 - accuracy: 0.3697 - val_loss: 1.3282 - val_accuracy: 0.3620\n",
      "Epoch 5/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.3038 - accuracy: 0.3907 - val_loss: 1.3217 - val_accuracy: 0.3827\n",
      "Epoch 6/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.2842 - accuracy: 0.4020 - val_loss: 1.3013 - val_accuracy: 0.3820\n",
      "Epoch 7/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.2678 - accuracy: 0.4164 - val_loss: 1.3015 - val_accuracy: 0.3900\n",
      "Epoch 8/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.2469 - accuracy: 0.4266 - val_loss: 1.2984 - val_accuracy: 0.3667\n",
      "Epoch 9/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.2278 - accuracy: 0.4414 - val_loss: 1.2829 - val_accuracy: 0.3940\n",
      "Epoch 10/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.2114 - accuracy: 0.4519 - val_loss: 1.2835 - val_accuracy: 0.3973\n",
      "Epoch 11/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.1999 - accuracy: 0.4524 - val_loss: 1.2716 - val_accuracy: 0.3887\n",
      "Epoch 12/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.1974 - accuracy: 0.4654 - val_loss: 1.2641 - val_accuracy: 0.4113\n",
      "Epoch 13/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.1759 - accuracy: 0.4828 - val_loss: 1.2636 - val_accuracy: 0.3993\n",
      "Epoch 14/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.1626 - accuracy: 0.4812 - val_loss: 1.2590 - val_accuracy: 0.3847\n",
      "Epoch 15/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.1631 - accuracy: 0.4836 - val_loss: 1.2822 - val_accuracy: 0.4053\n",
      "Epoch 16/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.1522 - accuracy: 0.4852 - val_loss: 1.2598 - val_accuracy: 0.4173\n",
      "Epoch 17/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.1416 - accuracy: 0.4927 - val_loss: 1.2577 - val_accuracy: 0.4247\n",
      "Epoch 18/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.1260 - accuracy: 0.5098 - val_loss: 1.2650 - val_accuracy: 0.4340\n",
      "Epoch 19/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.1190 - accuracy: 0.5082 - val_loss: 1.2528 - val_accuracy: 0.4387\n",
      "Epoch 20/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.1145 - accuracy: 0.5088 - val_loss: 1.2565 - val_accuracy: 0.4300\n",
      "Epoch 21/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 1.0998 - accuracy: 0.5224 - val_loss: 1.2687 - val_accuracy: 0.4260\n",
      "Epoch 22/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.0924 - accuracy: 0.5277 - val_loss: 1.2764 - val_accuracy: 0.4153\n",
      "Epoch 23/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.0873 - accuracy: 0.5284 - val_loss: 1.2651 - val_accuracy: 0.4387\n",
      "Epoch 24/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.0770 - accuracy: 0.5277 - val_loss: 1.2896 - val_accuracy: 0.4173\n",
      "Epoch 25/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.0672 - accuracy: 0.5444 - val_loss: 1.2752 - val_accuracy: 0.4320\n",
      "Epoch 26/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.0586 - accuracy: 0.5453 - val_loss: 1.3050 - val_accuracy: 0.4193\n",
      "Epoch 27/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.0528 - accuracy: 0.5536 - val_loss: 1.2814 - val_accuracy: 0.4367\n",
      "Epoch 28/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.0410 - accuracy: 0.5573 - val_loss: 1.2706 - val_accuracy: 0.4307\n",
      "Epoch 29/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.0504 - accuracy: 0.5457 - val_loss: 1.2930 - val_accuracy: 0.4280\n",
      "Epoch 30/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.0338 - accuracy: 0.5517 - val_loss: 1.2821 - val_accuracy: 0.4253\n",
      "Epoch 31/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.0193 - accuracy: 0.5698 - val_loss: 1.3203 - val_accuracy: 0.4140\n",
      "Epoch 32/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.0155 - accuracy: 0.5723 - val_loss: 1.3004 - val_accuracy: 0.4280\n",
      "Epoch 33/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.0111 - accuracy: 0.5703 - val_loss: 1.2961 - val_accuracy: 0.4340\n",
      "Epoch 34/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.0136 - accuracy: 0.5677 - val_loss: 1.3022 - val_accuracy: 0.4300\n",
      "Epoch 35/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.0053 - accuracy: 0.5713 - val_loss: 1.3072 - val_accuracy: 0.4260\n",
      "Epoch 36/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.9882 - accuracy: 0.5830 - val_loss: 1.3063 - val_accuracy: 0.4373\n",
      "Epoch 37/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.9883 - accuracy: 0.5856 - val_loss: 1.3014 - val_accuracy: 0.4173\n",
      "Epoch 38/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.9847 - accuracy: 0.5830 - val_loss: 1.3015 - val_accuracy: 0.4340\n",
      "Epoch 39/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.9643 - accuracy: 0.5905 - val_loss: 1.3210 - val_accuracy: 0.4393\n",
      "Epoch 40/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.9602 - accuracy: 0.5960 - val_loss: 1.3140 - val_accuracy: 0.4300\n",
      "Epoch 41/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.9671 - accuracy: 0.5875 - val_loss: 1.3215 - val_accuracy: 0.4427\n",
      "Epoch 42/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.9688 - accuracy: 0.5934 - val_loss: 1.3274 - val_accuracy: 0.4253\n",
      "Epoch 43/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.9562 - accuracy: 0.5974 - val_loss: 1.3323 - val_accuracy: 0.4293\n",
      "Epoch 44/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.9563 - accuracy: 0.5967 - val_loss: 1.3053 - val_accuracy: 0.4413\n",
      "Epoch 45/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.9481 - accuracy: 0.6063 - val_loss: 1.3278 - val_accuracy: 0.4247\n",
      "Epoch 46/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.9363 - accuracy: 0.6088 - val_loss: 1.3448 - val_accuracy: 0.4240\n",
      "Epoch 47/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.9345 - accuracy: 0.6050 - val_loss: 1.3422 - val_accuracy: 0.4373\n",
      "Epoch 48/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.9150 - accuracy: 0.6220 - val_loss: 1.3702 - val_accuracy: 0.4227\n",
      "Epoch 49/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.9311 - accuracy: 0.6076 - val_loss: 1.3268 - val_accuracy: 0.4447\n",
      "Epoch 50/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.9202 - accuracy: 0.6129 - val_loss: 1.3501 - val_accuracy: 0.4367\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.5835 - accuracy: 0.8361\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 1.3471 - accuracy: 0.4216\n",
      "========== period: 100  ==========\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_39 (Conv2D)          (None, 50, 1, 25)         5525      \n",
      "                                                                 \n",
      " max_pooling2d_39 (MaxPoolin  (None, 25, 1, 25)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_39 (Bat  (None, 25, 1, 25)        100       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 25, 1, 25)         0         \n",
      "                                                                 \n",
      " conv2d_40 (Conv2D)          (None, 25, 1, 50)         12550     \n",
      "                                                                 \n",
      " max_pooling2d_40 (MaxPoolin  (None, 13, 1, 50)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_40 (Bat  (None, 13, 1, 50)        200       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 13, 1, 50)         0         \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 13, 1, 100)        50100     \n",
      "                                                                 \n",
      " max_pooling2d_41 (MaxPoolin  (None, 7, 1, 100)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_41 (Bat  (None, 7, 1, 100)        400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 7, 1, 100)         0         \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 700)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 4)                 2804      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 71,679\n",
      "Trainable params: 71,329\n",
      "Non-trainable params: 350\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "218/218 [==============================] - 3s 9ms/step - loss: 1.7919 - accuracy: 0.3009 - val_loss: 1.3462 - val_accuracy: 0.3740\n",
      "Epoch 2/50\n",
      "218/218 [==============================] - 2s 8ms/step - loss: 1.4305 - accuracy: 0.3539 - val_loss: 1.3026 - val_accuracy: 0.3860\n",
      "Epoch 3/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 1.3408 - accuracy: 0.3914 - val_loss: 1.2759 - val_accuracy: 0.4033\n",
      "Epoch 4/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 1.2804 - accuracy: 0.4182 - val_loss: 1.2629 - val_accuracy: 0.3873\n",
      "Epoch 5/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 1.2583 - accuracy: 0.4351 - val_loss: 1.2510 - val_accuracy: 0.4213\n",
      "Epoch 6/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 1.2252 - accuracy: 0.4491 - val_loss: 1.2580 - val_accuracy: 0.4173\n",
      "Epoch 7/50\n",
      "218/218 [==============================] - 2s 10ms/step - loss: 1.1933 - accuracy: 0.4766 - val_loss: 1.2367 - val_accuracy: 0.4473\n",
      "Epoch 8/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 1.1652 - accuracy: 0.4866 - val_loss: 1.2305 - val_accuracy: 0.4353\n",
      "Epoch 9/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 1.1395 - accuracy: 0.4997 - val_loss: 1.2877 - val_accuracy: 0.4207\n",
      "Epoch 10/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 1.1100 - accuracy: 0.5111 - val_loss: 1.2095 - val_accuracy: 0.4487\n",
      "Epoch 11/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 1.0835 - accuracy: 0.5316 - val_loss: 1.1708 - val_accuracy: 0.4907\n",
      "Epoch 12/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 1.0709 - accuracy: 0.5382 - val_loss: 1.1863 - val_accuracy: 0.4847\n",
      "Epoch 13/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 1.0322 - accuracy: 0.5603 - val_loss: 1.1600 - val_accuracy: 0.4960\n",
      "Epoch 14/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 1.0178 - accuracy: 0.5654 - val_loss: 1.1544 - val_accuracy: 0.4807\n",
      "Epoch 15/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 1.0118 - accuracy: 0.5770 - val_loss: 1.1257 - val_accuracy: 0.5073\n",
      "Epoch 16/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 0.9871 - accuracy: 0.5784 - val_loss: 1.1416 - val_accuracy: 0.5000\n",
      "Epoch 17/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 0.9645 - accuracy: 0.5912 - val_loss: 1.1362 - val_accuracy: 0.5007\n",
      "Epoch 18/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 0.9459 - accuracy: 0.5994 - val_loss: 1.1485 - val_accuracy: 0.5080\n",
      "Epoch 19/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 0.9507 - accuracy: 0.6009 - val_loss: 1.1272 - val_accuracy: 0.5307\n",
      "Epoch 20/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 0.9299 - accuracy: 0.6052 - val_loss: 1.1345 - val_accuracy: 0.5260\n",
      "Epoch 21/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 0.9138 - accuracy: 0.6155 - val_loss: 1.1560 - val_accuracy: 0.4940\n",
      "Epoch 22/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 0.9006 - accuracy: 0.6253 - val_loss: 1.1504 - val_accuracy: 0.5013\n",
      "Epoch 23/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 0.8842 - accuracy: 0.6313 - val_loss: 1.1237 - val_accuracy: 0.5267\n",
      "Epoch 24/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 0.8780 - accuracy: 0.6381 - val_loss: 1.1744 - val_accuracy: 0.5120\n",
      "Epoch 25/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 0.8628 - accuracy: 0.6405 - val_loss: 1.1479 - val_accuracy: 0.5120\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218/218 [==============================] - 2s 9ms/step - loss: 0.8571 - accuracy: 0.6421 - val_loss: 1.1351 - val_accuracy: 0.5233\n",
      "Epoch 27/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 0.8435 - accuracy: 0.6516 - val_loss: 1.1642 - val_accuracy: 0.4913\n",
      "Epoch 28/50\n",
      "218/218 [==============================] - 2s 8ms/step - loss: 0.8391 - accuracy: 0.6530 - val_loss: 1.1479 - val_accuracy: 0.5227\n",
      "Epoch 29/50\n",
      "218/218 [==============================] - 2s 8ms/step - loss: 0.8144 - accuracy: 0.6662 - val_loss: 1.1390 - val_accuracy: 0.5287\n",
      "Epoch 30/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 0.8119 - accuracy: 0.6635 - val_loss: 1.1360 - val_accuracy: 0.5173\n",
      "Epoch 31/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 0.8076 - accuracy: 0.6681 - val_loss: 1.2136 - val_accuracy: 0.4967\n",
      "Epoch 32/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 0.8109 - accuracy: 0.6670 - val_loss: 1.1294 - val_accuracy: 0.5467\n",
      "Epoch 33/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 0.7913 - accuracy: 0.6726 - val_loss: 1.1312 - val_accuracy: 0.5313\n",
      "Epoch 34/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 0.7762 - accuracy: 0.6839 - val_loss: 1.1393 - val_accuracy: 0.5307\n",
      "Epoch 35/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 0.7670 - accuracy: 0.6855 - val_loss: 1.1701 - val_accuracy: 0.5173\n",
      "Epoch 36/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 0.7668 - accuracy: 0.6909 - val_loss: 1.1206 - val_accuracy: 0.5440\n",
      "Epoch 37/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 0.7521 - accuracy: 0.6921 - val_loss: 1.1655 - val_accuracy: 0.5327\n",
      "Epoch 38/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 0.7386 - accuracy: 0.6983 - val_loss: 1.1496 - val_accuracy: 0.5253\n",
      "Epoch 39/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 0.7556 - accuracy: 0.6894 - val_loss: 1.1722 - val_accuracy: 0.5153\n",
      "Epoch 40/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 0.7263 - accuracy: 0.7093 - val_loss: 1.1281 - val_accuracy: 0.5320\n",
      "Epoch 41/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 0.7341 - accuracy: 0.7037 - val_loss: 1.1401 - val_accuracy: 0.5333\n",
      "Epoch 42/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 0.7276 - accuracy: 0.7023 - val_loss: 1.1542 - val_accuracy: 0.5247\n",
      "Epoch 43/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 0.7083 - accuracy: 0.7148 - val_loss: 1.1385 - val_accuracy: 0.5427\n",
      "Epoch 44/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 0.7132 - accuracy: 0.7065 - val_loss: 1.2003 - val_accuracy: 0.5220\n",
      "Epoch 45/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 0.7069 - accuracy: 0.7159 - val_loss: 1.1272 - val_accuracy: 0.5267\n",
      "Epoch 46/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 0.7045 - accuracy: 0.7135 - val_loss: 1.1331 - val_accuracy: 0.5427\n",
      "Epoch 47/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 0.7006 - accuracy: 0.7147 - val_loss: 1.1780 - val_accuracy: 0.5333\n",
      "Epoch 48/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 0.6737 - accuracy: 0.7295 - val_loss: 1.1911 - val_accuracy: 0.5180\n",
      "Epoch 49/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 0.6850 - accuracy: 0.7180 - val_loss: 1.1586 - val_accuracy: 0.5240\n",
      "Epoch 50/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 0.6919 - accuracy: 0.7220 - val_loss: 1.1496 - val_accuracy: 0.5433\n",
      "218/218 [==============================] - 1s 2ms/step - loss: 0.3072 - accuracy: 0.9339\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 1.1532 - accuracy: 0.5056\n",
      "========== period: 150  ==========\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_42 (Conv2D)          (None, 75, 1, 25)         5525      \n",
      "                                                                 \n",
      " max_pooling2d_42 (MaxPoolin  (None, 38, 1, 25)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_42 (Bat  (None, 38, 1, 25)        100       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, 38, 1, 25)         0         \n",
      "                                                                 \n",
      " conv2d_43 (Conv2D)          (None, 38, 1, 50)         12550     \n",
      "                                                                 \n",
      " max_pooling2d_43 (MaxPoolin  (None, 19, 1, 50)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_43 (Bat  (None, 19, 1, 50)        200       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 19, 1, 50)         0         \n",
      "                                                                 \n",
      " conv2d_44 (Conv2D)          (None, 19, 1, 100)        50100     \n",
      "                                                                 \n",
      " max_pooling2d_44 (MaxPoolin  (None, 10, 1, 100)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_44 (Bat  (None, 10, 1, 100)       400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_44 (Dropout)        (None, 10, 1, 100)        0         \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 4)                 4004      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 72,879\n",
      "Trainable params: 72,529\n",
      "Non-trainable params: 350\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "218/218 [==============================] - 4s 12ms/step - loss: 1.8289 - accuracy: 0.3167 - val_loss: 1.4980 - val_accuracy: 0.3113\n",
      "Epoch 2/50\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 1.4495 - accuracy: 0.3636 - val_loss: 1.3748 - val_accuracy: 0.3420\n",
      "Epoch 3/50\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 1.3263 - accuracy: 0.4148 - val_loss: 1.3306 - val_accuracy: 0.3500\n",
      "Epoch 4/50\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 1.2634 - accuracy: 0.4342 - val_loss: 1.2841 - val_accuracy: 0.3727\n",
      "Epoch 5/50\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 1.1938 - accuracy: 0.4797 - val_loss: 1.2463 - val_accuracy: 0.4253\n",
      "Epoch 6/50\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 1.1631 - accuracy: 0.4908 - val_loss: 1.2370 - val_accuracy: 0.4353\n",
      "Epoch 7/50\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 1.1228 - accuracy: 0.5102 - val_loss: 1.2529 - val_accuracy: 0.4247\n",
      "Epoch 8/50\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 1.0890 - accuracy: 0.5292 - val_loss: 1.2049 - val_accuracy: 0.4560\n",
      "Epoch 9/50\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 1.0556 - accuracy: 0.5473 - val_loss: 1.1680 - val_accuracy: 0.4773\n",
      "Epoch 10/50\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 1.0200 - accuracy: 0.5644 - val_loss: 1.1865 - val_accuracy: 0.4840\n",
      "Epoch 11/50\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 0.9865 - accuracy: 0.5881 - val_loss: 1.1949 - val_accuracy: 0.4873\n",
      "Epoch 12/50\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 0.9778 - accuracy: 0.5940 - val_loss: 1.1518 - val_accuracy: 0.5027\n",
      "Epoch 13/50\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 0.9569 - accuracy: 0.6007 - val_loss: 1.0945 - val_accuracy: 0.5153\n",
      "Epoch 14/50\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 0.9233 - accuracy: 0.6101 - val_loss: 1.1110 - val_accuracy: 0.5273\n",
      "Epoch 15/50\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 0.8989 - accuracy: 0.6312 - val_loss: 1.0992 - val_accuracy: 0.5247\n",
      "Epoch 16/50\n",
      "218/218 [==============================] - 3s 13ms/step - loss: 0.8932 - accuracy: 0.6330 - val_loss: 1.1076 - val_accuracy: 0.5427\n",
      "Epoch 17/50\n",
      "218/218 [==============================] - 3s 13ms/step - loss: 0.8750 - accuracy: 0.6421 - val_loss: 1.1423 - val_accuracy: 0.5240\n",
      "Epoch 18/50\n",
      "218/218 [==============================] - 3s 13ms/step - loss: 0.8590 - accuracy: 0.6466 - val_loss: 1.0671 - val_accuracy: 0.5440\n",
      "Epoch 19/50\n",
      "218/218 [==============================] - 3s 13ms/step - loss: 0.8437 - accuracy: 0.6569 - val_loss: 1.0596 - val_accuracy: 0.5673\n",
      "Epoch 20/50\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 0.8302 - accuracy: 0.6602 - val_loss: 1.1143 - val_accuracy: 0.5300\n",
      "Epoch 21/50\n",
      "218/218 [==============================] - 3s 13ms/step - loss: 0.8005 - accuracy: 0.6784 - val_loss: 1.1110 - val_accuracy: 0.5480\n",
      "Epoch 22/50\n",
      "218/218 [==============================] - 3s 13ms/step - loss: 0.7925 - accuracy: 0.6869 - val_loss: 1.1008 - val_accuracy: 0.5527\n",
      "Epoch 23/50\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 0.7961 - accuracy: 0.6797 - val_loss: 1.1238 - val_accuracy: 0.5507\n",
      "Epoch 24/50\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 0.7722 - accuracy: 0.6899 - val_loss: 1.1864 - val_accuracy: 0.5193\n",
      "Epoch 25/50\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 0.7577 - accuracy: 0.6963 - val_loss: 1.1103 - val_accuracy: 0.5520\n",
      "Epoch 26/50\n",
      "218/218 [==============================] - 3s 13ms/step - loss: 0.7288 - accuracy: 0.7108 - val_loss: 1.1332 - val_accuracy: 0.5340\n",
      "Epoch 27/50\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 0.7312 - accuracy: 0.7072 - val_loss: 1.1604 - val_accuracy: 0.5207\n",
      "Epoch 28/50\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 0.7217 - accuracy: 0.7115 - val_loss: 1.1247 - val_accuracy: 0.5280\n",
      "Epoch 29/50\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 0.7126 - accuracy: 0.7157 - val_loss: 1.1080 - val_accuracy: 0.5500\n",
      "Epoch 30/50\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 0.6771 - accuracy: 0.7295 - val_loss: 1.1366 - val_accuracy: 0.5227\n",
      "Epoch 31/50\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 0.6776 - accuracy: 0.7259 - val_loss: 1.1549 - val_accuracy: 0.5547\n",
      "Epoch 32/50\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 0.6650 - accuracy: 0.7381 - val_loss: 1.1231 - val_accuracy: 0.5400\n",
      "Epoch 33/50\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 0.6552 - accuracy: 0.7414 - val_loss: 1.1712 - val_accuracy: 0.5507\n",
      "Epoch 34/50\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 0.6671 - accuracy: 0.7310 - val_loss: 1.1484 - val_accuracy: 0.5460\n",
      "Epoch 35/50\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 0.6633 - accuracy: 0.7392 - val_loss: 1.1225 - val_accuracy: 0.5520\n",
      "Epoch 36/50\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 0.6486 - accuracy: 0.7407 - val_loss: 1.1519 - val_accuracy: 0.5533\n",
      "Epoch 37/50\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 0.6166 - accuracy: 0.7542 - val_loss: 1.1488 - val_accuracy: 0.5433\n",
      "Epoch 38/50\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 0.6255 - accuracy: 0.7545 - val_loss: 1.1284 - val_accuracy: 0.5593\n",
      "Epoch 39/50\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 0.6318 - accuracy: 0.7530 - val_loss: 1.1450 - val_accuracy: 0.5560\n",
      "Epoch 40/50\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 0.6261 - accuracy: 0.7530 - val_loss: 1.1350 - val_accuracy: 0.5567\n",
      "Epoch 41/50\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 0.6230 - accuracy: 0.7601 - val_loss: 1.1292 - val_accuracy: 0.5553\n",
      "Epoch 42/50\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 0.5942 - accuracy: 0.7718 - val_loss: 1.1699 - val_accuracy: 0.5520\n",
      "Epoch 43/50\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 0.6106 - accuracy: 0.7599 - val_loss: 1.1542 - val_accuracy: 0.5620\n",
      "Epoch 44/50\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 0.5968 - accuracy: 0.7648 - val_loss: 1.1850 - val_accuracy: 0.5600\n",
      "Epoch 45/50\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 0.5923 - accuracy: 0.7701 - val_loss: 1.1884 - val_accuracy: 0.5547\n",
      "Epoch 46/50\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 0.5860 - accuracy: 0.7701 - val_loss: 1.2013 - val_accuracy: 0.5500\n",
      "Epoch 47/50\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 0.5788 - accuracy: 0.7726 - val_loss: 1.1332 - val_accuracy: 0.5527\n",
      "Epoch 48/50\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 0.5741 - accuracy: 0.7744 - val_loss: 1.1683 - val_accuracy: 0.5407\n",
      "Epoch 49/50\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 0.5689 - accuracy: 0.7803 - val_loss: 1.1753 - val_accuracy: 0.5720\n",
      "Epoch 50/50\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 0.5461 - accuracy: 0.7917 - val_loss: 1.1822 - val_accuracy: 0.5673\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.1771 - accuracy: 0.9740\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 1.0387 - accuracy: 0.5841\n",
      "========== period: 200  ==========\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_45 (Conv2D)          (None, 100, 1, 25)        5525      \n",
      "                                                                 \n",
      " max_pooling2d_45 (MaxPoolin  (None, 50, 1, 25)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_45 (Bat  (None, 50, 1, 25)        100       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_45 (Dropout)        (None, 50, 1, 25)         0         \n",
      "                                                                 \n",
      " conv2d_46 (Conv2D)          (None, 50, 1, 50)         12550     \n",
      "                                                                 \n",
      " max_pooling2d_46 (MaxPoolin  (None, 25, 1, 50)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_46 (Bat  (None, 25, 1, 50)        200       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_46 (Dropout)        (None, 25, 1, 50)         0         \n",
      "                                                                 \n",
      " conv2d_47 (Conv2D)          (None, 25, 1, 100)        50100     \n",
      "                                                                 \n",
      " max_pooling2d_47 (MaxPoolin  (None, 13, 1, 100)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_47 (Bat  (None, 13, 1, 100)       400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_47 (Dropout)        (None, 13, 1, 100)        0         \n",
      "                                                                 \n",
      " flatten_15 (Flatten)        (None, 1300)              0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 4)                 5204      \n",
      "                                                                 \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 74,079\n",
      "Trainable params: 73,729\n",
      "Non-trainable params: 350\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "218/218 [==============================] - 4s 16ms/step - loss: 1.9295 - accuracy: 0.3111 - val_loss: 1.3886 - val_accuracy: 0.3127\n",
      "Epoch 2/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 1.4709 - accuracy: 0.3672 - val_loss: 1.2869 - val_accuracy: 0.3973\n",
      "Epoch 3/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 1.3142 - accuracy: 0.4277 - val_loss: 1.2158 - val_accuracy: 0.4307\n",
      "Epoch 4/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 1.2380 - accuracy: 0.4566 - val_loss: 1.2234 - val_accuracy: 0.4513\n",
      "Epoch 5/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 1.1686 - accuracy: 0.4928 - val_loss: 1.1503 - val_accuracy: 0.4773\n",
      "Epoch 6/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 1.1069 - accuracy: 0.5234 - val_loss: 1.1144 - val_accuracy: 0.5020\n",
      "Epoch 7/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 1.0534 - accuracy: 0.5491 - val_loss: 1.0883 - val_accuracy: 0.5013\n",
      "Epoch 8/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 1.0118 - accuracy: 0.5716 - val_loss: 1.0502 - val_accuracy: 0.5527\n",
      "Epoch 9/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 0.9760 - accuracy: 0.5958 - val_loss: 1.0269 - val_accuracy: 0.5527\n",
      "Epoch 10/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 0.9588 - accuracy: 0.5981 - val_loss: 1.0391 - val_accuracy: 0.5533\n",
      "Epoch 11/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 0.9223 - accuracy: 0.6147 - val_loss: 1.0530 - val_accuracy: 0.5493\n",
      "Epoch 12/50\n",
      "218/218 [==============================] - 3s 16ms/step - loss: 0.8994 - accuracy: 0.6302 - val_loss: 0.9771 - val_accuracy: 0.5993\n",
      "Epoch 13/50\n",
      "218/218 [==============================] - 3s 16ms/step - loss: 0.8747 - accuracy: 0.6401 - val_loss: 0.9790 - val_accuracy: 0.6067\n",
      "Epoch 14/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 0.8299 - accuracy: 0.6621 - val_loss: 1.0088 - val_accuracy: 0.5613\n",
      "Epoch 15/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 0.7960 - accuracy: 0.6805 - val_loss: 1.0368 - val_accuracy: 0.5660\n",
      "Epoch 16/50\n",
      "218/218 [==============================] - 3s 16ms/step - loss: 0.8016 - accuracy: 0.6789 - val_loss: 0.9515 - val_accuracy: 0.5980\n",
      "Epoch 17/50\n",
      "218/218 [==============================] - 3s 16ms/step - loss: 0.7773 - accuracy: 0.6809 - val_loss: 0.9800 - val_accuracy: 0.5747\n",
      "Epoch 18/50\n",
      "218/218 [==============================] - 3s 16ms/step - loss: 0.7750 - accuracy: 0.6889 - val_loss: 0.9451 - val_accuracy: 0.6173\n",
      "Epoch 19/50\n",
      "218/218 [==============================] - 3s 16ms/step - loss: 0.7304 - accuracy: 0.7092 - val_loss: 0.9311 - val_accuracy: 0.6200\n",
      "Epoch 20/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 0.7242 - accuracy: 0.7080 - val_loss: 0.9776 - val_accuracy: 0.5833\n",
      "Epoch 21/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 0.7139 - accuracy: 0.7177 - val_loss: 0.9404 - val_accuracy: 0.6080\n",
      "Epoch 22/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 0.6910 - accuracy: 0.7274 - val_loss: 0.9128 - val_accuracy: 0.6453\n",
      "Epoch 23/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 0.6661 - accuracy: 0.7375 - val_loss: 0.9106 - val_accuracy: 0.6307\n",
      "Epoch 24/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 0.6641 - accuracy: 0.7332 - val_loss: 0.9481 - val_accuracy: 0.6200\n",
      "Epoch 25/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 0.6399 - accuracy: 0.7474 - val_loss: 0.9816 - val_accuracy: 0.6133\n",
      "Epoch 26/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 0.6333 - accuracy: 0.7562 - val_loss: 0.9332 - val_accuracy: 0.6347\n",
      "Epoch 27/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 0.6040 - accuracy: 0.7579 - val_loss: 0.9387 - val_accuracy: 0.6313\n",
      "Epoch 28/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 0.5976 - accuracy: 0.7631 - val_loss: 0.9513 - val_accuracy: 0.6380\n",
      "Epoch 29/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 0.5987 - accuracy: 0.7647 - val_loss: 0.9475 - val_accuracy: 0.6427\n",
      "Epoch 30/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 0.5709 - accuracy: 0.7739 - val_loss: 0.9661 - val_accuracy: 0.6287\n",
      "Epoch 31/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 0.5688 - accuracy: 0.7776 - val_loss: 0.9535 - val_accuracy: 0.6360\n",
      "Epoch 32/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 0.5789 - accuracy: 0.7700 - val_loss: 0.9951 - val_accuracy: 0.6253\n",
      "Epoch 33/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 0.5644 - accuracy: 0.7833 - val_loss: 0.9443 - val_accuracy: 0.6367\n",
      "Epoch 34/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 0.5547 - accuracy: 0.7826 - val_loss: 0.9473 - val_accuracy: 0.6453\n",
      "Epoch 35/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 0.5303 - accuracy: 0.7892 - val_loss: 0.9297 - val_accuracy: 0.6473\n",
      "Epoch 36/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 0.5342 - accuracy: 0.7932 - val_loss: 0.9792 - val_accuracy: 0.6253\n",
      "Epoch 37/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 0.5297 - accuracy: 0.7950 - val_loss: 0.9176 - val_accuracy: 0.6713\n",
      "Epoch 38/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 0.5309 - accuracy: 0.7968 - val_loss: 0.9220 - val_accuracy: 0.6507\n",
      "Epoch 39/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 0.5164 - accuracy: 0.8013 - val_loss: 0.9885 - val_accuracy: 0.6347\n",
      "Epoch 40/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 0.5104 - accuracy: 0.8016 - val_loss: 0.9680 - val_accuracy: 0.6460\n",
      "Epoch 41/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 0.5016 - accuracy: 0.8017 - val_loss: 0.9174 - val_accuracy: 0.6467\n",
      "Epoch 42/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 0.4954 - accuracy: 0.8092 - val_loss: 0.9343 - val_accuracy: 0.6553\n",
      "Epoch 43/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 0.4972 - accuracy: 0.8060 - val_loss: 0.9553 - val_accuracy: 0.6413\n",
      "Epoch 44/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 0.4832 - accuracy: 0.8145 - val_loss: 0.9455 - val_accuracy: 0.6400\n",
      "Epoch 45/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 0.4751 - accuracy: 0.8164 - val_loss: 0.9353 - val_accuracy: 0.6520\n",
      "Epoch 46/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 0.4923 - accuracy: 0.8111 - val_loss: 0.9671 - val_accuracy: 0.6533\n",
      "Epoch 47/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 0.4760 - accuracy: 0.8195 - val_loss: 0.9393 - val_accuracy: 0.6660\n",
      "Epoch 48/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 0.4429 - accuracy: 0.8310 - val_loss: 0.9143 - val_accuracy: 0.6793\n",
      "Epoch 49/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 0.4501 - accuracy: 0.8259 - val_loss: 0.9460 - val_accuracy: 0.6507\n",
      "Epoch 50/50\n",
      "218/218 [==============================] - 3s 16ms/step - loss: 0.4681 - accuracy: 0.8228 - val_loss: 0.9600 - val_accuracy: 0.6413\n",
      "218/218 [==============================] - 1s 4ms/step - loss: 0.1113 - accuracy: 0.9871\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0001 - accuracy: 0.6146\n",
      "========== period: 250  ==========\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_48 (Conv2D)          (None, 125, 1, 25)        5525      \n",
      "                                                                 \n",
      " max_pooling2d_48 (MaxPoolin  (None, 63, 1, 25)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_48 (Bat  (None, 63, 1, 25)        100       \n",
      " chNormalization)                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " dropout_48 (Dropout)        (None, 63, 1, 25)         0         \n",
      "                                                                 \n",
      " conv2d_49 (Conv2D)          (None, 63, 1, 50)         12550     \n",
      "                                                                 \n",
      " max_pooling2d_49 (MaxPoolin  (None, 32, 1, 50)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_49 (Bat  (None, 32, 1, 50)        200       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 32, 1, 50)         0         \n",
      "                                                                 \n",
      " conv2d_50 (Conv2D)          (None, 32, 1, 100)        50100     \n",
      "                                                                 \n",
      " max_pooling2d_50 (MaxPoolin  (None, 16, 1, 100)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_50 (Bat  (None, 16, 1, 100)       400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_50 (Dropout)        (None, 16, 1, 100)        0         \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 4)                 6404      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 75,279\n",
      "Trainable params: 74,929\n",
      "Non-trainable params: 350\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "218/218 [==============================] - 5s 20ms/step - loss: 1.9856 - accuracy: 0.3109 - val_loss: 1.4152 - val_accuracy: 0.3813\n",
      "Epoch 2/50\n",
      "218/218 [==============================] - 4s 19ms/step - loss: 1.4718 - accuracy: 0.3973 - val_loss: 1.2802 - val_accuracy: 0.4107\n",
      "Epoch 3/50\n",
      "218/218 [==============================] - 4s 19ms/step - loss: 1.2764 - accuracy: 0.4629 - val_loss: 1.2419 - val_accuracy: 0.4093\n",
      "Epoch 4/50\n",
      "218/218 [==============================] - 4s 19ms/step - loss: 1.1456 - accuracy: 0.5149 - val_loss: 1.1971 - val_accuracy: 0.4740\n",
      "Epoch 5/50\n",
      "218/218 [==============================] - 4s 19ms/step - loss: 1.0718 - accuracy: 0.5464 - val_loss: 1.1371 - val_accuracy: 0.5060\n",
      "Epoch 6/50\n",
      "218/218 [==============================] - 4s 19ms/step - loss: 1.0152 - accuracy: 0.5747 - val_loss: 1.1238 - val_accuracy: 0.4853\n",
      "Epoch 7/50\n",
      "218/218 [==============================] - 4s 19ms/step - loss: 0.9524 - accuracy: 0.6083 - val_loss: 1.1175 - val_accuracy: 0.5100\n",
      "Epoch 8/50\n",
      "218/218 [==============================] - 4s 19ms/step - loss: 0.9107 - accuracy: 0.6227 - val_loss: 1.0750 - val_accuracy: 0.5253\n",
      "Epoch 9/50\n",
      "218/218 [==============================] - 4s 19ms/step - loss: 0.8765 - accuracy: 0.6437 - val_loss: 1.0748 - val_accuracy: 0.5373\n",
      "Epoch 10/50\n",
      "218/218 [==============================] - 4s 19ms/step - loss: 0.8509 - accuracy: 0.6578 - val_loss: 1.0112 - val_accuracy: 0.5527\n",
      "Epoch 11/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 0.8046 - accuracy: 0.6730 - val_loss: 1.1044 - val_accuracy: 0.5173\n",
      "Epoch 12/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 0.7716 - accuracy: 0.6885 - val_loss: 1.0108 - val_accuracy: 0.5873\n",
      "Epoch 13/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 0.7487 - accuracy: 0.7045 - val_loss: 1.0140 - val_accuracy: 0.5433\n",
      "Epoch 14/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 0.7229 - accuracy: 0.7105 - val_loss: 1.0475 - val_accuracy: 0.5553\n",
      "Epoch 15/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 0.7131 - accuracy: 0.7136 - val_loss: 1.0213 - val_accuracy: 0.5480\n",
      "Epoch 16/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 0.6950 - accuracy: 0.7233 - val_loss: 0.9998 - val_accuracy: 0.5593\n",
      "Epoch 17/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 0.6822 - accuracy: 0.7283 - val_loss: 0.9757 - val_accuracy: 0.5653\n",
      "Epoch 18/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 0.6342 - accuracy: 0.7499 - val_loss: 1.0095 - val_accuracy: 0.5720\n",
      "Epoch 19/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 0.6424 - accuracy: 0.7460 - val_loss: 0.9902 - val_accuracy: 0.5873\n",
      "Epoch 20/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 0.6116 - accuracy: 0.7611 - val_loss: 0.9527 - val_accuracy: 0.6033\n",
      "Epoch 21/50\n",
      "218/218 [==============================] - 4s 19ms/step - loss: 0.6046 - accuracy: 0.7566 - val_loss: 0.9854 - val_accuracy: 0.5827\n",
      "Epoch 22/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 0.5805 - accuracy: 0.7726 - val_loss: 0.9569 - val_accuracy: 0.5813\n",
      "Epoch 23/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 0.5620 - accuracy: 0.7760 - val_loss: 0.9984 - val_accuracy: 0.5980\n",
      "Epoch 24/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 0.5616 - accuracy: 0.7810 - val_loss: 0.9458 - val_accuracy: 0.6220\n",
      "Epoch 25/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 0.5425 - accuracy: 0.7888 - val_loss: 0.9725 - val_accuracy: 0.6140\n",
      "Epoch 26/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 0.5414 - accuracy: 0.7920 - val_loss: 0.9901 - val_accuracy: 0.6033\n",
      "Epoch 27/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 0.5316 - accuracy: 0.7947 - val_loss: 0.9793 - val_accuracy: 0.6080\n",
      "Epoch 28/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 0.5156 - accuracy: 0.8013 - val_loss: 0.9850 - val_accuracy: 0.6027\n",
      "Epoch 29/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 0.5022 - accuracy: 0.8039 - val_loss: 0.9715 - val_accuracy: 0.6320\n",
      "Epoch 30/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 0.5086 - accuracy: 0.8010 - val_loss: 1.0128 - val_accuracy: 0.5887\n",
      "Epoch 31/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 0.4999 - accuracy: 0.8037 - val_loss: 1.0048 - val_accuracy: 0.6167\n",
      "Epoch 32/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 0.4780 - accuracy: 0.8121 - val_loss: 0.9562 - val_accuracy: 0.6360\n",
      "Epoch 33/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 0.4698 - accuracy: 0.8162 - val_loss: 0.9697 - val_accuracy: 0.6273\n",
      "Epoch 34/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 0.4590 - accuracy: 0.8244 - val_loss: 0.9430 - val_accuracy: 0.6400\n",
      "Epoch 35/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 0.4549 - accuracy: 0.8240 - val_loss: 0.9870 - val_accuracy: 0.6240\n",
      "Epoch 36/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 0.4672 - accuracy: 0.8191 - val_loss: 0.9666 - val_accuracy: 0.6307\n",
      "Epoch 37/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 0.4387 - accuracy: 0.8295 - val_loss: 0.9806 - val_accuracy: 0.6307\n",
      "Epoch 38/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 0.4306 - accuracy: 0.8365 - val_loss: 0.9468 - val_accuracy: 0.6320\n",
      "Epoch 39/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 0.4261 - accuracy: 0.8382 - val_loss: 0.9805 - val_accuracy: 0.6293\n",
      "Epoch 40/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 0.4173 - accuracy: 0.8394 - val_loss: 0.9702 - val_accuracy: 0.6300\n",
      "Epoch 41/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 0.4251 - accuracy: 0.8361 - val_loss: 1.0324 - val_accuracy: 0.6180\n",
      "Epoch 42/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 0.4159 - accuracy: 0.8418 - val_loss: 0.9928 - val_accuracy: 0.6260\n",
      "Epoch 43/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 0.4114 - accuracy: 0.8402 - val_loss: 0.9753 - val_accuracy: 0.6213\n",
      "Epoch 44/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 0.4159 - accuracy: 0.8415 - val_loss: 0.9441 - val_accuracy: 0.6433\n",
      "Epoch 45/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 0.4125 - accuracy: 0.8435 - val_loss: 0.9967 - val_accuracy: 0.6313\n",
      "Epoch 46/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 0.3963 - accuracy: 0.8513 - val_loss: 0.9801 - val_accuracy: 0.6447\n",
      "Epoch 47/50\n",
      "218/218 [==============================] - 4s 19ms/step - loss: 0.3825 - accuracy: 0.8540 - val_loss: 0.9518 - val_accuracy: 0.6487\n",
      "Epoch 48/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 0.4045 - accuracy: 0.8484 - val_loss: 0.9464 - val_accuracy: 0.6273\n",
      "Epoch 49/50\n",
      "218/218 [==============================] - 4s 19ms/step - loss: 0.3794 - accuracy: 0.8578 - val_loss: 1.0142 - val_accuracy: 0.6233\n",
      "Epoch 50/50\n",
      "218/218 [==============================] - 4s 19ms/step - loss: 0.3849 - accuracy: 0.8586 - val_loss: 0.9905 - val_accuracy: 0.6420\n",
      "218/218 [==============================] - 1s 5ms/step - loss: 0.0537 - accuracy: 0.9964\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0150 - accuracy: 0.6422\n",
      "========== period: 300  ==========\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_51 (Conv2D)          (None, 150, 1, 25)        5525      \n",
      "                                                                 \n",
      " max_pooling2d_51 (MaxPoolin  (None, 75, 1, 25)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_51 (Bat  (None, 75, 1, 25)        100       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_51 (Dropout)        (None, 75, 1, 25)         0         \n",
      "                                                                 \n",
      " conv2d_52 (Conv2D)          (None, 75, 1, 50)         12550     \n",
      "                                                                 \n",
      " max_pooling2d_52 (MaxPoolin  (None, 38, 1, 50)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_52 (Bat  (None, 38, 1, 50)        200       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_52 (Dropout)        (None, 38, 1, 50)         0         \n",
      "                                                                 \n",
      " conv2d_53 (Conv2D)          (None, 38, 1, 100)        50100     \n",
      "                                                                 \n",
      " max_pooling2d_53 (MaxPoolin  (None, 19, 1, 100)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_53 (Bat  (None, 19, 1, 100)       400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_53 (Dropout)        (None, 19, 1, 100)        0         \n",
      "                                                                 \n",
      " flatten_17 (Flatten)        (None, 1900)              0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 4)                 7604      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 76,479\n",
      "Trainable params: 76,129\n",
      "Non-trainable params: 350\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "218/218 [==============================] - 5s 20ms/step - loss: 2.0601 - accuracy: 0.3378 - val_loss: 1.5632 - val_accuracy: 0.3900\n",
      "Epoch 2/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 1.4631 - accuracy: 0.4349 - val_loss: 1.4336 - val_accuracy: 0.3480\n",
      "Epoch 3/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 1.2399 - accuracy: 0.4884 - val_loss: 1.2398 - val_accuracy: 0.4253\n",
      "Epoch 4/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 1.1242 - accuracy: 0.5302 - val_loss: 1.1597 - val_accuracy: 0.4960\n",
      "Epoch 5/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 1.0405 - accuracy: 0.5672 - val_loss: 1.1074 - val_accuracy: 0.4940\n",
      "Epoch 6/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.9790 - accuracy: 0.6023 - val_loss: 1.0640 - val_accuracy: 0.5507\n",
      "Epoch 7/50\n",
      "218/218 [==============================] - 5s 22ms/step - loss: 0.9002 - accuracy: 0.6286 - val_loss: 1.0158 - val_accuracy: 0.5740\n",
      "Epoch 8/50\n",
      "218/218 [==============================] - 5s 22ms/step - loss: 0.8685 - accuracy: 0.6532 - val_loss: 1.0928 - val_accuracy: 0.5600\n",
      "Epoch 9/50\n",
      "218/218 [==============================] - 5s 22ms/step - loss: 0.8283 - accuracy: 0.6670 - val_loss: 1.0424 - val_accuracy: 0.5473\n",
      "Epoch 10/50\n",
      "218/218 [==============================] - 5s 22ms/step - loss: 0.8021 - accuracy: 0.6802 - val_loss: 0.9900 - val_accuracy: 0.5773\n",
      "Epoch 11/50\n",
      "218/218 [==============================] - 5s 22ms/step - loss: 0.7809 - accuracy: 0.6846 - val_loss: 1.0038 - val_accuracy: 0.5747\n",
      "Epoch 12/50\n",
      "218/218 [==============================] - 5s 22ms/step - loss: 0.7297 - accuracy: 0.7020 - val_loss: 1.0335 - val_accuracy: 0.5467\n",
      "Epoch 13/50\n",
      "218/218 [==============================] - 5s 22ms/step - loss: 0.7221 - accuracy: 0.7141 - val_loss: 1.0026 - val_accuracy: 0.5833\n",
      "Epoch 14/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.6886 - accuracy: 0.7201 - val_loss: 0.9548 - val_accuracy: 0.5887\n",
      "Epoch 15/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.6953 - accuracy: 0.7290 - val_loss: 1.0429 - val_accuracy: 0.5833\n",
      "Epoch 16/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.6486 - accuracy: 0.7476 - val_loss: 0.9894 - val_accuracy: 0.5860\n",
      "Epoch 17/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.6277 - accuracy: 0.7507 - val_loss: 0.9861 - val_accuracy: 0.5927\n",
      "Epoch 18/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.6043 - accuracy: 0.7638 - val_loss: 0.9639 - val_accuracy: 0.5907\n",
      "Epoch 19/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.6003 - accuracy: 0.7675 - val_loss: 0.9695 - val_accuracy: 0.6027\n",
      "Epoch 20/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.5878 - accuracy: 0.7760 - val_loss: 0.9420 - val_accuracy: 0.6287\n",
      "Epoch 21/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.5621 - accuracy: 0.7783 - val_loss: 0.9563 - val_accuracy: 0.6347\n",
      "Epoch 22/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.5379 - accuracy: 0.7876 - val_loss: 1.0004 - val_accuracy: 0.5940\n",
      "Epoch 23/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.5409 - accuracy: 0.7897 - val_loss: 1.0285 - val_accuracy: 0.5927\n",
      "Epoch 24/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.5310 - accuracy: 0.7951 - val_loss: 0.9861 - val_accuracy: 0.6060\n",
      "Epoch 25/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.5030 - accuracy: 0.8042 - val_loss: 1.0203 - val_accuracy: 0.5907\n",
      "Epoch 26/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.4846 - accuracy: 0.8161 - val_loss: 1.0271 - val_accuracy: 0.6127\n",
      "Epoch 27/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.4796 - accuracy: 0.8138 - val_loss: 1.0264 - val_accuracy: 0.6240\n",
      "Epoch 28/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.4891 - accuracy: 0.8085 - val_loss: 1.0245 - val_accuracy: 0.6207\n",
      "Epoch 29/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.4660 - accuracy: 0.8185 - val_loss: 0.9785 - val_accuracy: 0.6387\n",
      "Epoch 30/50\n",
      "218/218 [==============================] - 5s 22ms/step - loss: 0.4599 - accuracy: 0.8218 - val_loss: 0.9864 - val_accuracy: 0.6493\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218/218 [==============================] - 5s 21ms/step - loss: 0.4409 - accuracy: 0.8305 - val_loss: 0.9877 - val_accuracy: 0.6293\n",
      "Epoch 32/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.4324 - accuracy: 0.8341 - val_loss: 1.0211 - val_accuracy: 0.6273\n",
      "Epoch 33/50\n",
      "218/218 [==============================] - 5s 22ms/step - loss: 0.4404 - accuracy: 0.8260 - val_loss: 0.9947 - val_accuracy: 0.6200\n",
      "Epoch 34/50\n",
      "218/218 [==============================] - 5s 22ms/step - loss: 0.4326 - accuracy: 0.8376 - val_loss: 1.0282 - val_accuracy: 0.6193\n",
      "Epoch 35/50\n",
      "218/218 [==============================] - 5s 22ms/step - loss: 0.4166 - accuracy: 0.8417 - val_loss: 1.0311 - val_accuracy: 0.6200\n",
      "Epoch 36/50\n",
      "218/218 [==============================] - 5s 22ms/step - loss: 0.4257 - accuracy: 0.8437 - val_loss: 1.0219 - val_accuracy: 0.6267\n",
      "Epoch 37/50\n",
      "218/218 [==============================] - 5s 22ms/step - loss: 0.4140 - accuracy: 0.8389 - val_loss: 0.9945 - val_accuracy: 0.6493\n",
      "Epoch 38/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.3936 - accuracy: 0.8474 - val_loss: 1.0094 - val_accuracy: 0.6353\n",
      "Epoch 39/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.3787 - accuracy: 0.8570 - val_loss: 1.0526 - val_accuracy: 0.6353\n",
      "Epoch 40/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.3974 - accuracy: 0.8444 - val_loss: 1.0628 - val_accuracy: 0.6267\n",
      "Epoch 41/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.3870 - accuracy: 0.8503 - val_loss: 0.9961 - val_accuracy: 0.6593\n",
      "Epoch 42/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.3848 - accuracy: 0.8503 - val_loss: 1.0528 - val_accuracy: 0.6380\n",
      "Epoch 43/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.3738 - accuracy: 0.8586 - val_loss: 1.0064 - val_accuracy: 0.6487\n",
      "Epoch 44/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.3683 - accuracy: 0.8579 - val_loss: 1.0755 - val_accuracy: 0.6153\n",
      "Epoch 45/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.3751 - accuracy: 0.8580 - val_loss: 1.0793 - val_accuracy: 0.6167\n",
      "Epoch 46/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.3627 - accuracy: 0.8586 - val_loss: 0.9731 - val_accuracy: 0.6607\n",
      "Epoch 47/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.3636 - accuracy: 0.8603 - val_loss: 1.0312 - val_accuracy: 0.6487\n",
      "Epoch 48/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.3472 - accuracy: 0.8713 - val_loss: 1.0137 - val_accuracy: 0.6453\n",
      "Epoch 49/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.3503 - accuracy: 0.8667 - val_loss: 0.9957 - val_accuracy: 0.6487\n",
      "Epoch 50/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.3574 - accuracy: 0.8667 - val_loss: 1.0036 - val_accuracy: 0.6527\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.0454 - accuracy: 0.9983\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.9902 - accuracy: 0.6653\n",
      "========== period: 350  ==========\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_54 (Conv2D)          (None, 175, 1, 25)        5525      \n",
      "                                                                 \n",
      " max_pooling2d_54 (MaxPoolin  (None, 88, 1, 25)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_54 (Bat  (None, 88, 1, 25)        100       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_54 (Dropout)        (None, 88, 1, 25)         0         \n",
      "                                                                 \n",
      " conv2d_55 (Conv2D)          (None, 88, 1, 50)         12550     \n",
      "                                                                 \n",
      " max_pooling2d_55 (MaxPoolin  (None, 44, 1, 50)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_55 (Bat  (None, 44, 1, 50)        200       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_55 (Dropout)        (None, 44, 1, 50)         0         \n",
      "                                                                 \n",
      " conv2d_56 (Conv2D)          (None, 44, 1, 100)        50100     \n",
      "                                                                 \n",
      " max_pooling2d_56 (MaxPoolin  (None, 22, 1, 100)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_56 (Bat  (None, 22, 1, 100)       400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_56 (Dropout)        (None, 22, 1, 100)        0         \n",
      "                                                                 \n",
      " flatten_18 (Flatten)        (None, 2200)              0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 4)                 8804      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77,679\n",
      "Trainable params: 77,329\n",
      "Non-trainable params: 350\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 2.0490 - accuracy: 0.3555 - val_loss: 1.5483 - val_accuracy: 0.3853\n",
      "Epoch 2/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 1.4542 - accuracy: 0.4374 - val_loss: 1.2998 - val_accuracy: 0.4267\n",
      "Epoch 3/50\n",
      "218/218 [==============================] - 5s 22ms/step - loss: 1.1933 - accuracy: 0.5224 - val_loss: 1.2279 - val_accuracy: 0.4787\n",
      "Epoch 4/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 1.0534 - accuracy: 0.5698 - val_loss: 1.1235 - val_accuracy: 0.5453\n",
      "Epoch 5/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.9798 - accuracy: 0.6119 - val_loss: 1.0824 - val_accuracy: 0.5400\n",
      "Epoch 6/50\n",
      "218/218 [==============================] - 5s 24ms/step - loss: 0.9170 - accuracy: 0.6257 - val_loss: 1.0861 - val_accuracy: 0.5820\n",
      "Epoch 7/50\n",
      "218/218 [==============================] - 5s 24ms/step - loss: 0.8588 - accuracy: 0.6550 - val_loss: 1.0490 - val_accuracy: 0.5907\n",
      "Epoch 8/50\n",
      "218/218 [==============================] - 5s 24ms/step - loss: 0.8094 - accuracy: 0.6736 - val_loss: 0.9805 - val_accuracy: 0.6220\n",
      "Epoch 9/50\n",
      "218/218 [==============================] - 5s 24ms/step - loss: 0.7649 - accuracy: 0.6901 - val_loss: 0.9857 - val_accuracy: 0.6267\n",
      "Epoch 10/50\n",
      "218/218 [==============================] - 5s 24ms/step - loss: 0.7457 - accuracy: 0.7026 - val_loss: 0.9641 - val_accuracy: 0.6367\n",
      "Epoch 11/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.7167 - accuracy: 0.7177 - val_loss: 0.9404 - val_accuracy: 0.6480\n",
      "Epoch 12/50\n",
      "218/218 [==============================] - 5s 24ms/step - loss: 0.6709 - accuracy: 0.7359 - val_loss: 0.9532 - val_accuracy: 0.6427\n",
      "Epoch 13/50\n",
      "218/218 [==============================] - 5s 24ms/step - loss: 0.6603 - accuracy: 0.7405 - val_loss: 0.9458 - val_accuracy: 0.6533\n",
      "Epoch 14/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.6199 - accuracy: 0.7583 - val_loss: 0.9556 - val_accuracy: 0.6547\n",
      "Epoch 15/50\n",
      "218/218 [==============================] - 5s 24ms/step - loss: 0.6323 - accuracy: 0.7516 - val_loss: 0.8994 - val_accuracy: 0.6453\n",
      "Epoch 16/50\n",
      "218/218 [==============================] - 5s 24ms/step - loss: 0.5977 - accuracy: 0.7690 - val_loss: 0.9422 - val_accuracy: 0.6580\n",
      "Epoch 17/50\n",
      "218/218 [==============================] - 5s 24ms/step - loss: 0.5642 - accuracy: 0.7770 - val_loss: 0.9086 - val_accuracy: 0.6527\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218/218 [==============================] - 5s 23ms/step - loss: 0.5608 - accuracy: 0.7799 - val_loss: 0.9114 - val_accuracy: 0.6520\n",
      "Epoch 19/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.5298 - accuracy: 0.7905 - val_loss: 0.9403 - val_accuracy: 0.6587\n",
      "Epoch 20/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.5203 - accuracy: 0.7978 - val_loss: 0.9411 - val_accuracy: 0.6473\n",
      "Epoch 21/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.5037 - accuracy: 0.7987 - val_loss: 0.9107 - val_accuracy: 0.6493\n",
      "Epoch 22/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.4993 - accuracy: 0.8096 - val_loss: 0.9102 - val_accuracy: 0.6587\n",
      "Epoch 23/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.4769 - accuracy: 0.8131 - val_loss: 0.8923 - val_accuracy: 0.6567\n",
      "Epoch 24/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.4740 - accuracy: 0.8184 - val_loss: 0.9372 - val_accuracy: 0.6580\n",
      "Epoch 25/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.4570 - accuracy: 0.8241 - val_loss: 0.9590 - val_accuracy: 0.6547\n",
      "Epoch 26/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.4458 - accuracy: 0.8329 - val_loss: 0.9446 - val_accuracy: 0.6587\n",
      "Epoch 27/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.4552 - accuracy: 0.8216 - val_loss: 0.9171 - val_accuracy: 0.6560\n",
      "Epoch 28/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.4339 - accuracy: 0.8293 - val_loss: 0.9654 - val_accuracy: 0.6673\n",
      "Epoch 29/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.4048 - accuracy: 0.8455 - val_loss: 0.9312 - val_accuracy: 0.6820\n",
      "Epoch 30/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.4125 - accuracy: 0.8415 - val_loss: 0.9214 - val_accuracy: 0.6740\n",
      "Epoch 31/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.3960 - accuracy: 0.8455 - val_loss: 0.9414 - val_accuracy: 0.6753\n",
      "Epoch 32/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.3925 - accuracy: 0.8501 - val_loss: 0.9201 - val_accuracy: 0.6753\n",
      "Epoch 33/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.3760 - accuracy: 0.8579 - val_loss: 0.9865 - val_accuracy: 0.6573\n",
      "Epoch 34/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.3821 - accuracy: 0.8537 - val_loss: 0.9727 - val_accuracy: 0.6693\n",
      "Epoch 35/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.3658 - accuracy: 0.8657 - val_loss: 0.9681 - val_accuracy: 0.6680\n",
      "Epoch 36/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.3791 - accuracy: 0.8579 - val_loss: 0.9319 - val_accuracy: 0.6767\n",
      "Epoch 37/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.3523 - accuracy: 0.8634 - val_loss: 0.9553 - val_accuracy: 0.6713\n",
      "Epoch 38/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.3672 - accuracy: 0.8632 - val_loss: 0.9420 - val_accuracy: 0.6587\n",
      "Epoch 39/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.3378 - accuracy: 0.8688 - val_loss: 0.9693 - val_accuracy: 0.6647\n",
      "Epoch 40/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.3453 - accuracy: 0.8682 - val_loss: 1.0038 - val_accuracy: 0.6787\n",
      "Epoch 41/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.3400 - accuracy: 0.8718 - val_loss: 0.9899 - val_accuracy: 0.6693\n",
      "Epoch 42/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.3322 - accuracy: 0.8759 - val_loss: 0.9872 - val_accuracy: 0.6707\n",
      "Epoch 43/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.3278 - accuracy: 0.8795 - val_loss: 0.9773 - val_accuracy: 0.6687\n",
      "Epoch 44/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.3352 - accuracy: 0.8730 - val_loss: 0.9424 - val_accuracy: 0.6760\n",
      "Epoch 45/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.3348 - accuracy: 0.8714 - val_loss: 0.9786 - val_accuracy: 0.6640\n",
      "Epoch 46/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.3250 - accuracy: 0.8756 - val_loss: 1.0060 - val_accuracy: 0.6660\n",
      "Epoch 47/50\n",
      "218/218 [==============================] - 5s 22ms/step - loss: 0.3165 - accuracy: 0.8772 - val_loss: 0.9872 - val_accuracy: 0.6633\n",
      "Epoch 48/50\n",
      "218/218 [==============================] - 5s 22ms/step - loss: 0.3136 - accuracy: 0.8774 - val_loss: 0.9889 - val_accuracy: 0.6720\n",
      "Epoch 49/50\n",
      "218/218 [==============================] - 5s 22ms/step - loss: 0.3135 - accuracy: 0.8841 - val_loss: 0.9875 - val_accuracy: 0.6560\n",
      "Epoch 50/50\n",
      "218/218 [==============================] - 5s 22ms/step - loss: 0.3153 - accuracy: 0.8810 - val_loss: 0.9827 - val_accuracy: 0.6567\n",
      "218/218 [==============================] - 1s 5ms/step - loss: 0.0358 - accuracy: 0.9981\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0287 - accuracy: 0.6676\n",
      "========== period: 400  ==========\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_57 (Conv2D)          (None, 200, 1, 25)        5525      \n",
      "                                                                 \n",
      " max_pooling2d_57 (MaxPoolin  (None, 100, 1, 25)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_57 (Bat  (None, 100, 1, 25)       100       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_57 (Dropout)        (None, 100, 1, 25)        0         \n",
      "                                                                 \n",
      " conv2d_58 (Conv2D)          (None, 100, 1, 50)        12550     \n",
      "                                                                 \n",
      " max_pooling2d_58 (MaxPoolin  (None, 50, 1, 50)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_58 (Bat  (None, 50, 1, 50)        200       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_58 (Dropout)        (None, 50, 1, 50)         0         \n",
      "                                                                 \n",
      " conv2d_59 (Conv2D)          (None, 50, 1, 100)        50100     \n",
      "                                                                 \n",
      " max_pooling2d_59 (MaxPoolin  (None, 25, 1, 100)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_59 (Bat  (None, 25, 1, 100)       400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_59 (Dropout)        (None, 25, 1, 100)        0         \n",
      "                                                                 \n",
      " flatten_19 (Flatten)        (None, 2500)              0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 4)                 10004     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 78,879\n",
      "Trainable params: 78,529\n",
      "Non-trainable params: 350\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "218/218 [==============================] - 6s 24ms/step - loss: 2.1238 - accuracy: 0.3647 - val_loss: 1.6343 - val_accuracy: 0.3647\n",
      "Epoch 2/50\n",
      "218/218 [==============================] - 5s 24ms/step - loss: 1.4371 - accuracy: 0.4639 - val_loss: 1.3099 - val_accuracy: 0.4393\n",
      "Epoch 3/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 1.1912 - accuracy: 0.5318 - val_loss: 1.2215 - val_accuracy: 0.5007\n",
      "Epoch 4/50\n",
      "218/218 [==============================] - 5s 24ms/step - loss: 1.0580 - accuracy: 0.5710 - val_loss: 1.1008 - val_accuracy: 0.5420\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218/218 [==============================] - 5s 24ms/step - loss: 1.0029 - accuracy: 0.5970 - val_loss: 1.1006 - val_accuracy: 0.5333\n",
      "Epoch 6/50\n",
      "218/218 [==============================] - 5s 24ms/step - loss: 0.9035 - accuracy: 0.6374 - val_loss: 1.0486 - val_accuracy: 0.5733\n",
      "Epoch 7/50\n",
      "218/218 [==============================] - 5s 25ms/step - loss: 0.8424 - accuracy: 0.6661 - val_loss: 1.0411 - val_accuracy: 0.5847\n",
      "Epoch 8/50\n",
      "218/218 [==============================] - 5s 25ms/step - loss: 0.8270 - accuracy: 0.6717 - val_loss: 0.9940 - val_accuracy: 0.6013\n",
      "Epoch 9/50\n",
      "218/218 [==============================] - 5s 25ms/step - loss: 0.7657 - accuracy: 0.6941 - val_loss: 0.9638 - val_accuracy: 0.6233\n",
      "Epoch 10/50\n",
      "218/218 [==============================] - 5s 25ms/step - loss: 0.7284 - accuracy: 0.7099 - val_loss: 0.9695 - val_accuracy: 0.6073\n",
      "Epoch 11/50\n",
      "218/218 [==============================] - 5s 25ms/step - loss: 0.7203 - accuracy: 0.7139 - val_loss: 0.9766 - val_accuracy: 0.6093\n",
      "Epoch 12/50\n",
      "218/218 [==============================] - 5s 25ms/step - loss: 0.6773 - accuracy: 0.7292 - val_loss: 0.9529 - val_accuracy: 0.6267\n",
      "Epoch 13/50\n",
      "218/218 [==============================] - 5s 25ms/step - loss: 0.6466 - accuracy: 0.7481 - val_loss: 0.8914 - val_accuracy: 0.6667\n",
      "Epoch 14/50\n",
      "218/218 [==============================] - 5s 25ms/step - loss: 0.6316 - accuracy: 0.7524 - val_loss: 0.8944 - val_accuracy: 0.6553\n",
      "Epoch 15/50\n",
      "218/218 [==============================] - 5s 24ms/step - loss: 0.5978 - accuracy: 0.7688 - val_loss: 0.8898 - val_accuracy: 0.6560\n",
      "Epoch 16/50\n",
      "218/218 [==============================] - 5s 24ms/step - loss: 0.6046 - accuracy: 0.7588 - val_loss: 0.8454 - val_accuracy: 0.6747\n",
      "Epoch 17/50\n",
      "218/218 [==============================] - 5s 24ms/step - loss: 0.5675 - accuracy: 0.7823 - val_loss: 0.8988 - val_accuracy: 0.6493\n",
      "Epoch 18/50\n",
      "218/218 [==============================] - 5s 24ms/step - loss: 0.5520 - accuracy: 0.7891 - val_loss: 0.9127 - val_accuracy: 0.6540\n",
      "Epoch 19/50\n",
      "218/218 [==============================] - 5s 24ms/step - loss: 0.5399 - accuracy: 0.7905 - val_loss: 0.8828 - val_accuracy: 0.6527\n",
      "Epoch 20/50\n",
      "218/218 [==============================] - 5s 24ms/step - loss: 0.5249 - accuracy: 0.7970 - val_loss: 0.8922 - val_accuracy: 0.6620\n",
      "Epoch 21/50\n",
      "218/218 [==============================] - 5s 24ms/step - loss: 0.5000 - accuracy: 0.8050 - val_loss: 0.8873 - val_accuracy: 0.6793\n",
      "Epoch 22/50\n",
      "218/218 [==============================] - 5s 24ms/step - loss: 0.4822 - accuracy: 0.8164 - val_loss: 0.8670 - val_accuracy: 0.6667\n",
      "Epoch 23/50\n",
      "218/218 [==============================] - 5s 24ms/step - loss: 0.4674 - accuracy: 0.8181 - val_loss: 0.8635 - val_accuracy: 0.6687\n",
      "Epoch 24/50\n",
      "218/218 [==============================] - 5s 25ms/step - loss: 0.4603 - accuracy: 0.8205 - val_loss: 0.8975 - val_accuracy: 0.6700\n",
      "Epoch 25/50\n",
      "218/218 [==============================] - 5s 25ms/step - loss: 0.4540 - accuracy: 0.8267 - val_loss: 0.8356 - val_accuracy: 0.6933\n",
      "Epoch 26/50\n",
      "218/218 [==============================] - 5s 25ms/step - loss: 0.4272 - accuracy: 0.8376 - val_loss: 0.8596 - val_accuracy: 0.6947\n",
      "Epoch 27/50\n",
      "218/218 [==============================] - 5s 25ms/step - loss: 0.4315 - accuracy: 0.8333 - val_loss: 0.8927 - val_accuracy: 0.6740\n",
      "Epoch 28/50\n",
      "218/218 [==============================] - 5s 25ms/step - loss: 0.4240 - accuracy: 0.8345 - val_loss: 0.8420 - val_accuracy: 0.6987\n",
      "Epoch 29/50\n",
      "218/218 [==============================] - 5s 25ms/step - loss: 0.4082 - accuracy: 0.8430 - val_loss: 0.9212 - val_accuracy: 0.6747\n",
      "Epoch 30/50\n",
      "218/218 [==============================] - 5s 25ms/step - loss: 0.4072 - accuracy: 0.8425 - val_loss: 0.8842 - val_accuracy: 0.6967\n",
      "Epoch 31/50\n",
      "218/218 [==============================] - 6s 26ms/step - loss: 0.3896 - accuracy: 0.8504 - val_loss: 0.8177 - val_accuracy: 0.6953\n",
      "Epoch 32/50\n",
      "218/218 [==============================] - 6s 26ms/step - loss: 0.3732 - accuracy: 0.8568 - val_loss: 0.8278 - val_accuracy: 0.6887\n",
      "Epoch 33/50\n",
      "218/218 [==============================] - 6s 26ms/step - loss: 0.3691 - accuracy: 0.8595 - val_loss: 0.8477 - val_accuracy: 0.7087\n",
      "Epoch 34/50\n",
      "218/218 [==============================] - 6s 26ms/step - loss: 0.3677 - accuracy: 0.8598 - val_loss: 0.8412 - val_accuracy: 0.6933\n",
      "Epoch 35/50\n",
      "218/218 [==============================] - 5s 25ms/step - loss: 0.3592 - accuracy: 0.8614 - val_loss: 0.8340 - val_accuracy: 0.7033\n",
      "Epoch 36/50\n",
      "218/218 [==============================] - 5s 24ms/step - loss: 0.3598 - accuracy: 0.8625 - val_loss: 0.8612 - val_accuracy: 0.7033\n",
      "Epoch 37/50\n",
      "218/218 [==============================] - 5s 24ms/step - loss: 0.3444 - accuracy: 0.8716 - val_loss: 0.8456 - val_accuracy: 0.7127\n",
      "Epoch 38/50\n",
      "218/218 [==============================] - 5s 25ms/step - loss: 0.3309 - accuracy: 0.8746 - val_loss: 0.8436 - val_accuracy: 0.7173\n",
      "Epoch 39/50\n",
      "218/218 [==============================] - 5s 25ms/step - loss: 0.3067 - accuracy: 0.8835 - val_loss: 0.8565 - val_accuracy: 0.7187\n",
      "Epoch 40/50\n",
      "218/218 [==============================] - 5s 25ms/step - loss: 0.3372 - accuracy: 0.8747 - val_loss: 0.8816 - val_accuracy: 0.6953\n",
      "Epoch 41/50\n",
      "218/218 [==============================] - 5s 25ms/step - loss: 0.3232 - accuracy: 0.8784 - val_loss: 0.8342 - val_accuracy: 0.7120\n",
      "Epoch 42/50\n",
      "218/218 [==============================] - 5s 25ms/step - loss: 0.3172 - accuracy: 0.8806 - val_loss: 0.8141 - val_accuracy: 0.7240\n",
      "Epoch 43/50\n",
      "218/218 [==============================] - 5s 25ms/step - loss: 0.3225 - accuracy: 0.8763 - val_loss: 0.7808 - val_accuracy: 0.7333\n",
      "Epoch 44/50\n",
      "218/218 [==============================] - 5s 25ms/step - loss: 0.3024 - accuracy: 0.8876 - val_loss: 0.8065 - val_accuracy: 0.7260\n",
      "Epoch 45/50\n",
      "218/218 [==============================] - 5s 25ms/step - loss: 0.3178 - accuracy: 0.8835 - val_loss: 0.7969 - val_accuracy: 0.7140\n",
      "Epoch 46/50\n",
      "218/218 [==============================] - 5s 25ms/step - loss: 0.3170 - accuracy: 0.8802 - val_loss: 0.8273 - val_accuracy: 0.7153\n",
      "Epoch 47/50\n",
      "218/218 [==============================] - 6s 25ms/step - loss: 0.2993 - accuracy: 0.8851 - val_loss: 0.8354 - val_accuracy: 0.7113\n",
      "Epoch 48/50\n",
      "218/218 [==============================] - 5s 25ms/step - loss: 0.2919 - accuracy: 0.8925 - val_loss: 0.8351 - val_accuracy: 0.7267\n",
      "Epoch 49/50\n",
      "218/218 [==============================] - 6s 25ms/step - loss: 0.2864 - accuracy: 0.8931 - val_loss: 0.8411 - val_accuracy: 0.7100\n",
      "Epoch 50/50\n",
      "218/218 [==============================] - 5s 25ms/step - loss: 0.2745 - accuracy: 0.9010 - val_loss: 0.9205 - val_accuracy: 0.7127\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.0333 - accuracy: 0.9981\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 1.0598 - accuracy: 0.6682\n",
      "========== period: 450  ==========\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_60 (Conv2D)          (None, 225, 1, 25)        5525      \n",
      "                                                                 \n",
      " max_pooling2d_60 (MaxPoolin  (None, 113, 1, 25)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_60 (Bat  (None, 113, 1, 25)       100       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_60 (Dropout)        (None, 113, 1, 25)        0         \n",
      "                                                                 \n",
      " conv2d_61 (Conv2D)          (None, 113, 1, 50)        12550     \n",
      "                                                                 \n",
      " max_pooling2d_61 (MaxPoolin  (None, 57, 1, 50)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_61 (Bat  (None, 57, 1, 50)        200       \n",
      " chNormalization)                                                \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dropout_61 (Dropout)        (None, 57, 1, 50)         0         \n",
      "                                                                 \n",
      " conv2d_62 (Conv2D)          (None, 57, 1, 100)        50100     \n",
      "                                                                 \n",
      " max_pooling2d_62 (MaxPoolin  (None, 29, 1, 100)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_62 (Bat  (None, 29, 1, 100)       400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_62 (Dropout)        (None, 29, 1, 100)        0         \n",
      "                                                                 \n",
      " flatten_20 (Flatten)        (None, 2900)              0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 4)                 11604     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,479\n",
      "Trainable params: 80,129\n",
      "Non-trainable params: 350\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "218/218 [==============================] - 7s 24ms/step - loss: 2.2560 - accuracy: 0.3516 - val_loss: 1.5733 - val_accuracy: 0.3927\n",
      "Epoch 2/50\n",
      "218/218 [==============================] - 5s 24ms/step - loss: 1.5610 - accuracy: 0.4312 - val_loss: 1.4335 - val_accuracy: 0.3653\n",
      "Epoch 3/50\n",
      "218/218 [==============================] - 5s 25ms/step - loss: 1.2473 - accuracy: 0.5168 - val_loss: 1.1872 - val_accuracy: 0.4660\n",
      "Epoch 4/50\n",
      "218/218 [==============================] - 6s 27ms/step - loss: 1.1051 - accuracy: 0.5612 - val_loss: 1.1440 - val_accuracy: 0.5047\n",
      "Epoch 5/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 0.9960 - accuracy: 0.6034 - val_loss: 1.1219 - val_accuracy: 0.5193\n",
      "Epoch 6/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 0.9152 - accuracy: 0.6386 - val_loss: 1.0372 - val_accuracy: 0.5580\n",
      "Epoch 7/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 0.8412 - accuracy: 0.6592 - val_loss: 1.0551 - val_accuracy: 0.5693\n",
      "Epoch 8/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.7848 - accuracy: 0.6930 - val_loss: 1.0227 - val_accuracy: 0.5727\n",
      "Epoch 9/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.7283 - accuracy: 0.7168 - val_loss: 0.9717 - val_accuracy: 0.5873\n",
      "Epoch 10/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.7153 - accuracy: 0.7177 - val_loss: 0.9639 - val_accuracy: 0.6080\n",
      "Epoch 11/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 0.6776 - accuracy: 0.7319 - val_loss: 0.9941 - val_accuracy: 0.5933\n",
      "Epoch 12/50\n",
      "218/218 [==============================] - 6s 26ms/step - loss: 0.6614 - accuracy: 0.7424 - val_loss: 0.9234 - val_accuracy: 0.6220\n",
      "Epoch 13/50\n",
      "218/218 [==============================] - 6s 26ms/step - loss: 0.6178 - accuracy: 0.7591 - val_loss: 0.9459 - val_accuracy: 0.6280\n",
      "Epoch 14/50\n",
      "218/218 [==============================] - 6s 27ms/step - loss: 0.5703 - accuracy: 0.7751 - val_loss: 0.9359 - val_accuracy: 0.6273\n",
      "Epoch 15/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 0.5691 - accuracy: 0.7783 - val_loss: 0.9530 - val_accuracy: 0.6193\n",
      "Epoch 16/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.5337 - accuracy: 0.7892 - val_loss: 0.8874 - val_accuracy: 0.6487\n",
      "Epoch 17/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 0.5129 - accuracy: 0.8020 - val_loss: 0.8777 - val_accuracy: 0.6453\n",
      "Epoch 18/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.4978 - accuracy: 0.8072 - val_loss: 0.8478 - val_accuracy: 0.6533\n",
      "Epoch 19/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 0.4945 - accuracy: 0.8055 - val_loss: 0.8634 - val_accuracy: 0.6827\n",
      "Epoch 20/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 0.4588 - accuracy: 0.8155 - val_loss: 0.9030 - val_accuracy: 0.6540\n",
      "Epoch 21/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.4652 - accuracy: 0.8214 - val_loss: 0.8718 - val_accuracy: 0.6640\n",
      "Epoch 22/50\n",
      "218/218 [==============================] - 6s 27ms/step - loss: 0.4453 - accuracy: 0.8300 - val_loss: 0.8753 - val_accuracy: 0.6740\n",
      "Epoch 23/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 0.4164 - accuracy: 0.8404 - val_loss: 0.8672 - val_accuracy: 0.6760\n",
      "Epoch 24/50\n",
      "218/218 [==============================] - 6s 27ms/step - loss: 0.4102 - accuracy: 0.8415 - val_loss: 0.9048 - val_accuracy: 0.6653\n",
      "Epoch 25/50\n",
      "218/218 [==============================] - 6s 27ms/step - loss: 0.3973 - accuracy: 0.8443 - val_loss: 0.8739 - val_accuracy: 0.6927\n",
      "Epoch 26/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 0.3813 - accuracy: 0.8524 - val_loss: 0.8520 - val_accuracy: 0.6813\n",
      "Epoch 27/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 0.3607 - accuracy: 0.8678 - val_loss: 0.9149 - val_accuracy: 0.6793\n",
      "Epoch 28/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 0.3703 - accuracy: 0.8569 - val_loss: 0.8579 - val_accuracy: 0.6953\n",
      "Epoch 29/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 0.3637 - accuracy: 0.8621 - val_loss: 0.8698 - val_accuracy: 0.6860\n",
      "Epoch 30/50\n",
      "218/218 [==============================] - 7s 30ms/step - loss: 0.3410 - accuracy: 0.8700 - val_loss: 0.8656 - val_accuracy: 0.6940\n",
      "Epoch 31/50\n",
      "218/218 [==============================] - 7s 30ms/step - loss: 0.3390 - accuracy: 0.8690 - val_loss: 0.9150 - val_accuracy: 0.6673\n",
      "Epoch 32/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.3383 - accuracy: 0.8667 - val_loss: 0.8674 - val_accuracy: 0.6993\n",
      "Epoch 33/50\n",
      "218/218 [==============================] - 6s 27ms/step - loss: 0.3320 - accuracy: 0.8749 - val_loss: 0.8549 - val_accuracy: 0.7007\n",
      "Epoch 34/50\n",
      "218/218 [==============================] - 6s 27ms/step - loss: 0.3140 - accuracy: 0.8818 - val_loss: 0.8562 - val_accuracy: 0.6933\n",
      "Epoch 35/50\n",
      "218/218 [==============================] - 6s 27ms/step - loss: 0.3156 - accuracy: 0.8757 - val_loss: 0.8720 - val_accuracy: 0.6993\n",
      "Epoch 36/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 0.3089 - accuracy: 0.8769 - val_loss: 0.9102 - val_accuracy: 0.7020\n",
      "Epoch 37/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 0.3072 - accuracy: 0.8862 - val_loss: 0.9185 - val_accuracy: 0.6847\n",
      "Epoch 38/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.2964 - accuracy: 0.8879 - val_loss: 0.9667 - val_accuracy: 0.6740\n",
      "Epoch 39/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 0.2838 - accuracy: 0.8953 - val_loss: 0.9329 - val_accuracy: 0.6987\n",
      "Epoch 40/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.2791 - accuracy: 0.8944 - val_loss: 0.9294 - val_accuracy: 0.6900\n",
      "Epoch 41/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.2979 - accuracy: 0.8852 - val_loss: 0.9398 - val_accuracy: 0.6893\n",
      "Epoch 42/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 0.2705 - accuracy: 0.8991 - val_loss: 0.9449 - val_accuracy: 0.6827\n",
      "Epoch 43/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 0.2870 - accuracy: 0.8944 - val_loss: 0.9149 - val_accuracy: 0.6973\n",
      "Epoch 44/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 0.2592 - accuracy: 0.9023 - val_loss: 0.9705 - val_accuracy: 0.6893\n",
      "Epoch 45/50\n",
      "218/218 [==============================] - 6s 27ms/step - loss: 0.2618 - accuracy: 0.8993 - val_loss: 0.9220 - val_accuracy: 0.6973\n",
      "Epoch 46/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 0.2641 - accuracy: 0.9020 - val_loss: 0.9216 - val_accuracy: 0.6873\n",
      "Epoch 47/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 0.2591 - accuracy: 0.9026 - val_loss: 0.9802 - val_accuracy: 0.7047\n",
      "Epoch 48/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.2454 - accuracy: 0.9066 - val_loss: 0.9084 - val_accuracy: 0.7007\n",
      "Epoch 49/50\n",
      "218/218 [==============================] - 7s 30ms/step - loss: 0.2766 - accuracy: 0.8976 - val_loss: 0.9042 - val_accuracy: 0.7047\n",
      "Epoch 50/50\n",
      "218/218 [==============================] - 7s 31ms/step - loss: 0.2433 - accuracy: 0.9101 - val_loss: 0.9367 - val_accuracy: 0.7073\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.0141 - accuracy: 0.9999\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 1.1172 - accuracy: 0.6783\n",
      "========== period: 500  ==========\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_63 (Conv2D)          (None, 250, 1, 25)        5525      \n",
      "                                                                 \n",
      " max_pooling2d_63 (MaxPoolin  (None, 125, 1, 25)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_63 (Bat  (None, 125, 1, 25)       100       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_63 (Dropout)        (None, 125, 1, 25)        0         \n",
      "                                                                 \n",
      " conv2d_64 (Conv2D)          (None, 125, 1, 50)        12550     \n",
      "                                                                 \n",
      " max_pooling2d_64 (MaxPoolin  (None, 63, 1, 50)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_64 (Bat  (None, 63, 1, 50)        200       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_64 (Dropout)        (None, 63, 1, 50)         0         \n",
      "                                                                 \n",
      " conv2d_65 (Conv2D)          (None, 63, 1, 100)        50100     \n",
      "                                                                 \n",
      " max_pooling2d_65 (MaxPoolin  (None, 32, 1, 100)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_65 (Bat  (None, 32, 1, 100)       400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_65 (Dropout)        (None, 32, 1, 100)        0         \n",
      "                                                                 \n",
      " flatten_21 (Flatten)        (None, 3200)              0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 4)                 12804     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 81,679\n",
      "Trainable params: 81,329\n",
      "Non-trainable params: 350\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "218/218 [==============================] - 9s 35ms/step - loss: 2.2678 - accuracy: 0.3672 - val_loss: 1.5619 - val_accuracy: 0.4113\n",
      "Epoch 2/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 1.5245 - accuracy: 0.4644 - val_loss: 1.3472 - val_accuracy: 0.4113\n",
      "Epoch 3/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 1.2604 - accuracy: 0.5226 - val_loss: 1.1979 - val_accuracy: 0.5113\n",
      "Epoch 4/50\n",
      "218/218 [==============================] - 7s 33ms/step - loss: 1.1150 - accuracy: 0.5687 - val_loss: 1.1814 - val_accuracy: 0.4813\n",
      "Epoch 5/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 0.9956 - accuracy: 0.6057 - val_loss: 1.1098 - val_accuracy: 0.5253\n",
      "Epoch 6/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 0.9098 - accuracy: 0.6366 - val_loss: 1.0904 - val_accuracy: 0.5500\n",
      "Epoch 7/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 0.8664 - accuracy: 0.6560 - val_loss: 1.0803 - val_accuracy: 0.5707\n",
      "Epoch 8/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 0.8061 - accuracy: 0.6823 - val_loss: 1.1018 - val_accuracy: 0.5513\n",
      "Epoch 9/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 0.7679 - accuracy: 0.6941 - val_loss: 1.0150 - val_accuracy: 0.6047\n",
      "Epoch 10/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 0.7005 - accuracy: 0.7177 - val_loss: 0.9926 - val_accuracy: 0.6247\n",
      "Epoch 11/50\n",
      "218/218 [==============================] - 7s 31ms/step - loss: 0.6805 - accuracy: 0.7341 - val_loss: 0.9669 - val_accuracy: 0.6393\n",
      "Epoch 12/50\n",
      "218/218 [==============================] - 7s 31ms/step - loss: 0.6465 - accuracy: 0.7507 - val_loss: 0.9313 - val_accuracy: 0.6493\n",
      "Epoch 13/50\n",
      "218/218 [==============================] - 7s 31ms/step - loss: 0.6040 - accuracy: 0.7652 - val_loss: 0.9522 - val_accuracy: 0.6407\n",
      "Epoch 14/50\n",
      "218/218 [==============================] - 7s 31ms/step - loss: 0.5719 - accuracy: 0.7800 - val_loss: 0.8626 - val_accuracy: 0.6760\n",
      "Epoch 15/50\n",
      "218/218 [==============================] - 7s 31ms/step - loss: 0.5457 - accuracy: 0.7865 - val_loss: 0.9196 - val_accuracy: 0.6707\n",
      "Epoch 16/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 0.5209 - accuracy: 0.7994 - val_loss: 0.8842 - val_accuracy: 0.6693\n",
      "Epoch 17/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 0.5008 - accuracy: 0.8103 - val_loss: 0.8969 - val_accuracy: 0.6540\n",
      "Epoch 18/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 0.5031 - accuracy: 0.8056 - val_loss: 0.8700 - val_accuracy: 0.6687\n",
      "Epoch 19/50\n",
      "218/218 [==============================] - 7s 34ms/step - loss: 0.4628 - accuracy: 0.8237 - val_loss: 0.9091 - val_accuracy: 0.6587\n",
      "Epoch 20/50\n",
      "218/218 [==============================] - 7s 34ms/step - loss: 0.4507 - accuracy: 0.8239 - val_loss: 0.8746 - val_accuracy: 0.6940\n",
      "Epoch 21/50\n",
      "218/218 [==============================] - 7s 31ms/step - loss: 0.4201 - accuracy: 0.8401 - val_loss: 0.8593 - val_accuracy: 0.7040\n",
      "Epoch 22/50\n",
      "218/218 [==============================] - 7s 31ms/step - loss: 0.4307 - accuracy: 0.8338 - val_loss: 0.8843 - val_accuracy: 0.6940\n",
      "Epoch 23/50\n",
      "218/218 [==============================] - 7s 31ms/step - loss: 0.4029 - accuracy: 0.8474 - val_loss: 0.9018 - val_accuracy: 0.6807\n",
      "Epoch 24/50\n",
      "218/218 [==============================] - 7s 31ms/step - loss: 0.3895 - accuracy: 0.8501 - val_loss: 0.8663 - val_accuracy: 0.7240\n",
      "Epoch 25/50\n",
      "218/218 [==============================] - 7s 31ms/step - loss: 0.3788 - accuracy: 0.8569 - val_loss: 0.8768 - val_accuracy: 0.7047\n",
      "Epoch 26/50\n",
      "218/218 [==============================] - 7s 31ms/step - loss: 0.3641 - accuracy: 0.8605 - val_loss: 0.9320 - val_accuracy: 0.7060\n",
      "Epoch 27/50\n",
      "218/218 [==============================] - 7s 34ms/step - loss: 0.3760 - accuracy: 0.8572 - val_loss: 0.8813 - val_accuracy: 0.7100\n",
      "Epoch 28/50\n",
      "218/218 [==============================] - 7s 34ms/step - loss: 0.3757 - accuracy: 0.8563 - val_loss: 0.8670 - val_accuracy: 0.7313\n",
      "Epoch 29/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 0.3365 - accuracy: 0.8718 - val_loss: 0.9678 - val_accuracy: 0.6960\n",
      "Epoch 30/50\n",
      "218/218 [==============================] - 7s 31ms/step - loss: 0.3447 - accuracy: 0.8726 - val_loss: 0.8785 - val_accuracy: 0.7033\n",
      "Epoch 31/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 0.3287 - accuracy: 0.8777 - val_loss: 0.8847 - val_accuracy: 0.7073\n",
      "Epoch 32/50\n",
      "218/218 [==============================] - 7s 31ms/step - loss: 0.3060 - accuracy: 0.8841 - val_loss: 0.8904 - val_accuracy: 0.7033\n",
      "Epoch 33/50\n",
      "218/218 [==============================] - 7s 31ms/step - loss: 0.3063 - accuracy: 0.8802 - val_loss: 0.9223 - val_accuracy: 0.6967\n",
      "Epoch 34/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 0.3092 - accuracy: 0.8832 - val_loss: 0.9240 - val_accuracy: 0.7060\n",
      "Epoch 35/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 0.2883 - accuracy: 0.8911 - val_loss: 0.9207 - val_accuracy: 0.7100\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218/218 [==============================] - 7s 32ms/step - loss: 0.2953 - accuracy: 0.8894 - val_loss: 0.8947 - val_accuracy: 0.7113\n",
      "Epoch 37/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 0.2976 - accuracy: 0.8842 - val_loss: 0.8917 - val_accuracy: 0.6980\n",
      "Epoch 38/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 0.2843 - accuracy: 0.8935 - val_loss: 0.9351 - val_accuracy: 0.7073\n",
      "Epoch 39/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 0.2837 - accuracy: 0.8918 - val_loss: 0.9393 - val_accuracy: 0.6900\n",
      "Epoch 40/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 0.2753 - accuracy: 0.8993 - val_loss: 0.9640 - val_accuracy: 0.7093\n",
      "Epoch 41/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 0.2735 - accuracy: 0.8954 - val_loss: 0.9189 - val_accuracy: 0.7000\n",
      "Epoch 42/50\n",
      "218/218 [==============================] - 7s 31ms/step - loss: 0.2649 - accuracy: 0.9011 - val_loss: 0.9404 - val_accuracy: 0.6927\n",
      "Epoch 43/50\n",
      "218/218 [==============================] - 7s 31ms/step - loss: 0.2483 - accuracy: 0.9066 - val_loss: 0.9043 - val_accuracy: 0.7020\n",
      "Epoch 44/50\n",
      "218/218 [==============================] - 7s 31ms/step - loss: 0.2560 - accuracy: 0.9014 - val_loss: 0.9221 - val_accuracy: 0.7107\n",
      "Epoch 45/50\n",
      "218/218 [==============================] - 7s 31ms/step - loss: 0.2555 - accuracy: 0.9063 - val_loss: 0.9735 - val_accuracy: 0.6967\n",
      "Epoch 46/50\n",
      "218/218 [==============================] - 7s 31ms/step - loss: 0.2498 - accuracy: 0.9076 - val_loss: 0.9307 - val_accuracy: 0.7120\n",
      "Epoch 47/50\n",
      "218/218 [==============================] - 7s 31ms/step - loss: 0.2444 - accuracy: 0.9095 - val_loss: 0.8877 - val_accuracy: 0.7007\n",
      "Epoch 48/50\n",
      "218/218 [==============================] - 7s 31ms/step - loss: 0.2473 - accuracy: 0.9086 - val_loss: 0.9474 - val_accuracy: 0.7033\n",
      "Epoch 49/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 0.2427 - accuracy: 0.9078 - val_loss: 0.9111 - val_accuracy: 0.7127\n",
      "Epoch 50/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 0.2302 - accuracy: 0.9121 - val_loss: 0.9202 - val_accuracy: 0.7253\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.0162 - accuracy: 0.9999\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 1.0618 - accuracy: 0.6682\n",
      "{'50': 0.8360632061958313, '100': 0.9339080452919006, '150': 0.973994255065918, '200': 0.9870689511299133, '250': 0.9964080452919006, '300': 0.998275876045227, '350': 0.9981321692466736, '400': 0.9981321692466736, '450': 0.9998562932014465, '500': 0.9998562932014465}\n",
      "{'50': 0.42155757546424866, '100': 0.505643367767334, '150': 0.5840857625007629, '200': 0.6145598292350769, '250': 0.6422122120857239, '300': 0.6653499007225037, '350': 0.6676072478294373, '400': 0.6681715846061707, '450': 0.678329586982727, '500': 0.6681715846061707}\n"
     ]
    }
   ],
   "source": [
    "short_time_train_scores = {}\n",
    "short_time_test_scores = {}\n",
    "for i in range(50, 550, 50):\n",
    "    print(\"========== period:\", i, \" ==========\")\n",
    "    y_test = np.load(\"y_test.npy\")\n",
    "    y_test -= 769\n",
    "    x_train, x_valid, x_test, y_train, y_valid, y_test = data_finalize(total_number=2115, takeout_sample=375, period=i, y_test=y_test)\n",
    "\n",
    "    model = Sequential([\n",
    "\n",
    "      # Conv. block 1\n",
    "      keras.layers.Conv2D(filters=25, kernel_size=(10,1), padding='same', activation=tf.nn.gelu, input_shape=(x_train.shape[1],1,22)),\n",
    "      keras.layers.MaxPooling2D(pool_size=(2,1), padding='same'), # Read the keras documentation\n",
    "      keras.layers.BatchNormalization(),\n",
    "      keras.layers.Dropout(0.5),\n",
    "\n",
    "      # Conv. block 2\n",
    "      keras.layers.Conv2D(filters=50, kernel_size=(10,1), padding='same', activation=tf.nn.gelu),\n",
    "      keras.layers.MaxPooling2D(pool_size=(2,1), padding='same'),\n",
    "      keras.layers.BatchNormalization(),\n",
    "      keras.layers.Dropout(0.5),\n",
    "\n",
    "      # Conv. block 3\n",
    "      keras.layers.Conv2D(filters=100, kernel_size=(10,1), padding='same', activation=tf.nn.gelu),\n",
    "      keras.layers.MaxPooling2D(pool_size=(2,1), padding='same'),\n",
    "      keras.layers.BatchNormalization(),\n",
    "      keras.layers.Dropout(0.5),\n",
    "\n",
    "      # Output layer with Softmax activation\n",
    "      keras.layers.Flatten(), # Flattens the input\n",
    "      keras.layers.Dense(4, activation='softmax') # Output FC layer with softmax activation\n",
    "\n",
    "  ])\n",
    "\n",
    "    # Printing the model summary\n",
    "    model.summary()\n",
    "\n",
    "  \n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer=cnn_optimizer,\n",
    "                 metrics=['accuracy'])\n",
    "  \n",
    "\n",
    "    # Training and validating the model\n",
    "    model_results = model.fit(x_train,\n",
    "                  y_train,\n",
    "                  batch_size=32,\n",
    "                  epochs=epochs,\n",
    "                  validation_data=(x_valid, y_valid), verbose=True)\n",
    "\n",
    "    short_time_train_scores[str(i)] = model.evaluate(x_train, y_train)[1]\n",
    "    short_time_test_scores[str(i)] = model.evaluate(x_test, y_test)[1]\n",
    "print(short_time_train_scores)\n",
    "print(short_time_test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create lists for x and y values\n",
    "x_values = [int(k) for k in short_time_train_scores.keys()] # convert keys to integer values\n",
    "train_scores = [v for v in short_time_train_scores.values()]\n",
    "test_scores = [v for v in short_time_test_scores.values()]\n",
    "\n",
    "# Plot the data\n",
    "plt.plot(x_values, train_scores, label='Train Scores')\n",
    "plt.plot(x_values, test_scores, label='Test Scores')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel('Time period')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Test Accuracy for time period between 50 and 500')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 300, 1, 25)        5525      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 150, 1, 25)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 150, 1, 25)       100       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 150, 1, 25)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 150, 1, 50)        12550     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 75, 1, 50)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 75, 1, 50)        200       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 75, 1, 50)         0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 75, 1, 100)        50100     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 38, 1, 100)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 38, 1, 100)       400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 38, 1, 100)        0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 3800)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 15204     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84,079\n",
      "Trainable params: 83,729\n",
      "Non-trainable params: 350\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "218/218 [==============================] - 6s 27ms/step - loss: 2.3409 - accuracy: 0.3438 - val_loss: 1.5848 - val_accuracy: 0.4027\n",
      "Epoch 2/50\n",
      "218/218 [==============================] - 6s 27ms/step - loss: 1.6237 - accuracy: 0.4431 - val_loss: 1.2146 - val_accuracy: 0.4740\n",
      "Epoch 3/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 1.3228 - accuracy: 0.5164 - val_loss: 1.1836 - val_accuracy: 0.5013\n",
      "Epoch 4/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 1.1411 - accuracy: 0.5631 - val_loss: 1.0599 - val_accuracy: 0.5573\n",
      "Epoch 5/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 1.0031 - accuracy: 0.6095 - val_loss: 1.0651 - val_accuracy: 0.5567\n",
      "Epoch 6/50\n",
      "218/218 [==============================] - 7s 31ms/step - loss: 0.9459 - accuracy: 0.6269 - val_loss: 1.0073 - val_accuracy: 0.5727\n",
      "Epoch 7/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.8634 - accuracy: 0.6596 - val_loss: 1.0587 - val_accuracy: 0.5647\n",
      "Epoch 8/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.8054 - accuracy: 0.6909 - val_loss: 0.9889 - val_accuracy: 0.5853\n",
      "Epoch 9/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.7477 - accuracy: 0.7089 - val_loss: 0.9975 - val_accuracy: 0.6013\n",
      "Epoch 10/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.6960 - accuracy: 0.7299 - val_loss: 1.0226 - val_accuracy: 0.5920\n",
      "Epoch 11/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.6743 - accuracy: 0.7345 - val_loss: 0.9639 - val_accuracy: 0.6093\n",
      "Epoch 12/50\n",
      "218/218 [==============================] - 6s 30ms/step - loss: 0.6358 - accuracy: 0.7523 - val_loss: 0.9368 - val_accuracy: 0.6367\n",
      "Epoch 13/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.5992 - accuracy: 0.7678 - val_loss: 0.9232 - val_accuracy: 0.6313\n",
      "Epoch 14/50\n",
      "218/218 [==============================] - 7s 31ms/step - loss: 0.5854 - accuracy: 0.7737 - val_loss: 0.9306 - val_accuracy: 0.6300\n",
      "Epoch 15/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 0.5469 - accuracy: 0.7851 - val_loss: 0.9667 - val_accuracy: 0.6213\n",
      "Epoch 16/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.5170 - accuracy: 0.8029 - val_loss: 0.9659 - val_accuracy: 0.6300\n",
      "Epoch 17/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 0.4921 - accuracy: 0.8171 - val_loss: 0.9445 - val_accuracy: 0.6480\n",
      "Epoch 18/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 0.4773 - accuracy: 0.8197 - val_loss: 0.9944 - val_accuracy: 0.6387\n",
      "Epoch 19/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.4510 - accuracy: 0.8233 - val_loss: 1.0052 - val_accuracy: 0.6453\n",
      "Epoch 20/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.4483 - accuracy: 0.8280 - val_loss: 0.9811 - val_accuracy: 0.6460\n",
      "Epoch 21/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.4293 - accuracy: 0.8351 - val_loss: 0.9515 - val_accuracy: 0.6567\n",
      "Epoch 22/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 0.3882 - accuracy: 0.8463 - val_loss: 1.0186 - val_accuracy: 0.6480\n",
      "Epoch 23/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 0.4125 - accuracy: 0.8412 - val_loss: 1.0013 - val_accuracy: 0.6640\n",
      "Epoch 24/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.3941 - accuracy: 0.8516 - val_loss: 0.9909 - val_accuracy: 0.6567\n",
      "Epoch 25/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.3733 - accuracy: 0.8596 - val_loss: 0.9191 - val_accuracy: 0.6887\n",
      "Epoch 26/50\n",
      "218/218 [==============================] - 7s 30ms/step - loss: 0.3617 - accuracy: 0.8606 - val_loss: 1.0300 - val_accuracy: 0.6740\n",
      "Epoch 27/50\n",
      "218/218 [==============================] - 7s 30ms/step - loss: 0.3538 - accuracy: 0.8664 - val_loss: 0.9731 - val_accuracy: 0.6627\n",
      "Epoch 28/50\n",
      "218/218 [==============================] - 6s 30ms/step - loss: 0.3253 - accuracy: 0.8751 - val_loss: 1.0525 - val_accuracy: 0.6433\n",
      "Epoch 29/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.3150 - accuracy: 0.8823 - val_loss: 1.0091 - val_accuracy: 0.6607\n",
      "Epoch 30/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 0.3272 - accuracy: 0.8759 - val_loss: 1.0496 - val_accuracy: 0.6767\n",
      "Epoch 31/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.3200 - accuracy: 0.8816 - val_loss: 1.1032 - val_accuracy: 0.6553\n",
      "Epoch 32/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 0.3144 - accuracy: 0.8818 - val_loss: 1.1136 - val_accuracy: 0.6613\n",
      "Epoch 33/50\n",
      "218/218 [==============================] - 6s 30ms/step - loss: 0.3046 - accuracy: 0.8836 - val_loss: 1.0378 - val_accuracy: 0.6593\n",
      "Epoch 34/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.2944 - accuracy: 0.8886 - val_loss: 1.0633 - val_accuracy: 0.6540\n",
      "Epoch 35/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.2831 - accuracy: 0.8915 - val_loss: 1.0763 - val_accuracy: 0.6533\n",
      "Epoch 36/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 0.2781 - accuracy: 0.8924 - val_loss: 1.0545 - val_accuracy: 0.6667\n",
      "Epoch 37/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.2968 - accuracy: 0.8868 - val_loss: 1.0300 - val_accuracy: 0.6860\n",
      "Epoch 38/50\n",
      "218/218 [==============================] - 6s 30ms/step - loss: 0.2539 - accuracy: 0.9019 - val_loss: 1.0148 - val_accuracy: 0.6787\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218/218 [==============================] - 6s 29ms/step - loss: 0.2644 - accuracy: 0.8980 - val_loss: 1.0358 - val_accuracy: 0.6720\n",
      "Epoch 40/50\n",
      "218/218 [==============================] - 6s 30ms/step - loss: 0.2582 - accuracy: 0.9022 - val_loss: 1.1116 - val_accuracy: 0.6607\n",
      "Epoch 41/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.2629 - accuracy: 0.9019 - val_loss: 1.0375 - val_accuracy: 0.6747\n",
      "Epoch 42/50\n",
      "218/218 [==============================] - 6s 30ms/step - loss: 0.2533 - accuracy: 0.9026 - val_loss: 1.0947 - val_accuracy: 0.6520\n",
      "Epoch 43/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.2624 - accuracy: 0.9001 - val_loss: 1.0419 - val_accuracy: 0.6700\n",
      "Epoch 44/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.2496 - accuracy: 0.9059 - val_loss: 1.0510 - val_accuracy: 0.6767\n",
      "Epoch 45/50\n",
      "218/218 [==============================] - 6s 30ms/step - loss: 0.2212 - accuracy: 0.9194 - val_loss: 1.0740 - val_accuracy: 0.6780\n",
      "Epoch 46/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.2362 - accuracy: 0.9112 - val_loss: 1.0812 - val_accuracy: 0.6733\n",
      "Epoch 47/50\n",
      "218/218 [==============================] - 6s 30ms/step - loss: 0.2326 - accuracy: 0.9138 - val_loss: 1.1463 - val_accuracy: 0.6747\n",
      "Epoch 48/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.2320 - accuracy: 0.9141 - val_loss: 1.1190 - val_accuracy: 0.6667\n",
      "Epoch 49/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.2207 - accuracy: 0.9167 - val_loss: 1.0899 - val_accuracy: 0.6773\n",
      "Epoch 50/50\n",
      "218/218 [==============================] - 6s 30ms/step - loss: 0.2289 - accuracy: 0.9161 - val_loss: 1.1223 - val_accuracy: 0.6787\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.0088 - accuracy: 0.9997\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.1226 - accuracy: 0.6840\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 350, 1, 25)        5525      \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 175, 1, 25)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 175, 1, 25)       100       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 175, 1, 25)        0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 175, 1, 50)        12550     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 88, 1, 50)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 88, 1, 50)        200       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 88, 1, 50)         0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 88, 1, 100)        50100     \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 44, 1, 100)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 44, 1, 100)       400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 44, 1, 100)        0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 4400)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 17604     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,479\n",
      "Trainable params: 86,129\n",
      "Non-trainable params: 350\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "218/218 [==============================] - 7s 31ms/step - loss: 2.5845 - accuracy: 0.3547 - val_loss: 1.8917 - val_accuracy: 0.3927\n",
      "Epoch 2/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 1.7099 - accuracy: 0.4559 - val_loss: 1.4215 - val_accuracy: 0.4420\n",
      "Epoch 3/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 1.3437 - accuracy: 0.5233 - val_loss: 1.2632 - val_accuracy: 0.4900\n",
      "Epoch 4/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 1.1449 - accuracy: 0.5734 - val_loss: 1.1928 - val_accuracy: 0.5140\n",
      "Epoch 5/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 1.0396 - accuracy: 0.5991 - val_loss: 1.1417 - val_accuracy: 0.5667\n",
      "Epoch 6/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 0.9174 - accuracy: 0.6417 - val_loss: 1.1411 - val_accuracy: 0.5607\n",
      "Epoch 7/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 0.8571 - accuracy: 0.6645 - val_loss: 1.0836 - val_accuracy: 0.5627\n",
      "Epoch 8/50\n",
      "218/218 [==============================] - 7s 34ms/step - loss: 0.7884 - accuracy: 0.6925 - val_loss: 1.0671 - val_accuracy: 0.5780\n",
      "Epoch 9/50\n",
      "218/218 [==============================] - 7s 34ms/step - loss: 0.7449 - accuracy: 0.7032 - val_loss: 1.0646 - val_accuracy: 0.5760\n",
      "Epoch 10/50\n",
      "218/218 [==============================] - 7s 33ms/step - loss: 0.7068 - accuracy: 0.7243 - val_loss: 1.0245 - val_accuracy: 0.6173\n",
      "Epoch 11/50\n",
      "218/218 [==============================] - 7s 34ms/step - loss: 0.6618 - accuracy: 0.7411 - val_loss: 1.0653 - val_accuracy: 0.5847\n",
      "Epoch 12/50\n",
      "218/218 [==============================] - 7s 34ms/step - loss: 0.6306 - accuracy: 0.7549 - val_loss: 1.0631 - val_accuracy: 0.5673\n",
      "Epoch 13/50\n",
      "218/218 [==============================] - 7s 34ms/step - loss: 0.6236 - accuracy: 0.7601 - val_loss: 1.0557 - val_accuracy: 0.6107\n",
      "Epoch 14/50\n",
      "218/218 [==============================] - 7s 34ms/step - loss: 0.5786 - accuracy: 0.7734 - val_loss: 1.0498 - val_accuracy: 0.5940\n",
      "Epoch 15/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 0.5447 - accuracy: 0.7898 - val_loss: 1.0068 - val_accuracy: 0.6220\n",
      "Epoch 16/50\n",
      "218/218 [==============================] - 7s 33ms/step - loss: 0.5335 - accuracy: 0.7932 - val_loss: 1.0461 - val_accuracy: 0.5907\n",
      "Epoch 17/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 0.4982 - accuracy: 0.8091 - val_loss: 1.0402 - val_accuracy: 0.6233\n",
      "Epoch 18/50\n",
      "218/218 [==============================] - 7s 33ms/step - loss: 0.4868 - accuracy: 0.8200 - val_loss: 1.0678 - val_accuracy: 0.5967\n",
      "Epoch 19/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 0.4685 - accuracy: 0.8197 - val_loss: 1.0457 - val_accuracy: 0.6120\n",
      "Epoch 20/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 0.4502 - accuracy: 0.8261 - val_loss: 1.0389 - val_accuracy: 0.6113\n",
      "Epoch 21/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 0.4330 - accuracy: 0.8330 - val_loss: 1.0367 - val_accuracy: 0.6360\n",
      "Epoch 22/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 0.4349 - accuracy: 0.8299 - val_loss: 0.9965 - val_accuracy: 0.6373\n",
      "Epoch 23/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 0.4136 - accuracy: 0.8362 - val_loss: 1.0483 - val_accuracy: 0.6173\n",
      "Epoch 24/50\n",
      "218/218 [==============================] - 7s 33ms/step - loss: 0.3980 - accuracy: 0.8438 - val_loss: 1.0460 - val_accuracy: 0.6293\n",
      "Epoch 25/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 0.3767 - accuracy: 0.8566 - val_loss: 1.0541 - val_accuracy: 0.6407\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218/218 [==============================] - 7s 33ms/step - loss: 0.3601 - accuracy: 0.8674 - val_loss: 1.0681 - val_accuracy: 0.6153\n",
      "Epoch 27/50\n",
      "218/218 [==============================] - 7s 34ms/step - loss: 0.3624 - accuracy: 0.8634 - val_loss: 1.0260 - val_accuracy: 0.6360\n",
      "Epoch 28/50\n",
      "218/218 [==============================] - 7s 34ms/step - loss: 0.3420 - accuracy: 0.8675 - val_loss: 1.0554 - val_accuracy: 0.6247\n",
      "Epoch 29/50\n",
      "218/218 [==============================] - 7s 33ms/step - loss: 0.3317 - accuracy: 0.8772 - val_loss: 1.0408 - val_accuracy: 0.6520\n",
      "Epoch 30/50\n",
      "218/218 [==============================] - 7s 33ms/step - loss: 0.3267 - accuracy: 0.8783 - val_loss: 1.0668 - val_accuracy: 0.6440\n",
      "Epoch 31/50\n",
      "218/218 [==============================] - 7s 34ms/step - loss: 0.3213 - accuracy: 0.8777 - val_loss: 1.0281 - val_accuracy: 0.6533\n",
      "Epoch 32/50\n",
      "218/218 [==============================] - 7s 34ms/step - loss: 0.3133 - accuracy: 0.8777 - val_loss: 1.0027 - val_accuracy: 0.6627\n",
      "Epoch 33/50\n",
      "218/218 [==============================] - 7s 34ms/step - loss: 0.2878 - accuracy: 0.8886 - val_loss: 1.0219 - val_accuracy: 0.6540\n",
      "Epoch 34/50\n",
      "218/218 [==============================] - 7s 34ms/step - loss: 0.2931 - accuracy: 0.8914 - val_loss: 0.9879 - val_accuracy: 0.6600\n",
      "Epoch 35/50\n",
      "218/218 [==============================] - 7s 34ms/step - loss: 0.2946 - accuracy: 0.8915 - val_loss: 1.0108 - val_accuracy: 0.6673\n",
      "Epoch 36/50\n",
      "218/218 [==============================] - 7s 34ms/step - loss: 0.2801 - accuracy: 0.8920 - val_loss: 1.0494 - val_accuracy: 0.6347\n",
      "Epoch 37/50\n",
      "218/218 [==============================] - 7s 33ms/step - loss: 0.2660 - accuracy: 0.9014 - val_loss: 1.0054 - val_accuracy: 0.6580\n",
      "Epoch 38/50\n",
      "218/218 [==============================] - 7s 34ms/step - loss: 0.2536 - accuracy: 0.9046 - val_loss: 1.0339 - val_accuracy: 0.6727\n",
      "Epoch 39/50\n",
      "218/218 [==============================] - 7s 34ms/step - loss: 0.2545 - accuracy: 0.9052 - val_loss: 1.0508 - val_accuracy: 0.6673\n",
      "Epoch 40/50\n",
      "218/218 [==============================] - 7s 34ms/step - loss: 0.2453 - accuracy: 0.9063 - val_loss: 1.0455 - val_accuracy: 0.6920\n",
      "Epoch 41/50\n",
      "218/218 [==============================] - 7s 34ms/step - loss: 0.2545 - accuracy: 0.9069 - val_loss: 1.0030 - val_accuracy: 0.6860\n",
      "Epoch 42/50\n",
      "218/218 [==============================] - 7s 34ms/step - loss: 0.2455 - accuracy: 0.9086 - val_loss: 1.0429 - val_accuracy: 0.6807\n",
      "Epoch 43/50\n",
      "218/218 [==============================] - 7s 34ms/step - loss: 0.2469 - accuracy: 0.9079 - val_loss: 0.9911 - val_accuracy: 0.6847\n",
      "Epoch 44/50\n",
      "218/218 [==============================] - 7s 34ms/step - loss: 0.2516 - accuracy: 0.9050 - val_loss: 1.0647 - val_accuracy: 0.6660\n",
      "Epoch 45/50\n",
      "218/218 [==============================] - 7s 34ms/step - loss: 0.2357 - accuracy: 0.9129 - val_loss: 0.9711 - val_accuracy: 0.6753\n",
      "Epoch 46/50\n",
      "218/218 [==============================] - 7s 34ms/step - loss: 0.2190 - accuracy: 0.9194 - val_loss: 0.9936 - val_accuracy: 0.6920\n",
      "Epoch 47/50\n",
      "218/218 [==============================] - 7s 34ms/step - loss: 0.2265 - accuracy: 0.9171 - val_loss: 1.0371 - val_accuracy: 0.6820\n",
      "Epoch 48/50\n",
      "218/218 [==============================] - 7s 34ms/step - loss: 0.2244 - accuracy: 0.9172 - val_loss: 1.0315 - val_accuracy: 0.6833\n",
      "Epoch 49/50\n",
      "218/218 [==============================] - 7s 34ms/step - loss: 0.2279 - accuracy: 0.9152 - val_loss: 1.0288 - val_accuracy: 0.6673\n",
      "Epoch 50/50\n",
      "218/218 [==============================] - 7s 34ms/step - loss: 0.2118 - accuracy: 0.9223 - val_loss: 0.9587 - val_accuracy: 0.6847\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.0101 - accuracy: 1.0000\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 1.1955 - accuracy: 0.6569\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           (None, 400, 1, 25)        5525      \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 200, 1, 25)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 200, 1, 25)       100       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 200, 1, 25)        0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 200, 1, 50)        12550     \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 100, 1, 50)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 100, 1, 50)       200       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 100, 1, 50)        0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 100, 1, 100)       50100     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 50, 1, 100)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 50, 1, 100)       400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 50, 1, 100)        0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 5000)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 20004     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 88,879\n",
      "Trainable params: 88,529\n",
      "Non-trainable params: 350\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "218/218 [==============================] - 8s 35ms/step - loss: 2.7240 - accuracy: 0.3661 - val_loss: 1.8509 - val_accuracy: 0.3947\n",
      "Epoch 2/50\n",
      "218/218 [==============================] - 8s 36ms/step - loss: 1.6522 - accuracy: 0.4935 - val_loss: 1.5400 - val_accuracy: 0.4320\n",
      "Epoch 3/50\n",
      "218/218 [==============================] - 8s 36ms/step - loss: 1.2770 - accuracy: 0.5662 - val_loss: 1.3367 - val_accuracy: 0.4927\n",
      "Epoch 4/50\n",
      "218/218 [==============================] - 8s 36ms/step - loss: 1.0924 - accuracy: 0.6142 - val_loss: 1.2886 - val_accuracy: 0.5167\n",
      "Epoch 5/50\n",
      "218/218 [==============================] - 8s 36ms/step - loss: 0.9712 - accuracy: 0.6428 - val_loss: 1.3599 - val_accuracy: 0.4720\n",
      "Epoch 6/50\n",
      "218/218 [==============================] - 8s 36ms/step - loss: 0.8937 - accuracy: 0.6635 - val_loss: 1.2528 - val_accuracy: 0.5140\n",
      "Epoch 7/50\n",
      "218/218 [==============================] - 8s 36ms/step - loss: 0.7967 - accuracy: 0.6922 - val_loss: 1.2315 - val_accuracy: 0.5213\n",
      "Epoch 8/50\n",
      "218/218 [==============================] - 8s 37ms/step - loss: 0.7470 - accuracy: 0.7164 - val_loss: 1.2068 - val_accuracy: 0.5313\n",
      "Epoch 9/50\n",
      "218/218 [==============================] - 8s 36ms/step - loss: 0.7219 - accuracy: 0.7198 - val_loss: 1.3108 - val_accuracy: 0.5013\n",
      "Epoch 10/50\n",
      "218/218 [==============================] - 8s 37ms/step - loss: 0.6657 - accuracy: 0.7418 - val_loss: 1.2460 - val_accuracy: 0.5387\n",
      "Epoch 11/50\n",
      "218/218 [==============================] - 8s 38ms/step - loss: 0.6512 - accuracy: 0.7440 - val_loss: 1.2376 - val_accuracy: 0.5367\n",
      "Epoch 12/50\n",
      "218/218 [==============================] - 8s 39ms/step - loss: 0.5928 - accuracy: 0.7703 - val_loss: 1.1948 - val_accuracy: 0.5540\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218/218 [==============================] - 8s 37ms/step - loss: 0.5821 - accuracy: 0.7726 - val_loss: 1.2112 - val_accuracy: 0.5560\n",
      "Epoch 14/50\n",
      "218/218 [==============================] - 8s 36ms/step - loss: 0.5427 - accuracy: 0.7845 - val_loss: 1.2094 - val_accuracy: 0.5573\n",
      "Epoch 15/50\n",
      "218/218 [==============================] - 8s 36ms/step - loss: 0.5333 - accuracy: 0.7888 - val_loss: 1.1447 - val_accuracy: 0.5807\n",
      "Epoch 16/50\n",
      "218/218 [==============================] - 8s 37ms/step - loss: 0.5035 - accuracy: 0.8033 - val_loss: 1.2029 - val_accuracy: 0.5700\n",
      "Epoch 17/50\n",
      "218/218 [==============================] - 8s 37ms/step - loss: 0.4981 - accuracy: 0.8086 - val_loss: 1.1771 - val_accuracy: 0.5540\n",
      "Epoch 18/50\n",
      "218/218 [==============================] - 8s 36ms/step - loss: 0.4733 - accuracy: 0.8185 - val_loss: 1.1095 - val_accuracy: 0.6193\n",
      "Epoch 19/50\n",
      "218/218 [==============================] - 8s 37ms/step - loss: 0.4384 - accuracy: 0.8320 - val_loss: 1.1470 - val_accuracy: 0.5907\n",
      "Epoch 20/50\n",
      "218/218 [==============================] - 8s 37ms/step - loss: 0.4403 - accuracy: 0.8286 - val_loss: 1.1144 - val_accuracy: 0.6047\n",
      "Epoch 21/50\n",
      "218/218 [==============================] - 8s 38ms/step - loss: 0.4101 - accuracy: 0.8450 - val_loss: 1.1524 - val_accuracy: 0.5860\n",
      "Epoch 22/50\n",
      "218/218 [==============================] - 8s 37ms/step - loss: 0.4026 - accuracy: 0.8437 - val_loss: 1.1656 - val_accuracy: 0.6000\n",
      "Epoch 23/50\n",
      "218/218 [==============================] - 8s 38ms/step - loss: 0.3806 - accuracy: 0.8580 - val_loss: 1.1455 - val_accuracy: 0.6073\n",
      "Epoch 24/50\n",
      "218/218 [==============================] - 8s 38ms/step - loss: 0.3769 - accuracy: 0.8591 - val_loss: 1.1004 - val_accuracy: 0.6207\n",
      "Epoch 25/50\n",
      "218/218 [==============================] - 8s 38ms/step - loss: 0.3646 - accuracy: 0.8592 - val_loss: 1.1582 - val_accuracy: 0.6020\n",
      "Epoch 26/50\n",
      "218/218 [==============================] - 8s 38ms/step - loss: 0.3573 - accuracy: 0.8661 - val_loss: 1.0646 - val_accuracy: 0.6413\n",
      "Epoch 27/50\n",
      "218/218 [==============================] - 8s 38ms/step - loss: 0.3229 - accuracy: 0.8813 - val_loss: 1.1301 - val_accuracy: 0.6240\n",
      "Epoch 28/50\n",
      "218/218 [==============================] - 8s 38ms/step - loss: 0.3369 - accuracy: 0.8731 - val_loss: 1.1152 - val_accuracy: 0.6367\n",
      "Epoch 29/50\n",
      "218/218 [==============================] - 9s 40ms/step - loss: 0.3243 - accuracy: 0.8784 - val_loss: 1.0817 - val_accuracy: 0.6520\n",
      "Epoch 30/50\n",
      "217/218 [============================>.] - ETA: 0s - loss: 0.3160 - accuracy: 0.8799"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/18/mc_7692d7c9665mhcdrpp2v00000gn/T/ipykernel_5253/1713643516.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m               validation_data=(x_valid, y_valid), verbose=True)\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mlong_time_train_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/c247/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/c247/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                         \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                         \u001b[0m_use_cached_eval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1706\u001b[0m                     )\n\u001b[1;32m   1707\u001b[0m                     val_logs = {\n",
      "\u001b[0;32m~/opt/anaconda3/envs/c247/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/c247/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2038\u001b[0m                         ):\n\u001b[1;32m   2039\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2040\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2041\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2042\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/c247/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/c247/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/c247/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 919\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    920\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/opt/anaconda3/envs/c247/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m    134\u001b[0m     return concrete_function._call_flat(\n\u001b[0;32m--> 135\u001b[0;31m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/c247/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/c247/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    381\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/c247/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 53\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "long_time_train_scores = {}\n",
    "long_time_test_scores = {}\n",
    "for i in range(600, 1100, 100):\n",
    "    y_test = np.load(\"y_test.npy\")\n",
    "    y_test -= 769\n",
    "    x_train, x_valid, x_test, y_train, y_valid, y_test = data_finalize(total_number=2115, takeout_sample=375, period=i, y_test=y_test)\n",
    "\n",
    "    model = Sequential([\n",
    "\n",
    "      # Conv. block 1\n",
    "      keras.layers.Conv2D(filters=25, kernel_size=(10,1), padding='same', activation='relu', input_shape=(x_train.shape[1],1,22)),\n",
    "      keras.layers.MaxPooling2D(pool_size=(2,1), padding='same'), # Read the keras documentation\n",
    "      keras.layers.BatchNormalization(),\n",
    "      keras.layers.Dropout(0.5),\n",
    "\n",
    "      # Conv. block 2\n",
    "      keras.layers.Conv2D(filters=50, kernel_size=(10,1), padding='same', activation='relu'),\n",
    "      keras.layers.MaxPooling2D(pool_size=(2,1), padding='same'),\n",
    "      keras.layers.BatchNormalization(),\n",
    "      keras.layers.Dropout(0.5),\n",
    "\n",
    "      # Conv. block 3\n",
    "      keras.layers.Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='relu'),\n",
    "      keras.layers.MaxPooling2D(pool_size=(2,1), padding='same'),\n",
    "      keras.layers.BatchNormalization(),\n",
    "      keras.layers.Dropout(0.5),\n",
    "\n",
    "      # Output layer with Softmax activation\n",
    "      keras.layers.Flatten(), # Flattens the input\n",
    "      keras.layers.Dense(4, activation='softmax') # Output FC layer with softmax activation\n",
    "\n",
    "  ])\n",
    "\n",
    "  # Printing the model summary\n",
    "    model.summary()\n",
    "\n",
    "  \n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer=cnn_optimizer,\n",
    "                 metrics=['accuracy'])\n",
    "  \n",
    "\n",
    "  # Training and validating the model\n",
    "    model_results = model.fit(x_train,\n",
    "              y_train,\n",
    "              batch_size=32,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_valid, y_valid), verbose=True)\n",
    "\n",
    "    long_time_train_scores[str(i)] = model.evaluate(x_train, y_train)[1]\n",
    "    long_time_test_scores[str(i)] = model.evaluate(x_test, y_test)[1]\n",
    "print(long_time_train_scores)\n",
    "print(long_time_test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
