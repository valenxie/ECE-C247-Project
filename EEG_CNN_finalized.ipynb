{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "5DT3YzDfAoJG",
    "outputId": "9c78dd0a-fe3a-4413-9417-50b123f54cd1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 21:57:49.413202: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f8aefdb7550>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.layers.reshaping.flatten import Flatten\n",
    "from keras.layers.core.activation import Activation\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Reshape\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras import regularizers\n",
    "X_test = np.load(\"X_test.npy\")\n",
    "y_test = np.load(\"y_test.npy\")\n",
    "person_train_valid = np.load(\"person_train_valid.npy\")\n",
    "X_train_valid = np.load(\"X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"y_train_valid.npy\")\n",
    "person_test = np.load(\"person_test.npy\")\n",
    "\n",
    "y_train_valid -= 769\n",
    "y_test -= 769\n",
    "\n",
    "## Visualizing the data\n",
    "\n",
    "ch_data = X_train_valid[:,8,:] # extracts the 9th channel from the data\n",
    "\n",
    "\n",
    "class_0_ind = np.where(y_train_valid == 0) # finds the indices where the label is 0\n",
    "ch_data_class_0 = ch_data[class_0_ind] # finds the data where label is 0\n",
    "avg_ch_data_class_0 = np.mean(ch_data_class_0,axis=0) # finds the average representation of the 9th channel when label is 0\n",
    "\n",
    "\n",
    "class_1_ind = np.where(y_train_valid == 1)\n",
    "ch_data_class_1 = ch_data[class_1_ind]\n",
    "avg_ch_data_class_1 = np.mean(ch_data_class_1,axis=0)\n",
    "\n",
    "class_2_ind = np.where(y_train_valid == 2)\n",
    "ch_data_class_2 = ch_data[class_2_ind]\n",
    "avg_ch_data_class_2 = np.mean(ch_data_class_2,axis=0)\n",
    "\n",
    "class_3_ind = np.where(y_train_valid == 3)\n",
    "ch_data_class_3 = ch_data[class_3_ind]\n",
    "avg_ch_data_class_3 = np.mean(ch_data_class_3,axis=0)\n",
    "\n",
    "\n",
    "plt.plot(np.arange(1000),avg_ch_data_class_0)\n",
    "plt.plot(np.arange(1000),avg_ch_data_class_1)\n",
    "plt.plot(np.arange(1000),avg_ch_data_class_2)\n",
    "plt.plot(np.arange(1000),avg_ch_data_class_3)\n",
    "plt.axvline(x=500, label='line at t=500',c='cyan')\n",
    "\n",
    "plt.legend([\"Cue Onset left\", \"Cue Onset right\", \"Cue onset foot\", \"Cue onset tongue\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BvkwSOkwZCH2"
   },
   "outputs": [],
   "source": [
    "def data_prep(X,y,sub_sample,average,noise,period):\n",
    "    \n",
    "    total_X = None\n",
    "    total_y = None\n",
    "    \n",
    "    # Trimming the data (sample,22,1000) -> (sample,22,500)\n",
    "    X = X[:,:,0:period]\n",
    "\n",
    "    \n",
    "    # Maxpooling the data (sample,22,1000) -> (sample,22,500/sub_sample)\n",
    "    X_reshape = X.reshape(X.shape[0], X.shape[1], -1, sub_sample)\n",
    "    X_max = np.max(X_reshape, axis=3)\n",
    "    \n",
    "    total_X = X_max\n",
    "    total_y = y\n",
    "    \n",
    "    # Averaging + noise \n",
    "    X_average = np.mean(X.reshape(X.shape[0], X.shape[1], -1, average),axis=3)\n",
    "    if noise:\n",
    "      X_average = X_average + np.random.normal(0.0, 0.5, X_average.shape)\n",
    "    \n",
    "    total_X = np.vstack((total_X, X_average))\n",
    "    total_y = np.hstack((total_y, y))\n",
    "    \n",
    "    # Subsampling\n",
    "    \n",
    "    for i in range(sub_sample):\n",
    "        \n",
    "        X_subsample = X[:, :, i::sub_sample] + \\\n",
    "                            (np.random.normal(0.0, 0.5, X[:, :,i::sub_sample].shape) if noise else 0.0)\n",
    "            \n",
    "        total_X = np.vstack((total_X, X_subsample))\n",
    "        total_y = np.hstack((total_y, y))\n",
    "\n",
    "    return total_X,total_y\n",
    "        \n",
    "def data_finalize(period, total_number, takeout_sample, y_test=y_test): \n",
    "    ind_valid = np.random.choice(total_number, takeout_sample, replace=False)  # get 375 out of 2115 samples and no repetitation\n",
    "    ind_train = np.array(list(set(range(total_number)).difference(set(ind_valid)))) # a set(unordered) different with another set, set = set1 - set2\n",
    "\n",
    "    # Creating the training and validation sets using the generated indices\n",
    "    (X_train, X_valid) = X_train_valid[ind_train], X_train_valid[ind_valid] \n",
    "    (y_train, y_valid) = y_train_valid[ind_train], y_train_valid[ind_valid]\n",
    "    x_train,y_train = data_prep(X_train,y_train,2,2,True, period=period)\n",
    "    x_valid,y_valid = data_prep(X_valid,y_valid,2,2,True, period=period)\n",
    "    X_test_prep,y_test_prep = data_prep(X_test,y_test,2,2,True, period=period)\n",
    "\n",
    "    # Converting the labels to categorical variables for multiclass classification\n",
    "    y_train = to_categorical(y_train, 4)\n",
    "    y_valid = to_categorical(y_valid, 4)\n",
    "    y_test = to_categorical(y_test_prep, 4)\n",
    "\n",
    "    # Adding width of the segment to be 1\n",
    "    x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "    x_valid = x_valid.reshape(x_valid.shape[0], x_valid.shape[1], x_train.shape[2], 1)\n",
    "    x_test = X_test_prep.reshape(X_test_prep.shape[0], X_test_prep.shape[1], X_test_prep.shape[2], 1)\n",
    "\n",
    "\n",
    "    # Reshaping the training and validation dataset\n",
    "    x_train = np.swapaxes(x_train, 1,3)\n",
    "    x_train = np.swapaxes(x_train, 1,2)\n",
    "    x_valid = np.swapaxes(x_valid, 1,3)\n",
    "    x_valid = np.swapaxes(x_valid, 1,2)\n",
    "    x_test = np.swapaxes(x_test, 1,3)\n",
    "    x_test = np.swapaxes(x_test, 1,2)\n",
    "\n",
    "    return x_train, x_valid, x_test, y_train, y_valid, y_test\n",
    "\n",
    "\n",
    "\n",
    "X_train_valid_prep,y_train_valid_prep = data_prep(X_train_valid,y_train_valid,2,2,noise=True, period=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "73oNi5FjCAS2"
   },
   "source": [
    "# **Train the model on subject 1 data only and test it on both subject 1 test set and all subject test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XYDsW_1zCTPr",
    "outputId": "323c5539-98c7-4582-eea1-e6a4a29d6112"
   },
   "outputs": [],
   "source": [
    "# get subject 1 data for training and validation set\n",
    "person_train_valid = person_train_valid.flatten()\n",
    "X_train_valid=X_train_valid[np.where(person_train_valid==0)]\n",
    "y_train_valid=y_train_valid[np.where(person_train_valid==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v8NrEhQEFWWf",
    "outputId": "2b993fae-67c0-4708-e91f-250fb25ecbc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(237, 22, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_valid.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "RmMo3NY9Ghca"
   },
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "learning_rate = 1e-3\n",
    "epochs = 50\n",
    "cnn_optimizer = keras.optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8qr-vDpgzEAE",
    "outputId": "bc647a37-3334-4e57-f430-6c55f720b041"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 500, 1, 25)        5525      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 250, 1, 25)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 250, 1, 25)       100       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 250, 1, 25)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 250, 1, 50)        12550     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 125, 1, 50)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 125, 1, 50)       200       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 125, 1, 50)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 125, 1, 100)       50100     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 63, 1, 100)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 63, 1, 100)       400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 63, 1, 100)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6300)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 25204     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 94,079\n",
      "Trainable params: 93,729\n",
      "Non-trainable params: 350\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 21:58:14.362670: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "25/25 [==============================] - 2s 58ms/step - loss: 1.9807 - accuracy: 0.3667 - val_loss: 5.7457 - val_accuracy: 0.2560\n",
      "Epoch 2/50\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 1.2647 - accuracy: 0.5679 - val_loss: 2.3760 - val_accuracy: 0.3929\n",
      "Epoch 3/50\n",
      "25/25 [==============================] - 1s 51ms/step - loss: 0.9562 - accuracy: 0.6667 - val_loss: 1.9181 - val_accuracy: 0.3631\n",
      "Epoch 4/50\n",
      "25/25 [==============================] - 1s 51ms/step - loss: 0.6669 - accuracy: 0.7705 - val_loss: 1.7414 - val_accuracy: 0.3155\n",
      "Epoch 5/50\n",
      "25/25 [==============================] - 1s 50ms/step - loss: 0.5398 - accuracy: 0.8128 - val_loss: 1.9089 - val_accuracy: 0.3631\n",
      "Epoch 6/50\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.3870 - accuracy: 0.8615 - val_loss: 1.7603 - val_accuracy: 0.3988\n",
      "Epoch 7/50\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 0.2788 - accuracy: 0.9013 - val_loss: 1.7163 - val_accuracy: 0.4464\n",
      "Epoch 8/50\n",
      "25/25 [==============================] - 1s 50ms/step - loss: 0.2346 - accuracy: 0.9038 - val_loss: 1.8188 - val_accuracy: 0.4107\n",
      "Epoch 9/50\n",
      "25/25 [==============================] - 1s 52ms/step - loss: 0.1749 - accuracy: 0.9282 - val_loss: 1.9391 - val_accuracy: 0.4583\n",
      "Epoch 10/50\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.1480 - accuracy: 0.9487 - val_loss: 1.9293 - val_accuracy: 0.4583\n",
      "Epoch 11/50\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.1283 - accuracy: 0.9513 - val_loss: 2.0858 - val_accuracy: 0.4940\n",
      "Epoch 12/50\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.1366 - accuracy: 0.9526 - val_loss: 2.1648 - val_accuracy: 0.5238\n",
      "Epoch 13/50\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.1298 - accuracy: 0.9513 - val_loss: 2.4221 - val_accuracy: 0.4940\n",
      "Epoch 14/50\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.0917 - accuracy: 0.9705 - val_loss: 2.4617 - val_accuracy: 0.4286\n",
      "Epoch 15/50\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.0848 - accuracy: 0.9705 - val_loss: 2.5550 - val_accuracy: 0.4821\n",
      "Epoch 16/50\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.0799 - accuracy: 0.9705 - val_loss: 2.5738 - val_accuracy: 0.5000\n",
      "Epoch 17/50\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.0881 - accuracy: 0.9705 - val_loss: 2.5016 - val_accuracy: 0.4583\n",
      "Epoch 18/50\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.0371 - accuracy: 0.9885 - val_loss: 2.9252 - val_accuracy: 0.4107\n",
      "Epoch 19/50\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.0494 - accuracy: 0.9872 - val_loss: 2.6043 - val_accuracy: 0.4345\n",
      "Epoch 20/50\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.0566 - accuracy: 0.9821 - val_loss: 2.9175 - val_accuracy: 0.4167\n",
      "Epoch 21/50\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.0519 - accuracy: 0.9833 - val_loss: 2.5463 - val_accuracy: 0.4821\n",
      "Epoch 22/50\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.0554 - accuracy: 0.9808 - val_loss: 2.5793 - val_accuracy: 0.5119\n",
      "Epoch 23/50\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.0501 - accuracy: 0.9769 - val_loss: 3.0934 - val_accuracy: 0.4762\n",
      "Epoch 24/50\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.0399 - accuracy: 0.9872 - val_loss: 3.0285 - val_accuracy: 0.4821\n",
      "Epoch 25/50\n",
      "25/25 [==============================] - 1s 52ms/step - loss: 0.0471 - accuracy: 0.9821 - val_loss: 2.9553 - val_accuracy: 0.4762\n",
      "Epoch 26/50\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.0368 - accuracy: 0.9846 - val_loss: 3.1631 - val_accuracy: 0.4345\n",
      "Epoch 27/50\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.0255 - accuracy: 0.9897 - val_loss: 3.1005 - val_accuracy: 0.4464\n",
      "Epoch 28/50\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.0241 - accuracy: 0.9923 - val_loss: 3.1345 - val_accuracy: 0.4762\n",
      "Epoch 29/50\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.0157 - accuracy: 0.9974 - val_loss: 3.0527 - val_accuracy: 0.4762\n",
      "Epoch 30/50\n",
      "25/25 [==============================] - 1s 53ms/step - loss: 0.0155 - accuracy: 0.9923 - val_loss: 3.1408 - val_accuracy: 0.4286\n",
      "Epoch 31/50\n",
      "25/25 [==============================] - 1s 55ms/step - loss: 0.0161 - accuracy: 0.9962 - val_loss: 2.9748 - val_accuracy: 0.4702\n",
      "Epoch 32/50\n",
      "25/25 [==============================] - 1s 55ms/step - loss: 0.0162 - accuracy: 0.9949 - val_loss: 3.1067 - val_accuracy: 0.4702\n",
      "Epoch 33/50\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.0385 - accuracy: 0.9872 - val_loss: 2.7625 - val_accuracy: 0.4643\n",
      "Epoch 34/50\n",
      "25/25 [==============================] - 1s 57ms/step - loss: 0.0110 - accuracy: 0.9962 - val_loss: 2.6858 - val_accuracy: 0.5238\n",
      "Epoch 35/50\n",
      "25/25 [==============================] - 1s 56ms/step - loss: 0.0159 - accuracy: 0.9923 - val_loss: 2.8245 - val_accuracy: 0.4762\n",
      "Epoch 36/50\n",
      "25/25 [==============================] - 1s 56ms/step - loss: 0.0252 - accuracy: 0.9923 - val_loss: 2.5908 - val_accuracy: 0.5357\n",
      "Epoch 37/50\n",
      "25/25 [==============================] - 1s 56ms/step - loss: 0.0191 - accuracy: 0.9962 - val_loss: 2.6867 - val_accuracy: 0.4821\n",
      "Epoch 38/50\n",
      "25/25 [==============================] - 1s 56ms/step - loss: 0.0159 - accuracy: 0.9936 - val_loss: 2.6900 - val_accuracy: 0.5238\n",
      "Epoch 39/50\n",
      "25/25 [==============================] - 1s 55ms/step - loss: 0.0162 - accuracy: 0.9936 - val_loss: 2.3859 - val_accuracy: 0.5476\n",
      "Epoch 40/50\n",
      "25/25 [==============================] - 1s 56ms/step - loss: 0.0258 - accuracy: 0.9872 - val_loss: 2.3656 - val_accuracy: 0.4405\n",
      "Epoch 41/50\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 0.0248 - accuracy: 0.9897 - val_loss: 2.7135 - val_accuracy: 0.4583\n",
      "Epoch 42/50\n",
      "25/25 [==============================] - 1s 55ms/step - loss: 0.0088 - accuracy: 0.9962 - val_loss: 2.7183 - val_accuracy: 0.4464\n",
      "Epoch 43/50\n",
      "25/25 [==============================] - 1s 55ms/step - loss: 0.0321 - accuracy: 0.9923 - val_loss: 2.7082 - val_accuracy: 0.4881\n",
      "Epoch 44/50\n",
      "25/25 [==============================] - 1s 56ms/step - loss: 0.0155 - accuracy: 0.9962 - val_loss: 2.4923 - val_accuracy: 0.5060\n",
      "Epoch 45/50\n",
      "25/25 [==============================] - 1s 55ms/step - loss: 0.0132 - accuracy: 0.9962 - val_loss: 2.5204 - val_accuracy: 0.4940\n",
      "Epoch 46/50\n",
      "25/25 [==============================] - 1s 56ms/step - loss: 0.0300 - accuracy: 0.9885 - val_loss: 2.4903 - val_accuracy: 0.5238\n",
      "Epoch 47/50\n",
      "25/25 [==============================] - 1s 55ms/step - loss: 0.0196 - accuracy: 0.9949 - val_loss: 2.7530 - val_accuracy: 0.5119\n",
      "Epoch 48/50\n",
      "25/25 [==============================] - 1s 55ms/step - loss: 0.0135 - accuracy: 0.9962 - val_loss: 2.5634 - val_accuracy: 0.5774\n",
      "Epoch 49/50\n",
      "25/25 [==============================] - 1s 55ms/step - loss: 0.0346 - accuracy: 0.9872 - val_loss: 2.3886 - val_accuracy: 0.5655\n",
      "Epoch 50/50\n",
      "25/25 [==============================] - 1s 55ms/step - loss: 0.0121 - accuracy: 0.9962 - val_loss: 2.2130 - val_accuracy: 0.6131\n",
      "{'Sub1': 0.363095223903656}\n"
     ]
    }
   ],
   "source": [
    "period_accuracy={}\n",
    "x_train, x_valid, x_test, y_train, y_valid, y_test = data_finalize(total_number=237, takeout_sample=42, period=1000, y_test=y_test)\n",
    "# get subject 1 data for test set\n",
    "person_test=person_test.flatten()\n",
    "X_test_sub1 = x_test[np.where(person_test==0)]\n",
    "y_test_sub1 = y_test[np.where(person_test==0)]\n",
    "\n",
    "model_sub1 = Sequential([\n",
    "\n",
    "      # Conv. block 1\n",
    "      keras.layers.Conv2D(filters=25, kernel_size=(10,1), padding='same', activation=tf.nn.gelu, input_shape=(x_train.shape[1],1,22)),\n",
    "      keras.layers.MaxPooling2D(pool_size=(2,1), padding='same'), # Read the keras documentation\n",
    "      keras.layers.BatchNormalization(),\n",
    "      keras.layers.Dropout(0.5),\n",
    "\n",
    "      # Conv. block 2\n",
    "      keras.layers.Conv2D(filters=50, kernel_size=(10,1), padding='same', activation=tf.nn.gelu),\n",
    "      keras.layers.MaxPooling2D(pool_size=(2,1), padding='same'),\n",
    "      keras.layers.BatchNormalization(),\n",
    "      keras.layers.Dropout(0.5),\n",
    "\n",
    "      # Conv. block 3\n",
    "      keras.layers.Conv2D(filters=100, kernel_size=(10,1), padding='same', activation=tf.nn.gelu),\n",
    "      keras.layers.MaxPooling2D(pool_size=(2,1), padding='same'),\n",
    "      keras.layers.BatchNormalization(),\n",
    "      keras.layers.Dropout(0.5),\n",
    "\n",
    "      # Output layer with Softmax activation\n",
    "      keras.layers.Flatten(), # Flattens the input\n",
    "      keras.layers.Dense(4, activation='softmax') # Output FC layer with softmax activation\n",
    "\n",
    "  ])\n",
    "\n",
    "  # Printing the model summary\n",
    "model_sub1.summary()\n",
    "\n",
    "  \n",
    "\n",
    "model_sub1.compile(loss='categorical_crossentropy',\n",
    "                 optimizer=cnn_optimizer,\n",
    "                 metrics=['accuracy'])\n",
    "  \n",
    "\n",
    "  # Training and validating the model\n",
    "model_sub1_results = model_sub1.fit(x_train,\n",
    "              y_train,\n",
    "              batch_size=32,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_valid, y_valid), verbose=True)\n",
    "\n",
    "val_acc = model_sub1_results.history['val_accuracy'][2]\n",
    "period_accuracy['Sub1'] = val_acc\n",
    "print(period_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8W33IzSUCpBs",
    "outputId": "5e83e080-eaba-4dc3-ff80-6a83c4d3c072"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of the basic CNN model: 0.36000001430511475\n"
     ]
    }
   ],
   "source": [
    "cnn_score = model_sub1.evaluate(X_test_sub1, y_test_sub1, verbose=0)\n",
    "print('Test accuracy of the basic CNN model:',cnn_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PijIvZpwCpna",
    "outputId": "2db08eb0-927a-4fd3-f98d-4db5fdefb0ec"
   },
   "outputs": [],
   "source": [
    "# cnn_score = model_sub1.evaluate(x_test, y_test, verbose=0)\n",
    "# print('Test accuracy of the basic CNN model:',cnn_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load(\"X_test.npy\")\n",
    "y_test = np.load(\"y_test.npy\")\n",
    "X_train_valid = np.load(\"X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"y_train_valid.npy\")\n",
    "y_train_valid -= 769\n",
    "y_test -= 769"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jeXROCIqUe_7",
    "outputId": "60049651-600e-4f2d-f333-6ed2eac0922f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 500, 1, 25)        5525      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 250, 1, 25)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 250, 1, 25)       100       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 250, 1, 25)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 250, 1, 50)        12550     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 125, 1, 50)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 125, 1, 50)       200       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 125, 1, 50)        0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 125, 1, 100)       50100     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 63, 1, 100)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 63, 1, 100)       400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 63, 1, 100)        0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 6300)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 25204     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 94,079\n",
      "Trainable params: 93,729\n",
      "Non-trainable params: 350\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "218/218 [==============================] - 12s 50ms/step - loss: 3.2080 - accuracy: 0.3698 - val_loss: 3.1180 - val_accuracy: 0.3373\n",
      "Epoch 2/50\n",
      "218/218 [==============================] - 11s 52ms/step - loss: 1.9800 - accuracy: 0.4680 - val_loss: 1.9529 - val_accuracy: 0.3593\n",
      "Epoch 3/50\n",
      "218/218 [==============================] - 12s 54ms/step - loss: 1.4655 - accuracy: 0.5330 - val_loss: 1.7793 - val_accuracy: 0.4073\n",
      "Epoch 4/50\n",
      "218/218 [==============================] - 12s 55ms/step - loss: 1.1935 - accuracy: 0.5862 - val_loss: 1.6382 - val_accuracy: 0.4187\n",
      "Epoch 5/50\n",
      "218/218 [==============================] - 12s 56ms/step - loss: 1.0252 - accuracy: 0.6318 - val_loss: 1.6070 - val_accuracy: 0.4447\n",
      "Epoch 6/50\n",
      "218/218 [==============================] - 12s 55ms/step - loss: 0.8998 - accuracy: 0.6634 - val_loss: 1.4997 - val_accuracy: 0.4700\n",
      "Epoch 7/50\n",
      "218/218 [==============================] - 12s 55ms/step - loss: 0.8187 - accuracy: 0.6882 - val_loss: 1.5229 - val_accuracy: 0.4913\n",
      "Epoch 8/50\n",
      "218/218 [==============================] - 12s 55ms/step - loss: 0.7409 - accuracy: 0.7075 - val_loss: 1.4902 - val_accuracy: 0.4820\n",
      "Epoch 9/50\n",
      "218/218 [==============================] - 12s 56ms/step - loss: 0.6840 - accuracy: 0.7326 - val_loss: 1.4297 - val_accuracy: 0.5067\n",
      "Epoch 10/50\n",
      "218/218 [==============================] - 12s 55ms/step - loss: 0.6493 - accuracy: 0.7497 - val_loss: 1.3417 - val_accuracy: 0.5440\n",
      "Epoch 11/50\n",
      "218/218 [==============================] - 12s 55ms/step - loss: 0.5999 - accuracy: 0.7670 - val_loss: 1.4545 - val_accuracy: 0.4940\n",
      "Epoch 12/50\n",
      "218/218 [==============================] - 12s 55ms/step - loss: 0.5662 - accuracy: 0.7829 - val_loss: 1.3898 - val_accuracy: 0.5153\n",
      "Epoch 13/50\n",
      "218/218 [==============================] - 13s 57ms/step - loss: 0.5545 - accuracy: 0.7852 - val_loss: 1.3508 - val_accuracy: 0.5300\n",
      "Epoch 14/50\n",
      "218/218 [==============================] - 13s 58ms/step - loss: 0.5104 - accuracy: 0.8033 - val_loss: 1.3646 - val_accuracy: 0.5220\n",
      "Epoch 15/50\n",
      "218/218 [==============================] - 13s 58ms/step - loss: 0.4881 - accuracy: 0.8086 - val_loss: 1.4190 - val_accuracy: 0.5407\n",
      "Epoch 16/50\n",
      "218/218 [==============================] - 12s 55ms/step - loss: 0.4572 - accuracy: 0.8210 - val_loss: 1.3723 - val_accuracy: 0.5487\n",
      "Epoch 17/50\n",
      "218/218 [==============================] - 12s 55ms/step - loss: 0.4372 - accuracy: 0.8322 - val_loss: 1.3327 - val_accuracy: 0.5507\n",
      "Epoch 18/50\n",
      "218/218 [==============================] - 12s 57ms/step - loss: 0.4381 - accuracy: 0.8356 - val_loss: 1.3639 - val_accuracy: 0.5567\n",
      "Epoch 19/50\n",
      "218/218 [==============================] - 12s 56ms/step - loss: 0.3862 - accuracy: 0.8524 - val_loss: 1.3644 - val_accuracy: 0.5420\n",
      "Epoch 20/50\n",
      "218/218 [==============================] - 12s 56ms/step - loss: 0.3893 - accuracy: 0.8550 - val_loss: 1.4590 - val_accuracy: 0.5553\n",
      "Epoch 21/50\n",
      "218/218 [==============================] - 13s 58ms/step - loss: 0.3786 - accuracy: 0.8557 - val_loss: 1.3858 - val_accuracy: 0.5667\n",
      "Epoch 22/50\n",
      "218/218 [==============================] - 13s 59ms/step - loss: 0.3386 - accuracy: 0.8734 - val_loss: 1.3914 - val_accuracy: 0.5733\n",
      "Epoch 23/50\n",
      "218/218 [==============================] - 13s 59ms/step - loss: 0.3323 - accuracy: 0.8740 - val_loss: 1.3145 - val_accuracy: 0.5720\n",
      "Epoch 24/50\n",
      "218/218 [==============================] - 13s 59ms/step - loss: 0.3286 - accuracy: 0.8744 - val_loss: 1.3094 - val_accuracy: 0.6080\n",
      "Epoch 25/50\n",
      "218/218 [==============================] - 13s 60ms/step - loss: 0.3066 - accuracy: 0.8878 - val_loss: 1.4073 - val_accuracy: 0.5793\n",
      "Epoch 26/50\n",
      "218/218 [==============================] - 12s 57ms/step - loss: 0.3051 - accuracy: 0.8909 - val_loss: 1.3871 - val_accuracy: 0.5913\n",
      "Epoch 27/50\n",
      "218/218 [==============================] - 12s 56ms/step - loss: 0.2881 - accuracy: 0.8930 - val_loss: 1.3602 - val_accuracy: 0.6160\n",
      "Epoch 28/50\n",
      "218/218 [==============================] - 12s 56ms/step - loss: 0.2720 - accuracy: 0.8973 - val_loss: 1.3229 - val_accuracy: 0.6153\n",
      "Epoch 29/50\n",
      "218/218 [==============================] - 12s 54ms/step - loss: 0.2623 - accuracy: 0.8994 - val_loss: 1.3240 - val_accuracy: 0.6080\n",
      "Epoch 30/50\n",
      "218/218 [==============================] - 12s 55ms/step - loss: 0.2657 - accuracy: 0.8990 - val_loss: 1.3046 - val_accuracy: 0.6260\n",
      "Epoch 31/50\n",
      "218/218 [==============================] - 12s 56ms/step - loss: 0.2652 - accuracy: 0.9009 - val_loss: 1.3566 - val_accuracy: 0.6327\n",
      "Epoch 32/50\n",
      "218/218 [==============================] - 12s 56ms/step - loss: 0.2488 - accuracy: 0.9068 - val_loss: 1.4050 - val_accuracy: 0.6167\n",
      "Epoch 33/50\n",
      "218/218 [==============================] - 12s 56ms/step - loss: 0.2458 - accuracy: 0.9091 - val_loss: 1.4294 - val_accuracy: 0.6200\n",
      "Epoch 34/50\n",
      "218/218 [==============================] - 12s 56ms/step - loss: 0.2504 - accuracy: 0.9093 - val_loss: 1.3284 - val_accuracy: 0.6380\n",
      "Epoch 35/50\n",
      "218/218 [==============================] - 12s 56ms/step - loss: 0.2337 - accuracy: 0.9118 - val_loss: 1.4038 - val_accuracy: 0.6233\n",
      "Epoch 36/50\n",
      "218/218 [==============================] - 12s 56ms/step - loss: 0.2285 - accuracy: 0.9167 - val_loss: 1.4676 - val_accuracy: 0.6167\n",
      "Epoch 37/50\n",
      "218/218 [==============================] - 12s 57ms/step - loss: 0.2317 - accuracy: 0.9135 - val_loss: 1.3826 - val_accuracy: 0.6287\n",
      "Epoch 38/50\n",
      "218/218 [==============================] - 13s 58ms/step - loss: 0.2207 - accuracy: 0.9216 - val_loss: 1.4494 - val_accuracy: 0.6380\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218/218 [==============================] - 12s 57ms/step - loss: 0.2164 - accuracy: 0.9138 - val_loss: 1.4709 - val_accuracy: 0.6253\n",
      "Epoch 40/50\n",
      "218/218 [==============================] - 12s 56ms/step - loss: 0.1985 - accuracy: 0.9272 - val_loss: 1.4464 - val_accuracy: 0.6367\n",
      "Epoch 41/50\n",
      "218/218 [==============================] - 12s 56ms/step - loss: 0.2106 - accuracy: 0.9220 - val_loss: 1.4333 - val_accuracy: 0.6333\n",
      "Epoch 42/50\n",
      "218/218 [==============================] - 12s 57ms/step - loss: 0.1852 - accuracy: 0.9295 - val_loss: 1.4612 - val_accuracy: 0.6447\n",
      "Epoch 43/50\n",
      "218/218 [==============================] - 12s 55ms/step - loss: 0.1997 - accuracy: 0.9246 - val_loss: 1.4712 - val_accuracy: 0.6347\n",
      "Epoch 44/50\n",
      "218/218 [==============================] - 12s 54ms/step - loss: 0.1953 - accuracy: 0.9319 - val_loss: 1.5512 - val_accuracy: 0.6220\n",
      "Epoch 45/50\n",
      "218/218 [==============================] - 12s 56ms/step - loss: 0.1826 - accuracy: 0.9333 - val_loss: 1.5315 - val_accuracy: 0.6240\n",
      "Epoch 46/50\n",
      "218/218 [==============================] - 12s 57ms/step - loss: 0.1882 - accuracy: 0.9326 - val_loss: 1.4804 - val_accuracy: 0.6353\n",
      "Epoch 47/50\n",
      "218/218 [==============================] - 13s 58ms/step - loss: 0.1766 - accuracy: 0.9307 - val_loss: 1.5090 - val_accuracy: 0.6227\n",
      "Epoch 48/50\n",
      "218/218 [==============================] - 13s 58ms/step - loss: 0.1926 - accuracy: 0.9303 - val_loss: 1.4401 - val_accuracy: 0.6433\n",
      "Epoch 49/50\n",
      "218/218 [==============================] - 12s 57ms/step - loss: 0.1923 - accuracy: 0.9292 - val_loss: 1.4340 - val_accuracy: 0.6420\n",
      "Epoch 50/50\n",
      "218/218 [==============================] - 12s 56ms/step - loss: 0.1788 - accuracy: 0.9332 - val_loss: 1.3943 - val_accuracy: 0.6353\n",
      "{'1000': 0.359333336353302}\n"
     ]
    }
   ],
   "source": [
    "period_accuracy={}\n",
    "for i in range(1000, 1100, 100):\n",
    "    x_train, x_valid, x_test, y_train, y_valid, y_test = data_finalize(total_number=2115, takeout_sample=375, period=i, y_test=y_test)\n",
    "\n",
    "    model_all_subs = Sequential([\n",
    "\n",
    "      # Conv. block 1\n",
    "      keras.layers.Conv2D(filters=25, kernel_size=(10,1), padding='same', activation=tf.nn.gelu, input_shape=(x_train.shape[1],1,22)),\n",
    "      keras.layers.MaxPooling2D(pool_size=(2,1), padding='same'), \n",
    "      keras.layers.BatchNormalization(),\n",
    "      keras.layers.Dropout(0.5),\n",
    "\n",
    "      # Conv. block 2\n",
    "      keras.layers.Conv2D(filters=50, kernel_size=(10,1), padding='same', activation=tf.nn.gelu),\n",
    "      keras.layers.MaxPooling2D(pool_size=(2,1), padding='same'),\n",
    "      keras.layers.BatchNormalization(),\n",
    "      keras.layers.Dropout(0.5),\n",
    "\n",
    "      # Conv. block 3\n",
    "      keras.layers.Conv2D(filters=100, kernel_size=(10,1), padding='same', activation=tf.nn.gelu),\n",
    "      keras.layers.MaxPooling2D(pool_size=(2,1), padding='same'),\n",
    "      keras.layers.BatchNormalization(),\n",
    "      keras.layers.Dropout(0.5),\n",
    "\n",
    "      # Output layer with Softmax activation\n",
    "      keras.layers.Flatten(), # Flattens the input\n",
    "      keras.layers.Dense(4, activation='softmax') # Output FC layer with softmax activation\n",
    "\n",
    "  ])\n",
    "\n",
    "  # Printing the model summary\n",
    "    model_all_subs.summary()\n",
    "\n",
    "  \n",
    "\n",
    "    model_all_subs.compile(loss='categorical_crossentropy',\n",
    "                 optimizer=cnn_optimizer,\n",
    "                 metrics=['accuracy'])\n",
    "  \n",
    "\n",
    "  # Training and validating the model\n",
    "    model_all_subs_results = model_all_subs.fit(x_train,\n",
    "              y_train,\n",
    "              batch_size=32,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_valid, y_valid), verbose=True)\n",
    "\n",
    "    val_acc = model_all_subs_results.history['val_accuracy'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of the basic CNN model: 0.5\n"
     ]
    }
   ],
   "source": [
    "cnn_score = model_all_subs.evaluate(X_test_sub1, y_test_sub1, verbose=0)\n",
    "print('Test accuracy of model_all_subs on subject 1 data:',cnn_score[1])\n",
    "# print(X_test_sub1.shape)\n",
    "# print(y_test_sub1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "WqMPuChAH1va"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1772, 500, 1, 22)\n",
      "(1772, 4)\n",
      "Test accuracy of the basic CNN model: 0.6077877879142761\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "cnn_score = model_all_subs.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test accuracy of model_all_subs on all data:',cnn_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load(\"X_test.npy\")\n",
    "y_test = np.load(\"y_test.npy\")\n",
    "X_train_valid = np.load(\"X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"y_train_valid.npy\")\n",
    "y_train_valid -= 769\n",
    "y_test -= 769"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 25, 1, 26)         5174      \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 9, 1, 26)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 9, 1, 26)         104       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 9, 1, 26)          0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 9, 1, 52)          12220     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 3, 1, 52)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 3, 1, 52)         208       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 3, 1, 52)          0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 3, 1, 104)         48776     \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 1, 1, 104)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 1, 1, 104)        416       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 1, 1, 104)         0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 1, 1, 208)         194896    \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 1, 1, 208)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 1, 1, 208)        832       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 1, 1, 208)         0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 208)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 836       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 263,462\n",
      "Trainable params: 262,682\n",
      "Non-trainable params: 780\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "218/218 [==============================] - 3s 7ms/step - loss: 1.8672 - accuracy: 0.2741 - val_loss: 1.5928 - val_accuracy: 0.2953\n",
      "Epoch 2/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.6281 - accuracy: 0.2839 - val_loss: 1.5728 - val_accuracy: 0.2833\n",
      "Epoch 3/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.5855 - accuracy: 0.2864 - val_loss: 1.5458 - val_accuracy: 0.2920\n",
      "Epoch 4/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.5472 - accuracy: 0.3193 - val_loss: 1.5275 - val_accuracy: 0.3207\n",
      "Epoch 5/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.5202 - accuracy: 0.3292 - val_loss: 1.4979 - val_accuracy: 0.3460\n",
      "Epoch 6/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 1.4943 - accuracy: 0.3382 - val_loss: 1.4715 - val_accuracy: 0.3653\n",
      "Epoch 7/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 1.4684 - accuracy: 0.3501 - val_loss: 1.4546 - val_accuracy: 0.3500\n",
      "Epoch 8/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.4486 - accuracy: 0.3586 - val_loss: 1.4357 - val_accuracy: 0.3787\n",
      "Epoch 9/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.4298 - accuracy: 0.3684 - val_loss: 1.4216 - val_accuracy: 0.3740\n",
      "Epoch 10/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 1.4180 - accuracy: 0.3740 - val_loss: 1.4259 - val_accuracy: 0.3487\n",
      "Epoch 11/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 1.4025 - accuracy: 0.3813 - val_loss: 1.4054 - val_accuracy: 0.3660\n",
      "Epoch 12/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 1.3871 - accuracy: 0.3836 - val_loss: 1.3993 - val_accuracy: 0.3733\n",
      "Epoch 13/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.3786 - accuracy: 0.3953 - val_loss: 1.3879 - val_accuracy: 0.4040\n",
      "Epoch 14/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 1.3719 - accuracy: 0.4017 - val_loss: 1.4034 - val_accuracy: 0.3867\n",
      "Epoch 15/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 1.3557 - accuracy: 0.4165 - val_loss: 1.3992 - val_accuracy: 0.4080\n",
      "Epoch 16/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 1.3472 - accuracy: 0.4236 - val_loss: 1.4086 - val_accuracy: 0.3867\n",
      "Epoch 17/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 1.3351 - accuracy: 0.4404 - val_loss: 1.3795 - val_accuracy: 0.4173\n",
      "Epoch 18/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.3333 - accuracy: 0.4441 - val_loss: 1.3888 - val_accuracy: 0.3927\n",
      "Epoch 19/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.3322 - accuracy: 0.4343 - val_loss: 1.3788 - val_accuracy: 0.4100\n",
      "Epoch 20/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.3191 - accuracy: 0.4500 - val_loss: 1.4012 - val_accuracy: 0.3753\n",
      "Epoch 21/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.3147 - accuracy: 0.4606 - val_loss: 1.3929 - val_accuracy: 0.3867\n",
      "Epoch 22/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.3059 - accuracy: 0.4626 - val_loss: 1.3798 - val_accuracy: 0.4240\n",
      "Epoch 23/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.3052 - accuracy: 0.4632 - val_loss: 1.3764 - val_accuracy: 0.4407\n",
      "Epoch 24/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.2995 - accuracy: 0.4685 - val_loss: 1.3928 - val_accuracy: 0.4100\n",
      "Epoch 25/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.2874 - accuracy: 0.4818 - val_loss: 1.3714 - val_accuracy: 0.4393\n",
      "Epoch 26/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.2886 - accuracy: 0.4807 - val_loss: 1.3836 - val_accuracy: 0.4160\n",
      "Epoch 27/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.2833 - accuracy: 0.4878 - val_loss: 1.3842 - val_accuracy: 0.4313\n",
      "Epoch 28/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.2668 - accuracy: 0.4991 - val_loss: 1.3845 - val_accuracy: 0.4247\n",
      "Epoch 29/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.2757 - accuracy: 0.4881 - val_loss: 1.3819 - val_accuracy: 0.4513\n",
      "Epoch 30/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.2723 - accuracy: 0.4931 - val_loss: 1.3764 - val_accuracy: 0.4473\n",
      "Epoch 31/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.2660 - accuracy: 0.4981 - val_loss: 1.4021 - val_accuracy: 0.4000\n",
      "Epoch 32/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.2708 - accuracy: 0.4918 - val_loss: 1.3734 - val_accuracy: 0.4453\n",
      "Epoch 33/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.2523 - accuracy: 0.5070 - val_loss: 1.3853 - val_accuracy: 0.4393\n",
      "Epoch 34/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.2594 - accuracy: 0.4989 - val_loss: 1.3918 - val_accuracy: 0.4213\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218/218 [==============================] - 1s 6ms/step - loss: 1.2551 - accuracy: 0.5056 - val_loss: 1.3888 - val_accuracy: 0.4353\n",
      "Epoch 36/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.2515 - accuracy: 0.5045 - val_loss: 1.3945 - val_accuracy: 0.4253\n",
      "Epoch 37/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.2533 - accuracy: 0.5072 - val_loss: 1.4027 - val_accuracy: 0.4353\n",
      "Epoch 38/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.2442 - accuracy: 0.5111 - val_loss: 1.3939 - val_accuracy: 0.4267\n",
      "Epoch 39/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.2397 - accuracy: 0.5109 - val_loss: 1.4010 - val_accuracy: 0.4193\n",
      "Epoch 40/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.2525 - accuracy: 0.5073 - val_loss: 1.4177 - val_accuracy: 0.4247\n",
      "Epoch 41/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.2350 - accuracy: 0.5247 - val_loss: 1.4236 - val_accuracy: 0.4453\n",
      "Epoch 42/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.2381 - accuracy: 0.5228 - val_loss: 1.4156 - val_accuracy: 0.4187\n",
      "Epoch 43/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.2291 - accuracy: 0.5241 - val_loss: 1.4261 - val_accuracy: 0.4240\n",
      "Epoch 44/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.2285 - accuracy: 0.5221 - val_loss: 1.4148 - val_accuracy: 0.4307\n",
      "Epoch 45/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.2346 - accuracy: 0.5228 - val_loss: 1.3916 - val_accuracy: 0.4407\n",
      "Epoch 46/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.2316 - accuracy: 0.5234 - val_loss: 1.4052 - val_accuracy: 0.4373\n",
      "Epoch 47/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.2288 - accuracy: 0.5250 - val_loss: 1.3885 - val_accuracy: 0.4520\n",
      "Epoch 48/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.2319 - accuracy: 0.5287 - val_loss: 1.4068 - val_accuracy: 0.4347\n",
      "Epoch 49/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.2175 - accuracy: 0.5349 - val_loss: 1.4170 - val_accuracy: 0.4240\n",
      "Epoch 50/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 1.2209 - accuracy: 0.5297 - val_loss: 1.4334 - val_accuracy: 0.4373\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.9745 - accuracy: 0.6889\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 1.4603 - accuracy: 0.4238\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_10 (Conv2D)          (None, 50, 1, 26)         5174      \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 17, 1, 26)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 17, 1, 26)        104       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 17, 1, 26)         0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 17, 1, 52)         12220     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 6, 1, 52)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 6, 1, 52)         208       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 6, 1, 52)          0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 6, 1, 104)         48776     \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 2, 1, 104)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 2, 1, 104)        416       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 2, 1, 104)         0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 2, 1, 208)         194896    \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 1, 1, 208)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 1, 1, 208)        832       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 1, 1, 208)         0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 208)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 836       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 263,462\n",
      "Trainable params: 262,682\n",
      "Non-trainable params: 780\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "218/218 [==============================] - 3s 9ms/step - loss: 1.9898 - accuracy: 0.2749 - val_loss: 1.7414 - val_accuracy: 0.2760\n",
      "Epoch 2/50\n",
      "218/218 [==============================] - 2s 8ms/step - loss: 1.7446 - accuracy: 0.2914 - val_loss: 1.6735 - val_accuracy: 0.2840\n",
      "Epoch 3/50\n",
      "218/218 [==============================] - 2s 8ms/step - loss: 1.6742 - accuracy: 0.3027 - val_loss: 1.6403 - val_accuracy: 0.3007\n",
      "Epoch 4/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 1.6294 - accuracy: 0.3259 - val_loss: 1.5922 - val_accuracy: 0.3233\n",
      "Epoch 5/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 1.5756 - accuracy: 0.3463 - val_loss: 1.5858 - val_accuracy: 0.3120\n",
      "Epoch 6/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 1.5308 - accuracy: 0.3658 - val_loss: 1.5308 - val_accuracy: 0.3680\n",
      "Epoch 7/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 1.4974 - accuracy: 0.3839 - val_loss: 1.5110 - val_accuracy: 0.3660\n",
      "Epoch 8/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 1.4646 - accuracy: 0.4076 - val_loss: 1.4882 - val_accuracy: 0.3693\n",
      "Epoch 9/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 1.4419 - accuracy: 0.4203 - val_loss: 1.4665 - val_accuracy: 0.4040\n",
      "Epoch 10/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 1.4146 - accuracy: 0.4451 - val_loss: 1.4269 - val_accuracy: 0.4287\n",
      "Epoch 11/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 1.3919 - accuracy: 0.4569 - val_loss: 1.4267 - val_accuracy: 0.4360\n",
      "Epoch 12/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 1.3733 - accuracy: 0.4737 - val_loss: 1.3770 - val_accuracy: 0.4707\n",
      "Epoch 13/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 1.3462 - accuracy: 0.4864 - val_loss: 1.3899 - val_accuracy: 0.4627\n",
      "Epoch 14/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 1.3249 - accuracy: 0.4981 - val_loss: 1.3336 - val_accuracy: 0.4900\n",
      "Epoch 15/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 1.3134 - accuracy: 0.5057 - val_loss: 1.3572 - val_accuracy: 0.4760\n",
      "Epoch 16/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 1.2865 - accuracy: 0.5241 - val_loss: 1.3279 - val_accuracy: 0.4960\n",
      "Epoch 17/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 1.2773 - accuracy: 0.5386 - val_loss: 1.3655 - val_accuracy: 0.4647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 1.2591 - accuracy: 0.5494 - val_loss: 1.3262 - val_accuracy: 0.4940\n",
      "Epoch 19/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 1.2450 - accuracy: 0.5585 - val_loss: 1.3483 - val_accuracy: 0.4893\n",
      "Epoch 20/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 1.2403 - accuracy: 0.5602 - val_loss: 1.3684 - val_accuracy: 0.5053\n",
      "Epoch 21/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 1.2364 - accuracy: 0.5644 - val_loss: 1.3224 - val_accuracy: 0.5093\n",
      "Epoch 22/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 1.2311 - accuracy: 0.5668 - val_loss: 1.3956 - val_accuracy: 0.4867\n",
      "Epoch 23/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 1.2151 - accuracy: 0.5776 - val_loss: 1.3329 - val_accuracy: 0.5080\n",
      "Epoch 24/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 1.2104 - accuracy: 0.5790 - val_loss: 1.3440 - val_accuracy: 0.4960\n",
      "Epoch 25/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 1.2147 - accuracy: 0.5815 - val_loss: 1.3345 - val_accuracy: 0.5033\n",
      "Epoch 26/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 1.1995 - accuracy: 0.5917 - val_loss: 1.3451 - val_accuracy: 0.4960\n",
      "Epoch 27/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 1.1903 - accuracy: 0.6027 - val_loss: 1.3093 - val_accuracy: 0.5193\n",
      "Epoch 28/50\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 1.1922 - accuracy: 0.6024 - val_loss: 1.3490 - val_accuracy: 0.4993\n",
      "Epoch 29/50\n",
      "218/218 [==============================] - 2s 10ms/step - loss: 1.1815 - accuracy: 0.5984 - val_loss: 1.3368 - val_accuracy: 0.5280\n",
      "Epoch 30/50\n",
      "218/218 [==============================] - 2s 10ms/step - loss: 1.1806 - accuracy: 0.6024 - val_loss: 1.3669 - val_accuracy: 0.5020\n",
      "Epoch 31/50\n",
      "218/218 [==============================] - 2s 10ms/step - loss: 1.1751 - accuracy: 0.6078 - val_loss: 1.3589 - val_accuracy: 0.5013\n",
      "Epoch 32/50\n",
      "218/218 [==============================] - 2s 10ms/step - loss: 1.1666 - accuracy: 0.6119 - val_loss: 1.3286 - val_accuracy: 0.5153\n",
      "Epoch 33/50\n",
      "218/218 [==============================] - 2s 10ms/step - loss: 1.1633 - accuracy: 0.6227 - val_loss: 1.3582 - val_accuracy: 0.5147\n",
      "Epoch 34/50\n",
      "218/218 [==============================] - 2s 10ms/step - loss: 1.1635 - accuracy: 0.6138 - val_loss: 1.3362 - val_accuracy: 0.5220\n",
      "Epoch 35/50\n",
      "218/218 [==============================] - 2s 10ms/step - loss: 1.1433 - accuracy: 0.6279 - val_loss: 1.3463 - val_accuracy: 0.5293\n",
      "Epoch 36/50\n",
      "218/218 [==============================] - 2s 10ms/step - loss: 1.1571 - accuracy: 0.6213 - val_loss: 1.3651 - val_accuracy: 0.5280\n",
      "Epoch 37/50\n",
      "218/218 [==============================] - 2s 10ms/step - loss: 1.1450 - accuracy: 0.6260 - val_loss: 1.3393 - val_accuracy: 0.5327\n",
      "Epoch 38/50\n",
      "218/218 [==============================] - 2s 10ms/step - loss: 1.1450 - accuracy: 0.6263 - val_loss: 1.3415 - val_accuracy: 0.5213\n",
      "Epoch 39/50\n",
      "218/218 [==============================] - 2s 10ms/step - loss: 1.1438 - accuracy: 0.6338 - val_loss: 1.3753 - val_accuracy: 0.5287\n",
      "Epoch 40/50\n",
      "218/218 [==============================] - 2s 10ms/step - loss: 1.1317 - accuracy: 0.6412 - val_loss: 1.3691 - val_accuracy: 0.5307\n",
      "Epoch 41/50\n",
      "218/218 [==============================] - 2s 10ms/step - loss: 1.1358 - accuracy: 0.6346 - val_loss: 1.3656 - val_accuracy: 0.5453\n",
      "Epoch 42/50\n",
      "218/218 [==============================] - 2s 10ms/step - loss: 1.1426 - accuracy: 0.6422 - val_loss: 1.3916 - val_accuracy: 0.5280\n",
      "Epoch 43/50\n",
      "218/218 [==============================] - 2s 10ms/step - loss: 1.1276 - accuracy: 0.6415 - val_loss: 1.3857 - val_accuracy: 0.5427\n",
      "Epoch 44/50\n",
      "218/218 [==============================] - 2s 10ms/step - loss: 1.1284 - accuracy: 0.6358 - val_loss: 1.3721 - val_accuracy: 0.5200\n",
      "Epoch 45/50\n",
      "218/218 [==============================] - 2s 10ms/step - loss: 1.1367 - accuracy: 0.6399 - val_loss: 1.3898 - val_accuracy: 0.5213\n",
      "Epoch 46/50\n",
      "218/218 [==============================] - 2s 10ms/step - loss: 1.1228 - accuracy: 0.6438 - val_loss: 1.3991 - val_accuracy: 0.5247\n",
      "Epoch 47/50\n",
      "218/218 [==============================] - 2s 10ms/step - loss: 1.1363 - accuracy: 0.6366 - val_loss: 1.3389 - val_accuracy: 0.5360\n",
      "Epoch 48/50\n",
      "218/218 [==============================] - 2s 10ms/step - loss: 1.1138 - accuracy: 0.6464 - val_loss: 1.3388 - val_accuracy: 0.5367\n",
      "Epoch 49/50\n",
      "218/218 [==============================] - 2s 10ms/step - loss: 1.1160 - accuracy: 0.6448 - val_loss: 1.3563 - val_accuracy: 0.5287\n",
      "Epoch 50/50\n",
      "218/218 [==============================] - 2s 10ms/step - loss: 1.1205 - accuracy: 0.6444 - val_loss: 1.3822 - val_accuracy: 0.5373\n",
      "218/218 [==============================] - 1s 2ms/step - loss: 0.7598 - accuracy: 0.8398\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 1.3915 - accuracy: 0.5175\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_14 (Conv2D)          (None, 75, 1, 26)         5174      \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 25, 1, 26)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 25, 1, 26)        104       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 25, 1, 26)         0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 25, 1, 52)         12220     \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 9, 1, 52)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 9, 1, 52)         208       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 9, 1, 52)          0         \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 9, 1, 104)         48776     \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 3, 1, 104)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 3, 1, 104)        416       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 3, 1, 104)         0         \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 3, 1, 208)         194896    \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 1, 1, 208)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 1, 1, 208)        832       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 1, 1, 208)         0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 208)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4)                 836       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 263,462\n",
      "Trainable params: 262,682\n",
      "Non-trainable params: 780\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "218/218 [==============================] - 4s 12ms/step - loss: 2.0462 - accuracy: 0.2922 - val_loss: 1.7912 - val_accuracy: 0.3033\n",
      "Epoch 2/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.7830 - accuracy: 0.3249 - val_loss: 1.7038 - val_accuracy: 0.3380\n",
      "Epoch 3/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.7005 - accuracy: 0.3486 - val_loss: 1.6581 - val_accuracy: 0.3687\n",
      "Epoch 4/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.6382 - accuracy: 0.3672 - val_loss: 1.5972 - val_accuracy: 0.3713\n",
      "Epoch 5/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.5813 - accuracy: 0.3934 - val_loss: 1.5572 - val_accuracy: 0.3693\n",
      "Epoch 6/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.5247 - accuracy: 0.4239 - val_loss: 1.5078 - val_accuracy: 0.4153\n",
      "Epoch 7/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.4869 - accuracy: 0.4376 - val_loss: 1.4938 - val_accuracy: 0.3873\n",
      "Epoch 8/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.4362 - accuracy: 0.4680 - val_loss: 1.4164 - val_accuracy: 0.4793\n",
      "Epoch 9/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.3988 - accuracy: 0.4881 - val_loss: 1.4106 - val_accuracy: 0.4873\n",
      "Epoch 10/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.3769 - accuracy: 0.4915 - val_loss: 1.3860 - val_accuracy: 0.4653\n",
      "Epoch 11/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.3351 - accuracy: 0.5198 - val_loss: 1.3712 - val_accuracy: 0.4727\n",
      "Epoch 12/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.3193 - accuracy: 0.5333 - val_loss: 1.3041 - val_accuracy: 0.5327\n",
      "Epoch 13/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.3063 - accuracy: 0.5409 - val_loss: 1.3224 - val_accuracy: 0.5227\n",
      "Epoch 14/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.2800 - accuracy: 0.5552 - val_loss: 1.2809 - val_accuracy: 0.5520\n",
      "Epoch 15/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.2749 - accuracy: 0.5655 - val_loss: 1.3135 - val_accuracy: 0.5353\n",
      "Epoch 16/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.2618 - accuracy: 0.5728 - val_loss: 1.3243 - val_accuracy: 0.5400\n",
      "Epoch 17/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.2430 - accuracy: 0.5894 - val_loss: 1.2777 - val_accuracy: 0.5693\n",
      "Epoch 18/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.2382 - accuracy: 0.5915 - val_loss: 1.2971 - val_accuracy: 0.5273\n",
      "Epoch 19/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.2205 - accuracy: 0.5981 - val_loss: 1.3609 - val_accuracy: 0.5313\n",
      "Epoch 20/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.2219 - accuracy: 0.6011 - val_loss: 1.2743 - val_accuracy: 0.5693\n",
      "Epoch 21/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.2071 - accuracy: 0.6116 - val_loss: 1.3132 - val_accuracy: 0.5480\n",
      "Epoch 22/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.1892 - accuracy: 0.6233 - val_loss: 1.3095 - val_accuracy: 0.5520\n",
      "Epoch 23/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.1765 - accuracy: 0.6296 - val_loss: 1.2763 - val_accuracy: 0.5673\n",
      "Epoch 24/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.1876 - accuracy: 0.6312 - val_loss: 1.3373 - val_accuracy: 0.5380\n",
      "Epoch 25/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.1736 - accuracy: 0.6361 - val_loss: 1.2744 - val_accuracy: 0.5833\n",
      "Epoch 26/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.1703 - accuracy: 0.6397 - val_loss: 1.3018 - val_accuracy: 0.5780\n",
      "Epoch 27/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.1584 - accuracy: 0.6440 - val_loss: 1.3376 - val_accuracy: 0.5640\n",
      "Epoch 28/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.1484 - accuracy: 0.6545 - val_loss: 1.3095 - val_accuracy: 0.5687\n",
      "Epoch 29/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.1434 - accuracy: 0.6608 - val_loss: 1.2847 - val_accuracy: 0.5673\n",
      "Epoch 30/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.1451 - accuracy: 0.6601 - val_loss: 1.3143 - val_accuracy: 0.5600\n",
      "Epoch 31/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.1285 - accuracy: 0.6639 - val_loss: 1.3720 - val_accuracy: 0.5420\n",
      "Epoch 32/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.1482 - accuracy: 0.6545 - val_loss: 1.2970 - val_accuracy: 0.5593\n",
      "Epoch 33/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.1427 - accuracy: 0.6595 - val_loss: 1.3396 - val_accuracy: 0.5760\n",
      "Epoch 34/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.1375 - accuracy: 0.6658 - val_loss: 1.3186 - val_accuracy: 0.5740\n",
      "Epoch 35/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.1161 - accuracy: 0.6750 - val_loss: 1.3748 - val_accuracy: 0.5707\n",
      "Epoch 36/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.1088 - accuracy: 0.6792 - val_loss: 1.3261 - val_accuracy: 0.5627\n",
      "Epoch 37/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.1143 - accuracy: 0.6760 - val_loss: 1.3259 - val_accuracy: 0.5660\n",
      "Epoch 38/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.1252 - accuracy: 0.6655 - val_loss: 1.3149 - val_accuracy: 0.5680\n",
      "Epoch 39/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.1360 - accuracy: 0.6723 - val_loss: 1.2925 - val_accuracy: 0.5953\n",
      "Epoch 40/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.1111 - accuracy: 0.6809 - val_loss: 1.3190 - val_accuracy: 0.5800\n",
      "Epoch 41/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.1185 - accuracy: 0.6809 - val_loss: 1.3275 - val_accuracy: 0.5907\n",
      "Epoch 42/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.1113 - accuracy: 0.6833 - val_loss: 1.3054 - val_accuracy: 0.6060\n",
      "Epoch 43/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.0949 - accuracy: 0.6897 - val_loss: 1.3459 - val_accuracy: 0.5713\n",
      "Epoch 44/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.1019 - accuracy: 0.6922 - val_loss: 1.2938 - val_accuracy: 0.6067\n",
      "Epoch 45/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.1006 - accuracy: 0.6925 - val_loss: 1.3487 - val_accuracy: 0.5740\n",
      "Epoch 46/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.0950 - accuracy: 0.6960 - val_loss: 1.2634 - val_accuracy: 0.6080\n",
      "Epoch 47/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.0723 - accuracy: 0.7053 - val_loss: 1.3079 - val_accuracy: 0.6000\n",
      "Epoch 48/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.0809 - accuracy: 0.6983 - val_loss: 1.3076 - val_accuracy: 0.5973\n",
      "Epoch 49/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.0867 - accuracy: 0.7000 - val_loss: 1.3585 - val_accuracy: 0.5873\n",
      "Epoch 50/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 1.0780 - accuracy: 0.7020 - val_loss: 1.3454 - val_accuracy: 0.5800\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.6653 - accuracy: 0.9210\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 1.3790 - accuracy: 0.5666\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_18 (Conv2D)          (None, 100, 1, 26)        5174      \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 34, 1, 26)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 34, 1, 26)        104       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 34, 1, 26)         0         \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv2d_19 (Conv2D)          (None, 34, 1, 52)         12220     \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 12, 1, 52)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 12, 1, 52)        208       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 12, 1, 52)         0         \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 12, 1, 104)        48776     \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 4, 1, 104)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 4, 1, 104)        416       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 4, 1, 104)         0         \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 4, 1, 208)         194896    \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 2, 1, 208)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 2, 1, 208)        832       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 2, 1, 208)         0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 416)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 4)                 1668      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 264,294\n",
      "Trainable params: 263,514\n",
      "Non-trainable params: 780\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "218/218 [==============================] - 4s 14ms/step - loss: 2.2273 - accuracy: 0.2950 - val_loss: 1.9470 - val_accuracy: 0.3153\n",
      "Epoch 2/50\n",
      "218/218 [==============================] - 3s 13ms/step - loss: 1.8740 - accuracy: 0.3378 - val_loss: 1.7619 - val_accuracy: 0.3733\n",
      "Epoch 3/50\n",
      "218/218 [==============================] - 3s 13ms/step - loss: 1.7596 - accuracy: 0.3651 - val_loss: 1.7175 - val_accuracy: 0.3787\n",
      "Epoch 4/50\n",
      "218/218 [==============================] - 3s 13ms/step - loss: 1.6608 - accuracy: 0.4076 - val_loss: 1.6241 - val_accuracy: 0.4067\n",
      "Epoch 5/50\n",
      "218/218 [==============================] - 3s 13ms/step - loss: 1.5922 - accuracy: 0.4332 - val_loss: 1.5680 - val_accuracy: 0.4400\n",
      "Epoch 6/50\n",
      "218/218 [==============================] - 3s 13ms/step - loss: 1.5202 - accuracy: 0.4665 - val_loss: 1.5608 - val_accuracy: 0.4027\n",
      "Epoch 7/50\n",
      "218/218 [==============================] - 3s 13ms/step - loss: 1.4666 - accuracy: 0.4718 - val_loss: 1.4958 - val_accuracy: 0.4607\n",
      "Epoch 8/50\n",
      "218/218 [==============================] - 3s 13ms/step - loss: 1.4282 - accuracy: 0.4951 - val_loss: 1.4377 - val_accuracy: 0.4793\n",
      "Epoch 9/50\n",
      "218/218 [==============================] - 3s 13ms/step - loss: 1.3849 - accuracy: 0.5161 - val_loss: 1.4704 - val_accuracy: 0.4680\n",
      "Epoch 10/50\n",
      "218/218 [==============================] - 3s 13ms/step - loss: 1.3586 - accuracy: 0.5335 - val_loss: 1.4233 - val_accuracy: 0.4987\n",
      "Epoch 11/50\n",
      "218/218 [==============================] - 3s 13ms/step - loss: 1.3258 - accuracy: 0.5526 - val_loss: 1.3849 - val_accuracy: 0.5140\n",
      "Epoch 12/50\n",
      "218/218 [==============================] - 3s 13ms/step - loss: 1.2973 - accuracy: 0.5737 - val_loss: 1.3617 - val_accuracy: 0.5313\n",
      "Epoch 13/50\n",
      "218/218 [==============================] - 3s 13ms/step - loss: 1.2657 - accuracy: 0.5851 - val_loss: 1.3814 - val_accuracy: 0.5107\n",
      "Epoch 14/50\n",
      "218/218 [==============================] - 3s 13ms/step - loss: 1.2560 - accuracy: 0.5876 - val_loss: 1.3776 - val_accuracy: 0.5287\n",
      "Epoch 15/50\n",
      "218/218 [==============================] - 3s 14ms/step - loss: 1.2365 - accuracy: 0.6032 - val_loss: 1.3709 - val_accuracy: 0.5420\n",
      "Epoch 16/50\n",
      "218/218 [==============================] - 3s 14ms/step - loss: 1.2164 - accuracy: 0.6155 - val_loss: 1.3688 - val_accuracy: 0.5307\n",
      "Epoch 17/50\n",
      "218/218 [==============================] - 3s 14ms/step - loss: 1.2019 - accuracy: 0.6322 - val_loss: 1.3535 - val_accuracy: 0.5547\n",
      "Epoch 18/50\n",
      "218/218 [==============================] - 3s 14ms/step - loss: 1.1891 - accuracy: 0.6323 - val_loss: 1.3991 - val_accuracy: 0.5380\n",
      "Epoch 19/50\n",
      "218/218 [==============================] - 3s 14ms/step - loss: 1.1752 - accuracy: 0.6404 - val_loss: 1.3866 - val_accuracy: 0.5387\n",
      "Epoch 20/50\n",
      "218/218 [==============================] - 3s 14ms/step - loss: 1.1521 - accuracy: 0.6589 - val_loss: 1.3481 - val_accuracy: 0.5613\n",
      "Epoch 21/50\n",
      "218/218 [==============================] - 3s 14ms/step - loss: 1.1562 - accuracy: 0.6557 - val_loss: 1.3491 - val_accuracy: 0.5560\n",
      "Epoch 22/50\n",
      "218/218 [==============================] - 3s 14ms/step - loss: 1.1526 - accuracy: 0.6628 - val_loss: 1.3538 - val_accuracy: 0.5747\n",
      "Epoch 23/50\n",
      "218/218 [==============================] - 3s 14ms/step - loss: 1.1315 - accuracy: 0.6759 - val_loss: 1.3578 - val_accuracy: 0.5867\n",
      "Epoch 24/50\n",
      "218/218 [==============================] - 3s 14ms/step - loss: 1.1219 - accuracy: 0.6764 - val_loss: 1.3431 - val_accuracy: 0.6027\n",
      "Epoch 25/50\n",
      "218/218 [==============================] - 3s 14ms/step - loss: 1.1210 - accuracy: 0.6853 - val_loss: 1.3296 - val_accuracy: 0.6040\n",
      "Epoch 26/50\n",
      "218/218 [==============================] - 3s 14ms/step - loss: 1.1199 - accuracy: 0.6799 - val_loss: 1.3183 - val_accuracy: 0.6007\n",
      "Epoch 27/50\n",
      "218/218 [==============================] - 3s 14ms/step - loss: 1.0935 - accuracy: 0.6967 - val_loss: 1.3801 - val_accuracy: 0.5793\n",
      "Epoch 28/50\n",
      "218/218 [==============================] - 3s 14ms/step - loss: 1.0992 - accuracy: 0.6918 - val_loss: 1.3687 - val_accuracy: 0.5920\n",
      "Epoch 29/50\n",
      "218/218 [==============================] - 3s 14ms/step - loss: 1.0937 - accuracy: 0.6991 - val_loss: 1.3523 - val_accuracy: 0.5987\n",
      "Epoch 30/50\n",
      "218/218 [==============================] - 3s 14ms/step - loss: 1.0746 - accuracy: 0.7124 - val_loss: 1.3830 - val_accuracy: 0.5960\n",
      "Epoch 31/50\n",
      "218/218 [==============================] - 3s 14ms/step - loss: 1.0902 - accuracy: 0.7003 - val_loss: 1.3713 - val_accuracy: 0.6013\n",
      "Epoch 32/50\n",
      "218/218 [==============================] - 3s 14ms/step - loss: 1.0673 - accuracy: 0.7121 - val_loss: 1.3250 - val_accuracy: 0.6213\n",
      "Epoch 33/50\n",
      "218/218 [==============================] - 3s 14ms/step - loss: 1.0749 - accuracy: 0.7118 - val_loss: 1.3078 - val_accuracy: 0.6107\n",
      "Epoch 34/50\n",
      "218/218 [==============================] - 3s 14ms/step - loss: 1.0777 - accuracy: 0.7116 - val_loss: 1.3945 - val_accuracy: 0.5820\n",
      "Epoch 35/50\n",
      "218/218 [==============================] - 3s 14ms/step - loss: 1.0580 - accuracy: 0.7223 - val_loss: 1.3749 - val_accuracy: 0.5960\n",
      "Epoch 36/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 1.0647 - accuracy: 0.7148 - val_loss: 1.2886 - val_accuracy: 0.6307\n",
      "Epoch 37/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 1.0411 - accuracy: 0.7322 - val_loss: 1.3556 - val_accuracy: 0.5927\n",
      "Epoch 38/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 1.0442 - accuracy: 0.7320 - val_loss: 1.3607 - val_accuracy: 0.6153\n",
      "Epoch 39/50\n",
      "218/218 [==============================] - 3s 14ms/step - loss: 1.0422 - accuracy: 0.7348 - val_loss: 1.3575 - val_accuracy: 0.6053\n",
      "Epoch 40/50\n",
      "218/218 [==============================] - 3s 14ms/step - loss: 1.0502 - accuracy: 0.7341 - val_loss: 1.3159 - val_accuracy: 0.6253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "218/218 [==============================] - 3s 13ms/step - loss: 1.0247 - accuracy: 0.7424 - val_loss: 1.3101 - val_accuracy: 0.6287\n",
      "Epoch 42/50\n",
      "218/218 [==============================] - 3s 13ms/step - loss: 1.0432 - accuracy: 0.7343 - val_loss: 1.3207 - val_accuracy: 0.6340\n",
      "Epoch 43/50\n",
      "218/218 [==============================] - 3s 13ms/step - loss: 1.0254 - accuracy: 0.7434 - val_loss: 1.3426 - val_accuracy: 0.6073\n",
      "Epoch 44/50\n",
      "218/218 [==============================] - 3s 13ms/step - loss: 1.0168 - accuracy: 0.7468 - val_loss: 1.3352 - val_accuracy: 0.6307\n",
      "Epoch 45/50\n",
      "218/218 [==============================] - 3s 13ms/step - loss: 1.0267 - accuracy: 0.7378 - val_loss: 1.3513 - val_accuracy: 0.6173\n",
      "Epoch 46/50\n",
      "218/218 [==============================] - 3s 13ms/step - loss: 1.0352 - accuracy: 0.7361 - val_loss: 1.3392 - val_accuracy: 0.6293\n",
      "Epoch 47/50\n",
      "218/218 [==============================] - 3s 13ms/step - loss: 1.0261 - accuracy: 0.7392 - val_loss: 1.2893 - val_accuracy: 0.6393\n",
      "Epoch 48/50\n",
      "218/218 [==============================] - 3s 13ms/step - loss: 1.0285 - accuracy: 0.7397 - val_loss: 1.2897 - val_accuracy: 0.6433\n",
      "Epoch 49/50\n",
      "218/218 [==============================] - 3s 13ms/step - loss: 1.0106 - accuracy: 0.7527 - val_loss: 1.3601 - val_accuracy: 0.6100\n",
      "Epoch 50/50\n",
      "218/218 [==============================] - 3s 13ms/step - loss: 0.9991 - accuracy: 0.7537 - val_loss: 1.3458 - val_accuracy: 0.6240\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.6050 - accuracy: 0.9543\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 1.4079 - accuracy: 0.6140\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_22 (Conv2D)          (None, 125, 1, 26)        5174      \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 42, 1, 26)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_22 (Bat  (None, 42, 1, 26)        104       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 42, 1, 26)         0         \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 42, 1, 52)         12220     \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 14, 1, 52)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_23 (Bat  (None, 14, 1, 52)        208       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 14, 1, 52)         0         \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 14, 1, 104)        48776     \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPoolin  (None, 5, 1, 104)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_24 (Bat  (None, 5, 1, 104)        416       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 5, 1, 104)         0         \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 5, 1, 208)         194896    \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPoolin  (None, 2, 1, 208)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_25 (Bat  (None, 2, 1, 208)        832       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 2, 1, 208)         0         \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 416)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 4)                 1668      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 264,294\n",
      "Trainable params: 263,514\n",
      "Non-trainable params: 780\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "218/218 [==============================] - 5s 16ms/step - loss: 2.3245 - accuracy: 0.2904 - val_loss: 1.9292 - val_accuracy: 0.3180\n",
      "Epoch 2/50\n",
      "218/218 [==============================] - 3s 16ms/step - loss: 1.9315 - accuracy: 0.3395 - val_loss: 1.8164 - val_accuracy: 0.3440\n",
      "Epoch 3/50\n",
      "218/218 [==============================] - 3s 16ms/step - loss: 1.7712 - accuracy: 0.3920 - val_loss: 1.7092 - val_accuracy: 0.4193\n",
      "Epoch 4/50\n",
      "218/218 [==============================] - 4s 19ms/step - loss: 1.6498 - accuracy: 0.4302 - val_loss: 1.6207 - val_accuracy: 0.4373\n",
      "Epoch 5/50\n",
      "218/218 [==============================] - 4s 18ms/step - loss: 1.5419 - accuracy: 0.4731 - val_loss: 1.5801 - val_accuracy: 0.4440\n",
      "Epoch 6/50\n",
      "218/218 [==============================] - 4s 19ms/step - loss: 1.4613 - accuracy: 0.5185 - val_loss: 1.4923 - val_accuracy: 0.5247\n",
      "Epoch 7/50\n",
      "218/218 [==============================] - 4s 17ms/step - loss: 1.3966 - accuracy: 0.5316 - val_loss: 1.4604 - val_accuracy: 0.5213\n",
      "Epoch 8/50\n",
      "218/218 [==============================] - 4s 16ms/step - loss: 1.3309 - accuracy: 0.5677 - val_loss: 1.3893 - val_accuracy: 0.5507\n",
      "Epoch 9/50\n",
      "218/218 [==============================] - 4s 17ms/step - loss: 1.2917 - accuracy: 0.5874 - val_loss: 1.3993 - val_accuracy: 0.5480\n",
      "Epoch 10/50\n",
      "218/218 [==============================] - 4s 16ms/step - loss: 1.2535 - accuracy: 0.6055 - val_loss: 1.3837 - val_accuracy: 0.5633\n",
      "Epoch 11/50\n",
      "218/218 [==============================] - 4s 16ms/step - loss: 1.2373 - accuracy: 0.6101 - val_loss: 1.3547 - val_accuracy: 0.5427\n",
      "Epoch 12/50\n",
      "218/218 [==============================] - 4s 16ms/step - loss: 1.2109 - accuracy: 0.6315 - val_loss: 1.3320 - val_accuracy: 0.5667\n",
      "Epoch 13/50\n",
      "218/218 [==============================] - 4s 16ms/step - loss: 1.1702 - accuracy: 0.6486 - val_loss: 1.3158 - val_accuracy: 0.6200\n",
      "Epoch 14/50\n",
      "218/218 [==============================] - 4s 16ms/step - loss: 1.1667 - accuracy: 0.6588 - val_loss: 1.3050 - val_accuracy: 0.5913\n",
      "Epoch 15/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 1.1360 - accuracy: 0.6671 - val_loss: 1.3490 - val_accuracy: 0.5793\n",
      "Epoch 16/50\n",
      "218/218 [==============================] - 3s 16ms/step - loss: 1.1288 - accuracy: 0.6739 - val_loss: 1.3573 - val_accuracy: 0.5893\n",
      "Epoch 17/50\n",
      "218/218 [==============================] - 3s 16ms/step - loss: 1.1211 - accuracy: 0.6822 - val_loss: 1.3137 - val_accuracy: 0.6067\n",
      "Epoch 18/50\n",
      "218/218 [==============================] - 3s 16ms/step - loss: 1.0986 - accuracy: 0.6924 - val_loss: 1.3586 - val_accuracy: 0.6233\n",
      "Epoch 19/50\n",
      "218/218 [==============================] - 3s 16ms/step - loss: 1.1044 - accuracy: 0.6928 - val_loss: 1.2963 - val_accuracy: 0.6233\n",
      "Epoch 20/50\n",
      "218/218 [==============================] - 3s 16ms/step - loss: 1.0789 - accuracy: 0.7121 - val_loss: 1.2375 - val_accuracy: 0.6513\n",
      "Epoch 21/50\n",
      "218/218 [==============================] - 3s 16ms/step - loss: 1.0631 - accuracy: 0.7194 - val_loss: 1.3145 - val_accuracy: 0.6233\n",
      "Epoch 22/50\n",
      "218/218 [==============================] - 3s 16ms/step - loss: 1.0586 - accuracy: 0.7241 - val_loss: 1.3538 - val_accuracy: 0.6100\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218/218 [==============================] - 3s 16ms/step - loss: 1.0634 - accuracy: 0.7198 - val_loss: 1.3124 - val_accuracy: 0.6287\n",
      "Epoch 24/50\n",
      "218/218 [==============================] - 3s 16ms/step - loss: 1.0348 - accuracy: 0.7389 - val_loss: 1.3223 - val_accuracy: 0.6173\n",
      "Epoch 25/50\n",
      "218/218 [==============================] - 3s 16ms/step - loss: 1.0260 - accuracy: 0.7356 - val_loss: 1.2631 - val_accuracy: 0.6467\n",
      "Epoch 26/50\n",
      "218/218 [==============================] - 3s 16ms/step - loss: 1.0340 - accuracy: 0.7392 - val_loss: 1.2438 - val_accuracy: 0.6467\n",
      "Epoch 27/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 1.0167 - accuracy: 0.7447 - val_loss: 1.2499 - val_accuracy: 0.6540\n",
      "Epoch 28/50\n",
      "218/218 [==============================] - 3s 16ms/step - loss: 1.0267 - accuracy: 0.7476 - val_loss: 1.2796 - val_accuracy: 0.6553\n",
      "Epoch 29/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 1.0344 - accuracy: 0.7398 - val_loss: 1.2659 - val_accuracy: 0.6500\n",
      "Epoch 30/50\n",
      "218/218 [==============================] - 3s 16ms/step - loss: 1.0090 - accuracy: 0.7464 - val_loss: 1.3006 - val_accuracy: 0.6427\n",
      "Epoch 31/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 0.9980 - accuracy: 0.7573 - val_loss: 1.3550 - val_accuracy: 0.6227\n",
      "Epoch 32/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 1.0088 - accuracy: 0.7504 - val_loss: 1.2855 - val_accuracy: 0.6320\n",
      "Epoch 33/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 1.0003 - accuracy: 0.7593 - val_loss: 1.2748 - val_accuracy: 0.6547\n",
      "Epoch 34/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 1.0099 - accuracy: 0.7559 - val_loss: 1.2765 - val_accuracy: 0.6533\n",
      "Epoch 35/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 0.9890 - accuracy: 0.7668 - val_loss: 1.3338 - val_accuracy: 0.6393\n",
      "Epoch 36/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 0.9947 - accuracy: 0.7616 - val_loss: 1.3028 - val_accuracy: 0.6580\n",
      "Epoch 37/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 1.0010 - accuracy: 0.7631 - val_loss: 1.3051 - val_accuracy: 0.6560\n",
      "Epoch 38/50\n",
      "218/218 [==============================] - 3s 15ms/step - loss: 0.9776 - accuracy: 0.7723 - val_loss: 1.3495 - val_accuracy: 0.6360\n",
      "Epoch 39/50\n",
      "218/218 [==============================] - 3s 16ms/step - loss: 0.9786 - accuracy: 0.7713 - val_loss: 1.3254 - val_accuracy: 0.6513\n",
      "Epoch 40/50\n",
      "218/218 [==============================] - 3s 16ms/step - loss: 0.9925 - accuracy: 0.7704 - val_loss: 1.2865 - val_accuracy: 0.6440\n",
      "Epoch 41/50\n",
      "218/218 [==============================] - 3s 16ms/step - loss: 0.9750 - accuracy: 0.7789 - val_loss: 1.2923 - val_accuracy: 0.6453\n",
      "Epoch 42/50\n",
      "218/218 [==============================] - 3s 16ms/step - loss: 0.9564 - accuracy: 0.7858 - val_loss: 1.2993 - val_accuracy: 0.6413\n",
      "Epoch 43/50\n",
      "218/218 [==============================] - 3s 16ms/step - loss: 0.9860 - accuracy: 0.7763 - val_loss: 1.2883 - val_accuracy: 0.6613\n",
      "Epoch 44/50\n",
      "218/218 [==============================] - 3s 16ms/step - loss: 0.9716 - accuracy: 0.7769 - val_loss: 1.3293 - val_accuracy: 0.6460\n",
      "Epoch 45/50\n",
      "218/218 [==============================] - 4s 16ms/step - loss: 0.9597 - accuracy: 0.7800 - val_loss: 1.3094 - val_accuracy: 0.6633\n",
      "Epoch 46/50\n",
      "218/218 [==============================] - 3s 16ms/step - loss: 0.9659 - accuracy: 0.7841 - val_loss: 1.2889 - val_accuracy: 0.6607\n",
      "Epoch 47/50\n",
      "218/218 [==============================] - 4s 18ms/step - loss: 0.9482 - accuracy: 0.7901 - val_loss: 1.2933 - val_accuracy: 0.6553\n",
      "Epoch 48/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.9552 - accuracy: 0.7871 - val_loss: 1.3651 - val_accuracy: 0.6487\n",
      "Epoch 49/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.9467 - accuracy: 0.7909 - val_loss: 1.3304 - val_accuracy: 0.6547\n",
      "Epoch 50/50\n",
      "218/218 [==============================] - 4s 18ms/step - loss: 0.9634 - accuracy: 0.7846 - val_loss: 1.2899 - val_accuracy: 0.6480\n",
      "218/218 [==============================] - 1s 4ms/step - loss: 0.5556 - accuracy: 0.9822\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.2654 - accuracy: 0.6733\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_26 (Conv2D)          (None, 150, 1, 26)        5174      \n",
      "                                                                 \n",
      " max_pooling2d_26 (MaxPoolin  (None, 50, 1, 26)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_26 (Bat  (None, 50, 1, 26)        104       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 50, 1, 26)         0         \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 50, 1, 52)         12220     \n",
      "                                                                 \n",
      " max_pooling2d_27 (MaxPoolin  (None, 17, 1, 52)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_27 (Bat  (None, 17, 1, 52)        208       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 17, 1, 52)         0         \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 17, 1, 104)        48776     \n",
      "                                                                 \n",
      " max_pooling2d_28 (MaxPoolin  (None, 6, 1, 104)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_28 (Bat  (None, 6, 1, 104)        416       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 6, 1, 104)         0         \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 6, 1, 208)         194896    \n",
      "                                                                 \n",
      " max_pooling2d_29 (MaxPoolin  (None, 2, 1, 208)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_29 (Bat  (None, 2, 1, 208)        832       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 2, 1, 208)         0         \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 416)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 4)                 1668      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 264,294\n",
      "Trainable params: 263,514\n",
      "Non-trainable params: 780\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "218/218 [==============================] - 5s 19ms/step - loss: 2.2966 - accuracy: 0.2922 - val_loss: 1.9458 - val_accuracy: 0.2960\n",
      "Epoch 2/50\n",
      "218/218 [==============================] - 4s 18ms/step - loss: 1.9416 - accuracy: 0.3335 - val_loss: 1.8338 - val_accuracy: 0.3607\n",
      "Epoch 3/50\n",
      "218/218 [==============================] - 4s 18ms/step - loss: 1.7763 - accuracy: 0.3826 - val_loss: 1.7536 - val_accuracy: 0.3627\n",
      "Epoch 4/50\n",
      "218/218 [==============================] - 4s 18ms/step - loss: 1.6385 - accuracy: 0.4399 - val_loss: 1.6655 - val_accuracy: 0.4073\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218/218 [==============================] - 4s 19ms/step - loss: 1.5296 - accuracy: 0.4924 - val_loss: 1.5759 - val_accuracy: 0.4427\n",
      "Epoch 6/50\n",
      "218/218 [==============================] - 4s 18ms/step - loss: 1.4350 - accuracy: 0.5310 - val_loss: 1.4592 - val_accuracy: 0.5087\n",
      "Epoch 7/50\n",
      "218/218 [==============================] - 4s 18ms/step - loss: 1.3561 - accuracy: 0.5684 - val_loss: 1.4158 - val_accuracy: 0.5013\n",
      "Epoch 8/50\n",
      "218/218 [==============================] - 4s 19ms/step - loss: 1.2943 - accuracy: 0.5928 - val_loss: 1.3834 - val_accuracy: 0.5407\n",
      "Epoch 9/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 1.2523 - accuracy: 0.6121 - val_loss: 1.3543 - val_accuracy: 0.5433\n",
      "Epoch 10/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 1.2375 - accuracy: 0.6208 - val_loss: 1.3182 - val_accuracy: 0.5673\n",
      "Epoch 11/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 1.1795 - accuracy: 0.6499 - val_loss: 1.3042 - val_accuracy: 0.5827\n",
      "Epoch 12/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 1.1597 - accuracy: 0.6601 - val_loss: 1.2900 - val_accuracy: 0.5980\n",
      "Epoch 13/50\n",
      "218/218 [==============================] - 4s 19ms/step - loss: 1.1347 - accuracy: 0.6727 - val_loss: 1.3257 - val_accuracy: 0.5733\n",
      "Epoch 14/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 1.1156 - accuracy: 0.6856 - val_loss: 1.3510 - val_accuracy: 0.5673\n",
      "Epoch 15/50\n",
      "218/218 [==============================] - 4s 19ms/step - loss: 1.0999 - accuracy: 0.6917 - val_loss: 1.3184 - val_accuracy: 0.6053\n",
      "Epoch 16/50\n",
      "218/218 [==============================] - 4s 19ms/step - loss: 1.0724 - accuracy: 0.7089 - val_loss: 1.2909 - val_accuracy: 0.6093\n",
      "Epoch 17/50\n",
      "218/218 [==============================] - 4s 19ms/step - loss: 1.0604 - accuracy: 0.7210 - val_loss: 1.2609 - val_accuracy: 0.6073\n",
      "Epoch 18/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 1.0716 - accuracy: 0.7141 - val_loss: 1.3124 - val_accuracy: 0.6053\n",
      "Epoch 19/50\n",
      "218/218 [==============================] - 4s 19ms/step - loss: 1.0584 - accuracy: 0.7134 - val_loss: 1.2598 - val_accuracy: 0.6267\n",
      "Epoch 20/50\n",
      "218/218 [==============================] - 4s 19ms/step - loss: 1.0348 - accuracy: 0.7333 - val_loss: 1.2823 - val_accuracy: 0.6160\n",
      "Epoch 21/50\n",
      "218/218 [==============================] - 4s 19ms/step - loss: 1.0246 - accuracy: 0.7384 - val_loss: 1.2711 - val_accuracy: 0.6333\n",
      "Epoch 22/50\n",
      "218/218 [==============================] - 4s 19ms/step - loss: 0.9969 - accuracy: 0.7464 - val_loss: 1.4245 - val_accuracy: 0.5853\n",
      "Epoch 23/50\n",
      "218/218 [==============================] - 4s 19ms/step - loss: 1.0178 - accuracy: 0.7499 - val_loss: 1.2972 - val_accuracy: 0.6187\n",
      "Epoch 24/50\n",
      "218/218 [==============================] - 4s 19ms/step - loss: 0.9973 - accuracy: 0.7530 - val_loss: 1.3346 - val_accuracy: 0.6207\n",
      "Epoch 25/50\n",
      "218/218 [==============================] - 4s 18ms/step - loss: 1.0010 - accuracy: 0.7605 - val_loss: 1.2815 - val_accuracy: 0.6400\n",
      "Epoch 26/50\n",
      "218/218 [==============================] - 4s 18ms/step - loss: 1.0042 - accuracy: 0.7539 - val_loss: 1.3030 - val_accuracy: 0.6333\n",
      "Epoch 27/50\n",
      "218/218 [==============================] - 4s 18ms/step - loss: 0.9851 - accuracy: 0.7632 - val_loss: 1.3457 - val_accuracy: 0.6133\n",
      "Epoch 28/50\n",
      "218/218 [==============================] - 4s 18ms/step - loss: 0.9779 - accuracy: 0.7680 - val_loss: 1.3121 - val_accuracy: 0.6153\n",
      "Epoch 29/50\n",
      "218/218 [==============================] - 4s 18ms/step - loss: 0.9654 - accuracy: 0.7773 - val_loss: 1.3027 - val_accuracy: 0.6613\n",
      "Epoch 30/50\n",
      "218/218 [==============================] - 4s 19ms/step - loss: 0.9881 - accuracy: 0.7717 - val_loss: 1.3091 - val_accuracy: 0.6400\n",
      "Epoch 31/50\n",
      "218/218 [==============================] - 4s 19ms/step - loss: 0.9770 - accuracy: 0.7723 - val_loss: 1.3261 - val_accuracy: 0.6247\n",
      "Epoch 32/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 0.9627 - accuracy: 0.7789 - val_loss: 1.2822 - val_accuracy: 0.6693\n",
      "Epoch 33/50\n",
      "218/218 [==============================] - 4s 19ms/step - loss: 0.9525 - accuracy: 0.7882 - val_loss: 1.2984 - val_accuracy: 0.6613\n",
      "Epoch 34/50\n",
      "218/218 [==============================] - 4s 19ms/step - loss: 0.9568 - accuracy: 0.7842 - val_loss: 1.3033 - val_accuracy: 0.6660\n",
      "Epoch 35/50\n",
      "218/218 [==============================] - 4s 19ms/step - loss: 0.9433 - accuracy: 0.7931 - val_loss: 1.2871 - val_accuracy: 0.6700\n",
      "Epoch 36/50\n",
      "218/218 [==============================] - 4s 19ms/step - loss: 0.9435 - accuracy: 0.7954 - val_loss: 1.3577 - val_accuracy: 0.6267\n",
      "Epoch 37/50\n",
      "218/218 [==============================] - 4s 19ms/step - loss: 0.9471 - accuracy: 0.7912 - val_loss: 1.3720 - val_accuracy: 0.6307\n",
      "Epoch 38/50\n",
      "218/218 [==============================] - 4s 19ms/step - loss: 0.9540 - accuracy: 0.7894 - val_loss: 1.2853 - val_accuracy: 0.6540\n",
      "Epoch 39/50\n",
      "218/218 [==============================] - 4s 19ms/step - loss: 0.9421 - accuracy: 0.7920 - val_loss: 1.2809 - val_accuracy: 0.6740\n",
      "Epoch 40/50\n",
      "218/218 [==============================] - 4s 18ms/step - loss: 0.9346 - accuracy: 0.7934 - val_loss: 1.3421 - val_accuracy: 0.6400\n",
      "Epoch 41/50\n",
      "218/218 [==============================] - 4s 18ms/step - loss: 0.9451 - accuracy: 0.7935 - val_loss: 1.3452 - val_accuracy: 0.6373\n",
      "Epoch 42/50\n",
      "218/218 [==============================] - 4s 18ms/step - loss: 0.9435 - accuracy: 0.7987 - val_loss: 1.3373 - val_accuracy: 0.6420\n",
      "Epoch 43/50\n",
      "218/218 [==============================] - 4s 18ms/step - loss: 0.9440 - accuracy: 0.7955 - val_loss: 1.3597 - val_accuracy: 0.6420\n",
      "Epoch 44/50\n",
      "218/218 [==============================] - 4s 18ms/step - loss: 0.9339 - accuracy: 0.7981 - val_loss: 1.3430 - val_accuracy: 0.6453\n",
      "Epoch 45/50\n",
      "218/218 [==============================] - 4s 18ms/step - loss: 0.9218 - accuracy: 0.8075 - val_loss: 1.3734 - val_accuracy: 0.6340\n",
      "Epoch 46/50\n",
      "218/218 [==============================] - 4s 18ms/step - loss: 0.9302 - accuracy: 0.8000 - val_loss: 1.3119 - val_accuracy: 0.6527\n",
      "Epoch 47/50\n",
      "218/218 [==============================] - 4s 18ms/step - loss: 0.9156 - accuracy: 0.8105 - val_loss: 1.2974 - val_accuracy: 0.6680\n",
      "Epoch 48/50\n",
      "218/218 [==============================] - 4s 17ms/step - loss: 0.9216 - accuracy: 0.8066 - val_loss: 1.3910 - val_accuracy: 0.6300\n",
      "Epoch 49/50\n",
      "218/218 [==============================] - 4s 18ms/step - loss: 0.9383 - accuracy: 0.8063 - val_loss: 1.2964 - val_accuracy: 0.6533\n",
      "Epoch 50/50\n",
      "218/218 [==============================] - 4s 17ms/step - loss: 0.9235 - accuracy: 0.8029 - val_loss: 1.3090 - val_accuracy: 0.6453\n",
      "218/218 [==============================] - 1s 5ms/step - loss: 0.5312 - accuracy: 0.9920\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.3510 - accuracy: 0.6716\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_30 (Conv2D)          (None, 175, 1, 26)        5174      \n",
      "                                                                 \n",
      " max_pooling2d_30 (MaxPoolin  (None, 59, 1, 26)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_30 (Bat  (None, 59, 1, 26)        104       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 59, 1, 26)         0         \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 59, 1, 52)         12220     \n",
      "                                                                 \n",
      " max_pooling2d_31 (MaxPoolin  (None, 20, 1, 52)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_31 (Bat  (None, 20, 1, 52)        208       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 20, 1, 52)         0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 20, 1, 104)        48776     \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPoolin  (None, 7, 1, 104)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_32 (Bat  (None, 7, 1, 104)        416       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 7, 1, 104)         0         \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 7, 1, 208)         194896    \n",
      "                                                                 \n",
      " max_pooling2d_33 (MaxPoolin  (None, 3, 1, 208)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_33 (Bat  (None, 3, 1, 208)        832       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 3, 1, 208)         0         \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 624)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 4)                 2500      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 265,126\n",
      "Trainable params: 264,346\n",
      "Non-trainable params: 780\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "218/218 [==============================] - 5s 19ms/step - loss: 2.4092 - accuracy: 0.3036 - val_loss: 1.9778 - val_accuracy: 0.3453\n",
      "Epoch 2/50\n",
      "218/218 [==============================] - 4s 18ms/step - loss: 1.9952 - accuracy: 0.3443 - val_loss: 1.8375 - val_accuracy: 0.3540\n",
      "Epoch 3/50\n",
      "218/218 [==============================] - 4s 18ms/step - loss: 1.7958 - accuracy: 0.4007 - val_loss: 1.7625 - val_accuracy: 0.3727\n",
      "Epoch 4/50\n",
      "218/218 [==============================] - 4s 18ms/step - loss: 1.6831 - accuracy: 0.4407 - val_loss: 1.6280 - val_accuracy: 0.4547\n",
      "Epoch 5/50\n",
      "218/218 [==============================] - 4s 18ms/step - loss: 1.5755 - accuracy: 0.4871 - val_loss: 1.5435 - val_accuracy: 0.4873\n",
      "Epoch 6/50\n",
      "218/218 [==============================] - 4s 19ms/step - loss: 1.4862 - accuracy: 0.5181 - val_loss: 1.4924 - val_accuracy: 0.4940\n",
      "Epoch 7/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 1.4110 - accuracy: 0.5466 - val_loss: 1.4191 - val_accuracy: 0.5540\n",
      "Epoch 8/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 1.3448 - accuracy: 0.5767 - val_loss: 1.3663 - val_accuracy: 0.5653\n",
      "Epoch 9/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 1.2957 - accuracy: 0.5963 - val_loss: 1.3769 - val_accuracy: 0.5580\n",
      "Epoch 10/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 1.2580 - accuracy: 0.6188 - val_loss: 1.3205 - val_accuracy: 0.5893\n",
      "Epoch 11/50\n",
      "218/218 [==============================] - 4s 21ms/step - loss: 1.2227 - accuracy: 0.6261 - val_loss: 1.2799 - val_accuracy: 0.6147\n",
      "Epoch 12/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 1.1686 - accuracy: 0.6570 - val_loss: 1.3167 - val_accuracy: 0.5840\n",
      "Epoch 13/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 1.1484 - accuracy: 0.6634 - val_loss: 1.2635 - val_accuracy: 0.6320\n",
      "Epoch 14/50\n",
      "218/218 [==============================] - 5s 22ms/step - loss: 1.1280 - accuracy: 0.6770 - val_loss: 1.2626 - val_accuracy: 0.6240\n",
      "Epoch 15/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 1.1059 - accuracy: 0.6967 - val_loss: 1.3466 - val_accuracy: 0.6147\n",
      "Epoch 16/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 1.0887 - accuracy: 0.7052 - val_loss: 1.2630 - val_accuracy: 0.6387\n",
      "Epoch 17/50\n",
      "218/218 [==============================] - 4s 21ms/step - loss: 1.0699 - accuracy: 0.7158 - val_loss: 1.2902 - val_accuracy: 0.6253\n",
      "Epoch 18/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 1.0772 - accuracy: 0.7135 - val_loss: 1.2989 - val_accuracy: 0.6220\n",
      "Epoch 19/50\n",
      "218/218 [==============================] - 5s 22ms/step - loss: 1.0316 - accuracy: 0.7351 - val_loss: 1.2697 - val_accuracy: 0.6373\n",
      "Epoch 20/50\n",
      "218/218 [==============================] - 4s 21ms/step - loss: 1.0369 - accuracy: 0.7307 - val_loss: 1.3183 - val_accuracy: 0.6587\n",
      "Epoch 21/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 1.0427 - accuracy: 0.7389 - val_loss: 1.3024 - val_accuracy: 0.6373\n",
      "Epoch 22/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 1.0260 - accuracy: 0.7412 - val_loss: 1.2768 - val_accuracy: 0.6507\n",
      "Epoch 23/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 1.0029 - accuracy: 0.7549 - val_loss: 1.3308 - val_accuracy: 0.6327\n",
      "Epoch 24/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 1.0111 - accuracy: 0.7526 - val_loss: 1.3420 - val_accuracy: 0.6420\n",
      "Epoch 25/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.9881 - accuracy: 0.7693 - val_loss: 1.2835 - val_accuracy: 0.6473\n",
      "Epoch 26/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.9807 - accuracy: 0.7675 - val_loss: 1.3748 - val_accuracy: 0.6347\n",
      "Epoch 27/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.9973 - accuracy: 0.7575 - val_loss: 1.2645 - val_accuracy: 0.6647\n",
      "Epoch 28/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.9859 - accuracy: 0.7713 - val_loss: 1.3061 - val_accuracy: 0.6767\n",
      "Epoch 29/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.9681 - accuracy: 0.7754 - val_loss: 1.2743 - val_accuracy: 0.6520\n",
      "Epoch 30/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.9694 - accuracy: 0.7806 - val_loss: 1.3004 - val_accuracy: 0.6473\n",
      "Epoch 31/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.9623 - accuracy: 0.7835 - val_loss: 1.3079 - val_accuracy: 0.6613\n",
      "Epoch 32/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.9659 - accuracy: 0.7828 - val_loss: 1.2766 - val_accuracy: 0.6853\n",
      "Epoch 33/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.9473 - accuracy: 0.7909 - val_loss: 1.2785 - val_accuracy: 0.6627\n",
      "Epoch 34/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.9400 - accuracy: 0.7950 - val_loss: 1.2717 - val_accuracy: 0.6780\n",
      "Epoch 35/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.9376 - accuracy: 0.7987 - val_loss: 1.3422 - val_accuracy: 0.6540\n",
      "Epoch 36/50\n",
      "218/218 [==============================] - 5s 22ms/step - loss: 0.9478 - accuracy: 0.7947 - val_loss: 1.3553 - val_accuracy: 0.6747\n",
      "Epoch 37/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.9352 - accuracy: 0.8032 - val_loss: 1.2968 - val_accuracy: 0.6980\n",
      "Epoch 38/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 0.9448 - accuracy: 0.8020 - val_loss: 1.3727 - val_accuracy: 0.6340\n",
      "Epoch 39/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 0.9446 - accuracy: 0.7978 - val_loss: 1.3300 - val_accuracy: 0.6707\n",
      "Epoch 40/50\n",
      "218/218 [==============================] - 4s 21ms/step - loss: 0.9275 - accuracy: 0.8053 - val_loss: 1.3711 - val_accuracy: 0.6620\n",
      "Epoch 41/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 0.9441 - accuracy: 0.8003 - val_loss: 1.3110 - val_accuracy: 0.6800\n",
      "Epoch 42/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 0.9373 - accuracy: 0.8047 - val_loss: 1.3386 - val_accuracy: 0.6793\n",
      "Epoch 43/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.9344 - accuracy: 0.8082 - val_loss: 1.2797 - val_accuracy: 0.6853\n",
      "Epoch 44/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.9210 - accuracy: 0.8126 - val_loss: 1.3475 - val_accuracy: 0.6533\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218/218 [==============================] - 4s 20ms/step - loss: 0.8970 - accuracy: 0.8254 - val_loss: 1.2800 - val_accuracy: 0.6900\n",
      "Epoch 46/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 0.9202 - accuracy: 0.8119 - val_loss: 1.3589 - val_accuracy: 0.6587\n",
      "Epoch 47/50\n",
      "218/218 [==============================] - 4s 20ms/step - loss: 0.9248 - accuracy: 0.8162 - val_loss: 1.3397 - val_accuracy: 0.6660\n",
      "Epoch 48/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.9119 - accuracy: 0.8193 - val_loss: 1.3231 - val_accuracy: 0.6967\n",
      "Epoch 49/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.9353 - accuracy: 0.8168 - val_loss: 1.3595 - val_accuracy: 0.6833\n",
      "Epoch 50/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 0.9067 - accuracy: 0.8249 - val_loss: 1.3319 - val_accuracy: 0.6907\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5375 - accuracy: 0.9930\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.2630 - accuracy: 0.6953\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_34 (Conv2D)          (None, 200, 1, 26)        5174      \n",
      "                                                                 \n",
      " max_pooling2d_34 (MaxPoolin  (None, 67, 1, 26)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_34 (Bat  (None, 67, 1, 26)        104       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 67, 1, 26)         0         \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 67, 1, 52)         12220     \n",
      "                                                                 \n",
      " max_pooling2d_35 (MaxPoolin  (None, 23, 1, 52)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_35 (Bat  (None, 23, 1, 52)        208       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 23, 1, 52)         0         \n",
      "                                                                 \n",
      " conv2d_36 (Conv2D)          (None, 23, 1, 104)        48776     \n",
      "                                                                 \n",
      " max_pooling2d_36 (MaxPoolin  (None, 8, 1, 104)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_36 (Bat  (None, 8, 1, 104)        416       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 8, 1, 104)         0         \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 8, 1, 208)         194896    \n",
      "                                                                 \n",
      " max_pooling2d_37 (MaxPoolin  (None, 3, 1, 208)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_37 (Bat  (None, 3, 1, 208)        832       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 3, 1, 208)         0         \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 624)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 4)                 2500      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 265,126\n",
      "Trainable params: 264,346\n",
      "Non-trainable params: 780\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "218/218 [==============================] - 6s 22ms/step - loss: 2.3654 - accuracy: 0.3109 - val_loss: 1.9977 - val_accuracy: 0.3460\n",
      "Epoch 2/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 1.9531 - accuracy: 0.3626 - val_loss: 1.7954 - val_accuracy: 0.3973\n",
      "Epoch 3/50\n",
      "218/218 [==============================] - 5s 21ms/step - loss: 1.7495 - accuracy: 0.4286 - val_loss: 1.7139 - val_accuracy: 0.4193\n",
      "Epoch 4/50\n",
      "218/218 [==============================] - 5s 22ms/step - loss: 1.6231 - accuracy: 0.4615 - val_loss: 1.5599 - val_accuracy: 0.4660\n",
      "Epoch 5/50\n",
      "218/218 [==============================] - 5s 22ms/step - loss: 1.5058 - accuracy: 0.5191 - val_loss: 1.5074 - val_accuracy: 0.4840\n",
      "Epoch 6/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 1.4027 - accuracy: 0.5608 - val_loss: 1.4239 - val_accuracy: 0.5253\n",
      "Epoch 7/50\n",
      "218/218 [==============================] - 5s 22ms/step - loss: 1.3164 - accuracy: 0.6000 - val_loss: 1.3898 - val_accuracy: 0.5647\n",
      "Epoch 8/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 1.2646 - accuracy: 0.6216 - val_loss: 1.3656 - val_accuracy: 0.5553\n",
      "Epoch 9/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 1.2099 - accuracy: 0.6559 - val_loss: 1.3323 - val_accuracy: 0.5813\n",
      "Epoch 10/50\n",
      "218/218 [==============================] - 5s 24ms/step - loss: 1.1709 - accuracy: 0.6642 - val_loss: 1.3347 - val_accuracy: 0.6013\n",
      "Epoch 11/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 1.1422 - accuracy: 0.6868 - val_loss: 1.2305 - val_accuracy: 0.6327\n",
      "Epoch 12/50\n",
      "218/218 [==============================] - 5s 24ms/step - loss: 1.1009 - accuracy: 0.7056 - val_loss: 1.2727 - val_accuracy: 0.6267\n",
      "Epoch 13/50\n",
      "218/218 [==============================] - 5s 24ms/step - loss: 1.0726 - accuracy: 0.7172 - val_loss: 1.2350 - val_accuracy: 0.6480\n",
      "Epoch 14/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 1.0758 - accuracy: 0.7203 - val_loss: 1.4187 - val_accuracy: 0.5907\n",
      "Epoch 15/50\n",
      "218/218 [==============================] - 5s 24ms/step - loss: 1.0441 - accuracy: 0.7323 - val_loss: 1.2550 - val_accuracy: 0.6620\n",
      "Epoch 16/50\n",
      "218/218 [==============================] - 5s 24ms/step - loss: 1.0116 - accuracy: 0.7491 - val_loss: 1.2120 - val_accuracy: 0.6607\n",
      "Epoch 17/50\n",
      "218/218 [==============================] - 5s 24ms/step - loss: 1.0221 - accuracy: 0.7493 - val_loss: 1.2370 - val_accuracy: 0.6627\n",
      "Epoch 18/50\n",
      "218/218 [==============================] - 5s 24ms/step - loss: 0.9830 - accuracy: 0.7667 - val_loss: 1.4248 - val_accuracy: 0.5907\n",
      "Epoch 19/50\n",
      "218/218 [==============================] - 5s 24ms/step - loss: 1.0196 - accuracy: 0.7536 - val_loss: 1.1924 - val_accuracy: 0.6987\n",
      "Epoch 20/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.9677 - accuracy: 0.7685 - val_loss: 1.2508 - val_accuracy: 0.6553\n",
      "Epoch 21/50\n",
      "218/218 [==============================] - 5s 24ms/step - loss: 0.9795 - accuracy: 0.7727 - val_loss: 1.2383 - val_accuracy: 0.6887\n",
      "Epoch 22/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.9731 - accuracy: 0.7731 - val_loss: 1.2197 - val_accuracy: 0.6740\n",
      "Epoch 23/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.9468 - accuracy: 0.7864 - val_loss: 1.2250 - val_accuracy: 0.6687\n",
      "Epoch 24/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.9470 - accuracy: 0.7937 - val_loss: 1.2831 - val_accuracy: 0.6527\n",
      "Epoch 25/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.9586 - accuracy: 0.7830 - val_loss: 1.2805 - val_accuracy: 0.6727\n",
      "Epoch 26/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.9434 - accuracy: 0.7894 - val_loss: 1.2756 - val_accuracy: 0.6527\n",
      "Epoch 27/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.9468 - accuracy: 0.7941 - val_loss: 1.2166 - val_accuracy: 0.6753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50\n",
      "218/218 [==============================] - 5s 22ms/step - loss: 0.9505 - accuracy: 0.7925 - val_loss: 1.2288 - val_accuracy: 0.6693\n",
      "Epoch 29/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.9260 - accuracy: 0.7993 - val_loss: 1.2586 - val_accuracy: 0.6760\n",
      "Epoch 30/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.9338 - accuracy: 0.8016 - val_loss: 1.2386 - val_accuracy: 0.6733\n",
      "Epoch 31/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.9203 - accuracy: 0.8079 - val_loss: 1.2247 - val_accuracy: 0.7020\n",
      "Epoch 32/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.9268 - accuracy: 0.8039 - val_loss: 1.2608 - val_accuracy: 0.6840\n",
      "Epoch 33/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.9102 - accuracy: 0.8109 - val_loss: 1.3415 - val_accuracy: 0.6487\n",
      "Epoch 34/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.9038 - accuracy: 0.8188 - val_loss: 1.2434 - val_accuracy: 0.6973\n",
      "Epoch 35/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.9171 - accuracy: 0.8088 - val_loss: 1.1943 - val_accuracy: 0.6960\n",
      "Epoch 36/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.8881 - accuracy: 0.8273 - val_loss: 1.2433 - val_accuracy: 0.6740\n",
      "Epoch 37/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.8892 - accuracy: 0.8223 - val_loss: 1.3220 - val_accuracy: 0.6707\n",
      "Epoch 38/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.8820 - accuracy: 0.8310 - val_loss: 1.2793 - val_accuracy: 0.6613\n",
      "Epoch 39/50\n",
      "218/218 [==============================] - 5s 22ms/step - loss: 0.8925 - accuracy: 0.8257 - val_loss: 1.2428 - val_accuracy: 0.6900\n",
      "Epoch 40/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.8905 - accuracy: 0.8247 - val_loss: 1.3256 - val_accuracy: 0.6773\n",
      "Epoch 41/50\n",
      "218/218 [==============================] - 5s 22ms/step - loss: 0.8866 - accuracy: 0.8260 - val_loss: 1.2973 - val_accuracy: 0.6680\n",
      "Epoch 42/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.8852 - accuracy: 0.8283 - val_loss: 1.2398 - val_accuracy: 0.6913\n",
      "Epoch 43/50\n",
      "218/218 [==============================] - 5s 22ms/step - loss: 0.8852 - accuracy: 0.8307 - val_loss: 1.2668 - val_accuracy: 0.6740\n",
      "Epoch 44/50\n",
      "218/218 [==============================] - 5s 22ms/step - loss: 0.8910 - accuracy: 0.8338 - val_loss: 1.2773 - val_accuracy: 0.6720\n",
      "Epoch 45/50\n",
      "218/218 [==============================] - 5s 22ms/step - loss: 0.8955 - accuracy: 0.8220 - val_loss: 1.2945 - val_accuracy: 0.6747\n",
      "Epoch 46/50\n",
      "218/218 [==============================] - 5s 22ms/step - loss: 0.9023 - accuracy: 0.8256 - val_loss: 1.2334 - val_accuracy: 0.6887\n",
      "Epoch 47/50\n",
      "218/218 [==============================] - 5s 22ms/step - loss: 0.8894 - accuracy: 0.8279 - val_loss: 1.2958 - val_accuracy: 0.6767\n",
      "Epoch 48/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.8800 - accuracy: 0.8339 - val_loss: 1.2094 - val_accuracy: 0.6960\n",
      "Epoch 49/50\n",
      "218/218 [==============================] - 5s 24ms/step - loss: 0.8674 - accuracy: 0.8395 - val_loss: 1.2696 - val_accuracy: 0.6807\n",
      "Epoch 50/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.8787 - accuracy: 0.8346 - val_loss: 1.2631 - val_accuracy: 0.6773\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5290 - accuracy: 0.9925\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.3159 - accuracy: 0.6851\n",
      "{'50': 0.6889367699623108, '100': 0.8397988677024841, '150': 0.920976996421814, '200': 0.9543103575706482, '250': 0.9821839332580566, '300': 0.9919540286064148, '350': 0.9929597973823547, '400': 0.9925287365913391}\n",
      "{'50': 0.42381489276885986, '100': 0.5174943804740906, '150': 0.5665914416313171, '200': 0.6139954924583435, '250': 0.6732505559921265, '300': 0.6715575456619263, '350': 0.6952595710754395, '400': 0.6851015686988831}\n"
     ]
    }
   ],
   "source": [
    "short_time_train_scores = {}\n",
    "short_time_test_scores = {}\n",
    "for i in range(50, 450, 50):\n",
    "    y_test = np.load(\"y_test.npy\")\n",
    "    y_test -= 769\n",
    "    x_train, x_valid, x_test, y_train, y_valid, y_test = data_finalize(total_number=2115, takeout_sample=375, period=i, y_test=y_test)\n",
    "    l2_lambda = 0.001\n",
    "    \n",
    "    model = Sequential([\n",
    "\n",
    "      # Conv. block 1\n",
    "      keras.layers.Conv2D(filters=26, kernel_size=(9,1), padding='same', activation=tf.nn.gelu, kernel_regularizer=regularizers.l2(l2_lambda), input_shape=(x_train.shape[1],1,22)),\n",
    "      keras.layers.MaxPooling2D(pool_size=(3,1), padding='same'), # Read the keras documentation\n",
    "      keras.layers.BatchNormalization(),\n",
    "      keras.layers.Dropout(0.5),\n",
    "\n",
    "      # Conv. block 2\n",
    "      keras.layers.Conv2D(filters=52, kernel_size=(9,1), padding='same', activation=tf.nn.gelu, kernel_regularizer=regularizers.l2(l2_lambda)),\n",
    "      keras.layers.MaxPooling2D(pool_size=(3,1), padding='same'),\n",
    "      keras.layers.BatchNormalization(),\n",
    "      keras.layers.Dropout(0.5),\n",
    "\n",
    "      # Conv. block 3\n",
    "      keras.layers.Conv2D(filters=104, kernel_size=(9,1), padding='same', activation=tf.nn.gelu, kernel_regularizer=regularizers.l2(l2_lambda)),\n",
    "      keras.layers.MaxPooling2D(pool_size=(3,1), padding='same'),\n",
    "      keras.layers.BatchNormalization(),\n",
    "      keras.layers.Dropout(0.5),\n",
    "\n",
    "      keras.layers.Conv2D(filters=208, kernel_size=(9,1), padding='same', activation=tf.nn.gelu, kernel_regularizer=regularizers.l2(l2_lambda)),\n",
    "      keras.layers.MaxPooling2D(pool_size=(3,1), padding='same'),\n",
    "      keras.layers.BatchNormalization(),\n",
    "      keras.layers.Dropout(0.5),\n",
    "\n",
    "\n",
    "      # Output layer with Softmax activation\n",
    "      keras.layers.Flatten(), # Flattens the input\n",
    "      keras.layers.Dense(4, activation='softmax') # Output FC layer with softmax activation\n",
    "  ])\n",
    "\n",
    "    # Printing the model summary\n",
    "    model.summary()\n",
    "\n",
    "  \n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer=cnn_optimizer,\n",
    "                 metrics=['accuracy'])\n",
    "  \n",
    "\n",
    "    # Training and validating the model\n",
    "    model_results = model.fit(x_train,\n",
    "                  y_train,\n",
    "                  batch_size=32,\n",
    "                  epochs=epochs,\n",
    "                  validation_data=(x_valid, y_valid), verbose=True)\n",
    "\n",
    "    short_time_train_scores[str(i)] = model.evaluate(x_train, y_train)[1]\n",
    "    short_time_test_scores[str(i)] = model.evaluate(x_test, y_test)[1]\n",
    "print(short_time_train_scores)\n",
    "print(short_time_test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_38 (Conv2D)          (None, 225, 1, 26)        5174      \n",
      "                                                                 \n",
      " max_pooling2d_38 (MaxPoolin  (None, 75, 1, 26)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_38 (Bat  (None, 75, 1, 26)        104       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_38 (Dropout)        (None, 75, 1, 26)         0         \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 75, 1, 52)         12220     \n",
      "                                                                 \n",
      " max_pooling2d_39 (MaxPoolin  (None, 25, 1, 52)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_39 (Bat  (None, 25, 1, 52)        208       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 25, 1, 52)         0         \n",
      "                                                                 \n",
      " conv2d_40 (Conv2D)          (None, 25, 1, 104)        48776     \n",
      "                                                                 \n",
      " max_pooling2d_40 (MaxPoolin  (None, 9, 1, 104)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_40 (Bat  (None, 9, 1, 104)        416       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 9, 1, 104)         0         \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 9, 1, 208)         194896    \n",
      "                                                                 \n",
      " max_pooling2d_41 (MaxPoolin  (None, 3, 1, 208)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_41 (Bat  (None, 3, 1, 208)        832       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 3, 1, 208)         0         \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 624)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 4)                 2500      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 265,126\n",
      "Trainable params: 264,346\n",
      "Non-trainable params: 780\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "218/218 [==============================] - 6s 24ms/step - loss: 2.3542 - accuracy: 0.3089 - val_loss: 1.9890 - val_accuracy: 0.3427\n",
      "Epoch 2/50\n",
      "218/218 [==============================] - 5s 22ms/step - loss: 1.9287 - accuracy: 0.3868 - val_loss: 1.8078 - val_accuracy: 0.3760\n",
      "Epoch 3/50\n",
      "218/218 [==============================] - 5s 22ms/step - loss: 1.7305 - accuracy: 0.4481 - val_loss: 1.6614 - val_accuracy: 0.4327\n",
      "Epoch 4/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 1.5860 - accuracy: 0.5049 - val_loss: 1.5844 - val_accuracy: 0.4667\n",
      "Epoch 5/50\n",
      "218/218 [==============================] - 5s 22ms/step - loss: 1.4772 - accuracy: 0.5491 - val_loss: 1.4673 - val_accuracy: 0.5180\n",
      "Epoch 6/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 1.4000 - accuracy: 0.5756 - val_loss: 1.4124 - val_accuracy: 0.5387\n",
      "Epoch 7/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 1.3216 - accuracy: 0.6042 - val_loss: 1.3771 - val_accuracy: 0.5713\n",
      "Epoch 8/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 1.2645 - accuracy: 0.6368 - val_loss: 1.3721 - val_accuracy: 0.5360\n",
      "Epoch 9/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 1.2061 - accuracy: 0.6566 - val_loss: 1.2878 - val_accuracy: 0.6253\n",
      "Epoch 10/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 1.1776 - accuracy: 0.6731 - val_loss: 1.2816 - val_accuracy: 0.6213\n",
      "Epoch 11/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 1.1275 - accuracy: 0.7019 - val_loss: 1.2241 - val_accuracy: 0.6507\n",
      "Epoch 12/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 1.1066 - accuracy: 0.7013 - val_loss: 1.2208 - val_accuracy: 0.6433\n",
      "Epoch 13/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 1.0575 - accuracy: 0.7263 - val_loss: 1.2007 - val_accuracy: 0.6467\n",
      "Epoch 14/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 1.0607 - accuracy: 0.7226 - val_loss: 1.1835 - val_accuracy: 0.6580\n",
      "Epoch 15/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 1.0381 - accuracy: 0.7339 - val_loss: 1.1817 - val_accuracy: 0.6513\n",
      "Epoch 16/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 1.0162 - accuracy: 0.7533 - val_loss: 1.1894 - val_accuracy: 0.6647\n",
      "Epoch 17/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.9954 - accuracy: 0.7586 - val_loss: 1.1858 - val_accuracy: 0.6580\n",
      "Epoch 18/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.9824 - accuracy: 0.7671 - val_loss: 1.2660 - val_accuracy: 0.6260\n",
      "Epoch 19/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.9774 - accuracy: 0.7705 - val_loss: 1.2646 - val_accuracy: 0.6467\n",
      "Epoch 20/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.9703 - accuracy: 0.7741 - val_loss: 1.1743 - val_accuracy: 0.6793\n",
      "Epoch 21/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.9660 - accuracy: 0.7740 - val_loss: 1.1704 - val_accuracy: 0.6827\n",
      "Epoch 22/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.9589 - accuracy: 0.7806 - val_loss: 1.1459 - val_accuracy: 0.7033\n",
      "Epoch 23/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.9462 - accuracy: 0.7875 - val_loss: 1.2381 - val_accuracy: 0.6667\n",
      "Epoch 24/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.9316 - accuracy: 0.8000 - val_loss: 1.2087 - val_accuracy: 0.6860\n",
      "Epoch 25/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.9335 - accuracy: 0.8037 - val_loss: 1.1476 - val_accuracy: 0.7213\n",
      "Epoch 26/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.9310 - accuracy: 0.8010 - val_loss: 1.1275 - val_accuracy: 0.7127\n",
      "Epoch 27/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.9244 - accuracy: 0.8056 - val_loss: 1.2105 - val_accuracy: 0.6687\n",
      "Epoch 28/50\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.9449 - accuracy: 0.7993 - val_loss: 1.1797 - val_accuracy: 0.7007\n",
      "Epoch 29/50\n",
      "218/218 [==============================] - 5s 24ms/step - loss: 0.9155 - accuracy: 0.8125 - val_loss: 1.1749 - val_accuracy: 0.6867\n",
      "Epoch 30/50\n",
      "218/218 [==============================] - 5s 25ms/step - loss: 0.9072 - accuracy: 0.8181 - val_loss: 1.1569 - val_accuracy: 0.6960\n",
      "Epoch 31/50\n",
      "218/218 [==============================] - 6s 26ms/step - loss: 0.9082 - accuracy: 0.8138 - val_loss: 1.1516 - val_accuracy: 0.7113\n",
      "Epoch 32/50\n",
      "218/218 [==============================] - 6s 27ms/step - loss: 0.9070 - accuracy: 0.8182 - val_loss: 1.1898 - val_accuracy: 0.7093\n",
      "Epoch 33/50\n",
      "218/218 [==============================] - 6s 27ms/step - loss: 0.9131 - accuracy: 0.8139 - val_loss: 1.1875 - val_accuracy: 0.6920\n",
      "Epoch 34/50\n",
      "218/218 [==============================] - 7s 30ms/step - loss: 0.9215 - accuracy: 0.8185 - val_loss: 1.2752 - val_accuracy: 0.6540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "218/218 [==============================] - 6s 27ms/step - loss: 0.8863 - accuracy: 0.8263 - val_loss: 1.2032 - val_accuracy: 0.6980\n",
      "Epoch 36/50\n",
      "218/218 [==============================] - 6s 26ms/step - loss: 0.8869 - accuracy: 0.8339 - val_loss: 1.1802 - val_accuracy: 0.6993\n",
      "Epoch 37/50\n",
      "218/218 [==============================] - 5s 25ms/step - loss: 0.8978 - accuracy: 0.8272 - val_loss: 1.1644 - val_accuracy: 0.7067\n",
      "Epoch 38/50\n",
      "218/218 [==============================] - 5s 25ms/step - loss: 0.8742 - accuracy: 0.8313 - val_loss: 1.1412 - val_accuracy: 0.7393\n",
      "Epoch 39/50\n",
      "218/218 [==============================] - 5s 25ms/step - loss: 0.8733 - accuracy: 0.8346 - val_loss: 1.1282 - val_accuracy: 0.7413\n",
      "Epoch 40/50\n",
      "218/218 [==============================] - 5s 25ms/step - loss: 0.8805 - accuracy: 0.8371 - val_loss: 1.1854 - val_accuracy: 0.7127\n",
      "Epoch 41/50\n",
      "218/218 [==============================] - 5s 24ms/step - loss: 0.8860 - accuracy: 0.8307 - val_loss: 1.1430 - val_accuracy: 0.7333\n",
      "Epoch 42/50\n",
      "218/218 [==============================] - 5s 24ms/step - loss: 0.8821 - accuracy: 0.8355 - val_loss: 1.1581 - val_accuracy: 0.7160\n",
      "Epoch 43/50\n",
      "218/218 [==============================] - 5s 24ms/step - loss: 0.8641 - accuracy: 0.8411 - val_loss: 1.1562 - val_accuracy: 0.7260\n",
      "Epoch 44/50\n",
      "218/218 [==============================] - 5s 24ms/step - loss: 0.8648 - accuracy: 0.8402 - val_loss: 1.1904 - val_accuracy: 0.7040\n",
      "Epoch 45/50\n",
      "218/218 [==============================] - 5s 24ms/step - loss: 0.8711 - accuracy: 0.8398 - val_loss: 1.2563 - val_accuracy: 0.7093\n",
      "Epoch 46/50\n",
      "218/218 [==============================] - 5s 24ms/step - loss: 0.8692 - accuracy: 0.8345 - val_loss: 1.2110 - val_accuracy: 0.7180\n",
      "Epoch 47/50\n",
      "218/218 [==============================] - 5s 25ms/step - loss: 0.8677 - accuracy: 0.8437 - val_loss: 1.1864 - val_accuracy: 0.7367\n",
      "Epoch 48/50\n",
      "218/218 [==============================] - 6s 26ms/step - loss: 0.8875 - accuracy: 0.8404 - val_loss: 1.1709 - val_accuracy: 0.7213\n",
      "Epoch 49/50\n",
      "218/218 [==============================] - 6s 26ms/step - loss: 0.8499 - accuracy: 0.8455 - val_loss: 1.1612 - val_accuracy: 0.7340\n",
      "Epoch 50/50\n",
      "218/218 [==============================] - 6s 26ms/step - loss: 0.8598 - accuracy: 0.8496 - val_loss: 1.2170 - val_accuracy: 0.7407\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.5113 - accuracy: 0.9971\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 1.2630 - accuracy: 0.7032\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_42 (Conv2D)          (None, 250, 1, 26)        5174      \n",
      "                                                                 \n",
      " max_pooling2d_42 (MaxPoolin  (None, 84, 1, 26)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_42 (Bat  (None, 84, 1, 26)        104       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, 84, 1, 26)         0         \n",
      "                                                                 \n",
      " conv2d_43 (Conv2D)          (None, 84, 1, 52)         12220     \n",
      "                                                                 \n",
      " max_pooling2d_43 (MaxPoolin  (None, 28, 1, 52)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_43 (Bat  (None, 28, 1, 52)        208       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 28, 1, 52)         0         \n",
      "                                                                 \n",
      " conv2d_44 (Conv2D)          (None, 28, 1, 104)        48776     \n",
      "                                                                 \n",
      " max_pooling2d_44 (MaxPoolin  (None, 10, 1, 104)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_44 (Bat  (None, 10, 1, 104)       416       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_44 (Dropout)        (None, 10, 1, 104)        0         \n",
      "                                                                 \n",
      " conv2d_45 (Conv2D)          (None, 10, 1, 208)        194896    \n",
      "                                                                 \n",
      " max_pooling2d_45 (MaxPoolin  (None, 4, 1, 208)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_45 (Bat  (None, 4, 1, 208)        832       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_45 (Dropout)        (None, 4, 1, 208)         0         \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 832)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 4)                 3332      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 265,958\n",
      "Trainable params: 265,178\n",
      "Non-trainable params: 780\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "218/218 [==============================] - 7s 25ms/step - loss: 2.4124 - accuracy: 0.3408 - val_loss: 2.0293 - val_accuracy: 0.3587\n",
      "Epoch 2/50\n",
      "218/218 [==============================] - 5s 25ms/step - loss: 1.9773 - accuracy: 0.4036 - val_loss: 1.8369 - val_accuracy: 0.4280\n",
      "Epoch 3/50\n",
      "218/218 [==============================] - 6s 26ms/step - loss: 1.7534 - accuracy: 0.4789 - val_loss: 1.7276 - val_accuracy: 0.4607\n",
      "Epoch 4/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 1.6094 - accuracy: 0.5303 - val_loss: 1.6480 - val_accuracy: 0.4967\n",
      "Epoch 5/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 1.5031 - accuracy: 0.5649 - val_loss: 1.5404 - val_accuracy: 0.5427\n",
      "Epoch 6/50\n",
      "218/218 [==============================] - 6s 30ms/step - loss: 1.4036 - accuracy: 0.5961 - val_loss: 1.5376 - val_accuracy: 0.5187\n",
      "Epoch 7/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 1.3273 - accuracy: 0.6204 - val_loss: 1.4625 - val_accuracy: 0.5607\n",
      "Epoch 8/50\n",
      "218/218 [==============================] - 7s 31ms/step - loss: 1.2649 - accuracy: 0.6448 - val_loss: 1.4835 - val_accuracy: 0.5380\n",
      "Epoch 9/50\n",
      "218/218 [==============================] - 7s 31ms/step - loss: 1.1992 - accuracy: 0.6730 - val_loss: 1.3414 - val_accuracy: 0.6020\n",
      "Epoch 10/50\n",
      "218/218 [==============================] - 7s 30ms/step - loss: 1.1594 - accuracy: 0.6925 - val_loss: 1.3235 - val_accuracy: 0.6007\n",
      "Epoch 11/50\n",
      "218/218 [==============================] - 7s 30ms/step - loss: 1.1290 - accuracy: 0.6951 - val_loss: 1.3685 - val_accuracy: 0.5913\n",
      "Epoch 12/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 1.1077 - accuracy: 0.7102 - val_loss: 1.3345 - val_accuracy: 0.5813\n",
      "Epoch 13/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 1.0631 - accuracy: 0.7267 - val_loss: 1.3026 - val_accuracy: 0.6173\n",
      "Epoch 14/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 1.0405 - accuracy: 0.7369 - val_loss: 1.3077 - val_accuracy: 0.6420\n",
      "Epoch 15/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 1.0144 - accuracy: 0.7484 - val_loss: 1.3418 - val_accuracy: 0.6300\n",
      "Epoch 16/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 1.0166 - accuracy: 0.7534 - val_loss: 1.4207 - val_accuracy: 0.6053\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218/218 [==============================] - 6s 29ms/step - loss: 0.9923 - accuracy: 0.7638 - val_loss: 1.2422 - val_accuracy: 0.6600\n",
      "Epoch 18/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 0.9758 - accuracy: 0.7727 - val_loss: 1.2791 - val_accuracy: 0.6760\n",
      "Epoch 19/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.9644 - accuracy: 0.7787 - val_loss: 1.2952 - val_accuracy: 0.6567\n",
      "Epoch 20/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 0.9677 - accuracy: 0.7767 - val_loss: 1.2477 - val_accuracy: 0.6607\n",
      "Epoch 21/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 0.9438 - accuracy: 0.7911 - val_loss: 1.2608 - val_accuracy: 0.6700\n",
      "Epoch 22/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 0.9226 - accuracy: 0.8017 - val_loss: 1.2748 - val_accuracy: 0.6633\n",
      "Epoch 23/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 0.9361 - accuracy: 0.7970 - val_loss: 1.3286 - val_accuracy: 0.6560\n",
      "Epoch 24/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 0.9262 - accuracy: 0.8019 - val_loss: 1.2896 - val_accuracy: 0.6813\n",
      "Epoch 25/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 0.9098 - accuracy: 0.8122 - val_loss: 1.3795 - val_accuracy: 0.6520\n",
      "Epoch 26/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 0.9042 - accuracy: 0.8126 - val_loss: 1.3608 - val_accuracy: 0.6407\n",
      "Epoch 27/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 0.9050 - accuracy: 0.8151 - val_loss: 1.3369 - val_accuracy: 0.6640\n",
      "Epoch 28/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 0.9074 - accuracy: 0.8155 - val_loss: 1.3364 - val_accuracy: 0.6560\n",
      "Epoch 29/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 0.8987 - accuracy: 0.8211 - val_loss: 1.3489 - val_accuracy: 0.6553\n",
      "Epoch 30/50\n",
      "218/218 [==============================] - 6s 27ms/step - loss: 0.8980 - accuracy: 0.8230 - val_loss: 1.2932 - val_accuracy: 0.6800\n",
      "Epoch 31/50\n",
      "218/218 [==============================] - 6s 27ms/step - loss: 0.8958 - accuracy: 0.8257 - val_loss: 1.3468 - val_accuracy: 0.6700\n",
      "Epoch 32/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 0.8732 - accuracy: 0.8335 - val_loss: 1.2772 - val_accuracy: 0.6767\n",
      "Epoch 33/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.8793 - accuracy: 0.8335 - val_loss: 1.3030 - val_accuracy: 0.6613\n",
      "Epoch 34/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.8658 - accuracy: 0.8328 - val_loss: 1.3300 - val_accuracy: 0.6673\n",
      "Epoch 35/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.9011 - accuracy: 0.8247 - val_loss: 1.3141 - val_accuracy: 0.6647\n",
      "Epoch 36/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.8721 - accuracy: 0.8412 - val_loss: 1.4037 - val_accuracy: 0.6387\n",
      "Epoch 37/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.8934 - accuracy: 0.8320 - val_loss: 1.3627 - val_accuracy: 0.6620\n",
      "Epoch 38/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.8855 - accuracy: 0.8341 - val_loss: 1.3315 - val_accuracy: 0.6600\n",
      "Epoch 39/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.8725 - accuracy: 0.8382 - val_loss: 1.3569 - val_accuracy: 0.6820\n",
      "Epoch 40/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 0.8901 - accuracy: 0.8332 - val_loss: 1.3287 - val_accuracy: 0.6913\n",
      "Epoch 41/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.8872 - accuracy: 0.8399 - val_loss: 1.2893 - val_accuracy: 0.6800\n",
      "Epoch 42/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.8650 - accuracy: 0.8460 - val_loss: 1.2935 - val_accuracy: 0.7027\n",
      "Epoch 43/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.8489 - accuracy: 0.8522 - val_loss: 1.3879 - val_accuracy: 0.6733\n",
      "Epoch 44/50\n",
      "218/218 [==============================] - 6s 28ms/step - loss: 0.8349 - accuracy: 0.8586 - val_loss: 1.3359 - val_accuracy: 0.6773\n",
      "Epoch 45/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.8545 - accuracy: 0.8516 - val_loss: 1.3438 - val_accuracy: 0.6740\n",
      "Epoch 46/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.8397 - accuracy: 0.8545 - val_loss: 1.3509 - val_accuracy: 0.6687\n",
      "Epoch 47/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.8334 - accuracy: 0.8555 - val_loss: 1.3877 - val_accuracy: 0.6700\n",
      "Epoch 48/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.8762 - accuracy: 0.8454 - val_loss: 1.3515 - val_accuracy: 0.6787\n",
      "Epoch 49/50\n",
      "218/218 [==============================] - 6s 30ms/step - loss: 0.8739 - accuracy: 0.8517 - val_loss: 1.3507 - val_accuracy: 0.6847\n",
      "Epoch 50/50\n",
      "218/218 [==============================] - 7s 31ms/step - loss: 0.8600 - accuracy: 0.8516 - val_loss: 1.3686 - val_accuracy: 0.6607\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.5147 - accuracy: 0.9990\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 1.4086 - accuracy: 0.6546\n",
      "{'50': 0.6889367699623108, '100': 0.8397988677024841, '150': 0.920976996421814, '200': 0.9543103575706482, '250': 0.9821839332580566, '300': 0.9919540286064148, '350': 0.9929597973823547, '400': 0.9925287365913391, '450': 0.9971264600753784, '500': 0.9989942312240601}\n",
      "{'50': 0.42381489276885986, '100': 0.5174943804740906, '150': 0.5665914416313171, '200': 0.6139954924583435, '250': 0.6732505559921265, '300': 0.6715575456619263, '350': 0.6952595710754395, '400': 0.6851015686988831, '450': 0.703160285949707, '500': 0.6546275615692139}\n"
     ]
    }
   ],
   "source": [
    "for i in range(450, 550, 50):\n",
    "    y_test = np.load(\"y_test.npy\")\n",
    "    y_test -= 769\n",
    "    x_train, x_valid, x_test, y_train, y_valid, y_test = data_finalize(total_number=2115, takeout_sample=375, period=i, y_test=y_test)\n",
    "    l2_lambda = 0.001\n",
    "    \n",
    "    model = Sequential([\n",
    "\n",
    "      # Conv. block 1\n",
    "      keras.layers.Conv2D(filters=26, kernel_size=(9,1), padding='same', activation=tf.nn.gelu, kernel_regularizer=regularizers.l2(l2_lambda), input_shape=(x_train.shape[1],1,22)),\n",
    "      keras.layers.MaxPooling2D(pool_size=(3,1), padding='same'), # Read the keras documentation\n",
    "      keras.layers.BatchNormalization(),\n",
    "      keras.layers.Dropout(0.5),\n",
    "\n",
    "      # Conv. block 2\n",
    "      keras.layers.Conv2D(filters=52, kernel_size=(9,1), padding='same', activation=tf.nn.gelu, kernel_regularizer=regularizers.l2(l2_lambda)),\n",
    "      keras.layers.MaxPooling2D(pool_size=(3,1), padding='same'),\n",
    "      keras.layers.BatchNormalization(),\n",
    "      keras.layers.Dropout(0.5),\n",
    "\n",
    "      # Conv. block 3\n",
    "      keras.layers.Conv2D(filters=104, kernel_size=(9,1), padding='same', activation=tf.nn.gelu, kernel_regularizer=regularizers.l2(l2_lambda)),\n",
    "      keras.layers.MaxPooling2D(pool_size=(3,1), padding='same'),\n",
    "      keras.layers.BatchNormalization(),\n",
    "      keras.layers.Dropout(0.5),\n",
    "\n",
    "      keras.layers.Conv2D(filters=208, kernel_size=(9,1), padding='same', activation=tf.nn.gelu, kernel_regularizer=regularizers.l2(l2_lambda)),\n",
    "      keras.layers.MaxPooling2D(pool_size=(3,1), padding='same'),\n",
    "      keras.layers.BatchNormalization(),\n",
    "      keras.layers.Dropout(0.5),\n",
    "\n",
    "\n",
    "      # Output layer with Softmax activation\n",
    "      keras.layers.Flatten(), # Flattens the input\n",
    "      keras.layers.Dense(4, activation='softmax') # Output FC layer with softmax activation\n",
    "  ])\n",
    "\n",
    "    # Printing the model summary\n",
    "    model.summary()\n",
    "\n",
    "  \n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer=cnn_optimizer,\n",
    "                 metrics=['accuracy'])\n",
    "  \n",
    "\n",
    "    # Training and validating the model\n",
    "    model_results = model.fit(x_train,\n",
    "                  y_train,\n",
    "                  batch_size=32,\n",
    "                  epochs=epochs,\n",
    "                  validation_data=(x_valid, y_valid), verbose=True)\n",
    "\n",
    "    short_time_train_scores[str(i)] = model.evaluate(x_train, y_train)[1]\n",
    "    short_time_test_scores[str(i)] = model.evaluate(x_test, y_test)[1]\n",
    "print(short_time_train_scores)\n",
    "print(short_time_test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create lists for x and y values\n",
    "x_values = [int(k) for k in short_time_train_scores.keys()] # convert keys to integer values\n",
    "train_scores = [v for v in short_time_train_scores.values()]\n",
    "test_scores = [v for v in short_time_test_scores.values()]\n",
    "\n",
    "# Plot the data\n",
    "plt.plot(x_values, train_scores, label='Train Scores')\n",
    "plt.plot(x_values, test_scores, label='Test Scores')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel('Time period')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Test Accuracy for time period between 50 and 500')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_50 (Conv2D)          (None, 300, 1, 26)        5174      \n",
      "                                                                 \n",
      " max_pooling2d_50 (MaxPoolin  (None, 100, 1, 26)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_50 (Bat  (None, 100, 1, 26)       104       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_50 (Dropout)        (None, 100, 1, 26)        0         \n",
      "                                                                 \n",
      " conv2d_51 (Conv2D)          (None, 100, 1, 52)        12220     \n",
      "                                                                 \n",
      " max_pooling2d_51 (MaxPoolin  (None, 34, 1, 52)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_51 (Bat  (None, 34, 1, 52)        208       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_51 (Dropout)        (None, 34, 1, 52)         0         \n",
      "                                                                 \n",
      " conv2d_52 (Conv2D)          (None, 34, 1, 104)        48776     \n",
      "                                                                 \n",
      " max_pooling2d_52 (MaxPoolin  (None, 12, 1, 104)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_52 (Bat  (None, 12, 1, 104)       416       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_52 (Dropout)        (None, 12, 1, 104)        0         \n",
      "                                                                 \n",
      " conv2d_53 (Conv2D)          (None, 12, 1, 208)        194896    \n",
      "                                                                 \n",
      " max_pooling2d_53 (MaxPoolin  (None, 4, 1, 208)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_53 (Bat  (None, 4, 1, 208)        832       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_53 (Dropout)        (None, 4, 1, 208)         0         \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 832)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 4)                 3332      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 265,958\n",
      "Trainable params: 265,178\n",
      "Non-trainable params: 780\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "218/218 [==============================] - 7s 26ms/step - loss: 2.4134 - accuracy: 0.3221 - val_loss: 1.9894 - val_accuracy: 0.3847\n",
      "Epoch 2/50\n",
      "218/218 [==============================] - 6s 27ms/step - loss: 1.9755 - accuracy: 0.3954 - val_loss: 1.7970 - val_accuracy: 0.3633\n",
      "Epoch 3/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 1.7651 - accuracy: 0.4501 - val_loss: 1.7089 - val_accuracy: 0.4007\n",
      "Epoch 4/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 1.6160 - accuracy: 0.5026 - val_loss: 1.6729 - val_accuracy: 0.4307\n",
      "Epoch 5/50\n",
      "218/218 [==============================] - 7s 30ms/step - loss: 1.5188 - accuracy: 0.5407 - val_loss: 1.5319 - val_accuracy: 0.4840\n",
      "Epoch 6/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 1.4366 - accuracy: 0.5693 - val_loss: 1.4649 - val_accuracy: 0.5113\n",
      "Epoch 7/50\n",
      "218/218 [==============================] - 7s 31ms/step - loss: 1.3451 - accuracy: 0.6073 - val_loss: 1.4591 - val_accuracy: 0.5413\n",
      "Epoch 8/50\n",
      "218/218 [==============================] - 7s 31ms/step - loss: 1.2917 - accuracy: 0.6320 - val_loss: 1.4097 - val_accuracy: 0.5380\n",
      "Epoch 9/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 1.2491 - accuracy: 0.6422 - val_loss: 1.3941 - val_accuracy: 0.5887\n",
      "Epoch 10/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 1.2018 - accuracy: 0.6626 - val_loss: 1.3218 - val_accuracy: 0.5907\n",
      "Epoch 11/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 1.1448 - accuracy: 0.6917 - val_loss: 1.3654 - val_accuracy: 0.5947\n",
      "Epoch 12/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 1.1356 - accuracy: 0.6971 - val_loss: 1.3698 - val_accuracy: 0.5847\n",
      "Epoch 13/50\n",
      "218/218 [==============================] - 7s 30ms/step - loss: 1.0861 - accuracy: 0.7197 - val_loss: 1.2965 - val_accuracy: 0.6327\n",
      "Epoch 14/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 1.0611 - accuracy: 0.7315 - val_loss: 1.2757 - val_accuracy: 0.6280\n",
      "Epoch 15/50\n",
      "218/218 [==============================] - 7s 31ms/step - loss: 1.0343 - accuracy: 0.7514 - val_loss: 1.3003 - val_accuracy: 0.6147\n",
      "Epoch 16/50\n",
      "218/218 [==============================] - 7s 30ms/step - loss: 1.0259 - accuracy: 0.7556 - val_loss: 1.2837 - val_accuracy: 0.6427\n",
      "Epoch 17/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 1.0156 - accuracy: 0.7606 - val_loss: 1.2720 - val_accuracy: 0.6467\n",
      "Epoch 18/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.9979 - accuracy: 0.7680 - val_loss: 1.2697 - val_accuracy: 0.6533\n",
      "Epoch 19/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 0.9811 - accuracy: 0.7802 - val_loss: 1.2729 - val_accuracy: 0.6393\n",
      "Epoch 20/50\n",
      "218/218 [==============================] - 7s 33ms/step - loss: 0.9574 - accuracy: 0.7851 - val_loss: 1.2762 - val_accuracy: 0.6787\n",
      "Epoch 21/50\n",
      "218/218 [==============================] - 7s 33ms/step - loss: 0.9516 - accuracy: 0.7966 - val_loss: 1.2628 - val_accuracy: 0.6533\n",
      "Epoch 22/50\n",
      "218/218 [==============================] - 7s 33ms/step - loss: 0.9237 - accuracy: 0.8082 - val_loss: 1.2484 - val_accuracy: 0.6473\n",
      "Epoch 23/50\n",
      "218/218 [==============================] - 7s 33ms/step - loss: 0.9387 - accuracy: 0.8013 - val_loss: 1.2816 - val_accuracy: 0.6740\n",
      "Epoch 24/50\n",
      "218/218 [==============================] - 8s 35ms/step - loss: 0.9363 - accuracy: 0.8050 - val_loss: 1.2523 - val_accuracy: 0.6547\n",
      "Epoch 25/50\n",
      "218/218 [==============================] - 7s 33ms/step - loss: 0.9062 - accuracy: 0.8204 - val_loss: 1.2732 - val_accuracy: 0.6653\n",
      "Epoch 26/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 0.9169 - accuracy: 0.8147 - val_loss: 1.2470 - val_accuracy: 0.6767\n",
      "Epoch 27/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 0.9170 - accuracy: 0.8144 - val_loss: 1.2093 - val_accuracy: 0.6953\n",
      "Epoch 28/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 0.9231 - accuracy: 0.8207 - val_loss: 1.2478 - val_accuracy: 0.6720\n",
      "Epoch 29/50\n",
      "218/218 [==============================] - 7s 33ms/step - loss: 0.8964 - accuracy: 0.8254 - val_loss: 1.3034 - val_accuracy: 0.6667\n",
      "Epoch 30/50\n",
      "218/218 [==============================] - 7s 33ms/step - loss: 0.8906 - accuracy: 0.8303 - val_loss: 1.2607 - val_accuracy: 0.6793\n",
      "Epoch 31/50\n",
      "218/218 [==============================] - 7s 33ms/step - loss: 0.8897 - accuracy: 0.8323 - val_loss: 1.2706 - val_accuracy: 0.6667\n",
      "Epoch 32/50\n",
      "218/218 [==============================] - 7s 34ms/step - loss: 0.8689 - accuracy: 0.8401 - val_loss: 1.2090 - val_accuracy: 0.6847\n",
      "Epoch 33/50\n",
      "218/218 [==============================] - 7s 33ms/step - loss: 0.8627 - accuracy: 0.8392 - val_loss: 1.2180 - val_accuracy: 0.7020\n",
      "Epoch 34/50\n",
      "218/218 [==============================] - 7s 33ms/step - loss: 0.8850 - accuracy: 0.8342 - val_loss: 1.2479 - val_accuracy: 0.6967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "218/218 [==============================] - 7s 31ms/step - loss: 0.8644 - accuracy: 0.8432 - val_loss: 1.3106 - val_accuracy: 0.6520\n",
      "Epoch 36/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 0.8705 - accuracy: 0.8455 - val_loss: 1.2415 - val_accuracy: 0.7013\n",
      "Epoch 37/50\n",
      "218/218 [==============================] - 7s 31ms/step - loss: 0.8854 - accuracy: 0.8391 - val_loss: 1.2983 - val_accuracy: 0.6673\n",
      "Epoch 38/50\n",
      "218/218 [==============================] - 7s 31ms/step - loss: 0.8637 - accuracy: 0.8463 - val_loss: 1.2596 - val_accuracy: 0.6913\n",
      "Epoch 39/50\n",
      "218/218 [==============================] - 7s 30ms/step - loss: 0.8681 - accuracy: 0.8438 - val_loss: 1.2931 - val_accuracy: 0.6753\n",
      "Epoch 40/50\n",
      "218/218 [==============================] - 6s 30ms/step - loss: 0.8544 - accuracy: 0.8503 - val_loss: 1.2822 - val_accuracy: 0.6953\n",
      "Epoch 41/50\n",
      "218/218 [==============================] - 6s 29ms/step - loss: 0.8604 - accuracy: 0.8460 - val_loss: 1.3344 - val_accuracy: 0.6853\n",
      "Epoch 42/50\n",
      "218/218 [==============================] - 6s 30ms/step - loss: 0.8401 - accuracy: 0.8547 - val_loss: 1.3294 - val_accuracy: 0.6840\n",
      "Epoch 43/50\n",
      "218/218 [==============================] - 7s 30ms/step - loss: 0.8459 - accuracy: 0.8519 - val_loss: 1.3907 - val_accuracy: 0.6693\n",
      "Epoch 44/50\n",
      "218/218 [==============================] - 7s 30ms/step - loss: 0.8554 - accuracy: 0.8546 - val_loss: 1.3449 - val_accuracy: 0.6773\n",
      "Epoch 45/50\n",
      "218/218 [==============================] - 7s 30ms/step - loss: 0.8718 - accuracy: 0.8458 - val_loss: 1.2432 - val_accuracy: 0.7213\n",
      "Epoch 46/50\n",
      "218/218 [==============================] - 7s 31ms/step - loss: 0.8778 - accuracy: 0.8457 - val_loss: 1.2455 - val_accuracy: 0.7153\n",
      "Epoch 47/50\n",
      "218/218 [==============================] - 7s 31ms/step - loss: 0.8302 - accuracy: 0.8714 - val_loss: 1.3263 - val_accuracy: 0.6860\n",
      "Epoch 48/50\n",
      "218/218 [==============================] - 7s 31ms/step - loss: 0.8651 - accuracy: 0.8476 - val_loss: 1.3027 - val_accuracy: 0.6867\n",
      "Epoch 49/50\n",
      "218/218 [==============================] - 7s 30ms/step - loss: 0.8533 - accuracy: 0.8563 - val_loss: 1.2703 - val_accuracy: 0.6713\n",
      "Epoch 50/50\n",
      "218/218 [==============================] - 7s 31ms/step - loss: 0.8403 - accuracy: 0.8635 - val_loss: 1.3598 - val_accuracy: 0.6593\n",
      "218/218 [==============================] - 2s 8ms/step - loss: 0.5256 - accuracy: 0.9960\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 1.5050 - accuracy: 0.6439\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_54 (Conv2D)          (None, 350, 1, 26)        5174      \n",
      "                                                                 \n",
      " max_pooling2d_54 (MaxPoolin  (None, 117, 1, 26)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_54 (Bat  (None, 117, 1, 26)       104       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_54 (Dropout)        (None, 117, 1, 26)        0         \n",
      "                                                                 \n",
      " conv2d_55 (Conv2D)          (None, 117, 1, 52)        12220     \n",
      "                                                                 \n",
      " max_pooling2d_55 (MaxPoolin  (None, 39, 1, 52)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_55 (Bat  (None, 39, 1, 52)        208       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_55 (Dropout)        (None, 39, 1, 52)         0         \n",
      "                                                                 \n",
      " conv2d_56 (Conv2D)          (None, 39, 1, 104)        48776     \n",
      "                                                                 \n",
      " max_pooling2d_56 (MaxPoolin  (None, 13, 1, 104)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_56 (Bat  (None, 13, 1, 104)       416       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_56 (Dropout)        (None, 13, 1, 104)        0         \n",
      "                                                                 \n",
      " conv2d_57 (Conv2D)          (None, 13, 1, 208)        194896    \n",
      "                                                                 \n",
      " max_pooling2d_57 (MaxPoolin  (None, 5, 1, 208)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_57 (Bat  (None, 5, 1, 208)        832       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_57 (Dropout)        (None, 5, 1, 208)         0         \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 1040)              0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 4)                 4164      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,790\n",
      "Trainable params: 266,010\n",
      "Non-trainable params: 780\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "218/218 [==============================] - 8s 31ms/step - loss: 2.4962 - accuracy: 0.3240 - val_loss: 2.0220 - val_accuracy: 0.3773\n",
      "Epoch 2/50\n",
      "218/218 [==============================] - 7s 31ms/step - loss: 2.0519 - accuracy: 0.3759 - val_loss: 1.8770 - val_accuracy: 0.3660\n",
      "Epoch 3/50\n",
      "218/218 [==============================] - 7s 32ms/step - loss: 1.8404 - accuracy: 0.4361 - val_loss: 1.6981 - val_accuracy: 0.4647\n",
      "Epoch 4/50\n",
      "218/218 [==============================] - 8s 34ms/step - loss: 1.6862 - accuracy: 0.4848 - val_loss: 1.6583 - val_accuracy: 0.4673\n",
      "Epoch 5/50\n",
      "218/218 [==============================] - 8s 35ms/step - loss: 1.5718 - accuracy: 0.5159 - val_loss: 1.6478 - val_accuracy: 0.4480\n",
      "Epoch 6/50\n",
      "218/218 [==============================] - 8s 35ms/step - loss: 1.4718 - accuracy: 0.5569 - val_loss: 1.5585 - val_accuracy: 0.5027\n",
      "Epoch 7/50\n",
      "218/218 [==============================] - 8s 35ms/step - loss: 1.3889 - accuracy: 0.5950 - val_loss: 1.4595 - val_accuracy: 0.5493\n",
      "Epoch 8/50\n",
      "218/218 [==============================] - 8s 35ms/step - loss: 1.3043 - accuracy: 0.6296 - val_loss: 1.4544 - val_accuracy: 0.5640\n",
      "Epoch 9/50\n",
      "218/218 [==============================] - 8s 35ms/step - loss: 1.2419 - accuracy: 0.6570 - val_loss: 1.4486 - val_accuracy: 0.5640\n",
      "Epoch 10/50\n",
      "218/218 [==============================] - 8s 35ms/step - loss: 1.2144 - accuracy: 0.6747 - val_loss: 1.3887 - val_accuracy: 0.5740\n",
      "Epoch 11/50\n",
      "218/218 [==============================] - 8s 35ms/step - loss: 1.1543 - accuracy: 0.6970 - val_loss: 1.4083 - val_accuracy: 0.5940\n",
      "Epoch 12/50\n",
      "218/218 [==============================] - 8s 35ms/step - loss: 1.1172 - accuracy: 0.7205 - val_loss: 1.3977 - val_accuracy: 0.6113\n",
      "Epoch 13/50\n",
      "218/218 [==============================] - 8s 35ms/step - loss: 1.0970 - accuracy: 0.7201 - val_loss: 1.3418 - val_accuracy: 0.6327\n",
      "Epoch 14/50\n",
      "218/218 [==============================] - 8s 35ms/step - loss: 1.0527 - accuracy: 0.7441 - val_loss: 1.4025 - val_accuracy: 0.6053\n",
      "Epoch 15/50\n",
      "218/218 [==============================] - 8s 35ms/step - loss: 1.0756 - accuracy: 0.7432 - val_loss: 1.3497 - val_accuracy: 0.6340\n",
      "Epoch 16/50\n",
      "218/218 [==============================] - 8s 35ms/step - loss: 1.0221 - accuracy: 0.7626 - val_loss: 1.3768 - val_accuracy: 0.6307\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218/218 [==============================] - 7s 34ms/step - loss: 1.0174 - accuracy: 0.7659 - val_loss: 1.3821 - val_accuracy: 0.6400\n",
      "Epoch 18/50\n",
      "218/218 [==============================] - 7s 34ms/step - loss: 0.9898 - accuracy: 0.7776 - val_loss: 1.3661 - val_accuracy: 0.6447\n",
      "Epoch 19/50\n",
      "218/218 [==============================] - 8s 34ms/step - loss: 0.9786 - accuracy: 0.7836 - val_loss: 1.3935 - val_accuracy: 0.6227\n",
      "Epoch 20/50\n",
      "218/218 [==============================] - 7s 34ms/step - loss: 0.9462 - accuracy: 0.8006 - val_loss: 1.4205 - val_accuracy: 0.6367\n",
      "Epoch 21/50\n",
      "218/218 [==============================] - 7s 33ms/step - loss: 0.9509 - accuracy: 0.7990 - val_loss: 1.4182 - val_accuracy: 0.6280\n",
      "Epoch 22/50\n",
      "218/218 [==============================] - 7s 34ms/step - loss: 0.9319 - accuracy: 0.8111 - val_loss: 1.4222 - val_accuracy: 0.6367\n",
      "Epoch 23/50\n",
      "218/218 [==============================] - 8s 35ms/step - loss: 0.9389 - accuracy: 0.8069 - val_loss: 1.4113 - val_accuracy: 0.6487\n",
      "Epoch 24/50\n",
      "218/218 [==============================] - 8s 35ms/step - loss: 0.9225 - accuracy: 0.8129 - val_loss: 1.4910 - val_accuracy: 0.6293\n",
      "Epoch 25/50\n",
      "218/218 [==============================] - 9s 40ms/step - loss: 0.9131 - accuracy: 0.8214 - val_loss: 1.4972 - val_accuracy: 0.6267\n",
      "Epoch 26/50\n",
      "218/218 [==============================] - 10s 44ms/step - loss: 0.9167 - accuracy: 0.8224 - val_loss: 1.5289 - val_accuracy: 0.6233\n",
      "Epoch 27/50\n",
      "218/218 [==============================] - 9s 40ms/step - loss: 0.9034 - accuracy: 0.8305 - val_loss: 1.4722 - val_accuracy: 0.6413\n",
      "Epoch 28/50\n",
      "218/218 [==============================] - 8s 38ms/step - loss: 0.8914 - accuracy: 0.8364 - val_loss: 1.4774 - val_accuracy: 0.6287\n",
      "Epoch 29/50\n",
      "218/218 [==============================] - 8s 37ms/step - loss: 0.8929 - accuracy: 0.8384 - val_loss: 1.4236 - val_accuracy: 0.6620\n",
      "Epoch 30/50\n",
      "218/218 [==============================] - 8s 36ms/step - loss: 0.8821 - accuracy: 0.8379 - val_loss: 1.5052 - val_accuracy: 0.6220\n",
      "Epoch 31/50\n",
      "218/218 [==============================] - 8s 36ms/step - loss: 0.8881 - accuracy: 0.8411 - val_loss: 1.4606 - val_accuracy: 0.6567\n",
      "Epoch 32/50\n",
      "218/218 [==============================] - 8s 37ms/step - loss: 0.8899 - accuracy: 0.8366 - val_loss: 1.4344 - val_accuracy: 0.6500\n",
      "Epoch 33/50\n",
      "218/218 [==============================] - 9s 40ms/step - loss: 0.8852 - accuracy: 0.8376 - val_loss: 1.4744 - val_accuracy: 0.6447\n",
      "Epoch 34/50\n",
      "218/218 [==============================] - 9s 42ms/step - loss: 0.8901 - accuracy: 0.8408 - val_loss: 1.4920 - val_accuracy: 0.6327\n",
      "Epoch 35/50\n",
      "218/218 [==============================] - 9s 40ms/step - loss: 0.8853 - accuracy: 0.8418 - val_loss: 1.4978 - val_accuracy: 0.6727\n",
      "Epoch 36/50\n",
      "218/218 [==============================] - 9s 40ms/step - loss: 0.8776 - accuracy: 0.8478 - val_loss: 1.4344 - val_accuracy: 0.6593\n",
      "Epoch 37/50\n",
      "218/218 [==============================] - 9s 39ms/step - loss: 0.8487 - accuracy: 0.8583 - val_loss: 1.4217 - val_accuracy: 0.6760\n",
      "Epoch 38/50\n",
      "218/218 [==============================] - 8s 39ms/step - loss: 0.8725 - accuracy: 0.8470 - val_loss: 1.4621 - val_accuracy: 0.6680\n",
      "Epoch 39/50\n",
      "218/218 [==============================] - 8s 38ms/step - loss: 0.8696 - accuracy: 0.8537 - val_loss: 1.4402 - val_accuracy: 0.6700\n",
      "Epoch 40/50\n",
      "218/218 [==============================] - 8s 38ms/step - loss: 0.8672 - accuracy: 0.8559 - val_loss: 1.3925 - val_accuracy: 0.6960\n",
      "Epoch 41/50\n",
      "218/218 [==============================] - 8s 38ms/step - loss: 0.8577 - accuracy: 0.8560 - val_loss: 1.4481 - val_accuracy: 0.6700\n",
      "Epoch 42/50\n",
      "218/218 [==============================] - 9s 40ms/step - loss: 0.8621 - accuracy: 0.8618 - val_loss: 1.4495 - val_accuracy: 0.6840\n",
      "Epoch 43/50\n",
      "218/218 [==============================] - 9s 39ms/step - loss: 0.8558 - accuracy: 0.8589 - val_loss: 1.3680 - val_accuracy: 0.6813\n",
      "Epoch 44/50\n",
      "218/218 [==============================] - 8s 38ms/step - loss: 0.8705 - accuracy: 0.8557 - val_loss: 1.4784 - val_accuracy: 0.6707\n",
      "Epoch 45/50\n",
      "218/218 [==============================] - 8s 38ms/step - loss: 0.8562 - accuracy: 0.8602 - val_loss: 1.4452 - val_accuracy: 0.6833\n",
      "Epoch 46/50\n",
      "218/218 [==============================] - 8s 38ms/step - loss: 0.8592 - accuracy: 0.8568 - val_loss: 1.4422 - val_accuracy: 0.6733\n",
      "Epoch 47/50\n",
      "218/218 [==============================] - 8s 37ms/step - loss: 0.8565 - accuracy: 0.8649 - val_loss: 1.5556 - val_accuracy: 0.6427\n",
      "Epoch 48/50\n",
      "218/218 [==============================] - 8s 37ms/step - loss: 0.8608 - accuracy: 0.8547 - val_loss: 1.4671 - val_accuracy: 0.6700\n",
      "Epoch 49/50\n",
      "218/218 [==============================] - 8s 38ms/step - loss: 0.8388 - accuracy: 0.8657 - val_loss: 1.4900 - val_accuracy: 0.6580\n",
      "Epoch 50/50\n",
      "218/218 [==============================] - 8s 39ms/step - loss: 0.8420 - accuracy: 0.8654 - val_loss: 1.4354 - val_accuracy: 0.6707\n",
      "218/218 [==============================] - 2s 10ms/step - loss: 0.5266 - accuracy: 0.9968\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 1.4388 - accuracy: 0.6580\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_58 (Conv2D)          (None, 400, 1, 26)        5174      \n",
      "                                                                 \n",
      " max_pooling2d_58 (MaxPoolin  (None, 134, 1, 26)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_58 (Bat  (None, 134, 1, 26)       104       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_58 (Dropout)        (None, 134, 1, 26)        0         \n",
      "                                                                 \n",
      " conv2d_59 (Conv2D)          (None, 134, 1, 52)        12220     \n",
      "                                                                 \n",
      " max_pooling2d_59 (MaxPoolin  (None, 45, 1, 52)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_59 (Bat  (None, 45, 1, 52)        208       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_59 (Dropout)        (None, 45, 1, 52)         0         \n",
      "                                                                 \n",
      " conv2d_60 (Conv2D)          (None, 45, 1, 104)        48776     \n",
      "                                                                 \n",
      " max_pooling2d_60 (MaxPoolin  (None, 15, 1, 104)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_60 (Bat  (None, 15, 1, 104)       416       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_60 (Dropout)        (None, 15, 1, 104)        0         \n",
      "                                                                 \n",
      " conv2d_61 (Conv2D)          (None, 15, 1, 208)        194896    \n",
      "                                                                 \n",
      " max_pooling2d_61 (MaxPoolin  (None, 5, 1, 208)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_61 (Bat  (None, 5, 1, 208)        832       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_61 (Dropout)        (None, 5, 1, 208)         0         \n",
      "                                                                 \n",
      " flatten_15 (Flatten)        (None, 1040)              0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 4)                 4164      \n",
      "                                                                 \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 266,790\n",
      "Trainable params: 266,010\n",
      "Non-trainable params: 780\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "218/218 [==============================] - 9s 34ms/step - loss: 2.5298 - accuracy: 0.3282 - val_loss: 2.0404 - val_accuracy: 0.3707\n",
      "Epoch 2/50\n",
      "218/218 [==============================] - 8s 37ms/step - loss: 2.0524 - accuracy: 0.4060 - val_loss: 1.9137 - val_accuracy: 0.3893\n",
      "Epoch 3/50\n",
      "218/218 [==============================] - 9s 40ms/step - loss: 1.8445 - accuracy: 0.4649 - val_loss: 1.7435 - val_accuracy: 0.4800\n",
      "Epoch 4/50\n",
      "218/218 [==============================] - 9s 40ms/step - loss: 1.6742 - accuracy: 0.5132 - val_loss: 1.6512 - val_accuracy: 0.4673\n",
      "Epoch 5/50\n",
      "218/218 [==============================] - 9s 41ms/step - loss: 1.5308 - accuracy: 0.5674 - val_loss: 1.5833 - val_accuracy: 0.5380\n",
      "Epoch 6/50\n",
      "218/218 [==============================] - 9s 41ms/step - loss: 1.4579 - accuracy: 0.5963 - val_loss: 1.5017 - val_accuracy: 0.5447\n",
      "Epoch 7/50\n",
      "218/218 [==============================] - 9s 41ms/step - loss: 1.3719 - accuracy: 0.6339 - val_loss: 1.4451 - val_accuracy: 0.5733\n",
      "Epoch 8/50\n",
      "218/218 [==============================] - 9s 41ms/step - loss: 1.2986 - accuracy: 0.6539 - val_loss: 1.4058 - val_accuracy: 0.6153\n",
      "Epoch 9/50\n",
      "218/218 [==============================] - 9s 40ms/step - loss: 1.2220 - accuracy: 0.6818 - val_loss: 1.3586 - val_accuracy: 0.6273\n",
      "Epoch 10/50\n",
      "218/218 [==============================] - 9s 40ms/step - loss: 1.1710 - accuracy: 0.7013 - val_loss: 1.3609 - val_accuracy: 0.6153\n",
      "Epoch 11/50\n",
      "218/218 [==============================] - 9s 40ms/step - loss: 1.1246 - accuracy: 0.7122 - val_loss: 1.3248 - val_accuracy: 0.6307\n",
      "Epoch 12/50\n",
      "218/218 [==============================] - 8s 39ms/step - loss: 1.0949 - accuracy: 0.7296 - val_loss: 1.3464 - val_accuracy: 0.6447\n",
      "Epoch 13/50\n",
      "218/218 [==============================] - 8s 39ms/step - loss: 1.0718 - accuracy: 0.7399 - val_loss: 1.3400 - val_accuracy: 0.6487\n",
      "Epoch 14/50\n",
      "218/218 [==============================] - 9s 39ms/step - loss: 1.0375 - accuracy: 0.7549 - val_loss: 1.3539 - val_accuracy: 0.6540\n",
      "Epoch 15/50\n",
      "218/218 [==============================] - 9s 41ms/step - loss: 1.0485 - accuracy: 0.7524 - val_loss: 1.3583 - val_accuracy: 0.6560\n",
      "Epoch 16/50\n",
      "218/218 [==============================] - 9s 42ms/step - loss: 0.9919 - accuracy: 0.7813 - val_loss: 1.3885 - val_accuracy: 0.6547\n",
      "Epoch 17/50\n",
      "218/218 [==============================] - 9s 42ms/step - loss: 0.9948 - accuracy: 0.7828 - val_loss: 1.4000 - val_accuracy: 0.6320\n",
      "Epoch 18/50\n",
      "218/218 [==============================] - 9s 40ms/step - loss: 0.9793 - accuracy: 0.7845 - val_loss: 1.3336 - val_accuracy: 0.6587\n",
      "Epoch 19/50\n",
      "218/218 [==============================] - 9s 40ms/step - loss: 0.9640 - accuracy: 0.7899 - val_loss: 1.4997 - val_accuracy: 0.6400\n",
      "Epoch 20/50\n",
      "218/218 [==============================] - 9s 40ms/step - loss: 0.9719 - accuracy: 0.7930 - val_loss: 1.3885 - val_accuracy: 0.6580\n",
      "Epoch 21/50\n",
      "218/218 [==============================] - 9s 40ms/step - loss: 0.9409 - accuracy: 0.8049 - val_loss: 1.4053 - val_accuracy: 0.6547\n",
      "Epoch 22/50\n",
      "218/218 [==============================] - 9s 40ms/step - loss: 0.9271 - accuracy: 0.8193 - val_loss: 1.3551 - val_accuracy: 0.6733\n",
      "Epoch 23/50\n",
      "218/218 [==============================] - 9s 40ms/step - loss: 0.9169 - accuracy: 0.8191 - val_loss: 1.4109 - val_accuracy: 0.6413\n",
      "Epoch 24/50\n",
      "218/218 [==============================] - 9s 40ms/step - loss: 0.9125 - accuracy: 0.8203 - val_loss: 1.4389 - val_accuracy: 0.6540\n",
      "Epoch 25/50\n",
      "218/218 [==============================] - 9s 40ms/step - loss: 0.9468 - accuracy: 0.8098 - val_loss: 1.3828 - val_accuracy: 0.6827\n",
      "Epoch 26/50\n",
      "218/218 [==============================] - 9s 39ms/step - loss: 0.9038 - accuracy: 0.8303 - val_loss: 1.3922 - val_accuracy: 0.6793\n",
      "Epoch 27/50\n",
      "218/218 [==============================] - 9s 39ms/step - loss: 0.8826 - accuracy: 0.8391 - val_loss: 1.4479 - val_accuracy: 0.6707\n",
      "Epoch 28/50\n",
      "218/218 [==============================] - 9s 40ms/step - loss: 0.9197 - accuracy: 0.8241 - val_loss: 1.4399 - val_accuracy: 0.6740\n",
      "Epoch 29/50\n",
      "218/218 [==============================] - 9s 41ms/step - loss: 0.9053 - accuracy: 0.8309 - val_loss: 1.4837 - val_accuracy: 0.6593\n",
      "Epoch 30/50\n",
      "218/218 [==============================] - 9s 41ms/step - loss: 0.9131 - accuracy: 0.8273 - val_loss: 1.5212 - val_accuracy: 0.6567\n",
      "Epoch 31/50\n",
      "218/218 [==============================] - 9s 41ms/step - loss: 0.8940 - accuracy: 0.8402 - val_loss: 1.4361 - val_accuracy: 0.6693\n",
      "Epoch 32/50\n",
      "218/218 [==============================] - 9s 40ms/step - loss: 0.8868 - accuracy: 0.8438 - val_loss: 1.4430 - val_accuracy: 0.6853\n",
      "Epoch 33/50\n",
      "218/218 [==============================] - 8s 39ms/step - loss: 0.8766 - accuracy: 0.8491 - val_loss: 1.4567 - val_accuracy: 0.6753\n",
      "Epoch 34/50\n",
      "218/218 [==============================] - 8s 39ms/step - loss: 0.8838 - accuracy: 0.8484 - val_loss: 1.4324 - val_accuracy: 0.6727\n",
      "Epoch 35/50\n",
      "218/218 [==============================] - 9s 40ms/step - loss: 0.8688 - accuracy: 0.8511 - val_loss: 1.4183 - val_accuracy: 0.6847\n",
      "Epoch 36/50\n",
      "218/218 [==============================] - 9s 42ms/step - loss: 0.8915 - accuracy: 0.8422 - val_loss: 1.4628 - val_accuracy: 0.6640\n",
      "Epoch 37/50\n",
      "218/218 [==============================] - 9s 42ms/step - loss: 0.8774 - accuracy: 0.8524 - val_loss: 1.4200 - val_accuracy: 0.6933\n",
      "Epoch 38/50\n",
      "218/218 [==============================] - 9s 42ms/step - loss: 0.8838 - accuracy: 0.8493 - val_loss: 1.5152 - val_accuracy: 0.6493\n",
      "Epoch 39/50\n",
      "218/218 [==============================] - 9s 42ms/step - loss: 0.8802 - accuracy: 0.8453 - val_loss: 1.4229 - val_accuracy: 0.6840\n",
      "Epoch 40/50\n",
      "218/218 [==============================] - 9s 41ms/step - loss: 0.8647 - accuracy: 0.8553 - val_loss: 1.4816 - val_accuracy: 0.6653\n",
      "Epoch 41/50\n",
      "218/218 [==============================] - 9s 40ms/step - loss: 0.8437 - accuracy: 0.8642 - val_loss: 1.4511 - val_accuracy: 0.6907\n",
      "Epoch 42/50\n",
      "218/218 [==============================] - 9s 40ms/step - loss: 0.8543 - accuracy: 0.8579 - val_loss: 1.4552 - val_accuracy: 0.6727\n",
      "Epoch 43/50\n",
      "218/218 [==============================] - 9s 40ms/step - loss: 0.8782 - accuracy: 0.8496 - val_loss: 1.4240 - val_accuracy: 0.6727\n",
      "Epoch 44/50\n",
      "218/218 [==============================] - 9s 40ms/step - loss: 0.8649 - accuracy: 0.8565 - val_loss: 1.4325 - val_accuracy: 0.6773\n",
      "Epoch 45/50\n",
      "218/218 [==============================] - 9s 40ms/step - loss: 0.8441 - accuracy: 0.8652 - val_loss: 1.4829 - val_accuracy: 0.6740\n",
      "Epoch 46/50\n",
      "218/218 [==============================] - 9s 42ms/step - loss: 0.8700 - accuracy: 0.8506 - val_loss: 1.5002 - val_accuracy: 0.6780\n",
      "Epoch 47/50\n",
      "218/218 [==============================] - 10s 44ms/step - loss: 0.8463 - accuracy: 0.8619 - val_loss: 1.4585 - val_accuracy: 0.6653\n",
      "Epoch 48/50\n",
      "218/218 [==============================] - 10s 44ms/step - loss: 0.8557 - accuracy: 0.8573 - val_loss: 1.4660 - val_accuracy: 0.6660\n",
      "Epoch 49/50\n",
      "218/218 [==============================] - 10s 44ms/step - loss: 0.8426 - accuracy: 0.8644 - val_loss: 1.4987 - val_accuracy: 0.6667\n",
      "Epoch 50/50\n",
      "218/218 [==============================] - 9s 43ms/step - loss: 0.8541 - accuracy: 0.8649 - val_loss: 1.4470 - val_accuracy: 0.6827\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 0.5227 - accuracy: 0.9989\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.4594 - accuracy: 0.6569\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_62 (Conv2D)          (None, 450, 1, 26)        5174      \n",
      "                                                                 \n",
      " max_pooling2d_62 (MaxPoolin  (None, 150, 1, 26)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_62 (Bat  (None, 150, 1, 26)       104       \n",
      " chNormalization)                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " dropout_62 (Dropout)        (None, 150, 1, 26)        0         \n",
      "                                                                 \n",
      " conv2d_63 (Conv2D)          (None, 150, 1, 52)        12220     \n",
      "                                                                 \n",
      " max_pooling2d_63 (MaxPoolin  (None, 50, 1, 52)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_63 (Bat  (None, 50, 1, 52)        208       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_63 (Dropout)        (None, 50, 1, 52)         0         \n",
      "                                                                 \n",
      " conv2d_64 (Conv2D)          (None, 50, 1, 104)        48776     \n",
      "                                                                 \n",
      " max_pooling2d_64 (MaxPoolin  (None, 17, 1, 104)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_64 (Bat  (None, 17, 1, 104)       416       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_64 (Dropout)        (None, 17, 1, 104)        0         \n",
      "                                                                 \n",
      " conv2d_65 (Conv2D)          (None, 17, 1, 208)        194896    \n",
      "                                                                 \n",
      " max_pooling2d_65 (MaxPoolin  (None, 6, 1, 208)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_65 (Bat  (None, 6, 1, 208)        832       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_65 (Dropout)        (None, 6, 1, 208)         0         \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 1248)              0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 4)                 4996      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 267,622\n",
      "Trainable params: 266,842\n",
      "Non-trainable params: 780\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "218/218 [==============================] - 10s 39ms/step - loss: 2.6691 - accuracy: 0.3231 - val_loss: 2.1855 - val_accuracy: 0.3280\n",
      "Epoch 2/50\n",
      "218/218 [==============================] - 9s 42ms/step - loss: 2.1073 - accuracy: 0.3977 - val_loss: 1.9080 - val_accuracy: 0.3880\n",
      "Epoch 3/50\n",
      "218/218 [==============================] - 10s 46ms/step - loss: 1.8885 - accuracy: 0.4539 - val_loss: 1.8161 - val_accuracy: 0.4520\n",
      "Epoch 4/50\n",
      "218/218 [==============================] - 10s 46ms/step - loss: 1.7146 - accuracy: 0.5019 - val_loss: 1.7342 - val_accuracy: 0.4727\n",
      "Epoch 5/50\n",
      "218/218 [==============================] - 11s 49ms/step - loss: 1.5802 - accuracy: 0.5497 - val_loss: 1.6588 - val_accuracy: 0.5040\n",
      "Epoch 6/50\n",
      "218/218 [==============================] - 10s 48ms/step - loss: 1.4838 - accuracy: 0.5777 - val_loss: 1.6367 - val_accuracy: 0.5247\n",
      "Epoch 7/50\n",
      "218/218 [==============================] - 10s 47ms/step - loss: 1.3961 - accuracy: 0.6263 - val_loss: 1.6330 - val_accuracy: 0.5400\n",
      "Epoch 8/50\n",
      "218/218 [==============================] - 11s 48ms/step - loss: 1.3372 - accuracy: 0.6471 - val_loss: 1.6603 - val_accuracy: 0.5300\n",
      "Epoch 9/50\n",
      "218/218 [==============================] - 10s 46ms/step - loss: 1.2763 - accuracy: 0.6658 - val_loss: 1.6245 - val_accuracy: 0.5507\n",
      "Epoch 10/50\n",
      "218/218 [==============================] - 10s 45ms/step - loss: 1.2210 - accuracy: 0.6820 - val_loss: 1.5155 - val_accuracy: 0.5860\n",
      "Epoch 11/50\n",
      "218/218 [==============================] - 9s 42ms/step - loss: 1.1793 - accuracy: 0.7078 - val_loss: 1.4692 - val_accuracy: 0.6087\n",
      "Epoch 12/50\n",
      "218/218 [==============================] - 9s 40ms/step - loss: 1.1230 - accuracy: 0.7280 - val_loss: 1.3969 - val_accuracy: 0.6253\n",
      "Epoch 13/50\n",
      "218/218 [==============================] - 9s 42ms/step - loss: 1.0861 - accuracy: 0.7438 - val_loss: 1.4525 - val_accuracy: 0.6393\n",
      "Epoch 14/50\n",
      "218/218 [==============================] - 10s 44ms/step - loss: 1.0642 - accuracy: 0.7491 - val_loss: 1.4400 - val_accuracy: 0.6187\n",
      "Epoch 15/50\n",
      "218/218 [==============================] - 9s 43ms/step - loss: 1.0201 - accuracy: 0.7668 - val_loss: 1.4981 - val_accuracy: 0.6153\n",
      "Epoch 16/50\n",
      "218/218 [==============================] - 10s 45ms/step - loss: 1.0015 - accuracy: 0.7756 - val_loss: 1.5091 - val_accuracy: 0.6140\n",
      "Epoch 17/50\n",
      "218/218 [==============================] - 10s 44ms/step - loss: 1.0044 - accuracy: 0.7822 - val_loss: 1.4712 - val_accuracy: 0.6287\n",
      "Epoch 18/50\n",
      "218/218 [==============================] - 9s 43ms/step - loss: 0.9744 - accuracy: 0.7940 - val_loss: 1.4738 - val_accuracy: 0.6307\n",
      "Epoch 19/50\n",
      "218/218 [==============================] - 9s 43ms/step - loss: 0.9615 - accuracy: 0.8029 - val_loss: 1.4694 - val_accuracy: 0.6633\n",
      "Epoch 20/50\n",
      "218/218 [==============================] - 9s 41ms/step - loss: 0.9443 - accuracy: 0.8149 - val_loss: 1.4843 - val_accuracy: 0.6273\n",
      "Epoch 21/50\n",
      "218/218 [==============================] - 9s 40ms/step - loss: 0.9599 - accuracy: 0.8091 - val_loss: 1.4476 - val_accuracy: 0.6433\n",
      "Epoch 22/50\n",
      "218/218 [==============================] - 9s 41ms/step - loss: 0.9493 - accuracy: 0.8136 - val_loss: 1.5056 - val_accuracy: 0.6280\n",
      "Epoch 23/50\n",
      "218/218 [==============================] - 9s 43ms/step - loss: 0.9458 - accuracy: 0.8145 - val_loss: 1.5214 - val_accuracy: 0.6380\n",
      "Epoch 24/50\n",
      "218/218 [==============================] - 9s 43ms/step - loss: 0.9230 - accuracy: 0.8273 - val_loss: 1.4693 - val_accuracy: 0.6567\n",
      "Epoch 25/50\n",
      "218/218 [==============================] - 9s 43ms/step - loss: 0.9114 - accuracy: 0.8329 - val_loss: 1.5087 - val_accuracy: 0.6300\n",
      "Epoch 26/50\n",
      "218/218 [==============================] - 10s 44ms/step - loss: 0.9028 - accuracy: 0.8339 - val_loss: 1.4358 - val_accuracy: 0.6633\n",
      "Epoch 27/50\n",
      "218/218 [==============================] - 10s 46ms/step - loss: 0.8941 - accuracy: 0.8388 - val_loss: 1.4746 - val_accuracy: 0.6447\n",
      "Epoch 28/50\n",
      "218/218 [==============================] - 9s 43ms/step - loss: 0.8731 - accuracy: 0.8516 - val_loss: 1.5057 - val_accuracy: 0.6493\n",
      "Epoch 29/50\n",
      "218/218 [==============================] - 9s 42ms/step - loss: 0.8879 - accuracy: 0.8454 - val_loss: 1.4849 - val_accuracy: 0.6613\n",
      "Epoch 30/50\n",
      "218/218 [==============================] - 9s 41ms/step - loss: 0.8672 - accuracy: 0.8520 - val_loss: 1.3950 - val_accuracy: 0.6707\n",
      "Epoch 31/50\n",
      "218/218 [==============================] - 9s 41ms/step - loss: 0.8884 - accuracy: 0.8463 - val_loss: 1.5283 - val_accuracy: 0.6153\n",
      "Epoch 32/50\n",
      "218/218 [==============================] - 9s 43ms/step - loss: 0.8971 - accuracy: 0.8463 - val_loss: 1.4701 - val_accuracy: 0.6673\n",
      "Epoch 33/50\n",
      "218/218 [==============================] - 10s 44ms/step - loss: 0.8755 - accuracy: 0.8566 - val_loss: 1.5886 - val_accuracy: 0.6413\n",
      "Epoch 34/50\n",
      "218/218 [==============================] - 9s 44ms/step - loss: 0.8720 - accuracy: 0.8520 - val_loss: 1.4660 - val_accuracy: 0.6493\n",
      "Epoch 35/50\n",
      "218/218 [==============================] - 10s 44ms/step - loss: 0.8749 - accuracy: 0.8568 - val_loss: 1.5163 - val_accuracy: 0.6527\n",
      "Epoch 36/50\n",
      "218/218 [==============================] - 10s 44ms/step - loss: 0.8647 - accuracy: 0.8605 - val_loss: 1.5354 - val_accuracy: 0.6480\n",
      "Epoch 37/50\n",
      "218/218 [==============================] - 9s 42ms/step - loss: 0.8599 - accuracy: 0.8545 - val_loss: 1.5145 - val_accuracy: 0.6307\n",
      "Epoch 38/50\n",
      "218/218 [==============================] - 9s 42ms/step - loss: 0.8454 - accuracy: 0.8655 - val_loss: 1.5497 - val_accuracy: 0.6353\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218/218 [==============================] - 9s 42ms/step - loss: 0.8594 - accuracy: 0.8550 - val_loss: 1.5352 - val_accuracy: 0.6367\n",
      "Epoch 40/50\n",
      "218/218 [==============================] - 9s 42ms/step - loss: 0.8696 - accuracy: 0.8621 - val_loss: 1.5502 - val_accuracy: 0.6560\n",
      "Epoch 41/50\n",
      "218/218 [==============================] - 10s 44ms/step - loss: 0.8638 - accuracy: 0.8614 - val_loss: 1.4493 - val_accuracy: 0.6687\n",
      "Epoch 42/50\n",
      "218/218 [==============================] - 9s 42ms/step - loss: 0.8860 - accuracy: 0.8540 - val_loss: 1.4949 - val_accuracy: 0.6567\n",
      "Epoch 43/50\n",
      "218/218 [==============================] - 9s 41ms/step - loss: 0.8621 - accuracy: 0.8618 - val_loss: 1.4753 - val_accuracy: 0.6840\n",
      "Epoch 44/50\n",
      "218/218 [==============================] - 9s 41ms/step - loss: 0.8780 - accuracy: 0.8576 - val_loss: 1.5151 - val_accuracy: 0.6780\n",
      "Epoch 45/50\n",
      "218/218 [==============================] - 9s 43ms/step - loss: 0.8508 - accuracy: 0.8716 - val_loss: 1.5051 - val_accuracy: 0.6807\n",
      "Epoch 46/50\n",
      "218/218 [==============================] - 10s 44ms/step - loss: 0.8524 - accuracy: 0.8688 - val_loss: 1.4596 - val_accuracy: 0.6687\n",
      "Epoch 47/50\n",
      "218/218 [==============================] - 9s 43ms/step - loss: 0.8391 - accuracy: 0.8708 - val_loss: 1.4547 - val_accuracy: 0.6613\n",
      "Epoch 48/50\n",
      "218/218 [==============================] - 10s 45ms/step - loss: 0.8469 - accuracy: 0.8680 - val_loss: 1.5322 - val_accuracy: 0.6480\n",
      "Epoch 49/50\n",
      "218/218 [==============================] - 9s 43ms/step - loss: 0.8529 - accuracy: 0.8685 - val_loss: 1.5261 - val_accuracy: 0.6827\n",
      "Epoch 50/50\n",
      "218/218 [==============================] - 9s 43ms/step - loss: 0.8474 - accuracy: 0.8720 - val_loss: 1.4616 - val_accuracy: 0.6793\n",
      "218/218 [==============================] - 2s 10ms/step - loss: 0.5243 - accuracy: 0.9990\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.4848 - accuracy: 0.6738\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_66 (Conv2D)          (None, 500, 1, 26)        5174      \n",
      "                                                                 \n",
      " max_pooling2d_66 (MaxPoolin  (None, 167, 1, 26)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_66 (Bat  (None, 167, 1, 26)       104       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_66 (Dropout)        (None, 167, 1, 26)        0         \n",
      "                                                                 \n",
      " conv2d_67 (Conv2D)          (None, 167, 1, 52)        12220     \n",
      "                                                                 \n",
      " max_pooling2d_67 (MaxPoolin  (None, 56, 1, 52)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_67 (Bat  (None, 56, 1, 52)        208       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_67 (Dropout)        (None, 56, 1, 52)         0         \n",
      "                                                                 \n",
      " conv2d_68 (Conv2D)          (None, 56, 1, 104)        48776     \n",
      "                                                                 \n",
      " max_pooling2d_68 (MaxPoolin  (None, 19, 1, 104)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_68 (Bat  (None, 19, 1, 104)       416       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_68 (Dropout)        (None, 19, 1, 104)        0         \n",
      "                                                                 \n",
      " conv2d_69 (Conv2D)          (None, 19, 1, 208)        194896    \n",
      "                                                                 \n",
      " max_pooling2d_69 (MaxPoolin  (None, 7, 1, 208)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_69 (Bat  (None, 7, 1, 208)        832       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_69 (Dropout)        (None, 7, 1, 208)         0         \n",
      "                                                                 \n",
      " flatten_17 (Flatten)        (None, 1456)              0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 4)                 5828      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 268,454\n",
      "Trainable params: 267,674\n",
      "Non-trainable params: 780\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "218/218 [==============================] - 11s 45ms/step - loss: 2.7140 - accuracy: 0.3257 - val_loss: 2.2857 - val_accuracy: 0.3367\n",
      "Epoch 2/50\n",
      "218/218 [==============================] - 9s 40ms/step - loss: 2.2148 - accuracy: 0.3829 - val_loss: 1.9462 - val_accuracy: 0.3813\n",
      "Epoch 3/50\n",
      "218/218 [==============================] - 10s 45ms/step - loss: 1.9583 - accuracy: 0.4412 - val_loss: 1.9421 - val_accuracy: 0.3440\n",
      "Epoch 4/50\n",
      "218/218 [==============================] - 10s 46ms/step - loss: 1.7834 - accuracy: 0.5085 - val_loss: 1.8127 - val_accuracy: 0.4280\n",
      "Epoch 5/50\n",
      "218/218 [==============================] - 10s 46ms/step - loss: 1.6470 - accuracy: 0.5494 - val_loss: 1.7000 - val_accuracy: 0.5113\n",
      "Epoch 6/50\n",
      "218/218 [==============================] - 10s 46ms/step - loss: 1.5190 - accuracy: 0.5938 - val_loss: 1.6324 - val_accuracy: 0.5387\n",
      "Epoch 7/50\n",
      "218/218 [==============================] - 10s 47ms/step - loss: 1.4209 - accuracy: 0.6251 - val_loss: 1.5828 - val_accuracy: 0.5533\n",
      "Epoch 8/50\n",
      "218/218 [==============================] - 10s 46ms/step - loss: 1.3448 - accuracy: 0.6563 - val_loss: 1.5877 - val_accuracy: 0.5547\n",
      "Epoch 9/50\n",
      "218/218 [==============================] - 10s 46ms/step - loss: 1.2816 - accuracy: 0.6737 - val_loss: 1.5085 - val_accuracy: 0.5807\n",
      "Epoch 10/50\n",
      "218/218 [==============================] - 10s 46ms/step - loss: 1.2203 - accuracy: 0.6984 - val_loss: 1.4396 - val_accuracy: 0.6073\n",
      "Epoch 11/50\n",
      "218/218 [==============================] - 10s 46ms/step - loss: 1.1827 - accuracy: 0.7141 - val_loss: 1.4992 - val_accuracy: 0.5853\n",
      "Epoch 12/50\n",
      "218/218 [==============================] - 10s 47ms/step - loss: 1.1331 - accuracy: 0.7343 - val_loss: 1.4849 - val_accuracy: 0.5960\n",
      "Epoch 13/50\n",
      "218/218 [==============================] - 11s 48ms/step - loss: 1.0987 - accuracy: 0.7440 - val_loss: 1.4686 - val_accuracy: 0.5980\n",
      "Epoch 14/50\n",
      "218/218 [==============================] - 11s 50ms/step - loss: 1.0666 - accuracy: 0.7506 - val_loss: 1.5291 - val_accuracy: 0.5907\n",
      "Epoch 15/50\n",
      "218/218 [==============================] - 11s 51ms/step - loss: 1.0268 - accuracy: 0.7727 - val_loss: 1.4141 - val_accuracy: 0.6427\n",
      "Epoch 16/50\n",
      "218/218 [==============================] - 11s 50ms/step - loss: 1.0315 - accuracy: 0.7806 - val_loss: 1.5466 - val_accuracy: 0.5807\n",
      "Epoch 17/50\n",
      "218/218 [==============================] - 10s 48ms/step - loss: 0.9972 - accuracy: 0.7884 - val_loss: 1.4182 - val_accuracy: 0.6280\n",
      "Epoch 18/50\n",
      "218/218 [==============================] - 10s 47ms/step - loss: 0.9679 - accuracy: 0.7986 - val_loss: 1.4851 - val_accuracy: 0.6080\n",
      "Epoch 19/50\n",
      "218/218 [==============================] - 10s 46ms/step - loss: 0.9521 - accuracy: 0.8082 - val_loss: 1.4578 - val_accuracy: 0.6447\n",
      "Epoch 20/50\n",
      "218/218 [==============================] - 10s 46ms/step - loss: 0.9674 - accuracy: 0.8056 - val_loss: 1.5419 - val_accuracy: 0.6313\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218/218 [==============================] - 10s 48ms/step - loss: 0.9552 - accuracy: 0.8142 - val_loss: 1.4999 - val_accuracy: 0.6360\n",
      "Epoch 22/50\n",
      "218/218 [==============================] - 11s 51ms/step - loss: 0.9515 - accuracy: 0.8231 - val_loss: 1.5355 - val_accuracy: 0.6280\n",
      "Epoch 23/50\n",
      "218/218 [==============================] - 12s 53ms/step - loss: 0.9300 - accuracy: 0.8250 - val_loss: 1.4892 - val_accuracy: 0.6527\n",
      "Epoch 24/50\n",
      "218/218 [==============================] - 11s 49ms/step - loss: 0.9399 - accuracy: 0.8251 - val_loss: 1.5235 - val_accuracy: 0.6293\n",
      "Epoch 25/50\n",
      "218/218 [==============================] - 10s 48ms/step - loss: 0.9154 - accuracy: 0.8369 - val_loss: 1.4698 - val_accuracy: 0.6493\n",
      "Epoch 26/50\n",
      "218/218 [==============================] - 10s 47ms/step - loss: 0.9162 - accuracy: 0.8346 - val_loss: 1.5096 - val_accuracy: 0.6480\n",
      "Epoch 27/50\n",
      "218/218 [==============================] - 10s 48ms/step - loss: 0.9245 - accuracy: 0.8336 - val_loss: 1.4922 - val_accuracy: 0.6467\n",
      "Epoch 28/50\n",
      "218/218 [==============================] - 10s 48ms/step - loss: 0.8912 - accuracy: 0.8477 - val_loss: 1.4601 - val_accuracy: 0.6667\n",
      "Epoch 29/50\n",
      "218/218 [==============================] - 10s 48ms/step - loss: 0.8846 - accuracy: 0.8506 - val_loss: 1.5143 - val_accuracy: 0.6487\n",
      "Epoch 30/50\n",
      "218/218 [==============================] - 10s 48ms/step - loss: 0.8807 - accuracy: 0.8532 - val_loss: 1.5020 - val_accuracy: 0.6513\n",
      "Epoch 31/50\n",
      "218/218 [==============================] - 10s 48ms/step - loss: 0.8970 - accuracy: 0.8501 - val_loss: 1.5869 - val_accuracy: 0.6320\n",
      "Epoch 32/50\n",
      "218/218 [==============================] - 10s 48ms/step - loss: 0.9029 - accuracy: 0.8489 - val_loss: 1.5769 - val_accuracy: 0.6447\n",
      "Epoch 33/50\n",
      "218/218 [==============================] - 11s 49ms/step - loss: 0.8894 - accuracy: 0.8557 - val_loss: 1.5797 - val_accuracy: 0.6220\n",
      "Epoch 34/50\n",
      "218/218 [==============================] - 10s 48ms/step - loss: 0.8880 - accuracy: 0.8599 - val_loss: 1.5125 - val_accuracy: 0.6427\n",
      "Epoch 35/50\n",
      "218/218 [==============================] - 10s 47ms/step - loss: 0.8894 - accuracy: 0.8537 - val_loss: 1.5774 - val_accuracy: 0.6393\n",
      "Epoch 36/50\n",
      "218/218 [==============================] - 10s 46ms/step - loss: 0.9052 - accuracy: 0.8480 - val_loss: 1.4972 - val_accuracy: 0.6587\n",
      "Epoch 37/50\n",
      "218/218 [==============================] - 10s 46ms/step - loss: 0.8966 - accuracy: 0.8572 - val_loss: 1.5076 - val_accuracy: 0.6660\n",
      "Epoch 38/50\n",
      "218/218 [==============================] - 10s 47ms/step - loss: 0.8817 - accuracy: 0.8611 - val_loss: 1.5354 - val_accuracy: 0.6713\n",
      "Epoch 39/50\n",
      "218/218 [==============================] - 11s 49ms/step - loss: 0.8718 - accuracy: 0.8659 - val_loss: 1.5875 - val_accuracy: 0.6573\n",
      "Epoch 40/50\n",
      "218/218 [==============================] - 11s 49ms/step - loss: 0.8582 - accuracy: 0.8708 - val_loss: 1.5693 - val_accuracy: 0.6613\n",
      "Epoch 41/50\n",
      "218/218 [==============================] - 11s 49ms/step - loss: 0.8493 - accuracy: 0.8721 - val_loss: 1.5761 - val_accuracy: 0.6640\n",
      "Epoch 42/50\n",
      "218/218 [==============================] - 10s 48ms/step - loss: 0.8689 - accuracy: 0.8657 - val_loss: 1.5026 - val_accuracy: 0.6767\n",
      "Epoch 43/50\n",
      "218/218 [==============================] - 10s 48ms/step - loss: 0.8449 - accuracy: 0.8763 - val_loss: 1.5550 - val_accuracy: 0.6567\n",
      "Epoch 44/50\n",
      "218/218 [==============================] - 10s 47ms/step - loss: 0.8737 - accuracy: 0.8688 - val_loss: 1.5561 - val_accuracy: 0.6427\n",
      "Epoch 45/50\n",
      "218/218 [==============================] - 10s 46ms/step - loss: 0.8547 - accuracy: 0.8695 - val_loss: 1.5651 - val_accuracy: 0.6480\n",
      "Epoch 46/50\n",
      "218/218 [==============================] - 10s 46ms/step - loss: 0.8711 - accuracy: 0.8681 - val_loss: 1.5656 - val_accuracy: 0.6753\n",
      "Epoch 47/50\n",
      "218/218 [==============================] - 10s 48ms/step - loss: 0.8732 - accuracy: 0.8698 - val_loss: 1.5210 - val_accuracy: 0.6680\n",
      "Epoch 48/50\n",
      "218/218 [==============================] - 11s 49ms/step - loss: 0.8680 - accuracy: 0.8700 - val_loss: 1.5118 - val_accuracy: 0.6553\n",
      "Epoch 49/50\n",
      "218/218 [==============================] - 11s 49ms/step - loss: 0.8421 - accuracy: 0.8825 - val_loss: 1.4899 - val_accuracy: 0.6587\n",
      "Epoch 50/50\n",
      "218/218 [==============================] - 11s 49ms/step - loss: 0.8490 - accuracy: 0.8716 - val_loss: 1.5221 - val_accuracy: 0.6700\n",
      "218/218 [==============================] - 3s 12ms/step - loss: 0.5389 - accuracy: 0.9994\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 1.4951 - accuracy: 0.6625\n",
      "{'600': 0.995976984500885, '700': 0.9968391060829163, '800': 0.9988505840301514, '900': 0.9989942312240601, '1000': 0.9994252920150757}\n",
      "{'600': 0.6439051628112793, '700': 0.6580135226249695, '800': 0.6568848490715027, '900': 0.6738148927688599, '1000': 0.6625282168388367}\n"
     ]
    }
   ],
   "source": [
    "long_time_train_scores = {}\n",
    "long_time_test_scores = {}\n",
    "for i in range(600, 1100, 100):\n",
    "    y_test = np.load(\"y_test.npy\")\n",
    "    y_test -= 769\n",
    "    x_train, x_valid, x_test, y_train, y_valid, y_test = data_finalize(total_number=2115, takeout_sample=375, period=i, y_test=y_test)\n",
    "    l2_lambda = 0.001\n",
    "    \n",
    "    model = Sequential([\n",
    "\n",
    "      # Conv. block 1\n",
    "      keras.layers.Conv2D(filters=26, kernel_size=(9,1), padding='same', activation=tf.nn.gelu, kernel_regularizer=regularizers.l2(l2_lambda), input_shape=(x_train.shape[1],1,22)),\n",
    "      keras.layers.MaxPooling2D(pool_size=(3,1), padding='same'), # Read the keras documentation\n",
    "      keras.layers.BatchNormalization(),\n",
    "      keras.layers.Dropout(0.5),\n",
    "\n",
    "      # Conv. block 2\n",
    "      keras.layers.Conv2D(filters=52, kernel_size=(9,1), padding='same', activation=tf.nn.gelu, kernel_regularizer=regularizers.l2(l2_lambda)),\n",
    "      keras.layers.MaxPooling2D(pool_size=(3,1), padding='same'),\n",
    "      keras.layers.BatchNormalization(),\n",
    "      keras.layers.Dropout(0.5),\n",
    "\n",
    "      # Conv. block 3\n",
    "      keras.layers.Conv2D(filters=104, kernel_size=(9,1), padding='same', activation=tf.nn.gelu, kernel_regularizer=regularizers.l2(l2_lambda)),\n",
    "      keras.layers.MaxPooling2D(pool_size=(3,1), padding='same'),\n",
    "      keras.layers.BatchNormalization(),\n",
    "      keras.layers.Dropout(0.5),\n",
    "\n",
    "      keras.layers.Conv2D(filters=208, kernel_size=(9,1), padding='same', activation=tf.nn.gelu, kernel_regularizer=regularizers.l2(l2_lambda)),\n",
    "      keras.layers.MaxPooling2D(pool_size=(3,1), padding='same'),\n",
    "      keras.layers.BatchNormalization(),\n",
    "      keras.layers.Dropout(0.5),\n",
    "\n",
    "\n",
    "      # Output layer with Softmax activation\n",
    "      keras.layers.Flatten(), # Flattens the input\n",
    "      keras.layers.Dense(4, activation='softmax') # Output FC layer with softmax activation\n",
    "  ])\n",
    "\n",
    "  # Printing the model summary\n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer=cnn_optimizer,\n",
    "                 metrics=['accuracy'])\n",
    "  \n",
    "\n",
    "  # Training and validating the model\n",
    "    model_results = model.fit(x_train,\n",
    "              y_train,\n",
    "              batch_size=32,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_valid, y_valid), verbose=True)\n",
    "\n",
    "    long_time_train_scores[str(i)] = model.evaluate(x_train, y_train)[1]\n",
    "    long_time_test_scores[str(i)] = model.evaluate(x_test, y_test)[1]\n",
    "print(long_time_train_scores)\n",
    "print(long_time_test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAABqyklEQVR4nO3dd1xTV+MG8CcJEJYs2YgsrRMXKA6sWlEc9XXU7auIrf60Vmt5XbjRKq21SK2z1lVr66R2OaqoddS6tbVaijhQCzgBBWXl/P7AXAmEjQbM8/188tGce+655+RmPNwpE0IIEBEREekRua47QERERPSyMQARERGR3mEAIiIiIr3DAERERER6hwGIiIiI9A4DEBEREekdBiAiIiLSOwxAREREpHcYgIiIiEjvMAARvSRJSUno27cvqlevDplMhsjISJ30Y86cOZDJZDpZdmXwIsbv7u6O4cOHF1nn+vXrkMlkWLRoUYUum15dw4cPh7u7u6678cpiAKokZDJZiR6HDh0q97LS09MxZ86cMrW1a9cuyGQyODs7Q6VSlbsv+uSDDz7A3r17ERoaio0bN6JLly4vbFnlWcdUdVy6dAlz5szB9evXdd2VF6Z9+/Zavwu1fX4yMjIwZcoUODs7w8TEBH5+fti3b5/Wdn/77Tf4+/vD1NQUjo6OGD9+PB4/fvyih/NCnDx5Eu+++y58fHxgaGhYbMBfs2YN6tWrB2NjY9SuXRuff/651nq3b99G//79YWVlBQsLC/Ts2RNXr14tV5uViYGuO0C5Nm7cqPH8q6++wr59+wqU16tXr9zLSk9PR1hYGIDcL5fS2LRpE9zd3XH9+nUcOHAAAQEB5e6Pvjhw4AB69uyJiRMnvvBlFbWOZ8yYgalTp77wPlRWr9L4L126hLCwMLRv3/6V3lJQo0YNhIeHa5Q5OzsXqDd8+HBs374dEyZMQO3atbF+/Xp069YNBw8ehL+/v1Tv/Pnz6NixI+rVq4eIiAjcunULixYtQmxsLHbv3v3Cx1PRdu3ahS+//BKNGjWCp6cn/vnnn0Lrrlq1CqNHj8Zbb72FkJAQHDlyBOPHj0d6ejqmTJki1Xv8+DE6dOiAlJQUTJs2DYaGhli8eDHatWuH8+fPo3r16qVus9IRVCmNHTtWvKjVc/fuXQFAzJ49u1TzPX78WJiZmYklS5aIpk2biuHDh7+Q/lWEx48f67oLBchkMjF27NgKa+/JkyciJydH67SyruNX2Yt8T7i5uYmgoKAi61y7dk0AEJ988kmFLXfbtm0CgDh48GCFtVnZtGvXTjRo0KDYeidOnCjw+j558kR4eXmJVq1aadTt2rWrcHJyEikpKVLZ6tWrBQCxd+/eiut8OQUFBQk3N7di6yUmJor09HQhRNG/Henp6aJ69eqie/fuGuVDhgwRZmZm4sGDB1LZxx9/LACIkydPSmWXL18WCoVChIaGlqnNyoYBqJLS9ibOyckRixcvFvXr1xdKpVLY29uLUaNGFXiDnTp1SnTu3FlUr15dGBsbC3d3dxEcHCyEeP4lnP9Rkh/KjRs3CrlcLhISEsTHH38sLCwsxJMnTwrUe/LkiZg9e7aoXbu2UCqVwtHRUfTu3VtcuXJFYyyRkZGiYcOGQqlUCltbWxEYGChOnTql0c9169YVaD9/f2fPni0AiL/++ksMGjRIWFlZiSZNmgghhLhw4YIICgoSHh4eQqlUCgcHBxEcHCzu3btXoN1bt26JESNGCCcnJ2FkZCTc3d3F6NGjRUZGhoiLixMARERERIH5jh07JgCIb775Ruvrtm7dOq2vuVpcXJzo27evsLa2FiYmJsLPz0/89NNPGm0cPHhQABDffvutmD59unB2dhYymUw8fPiwwPKKW8fq1yv/azp27FixdetWUa9ePWFsbCxatmwp/vjjDyGEECtXrhReXl5CqVSKdu3aiWvXrhVY7u+//y4CAwOFhYWFMDExEa+//ro4evSo1tdE29g2b94sQkNDhYODgzA1NRU9evQQ8fHxZVpOUe8JbePPysoSc+fOFZ6ensLIyEi4ubmJ0NBQ8fTpU416KpVKzJs3T7i4uAgTExPRvn17cfHixVIHoIiICFGzZk1hbGwsXn/9dfHnn38WqH/58mXx1ltvCWtra6FUKoWPj4/4/vvvpemFva8OHjwoPvjgA2FjYyNUKpVU/7333hMAxGeffSaVJSYmCgBi+fLlUtnTp0/FrFmzhJeXlzAyMhI1atQQkyZNKvBaCJH7ndCsWTNhbGwsrK2txYABAwqsM3WA+euvv0T79u2FiYmJcHZ2Fh9//HGRr1f++bOyssSjR48KrTdp0iShUCg0Qo0QQixYsEAAkPqVkpIiDAwMxKRJkzTqZWRkCHNzc/H2228X2Z+MjAwxc+ZM0axZM2FhYSFMTU2Fv7+/OHDggEa9vOt71apV0nvL19dXI1Sofffdd6JBgwZCqVSKBg0aiKioqBIHoLyKCkA///yzACB+/vlnjfLffvtNABAbN26Uypo3by6aN29eoI3OnTsLLy+vMrVZ2TAAVVLa3sTvvPOOMDAwECNHjhQrV64UU6ZMEWZmZqJ58+YiMzNTCCFEUlKSsLa2Fq+99pr45JNPxOrVq8X06dNFvXr1hBC5fwWvWLFCABC9e/cWGzduFBs3bhQXLlwotk9dunQRHTt2FEIIcePGDSGTycTWrVs16mRnZ4uOHTsKAGLgwIFi6dKlIjw8XLzxxhti586dUr3hw4cLAKJr164iMjJSLFq0SPTs2VN8/vnnQoiyBaD69euLnj17iuXLl4tly5YJIYRYtGiRaNu2rZg7d6744osvxPvvvy9MTExEixYtNH4cbt++LZydnYWpqamYMGGCWLlypZg5c6aoV6+eFDLatGkjfHx8CvTn3XffFdWqVRNpaWlaX7e4uDixceNGAUB06tRJes2FyP0BcnBwENWqVRPTp08XERERonHjxkIul4uoqCipDXVIqF+/vmjSpImIiIgQ4eHhWpdZ3DouLAA1atRIuLq6io8++kh89NFHwtLSUtSsWVMsXbpU1K9fX3z66adixowZwsjISHTo0EFj/ujoaGFkZCRatWolPv30U7F48WLRqFEjYWRkJE6cOKH1dck/Nm9vb9GoUSMREREhpk6dKoyNjcVrr70m/WVbmuUU9Z7QNv6goCABQPTt21csW7ZMDBs2TAAQvXr10qg3Y8YMAUB069ZNLF26VIwYMUI4OzsLW1vbEgcgb29v4e7uLj7++GMRFhYmbGxshJ2dnUhMTJTqXrx4UVhaWor69euLjz/+WCxdulS8/vrrQiaTSe+LuLg4MX78eAFATJs2TVrPiYmJIioqSgDQCFbq91Xfvn2lMvUWpIsXLwohcv8w6dy5s/Q5WLVqlXjvvfeEgYGB6Nmzp8Z4PvzwQyGTycSAAQPE8uXLRVhYmLC1tRXu7u4awbxdu3bC2dlZuLq6ivfff18sX75cvPHGGwKA2LVrV5GvmXp+Q0NDYWRkJAAIBwcHMWPGDOk7Ty0gIED6nstr//79AoD44YcfhBBCHD16VAAQW7ZsKVDX399fNGvWrMj+3L17Vzg5OYmQkBCxYsUKsXDhQlGnTh1haGgozp07J9VTr++mTZuKWrVqiY8//lgsXLhQ2Nraiho1amj0f+/evUIul4uGDRuKiIgIMX36dGFpaSkaNGhQoQHoww8/FABEUlKSRnlGRoaQy+UiJCRECJH7PlAqlWLMmDEF2lB/BlJTU0vVZmXEAFRJ5X8THzlyRAAQmzZt0qi3Z88ejfLvvvtOAJC2pGhTlt0jSUlJwsDAQKxevVoqa926dYEvxbVr1xa6pUQdOA4cOCAAiPHjxxdapywBaNCgQQXq5v3xVPv2228FAHH48GGpbNiwYUIul2t93dR9WrVqlQAgLl++LE3LzMws0Y+fut/5d4FNmDBBABBHjhyRyh49eiQ8PDyEu7u7tItLHRI8PT21jim/otZxYQFIqVRqbNlRj9fR0VH6shNCiNDQUAFAqqtSqUTt2rVFYGCgRqhMT08XHh4eolOnTkX2VT02FxcXjeVs3bpVY4tFaZZT1Hsi//jPnz8vAIh33nlHo97EiRMFAOkv+zt37ggjIyPRvXt3jeVPmzZNAChxADIxMRG3bt2SytW7bj744AOprGPHjsLb21tjq4tKpRKtW7cWtWvXlsoK2wV2584djS07ycnJQi6Xi379+gkHBwep3vjx4zW2FKm38uZ9PwqRuwUQgDh27JgQQojr168LhUIh5s+fr1Hvzz//FAYGBhrl7dq1EwDEV199JZVlZGQIR0dH8dZbbxX5mgkhxIgRI8ScOXPEjh07xFdffSX+85//CACif//+GvUaNGgg3njjjQLz//XXXwKAWLlypcZrlvfzr9avXz/h6OhYZH+ys7NFRkaGRtnDhw+Fg4ODGDFihFSmXt/Vq1fX2Er//fffCwDixx9/lMqaNGkinJycRHJyslT2yy+/CAAVGoDGjh0rFAqF1ml2dnZi4MCBQojn3x9z584tUG/ZsmUCgPj7779L1WZlxLPAqoht27bB0tISnTp1wr1796SHj48PzM3NcfDgQQCAlZUVAOCnn35CVlZWhS1/8+bNkMvleOutt6SyQYMGYffu3Xj48KFUtmPHDtja2mLcuHEF2lCfmbBjxw7IZDLMnj270DplMXr06AJlJiYm0v+fPn2Ke/fuoWXLlgCAs2fPAgBUKhV27tyJHj16wNfXt9A+9e/fH8bGxti0aZM0be/evbh37x7++9//lqnPu3btQosWLTQO0DQ3N8eoUaNw/fp1XLp0SaN+UFCQxpgqUseOHTUOpPXz8wMAvPXWW6hWrVqBcvXZIOfPn0dsbCwGDx6M+/fvS+/NtLQ0dOzYEYcPHy7RGYPDhg3TWE7fvn3h5OSEXbt2lXk52t4T+anbDwkJ0Sj/3//+BwD4+eefAQD79+9HZmYmxo0bp/E+nTBhQrHLyKtXr15wcXGRnrdo0QJ+fn5SPx48eIADBw6gf//+ePTokTTO+/fvIzAwELGxsbh9+3aRy7Czs0PdunVx+PBhAMCxY8egUCgwadIkJCUlITY2FgBw5MgR+Pv7S+PZtm0b6tWrh7p162p8z7zxxhsAIH3PREVFQaVSoX///hr1HB0dUbt2bamemrm5ucZnxMjICC1atCj0jKK81qxZg9mzZ6NPnz4YOnQovv/+e4wcORJbt27F77//LtV78uQJlEplgfmNjY2l6Xn/LayuenphFAoFjIyMAOR+dzx48ADZ2dnw9fWVvlPyGjBgAKytraXnbdu2BfD885OQkIDz588jKCgIlpaWUr1OnTqhfv36RfaltJ48eSL1Pb+8Yy/uNcpbp6RtVkYMQFVEbGwsUlJSYG9vDzs7O43H48ePcefOHQBAu3bt8NZbbyEsLAy2trbo2bMn1q1bh4yMjHIt/+uvv0aLFi1w//59XLlyBVeuXEHTpk2RmZmJbdu2SfXi4uJQp04dGBgUfoJhXFwcnJ2dYWNjU64+5efh4VGg7MGDB3j//ffh4OAAExMT2NnZSfVSUlIAAHfv3kVqaioaNmxYZPtWVlbo0aMHvvnmG6ls06ZNcHFxkX4gSuvGjRuoU6dOgXL12X43btzQKNc2xopSs2ZNjefqL2NXV1et5ergq/4xDQoKKvDe/PLLL5GRkSG91kWpXbu2xnOZTIZatWpJp3iXZTkleb1u3LgBuVyOWrVqaZQ7OjrCyspKWgfqf/P3087OTuMHrrTjBIDXXntNGueVK1cghMDMmTMLjFP9R4P6816Utm3b4siRIwByg46vry98fX1hY2ODI0eOIDU1FRcuXJB+kIHc1/ivv/4qsNzXXntNY7mxsbEQQqB27doF6l6+fLlA/2rUqFHgjxtra2uNP55KQx1O9+/fL5WZmJho/Z57+vSpND3vv4XVLckfGBs2bECjRo1gbGyM6tWrw87ODj///LPW93n+z5X6vaIee2HvKwBavxvKw8TEBJmZmVqn5R17ca9R3jolbbMy4mnwVYRKpYK9vb3G1oe87OzsAOT+aGzfvh2///47fvzxR+zduxcjRozAp59+it9//x3m5ualXnZsbCxOnToFQPuHdNOmTRg1alSp2y1KYVuCcnJyCp1H2wetf//++O233zBp0iQ0adIE5ubmUKlU6NKlS5muYzRs2DBs27YNv/32G7y9vfHDDz/g3XffhVz+cv6WeJFfJgqFolTlQggAkF7HTz75BE2aNNFatyzvu/zKspzSvF6V5eKQ6nFOnDgRgYGBWuvkD2va+Pv7Y/Xq1bh69SqOHDmCtm3bQiaTwd/fH0eOHJGu5ZU3AKlUKnh7eyMiIkJrm+owrFKpIJPJsHv3bq3vj/zrobj3UGmp+/HgwQOpzMnJSeuWsYSEBADPT5t3cnLSKM9fV9vp9Xl9/fXXGD58OHr16oVJkybB3t4eCoUC4eHhiIuLK1C/osdeHk5OTsjJycGdO3dgb28vlWdmZuL+/fvS2G1sbKBUKgt9jQDN17MkbVZGDEBVhJeXF/bv3482bdqU6Eu9ZcuWaNmyJebPn49vvvkGQ4YMwebNm/HOO++U+ot+06ZNMDQ0xMaNGwt8mI8ePYolS5YgPj4eNWvWhJeXF06cOIGsrCwYGhoWOpa9e/fiwYMHhW4FUv+VlJycrFGef4tIUR4+fIjo6GiEhYVh1qxZUrl6S4KanZ0dLCwscPHixWLb7NKlC+zs7LBp0yb4+fkhPT0dQ4cOLXGf8nNzc0NMTEyB8r///luaXhYv88fcy8sLAGBhYVGu60LlXy9CCFy5cgWNGjWq0OXk5+bmBpVKhdjYWI3rbCUlJSE5OVlaB+p/Y2Nj4enpKdW7e/duqbZk5B8nAPzzzz/S7kd124aGhsWOs6j1rA42+/btw6lTp6RrH73++utYsWIFnJ2dYWZmBh8fH2keLy8vXLhwAR07diyybS8vLwgh4OHhIW0depnUu4/Uf/gBQJMmTXDw4EGkpqbCwsJCKj9x4oQ0HQAaNmwIAwMDnD59Gv3795fqZWZm4vz58xpl2mzfvh2enp6IiorSeI207dIvibzvq/y0fTeUh/o1OH36NLp16yaVnz59GiqVSpoul8vh7e2N06dPF2jjxIkT8PT0lHZXl7TNyoi7wKqI/v37IycnB/PmzSswLTs7WwoKDx8+LPCXhfoNqN6caWpqCqBguCjMpk2b0LZtWwwYMAB9+/bVeEyaNAkA8O233wLIPV7k3r17WLp0aYF21P166623IISQLtSnrY6FhQVsbW2lYxjUli9fXqI+A8//8sr/euS/BYVcLkevXr3w448/av3A553fwMAAgwYNwtatW7F+/Xp4e3tLP9Bl0a1bN5w8eRLHjx+XytLS0vDFF1/A3d29zMcAlHYdl4ePjw+8vLywaNEirVfSvXv3bona+eqrr/Do0SPp+fbt25GQkICuXbtW6HLyU39p539fqLeCdO/eHQAQEBAAQ0NDfP755xrvidLe0mTnzp0aWypOnjyJEydOSOO0t7dH+/btsWrVKq1/gecdp5mZGQDt69nDwwMuLi5YvHgxsrKy0KZNGwC5wSguLg7bt29Hy5YtNXZX9+/fH7dv38bq1asLtPfkyROkpaUBAPr06QOFQoGwsLACny8hBO7fv1/Sl6NIqampBXbDCCHw4YcfAoDGFrK+ffsiJycHX3zxhVSWkZGBdevWwc/PT9pqZGlpiYCAAHz99dca77eNGzfi8ePH6NevX5F90va9cuLECY3PcGk4OTmhSZMm2LBhg8YutH379hU4BrC83njjDdjY2GDFihUa5StWrICpqan0XgdyX89Tp05pfCfGxMTgwIEDGq9RadqsbLgFqIpo164d/u///g/h4eE4f/48OnfuDENDQ8TGxmLbtm347LPP0LdvX2zYsAHLly9H79694eXlhUePHmH16tWwsLCQvuhNTExQv359bNmyBa+99hpsbGzQsGFDrcfAnDhxAleuXMF7772ntV8uLi5o1qwZNm3ahClTpmDYsGH46quvEBISgpMnT6Jt27ZIS0vD/v378e6776Jnz57o0KEDhg4diiVLliA2NlbaHXXkyBF06NBBWtY777yDjz76CO+88w58fX1x+PDhIq9wmp+FhQVef/11LFy4EFlZWXBxccEvv/yCa9euFai7YMEC/PLLL2jXrh1GjRqFevXqISEhAdu2bcPRo0elg8uB3N1gS5YswcGDB/Hxxx+XuD/aTJ06Fd9++y26du2K8ePHw8bGBhs2bMC1a9ewY8eOMu9aK806Li+5XI4vv/wSXbt2RYMGDRAcHAwXFxfcvn0bBw8ehIWFBX788cdi27GxsYG/vz+Cg4ORlJSEyMhI1KpVCyNHjqzQ5eTXuHFjBAUF4YsvvkBycjLatWuHkydPYsOGDejVqxc6dOgAIHdrw8SJExEeHo4333wT3bp1w7lz57B7927Y2tqWeHm1atWCv78/xowZg4yMDERGRqJ69eqYPHmyVGfZsmXw9/eHt7c3Ro4cCU9PTyQlJeH48eO4desWLly4ACD3jxuFQoGPP/4YKSkpUCqVeOONN6RdEW3btsXmzZvh7e0tbVVt1qwZzMzM8M8//2Dw4MEafRs6dCi2bt2K0aNH4+DBg2jTpg1ycnLw999/Y+vWrdi7dy98fX3h5eWFDz/8EKGhobh+/Tp69eqFatWq4dq1a/juu+8watSoCrni+dmzZzFo0CAMGjQItWrVwpMnT/Ddd9/h2LFjGDVqFJo1aybV9fPzQ79+/RAaGoo7d+6gVq1a2LBhA65fv441a9ZotDt//ny0bt1a+rzfunULn376KTp37lzsLWrefPNNREVFoXfv3ujevTuuXbuGlStXon79+mW+lUZ4eDi6d+8Of39/jBgxAg8ePMDnn3+OBg0alKjNGzduSHcNUAcWdUh0c3OTtlKbmJhg3rx5GDt2LPr164fAwEAcOXIEX3/9NebPn6+xRf7dd9/F6tWr0b17d0ycOBGGhoaIiIiAg4ODdAxWadusdF72aWdUMoWdyvjFF18IHx8fYWJiIqpVqya8vb3F5MmTxb///iuEEOLs2bNi0KBBombNmtLFEt98801x+vRpjXZ+++034ePjI11bo7BT4seNGycAiLi4uEL7OmfOHAFAus5Menq6mD59uvDw8BCGhobC0dFR9O3bV6ON7Oxs8cknn4i6desKIyMjYWdnJ7p27SrOnDkj1UlPTxdvv/22sLS0FNWqVRP9+/eXTu/Vdhr83bt3C/Tt1q1bonfv3sLKykpYWlqKfv36iX///VfrmG/cuCGGDRsm7OzshFKpFJ6enmLs2LEFTnkVIveUW7lcrnE6c3Gg5TR4IZ5fCNHKykoYGxuLFi1aFHohxG3btpV4eYWt46IuhJhXYVcuLqwv586dE3369BHVq1cXSqVSuLm5if79+4vo6Ogi+5n3Io+hoaHC3t5emJiYiO7du4sbN24UqF+S5RT1nijsQohhYWHSe9bV1VXrhRBzcnJEWFiYcHJyKteFED/99FPh6uoqlEqlaNu2rdbrcMXFxYlhw4YJR0dHYWhoKFxcXMSbb74ptm/frlFv9erVwtPTUygUigKnxKtPWc5/PZeAgAABQOu6yczMFB9//LF0UT5ra2vh4+MjwsLCClxkcMeOHcLf31+YmZkJMzMzUbduXTF27FgRExMj1SnsSs4lucjf1atXRb9+/YS7u7swNjYWpqamwsfHR6xcuVLjUgRqT548ERMnThSOjo5CqVSK5s2biz179mht+8iRI6J169bC2NhY2NnZibFjx2pchqEwKpVKLFiwQLi5uQmlUimaNm0qfvrppwLjKerK39q+f3bs2CHq1asnlEqlqF+/fqkuhKj+DGl7tGvXrkD9L774QtSpU0cYGRkJLy8vsXjxYq2v582bN0Xfvn2FhYWFMDc3F2+++aaIjY3V2oeStlmZyITQwZFYRFVc06ZNYWNjg+joaF13pco7dOgQOnTogG3btqFv37667g4R6QkeA0RUSqdPn8b58+cxbNgwXXeFiIjKiMcAEZXQxYsXcebMGXz66adwcnLCgAEDdN0lIiIqI24BIiqh7du3Izg4GFlZWfj222+lK6ISEVHVw2OAiIiISO9wCxARERHpHQYgIiIi0js8CFoLlUqFf//9F9WqVas09wciIiKiogkh8OjRIzg7Oxd7IVkGIC3+/fffAnfAJiIioqrh5s2bqFGjRpF1GIC0UN/k7ebNmxo31SMiIqLKKzU1Fa6urtLveFEYgLRQ7/aysLBgACIiIqpiSnL4Cg+CJiIiIr3DAERERER6hwGIiIiI9A4DEBEREekdBiAiIiLSOwxAREREpHcYgIiIiEjvMAARERGR3mEAIiIiIr2j0wB0+PBh9OjRA87OzpDJZNi5c2ex8xw6dAjNmjWDUqlErVq1sH79+gJ1li1bBnd3dxgbG8PPzw8nT56s+M4TERFRlaXTAJSWlobGjRtj2bJlJap/7do1dO/eHR06dMD58+cxYcIEvPPOO9i7d69UZ8uWLQgJCcHs2bNx9uxZNG7cGIGBgbhz586LGgYRERFVMTIhhNB1J4Dc+3Z899136NWrV6F1pkyZgp9//hkXL16UygYOHIjk5GTs2bMHAODn54fmzZtj6dKlAACVSgVXV1eMGzcOU6dOLVFfUlNTYWlpiZSUFN4LjIiIqIooze93lboZ6vHjxxEQEKBRFhgYiAkTJgAAMjMzcebMGYSGhkrT5XI5AgICcPz48ULbzcjIQEZGhvQ8NTW1YjtORERUSQghIAQg1P8Hnj3PLYe25/nqIs90be1AYz4tdQVgYWwIS1PDlzr2vKpUAEpMTISDg4NGmYODA1JTU/HkyRM8fPgQOTk5Wuv8/fffhbYbHh6OsLCwF9JnIsolhECOSiD72SMnRyBbpUKOSiArz/NslUB2jnhWnjs9O8+0vPVyVAJZOQI5eebLLdfyXPp/7kPqF/L8P8/28PybxjW3lWufp2AbRdQrwTz5K2rOIwqrVsw4hPZpRfRBo72S1iukPP/UsvQ17w+pZtmzH9l8P7hF/VhLbWsJAvmXU1QogJa287aDvHXzT5f6UkigyDNfkcspYqza14NuvdveC5O71NXZ8qtUAHpRQkNDERISIj1PTU2Fq6urDntE+kIIkeeHXPU8IOQNBznq4KD5I65+/nweVSFtqfLMow4XqtzQoSVcSKFDa9jI38eC4aKoZRORfpDJABlyD28B1P8HZMidIANgIJfpsotVKwA5OjoiKSlJoywpKQkWFhYwMTGBQqGAQqHQWsfR0bHQdpVKJZRK5Qvp84smhIBKACohoHq2WVH1rEzk+zdvHVHIPM+na29XW/vqOhAoW18goFJpaR955lHl6x80n2tMl16XgnUE8i/n+TK0vQ7apueo8m7JyBdCtDzPDRXqsKF6vgUk35YIfSWXAQYKOQzkMijkMhgq5FDIZVqfGyhkUMhz6+Z9bvisroFCBgP587bUz5/PnztNrv42fibv13Ce4twvay3lRc6Tv2Ip2y6s3eL6U9jyCx+b9nmKGmdpX7Oil1n4PChJP5+1oS6SQfb8/zKZxg/u8x/jZzVleduQabSV9wc6fzuQ/o9ndfK2XYrlaPQ1TztalpO3raLakeYpZOza+qvxOqrHXdLlFNanIt7/lU2VCkCtWrXCrl27NMr27duHVq1aAQCMjIzg4+OD6Oho6WBqlUqF6OhovPfeey+7uwV8/fsNrD5yNfdHVZU/DADI86OuUuUJHdAeOirb5kyqOKUOA4pC6sjlUOSdlue5gVz+rA3ZswAh12gnb2DQFi40+6LZL3XoMFSo2yr43EAhg0Img1zHfwUSkX7SaQB6/Pgxrly5Ij2/du0azp8/DxsbG9SsWROhoaG4ffs2vvrqKwDA6NGjsXTpUkyePBkjRozAgQMHsHXrVvz8889SGyEhIQgKCoKvry9atGiByMhIpKWlITg4+KWPL7/Up1m4cT9dp32QP0voef+Vy2SQ5/nrRS6XPSvTrKNO+nK55jzqaXmfq+tI88i0zJPvX2k5UlnBedR90jaP/NlfL9rmkT8bnLZ5pP7LC+nLs9ctd3rutPwBQgoGimchI08o0RoGFLLnWy002sn9tyr9FUVEVBXpNACdPn0aHTp0kJ6rj8MJCgrC+vXrkZCQgPj4eGm6h4cHfv75Z3zwwQf47LPPUKNGDXz55ZcIDAyU6gwYMAB3797FrFmzkJiYiCZNmmDPnj0FDozWhd5NXeDnUb1g6MjzvEDoKBAStIcArWFGyzxERERUia4DVJnwOkBERERVT2l+v3kvMCIiItI7DEBERESkdxiAiIiISO8wABEREZHeYQAiIiIivcMARERERHqHAYiIiIj0DgMQERER6R0GICIiItI7DEBERESkdxiAiIiISO8wABEREZHeYQAiIiIivcMARERERHqHAYiIiIj0DgMQERER6R0GICIiItI7DEBERESkdxiAiIiISO8wABEREZHeYQAiIiIivcMARERERHqHAYiIiIj0DgMQERER6R0GICIiItI7DEBERESkdxiAiIiISO8wABEREZHeYQAiIiIivcMARERERHqHAYiIiIj0DgMQERER6R0GICIiItI7DEBERESkdxiAiIiISO8wABEREZHe0XkAWrZsGdzd3WFsbAw/Pz+cPHmy0LpZWVmYO3cuvLy8YGxsjMaNG2PPnj0adebMmQOZTKbxqFu37oseBhEREVUhOg1AW7ZsQUhICGbPno2zZ8+icePGCAwMxJ07d7TWnzFjBlatWoXPP/8cly5dwujRo9G7d2+cO3dOo16DBg2QkJAgPY4ePfoyhkNERERVhE4DUEREBEaOHIng4GDUr18fK1euhKmpKdauXau1/saNGzFt2jR069YNnp6eGDNmDLp164ZPP/1Uo56BgQEcHR2lh62t7csYDhEREVUROgtAmZmZOHPmDAICAp53Ri5HQEAAjh8/rnWejIwMGBsba5SZmJgU2MITGxsLZ2dneHp6YsiQIYiPj6/4ARAREVGVpbMAdO/ePeTk5MDBwUGj3MHBAYmJiVrnCQwMREREBGJjY6FSqbBv3z5ERUUhISFBquPn54f169djz549WLFiBa5du4a2bdvi0aNHhfYlIyMDqampGg8iIiJ6den8IOjS+Oyzz1C7dm3UrVsXRkZGeO+99xAcHAy5/Pkwunbtin79+qFRo0YIDAzErl27kJycjK1btxbabnh4OCwtLaWHq6vryxgOERER6YjOApCtrS0UCgWSkpI0ypOSkuDo6Kh1Hjs7O+zcuRNpaWm4ceMG/v77b5ibm8PT07PQ5VhZWeG1117DlStXCq0TGhqKlJQU6XHz5s2yDYqIiIiqBJ0FICMjI/j4+CA6OloqU6lUiI6ORqtWrYqc19jYGC4uLsjOzsaOHTvQs2fPQus+fvwYcXFxcHJyKrSOUqmEhYWFxoOIiIheXTrdBRYSEoLVq1djw4YNuHz5MsaMGYO0tDQEBwcDAIYNG4bQ0FCp/okTJxAVFYWrV6/iyJEj6NKlC1QqFSZPnizVmThxIn799Vdcv34dv/32G3r37g2FQoFBgwa99PERERFR5WSgy4UPGDAAd+/exaxZs5CYmIgmTZpgz5490oHR8fHxGsf3PH36FDNmzMDVq1dhbm6Obt26YePGjbCyspLq3Lp1C4MGDcL9+/dhZ2cHf39//P7777Czs3vZwyMiIqJKSiaEELruRGWTmpoKS0tLpKSkcHcYERFRFVGa3+8qdRYYERERUUVgACIiIiK9wwBEREREeocBiIiIiPQOAxARERHpHQYgIiIi0jsMQERERKR3GICIiIhI7zAAERERkd5hACIiIiK9wwBEREREeocBiIiIiPQOAxARERHpHQYgIiIi0jsMQERERKR3GICIiIhI7zAAERERkd5hACIiIiK9wwBEREREeocBiIiIiPQOAxARERHpHQYgIiIi0jsMQERERKR3GICIiIhI7zAAERERkd5hACIiIiK9wwBEREREeocBiIiIiPQOAxARERHpHQYgIiIi0jsMQERERKR3GICIiIhI7zAAERERkd5hACIiIiK9wwBEREREeocBiIiIiPQOAxARERHpHZ0HoGXLlsHd3R3Gxsbw8/PDyZMnC62blZWFuXPnwsvLC8bGxmjcuDH27NlTrjaJiIhI/+g0AG3ZsgUhISGYPXs2zp49i8aNGyMwMBB37tzRWn/GjBlYtWoVPv/8c1y6dAmjR49G7969ce7cuTK3SURERPpHJoQQulq4n58fmjdvjqVLlwIAVCoVXF1dMW7cOEydOrVAfWdnZ0yfPh1jx46Vyt566y2YmJjg66+/LlOb2qSmpsLS0hIpKSmwsLAo7zCJiIjoJSjN77fOtgBlZmbizJkzCAgIeN4ZuRwBAQE4fvy41nkyMjJgbGysUWZiYoKjR4+WuU11u6mpqRoPIiIienXpLADdu3cPOTk5cHBw0Ch3cHBAYmKi1nkCAwMRERGB2NhYqFQq7Nu3D1FRUUhISChzmwAQHh4OS0tL6eHq6lrO0REREVFlpvODoEvjs88+Q+3atVG3bl0YGRnhvffeQ3BwMOTy8g0jNDQUKSkp0uPmzZsV1GMiIiKqjHQWgGxtbaFQKJCUlKRRnpSUBEdHR63z2NnZYefOnUhLS8ONGzfw999/w9zcHJ6enmVuEwCUSiUsLCw0HkRERPTq0lkAMjIygo+PD6Kjo6UylUqF6OhotGrVqsh5jY2N4eLiguzsbOzYsQM9e/Ysd5tERESkPwx0ufCQkBAEBQXB19cXLVq0QGRkJNLS0hAcHAwAGDZsGFxcXBAeHg4AOHHiBG7fvo0mTZrg9u3bmDNnDlQqFSZPnlziNomIiIh0GoAGDBiAu3fvYtasWUhMTESTJk2wZ88e6SDm+Ph4jeN7nj59ihkzZuDq1aswNzdHt27dsHHjRlhZWZW4TSIiIiKdXgeosuJ1gIiIiKqeKnEdICIiIiJdYQAiIiIivcMARERERHqHAYiIiIj0DgMQERER6R0GICIiItI7DEBERESkdxiAiIiISO8wABEREZHeYQAiIiIivcMARERERHqHAYiIiIj0DgMQERER6R0GICIiItI7DEBERESkdxiAiIiISO8wABEREZHeYQAiIiIivcMARERERHqHAYiIiIj0DgMQERER6R0GICIiItI7DEBERESkdxiAiIiISO8wABEREZHeYQAiIiIivcMARERERHqHAYiIiIj0DgMQERER6R0GICIiItI7DEBERESkdxiAiIiISO8wABEREZHeYQAiIiIivcMARERERHqHAYiIiIj0js4D0LJly+Du7g5jY2P4+fnh5MmTRdaPjIxEnTp1YGJiAldXV3zwwQd4+vSpNH3OnDmQyWQaj7p1677oYRAREVEVYqDLhW/ZsgUhISFYuXIl/Pz8EBkZicDAQMTExMDe3r5A/W+++QZTp07F2rVr0bp1a/zzzz8YPnw4ZDIZIiIipHoNGjTA/v37pecGBjodJhEREVUypd4C5O7ujrlz5yI+Pr7cC4+IiMDIkSMRHByM+vXrY+XKlTA1NcXatWu11v/tt9/Qpk0bDB48GO7u7ujcuTMGDRpUYKuRgYEBHB0dpYetrW25+0pERESvjlIHoAkTJiAqKgqenp7o1KkTNm/ejIyMjFIvODMzE2fOnEFAQMDzzsjlCAgIwPHjx7XO07p1a5w5c0YKPFevXsWuXbvQrVs3jXqxsbFwdnaGp6cnhgwZUmxYy8jIQGpqqsaDiIiIXl1lCkDnz5/HyZMnUa9ePYwbNw5OTk547733cPbs2RK3c+/ePeTk5MDBwUGj3MHBAYmJiVrnGTx4MObOnQt/f38YGhrCy8sL7du3x7Rp06Q6fn5+WL9+Pfbs2YMVK1bg2rVraNu2LR49elRoX8LDw2FpaSk9XF1dSzwOIiIiqnrKfBB0s2bNsGTJEvz777+YPXs2vvzySzRv3hxNmjTB2rVrIYSoyH4CAA4dOoQFCxZg+fLlOHv2LKKiovDzzz9j3rx5Up2uXbuiX79+aNSoEQIDA7Fr1y4kJydj69athbYbGhqKlJQU6XHz5s0K7zsRERFVHmU+OjgrKwvfffcd1q1bh3379qFly5Z4++23cevWLUybNg379+/HN998U+j8tra2UCgUSEpK0ihPSkqCo6Oj1nlmzpyJoUOH4p133gEAeHt7Iy0tDaNGjcL06dMhlxfMc1ZWVnjttddw5cqVQvuiVCqhVCpLMmwiIiJ6BZQ6AJ09exbr1q3Dt99+C7lcjmHDhmHx4sUap5r37t0bzZs3L7IdIyMj+Pj4IDo6Gr169QIAqFQqREdH47333tM6T3p6eoGQo1AoAKDQLU6PHz9GXFwchg4dWtIhEhFRJZOTk4OsrCxdd4N0zNDQUPrdL69SB6DmzZujU6dOWLFiBXr16gVDQ8MCdTw8PDBw4MBi2woJCUFQUBB8fX3RokULREZGIi0tDcHBwQCAYcOGwcXFBeHh4QCAHj16ICIiAk2bNoWfnx+uXLmCmTNnokePHtILMnHiRPTo0QNubm7S7jmFQoFBgwaVdqhERKRjQggkJiYiOTlZ112hSsLKygqOjo6QyWTlaqfUAejq1atwc3Mrso6ZmRnWrVtXbFsDBgzA3bt3MWvWLCQmJqJJkybYs2ePdGB0fHy8xhafGTNmQCaTYcaMGbh9+zbs7OzQo0cPzJ8/X6pz69YtDBo0CPfv34ednR38/f3x+++/w87OrrRDJSIiHVOHH3t7e5iampb7R4+qLiEE0tPTcefOHQCAk5NTudqTiVIerXzq1CmoVCr4+flplJ84cQIKhQK+vr7l6lBlkJqaCktLS6SkpMDCwkLX3SEi0ks5OTn4559/YG9vj+rVq+u6O1RJ3L9/H3fu3MFrr71WYHdYaX6/S30W2NixY7WeJXX79m2MHTu2tM0RERFppT7mx9TUVMc9ocpE/X4o7zFhpQ5Aly5dQrNmzQqUN23aFJcuXSpXZ4iIiPLjbi/Kq6LeD6UOQEqlssCp6wCQkJDAe24RERFRlVDqANS5c2fpwoFqycnJmDZtGjp16lShnSMiIqJc7u7uiIyM1HU3XhmlDkCLFi3CzZs34ebmhg4dOqBDhw7w8PBAYmIiPv300xfRRyIioipDJpMV+ZgzZ06Z2j116hRGjRpVrr5du3YNgwcPhrOzM4yNjVGjRg307NkTf//9d7narYpKvc/KxcUFf/zxBzZt2oQLFy7AxMQEwcHBGDRokNZrAhEREemThIQE6f9btmzBrFmzEBMTI5WZm5tL/xdCICcnp0SHkJT3ci5ZWVno1KkT6tSpg6ioKDg5OeHWrVvYvXv3C73OUlZWVqXMB2W6F5iZmRlGjRqFZcuWYdGiRRg2bFilHBwREdHL5ujoKD0sLS0hk8mk53///TeqVauG3bt3w8fHB0qlEkePHkVcXBx69uwJBwcHmJubo3nz5ti/f79Gu/l3gclkMnz55Zfo3bs3TE1NUbt2bfzwww+F9uuvv/5CXFwcli9fjpYtW8LNzQ1t2rTBhx9+iJYtW0r11NfTs7GxgZmZGXx9fXHixAlp+ooVK+Dl5QUjIyPUqVMHGzdu1FiOTCbDihUr8J///AdmZmbStfq+//57NGvWDMbGxvD09ERYWBiys7MB5AbBOXPmoGbNmlAqlXB2dsb48ePLvA5KosxHLV+6dAnx8fHIzMzUKP/Pf/5T7k4RERFpI4TAk6wcnSzbxFBRYWcgTZ06FYsWLYKnpyesra1x8+ZNdOvWDfPnz4dSqcRXX32FHj16ICYmBjVr1iy0nbCwMCxcuBCffPIJPv/8cwwZMgQ3btyAjY1Ngbp2dnaQy+XYvn07JkyYoPWWEo8fP0a7du3g4uKCH374AY6Ojjh79ixUKhUA4LvvvsP777+PyMhIBAQE4KeffkJwcDBq1KiBDh06SO3MmTMHH330ESIjI2FgYIAjR45g2LBhWLJkCdq2bYu4uDhpd97s2bOxY8cOLF68GJs3b0aDBg2QmJiICxculPdlLlKZrgTdu3dv/Pnnn5DJZNI9uNRvipwc3bwxiYjo1fckKwf1Z+3VybIvzQ2EqVHFnO08d+5cjROHbGxs0LhxY+n5vHnz8N133+GHH34o9P6YADB8+HDpVk8LFizAkiVLcPLkSXTp0qVAXRcXFyxZsgSTJ09GWFgYfH190aFDBwwZMgSenp4AgG+++QZ3797FqVOnpBBVq1YtqY1FixZh+PDhePfddwHk3tLq999/x6JFizQC0ODBg6XbWgHAiBEjMHXqVAQFBQEAPD09MW/ePEyePBmzZ89GfHw8HB0dERAQAENDQ9SsWRMtWrQo+QtaBqXeBfb+++/Dw8MDd+7cgampKf766y8cPnwYvr6+OHTo0AvoIhER0asl/10THj9+jIkTJ6JevXqwsrKCubk5Ll++jPj4+CLbadSokfR/MzMzWFhYSLeK0Gbs2LFITEzEpk2b0KpVK2zbtg0NGjTAvn37AADnz59H06ZNtW5BAoDLly+jTZs2GmVt2rTB5cuXixzfhQsXMHfuXJibm0uPkSNHIiEhAenp6ejXrx+ePHkCT09PjBw5Et999520e+xFKXWUPX78OA4cOABbW1vI5XLI5XL4+/sjPDwc48ePx7lz515EP4mIiGBiqMCluYE6W3ZFMTMz03g+ceJE7Nu3D4sWLUKtWrVgYmKCvn37FjjMJL/8x9/KZDJpd1VhqlWrhh49eqBHjx748MMPERgYiA8//BCdOnWCiYlJ2QaUT/7xPX78GGFhYejTp0+BusbGxnB1dUVMTAz279+Pffv24d1338Unn3yCX3/99YUdY1zqAJSTk4Nq1aoBAGxtbfHvv/+iTp06cHNz0zjKnYiIqKLJZLIK2w1VmRw7dgzDhw9H7969AeQGhuvXr7/w5cpkMtStWxe//fYbgNwtSl9++SUePHigdStQvXr1cOzYMWlXlrrv9evXL3I5zZo1Q0xMjMbutPxMTEykYDZ27FjUrVsXf/75p9a7T1SEUr+LGjZsiAsXLsDDwwN+fn5YuHAhjIyM8MUXX0j7EImIiKjkateujaioKPTo0QMymQwzZ84sdktOaZ0/fx6zZ8/G0KFDUb9+fRgZGeHXX3/F2rVrMWXKFADAoEGDsGDBAvTq1Qvh4eFwcnLCuXPn4OzsjFatWmHSpEno378/mjZtioCAAPz444+IiooqcMZafrNmzcKbb76JmjVrom/fvpDL5bhw4QIuXryIDz/8EOvXr0dOTg78/PxgamqKr7/+GiYmJnBzc6vQ1yCvUh8DNGPGDGmlzJ07F9euXUPbtm2xa9cuLFmypMI7SERE9KqLiIiAtbU1WrdujR49eiAwMLDCt3zUqFED7u7uCAsLg5+fH5o1a4bPPvsMYWFhmD59OgDAyMgIv/zyC+zt7dGtWzd4e3vjo48+ks4Y69WrFz777DMsWrQIDRo0wKpVq7Bu3Tq0b9++yGUHBgbip59+wi+//ILmzZujZcuWWLx4sRRwrKyssHr1arRp0waNGjXC/v378eOPP6J69eoV+hrkJRPq07jK4cGDB7C2tn5lbliXmpoKS0tLpKSkwMLCQtfdISLSS0+fPsW1a9fg4eEBY2NjXXeHKomi3hel+f0u1RagrKwsGBgY4OLFixrlNjY2r0z4ISIioldfqQKQ+tx8XuuHiIiIqrJSHwM0ffp0TJs2DQ8ePHgR/SEiIiJ64Up9FtjSpUtx5coVODs7w83NrcC5/mfPnq2wzhERERG9CKUOQL169XoB3SAiIiJ6eUodgGbPnv0i+kFERET00pT6GCAiIiKiqq7UW4DkcnmRp7zzDDEiIiKq7EodgL777juN51lZWTh37hw2bNiAsLCwCusYERER0YtS6gDUs2fPAmV9+/ZFgwYNsGXLFrz99tsV0jEiIiKiF6XCjgFq2bIloqOjK6o5IiKiKkkmkxX5mDNnTrna3rlzZ7H1fv31V7zxxhuwsbGBqakpateujaCgIGRmZpZ52a+aUm8B0ubJkydYsmQJXFxcKqI5IiKiKishIUH6/5YtWzBr1izExMRIZebm5i90+ZcuXUKXLl0wbtw4LFmyBCYmJoiNjcWOHTte2HG6Qgjk5OTAwKBCYsVLUeotQNbW1rCxsZEe1tbWqFatGtauXYtPPvnkRfSRiIioynB0dJQelpaWkMlkGmWbN29GvXr1YGxsjLp162L58uXSvJmZmXjvvffg5OQEY2NjuLm5ITw8HADg7u4OAOjduzdkMpn0PL9ffvkFjo6OWLhwIRo2bAgvLy906dIFq1evhomJiVTv2LFjaN++PUxNTWFtbY3AwEA8fPgQAJCRkYHx48fD3t4exsbG8Pf3x6lTp6R5Dx06BJlMht27d8PHxwdKpRJHjx6FSqVCeHg4PDw8YGJigsaNG2P79u3SfA8fPsSQIUNgZ2cHExMT1K5dG+vWrauol75USh3VFi9erHEWmFwuh52dHfz8/GBtbV2hnSMiItIgBJCVrptlG5oC5bzx96ZNmzBr1iwsXboUTZs2xblz5zBy5EiYmZkhKCgIS5YswQ8//ICtW7eiZs2auHnzJm7evAkAOHXqFOzt7bFu3Tp06dIFCoVC6zIcHR2RkJCAw4cP4/XXX9da5/z58+jYsSNGjBiBzz77DAYGBjh48KC0hWjy5MnYsWMHNmzYADc3NyxcuBCBgYG4cuUKbGxspHamTp2KRYsWwdPTE9bW1ggPD8fXX3+NlStXonbt2jh8+DD++9//ws7ODu3atcPMmTNx6dIl7N69G7a2trhy5QqePHlSrte0rEodgIYPH/4CukFERFQCWenAAmfdLHvav4CRWfH1ijB79mx8+umn6NOnDwDAw8MDly5dwqpVqxAUFIT4+HjUrl0b/v7+kMlkcHNzk+a1s7MDAFhZWcHR0bHQZfTr1w979+5Fu3bt4OjoiJYtW6Jjx44YNmwYLCwsAAALFy6Er6+vxtanBg0aAADS0tKwYsUKrF+/Hl27dgUArF69Gvv27cOaNWswadIkaZ65c+eiU6dOAHK3Gi1YsAD79+9Hq1atAACenp44evQoVq1ahXbt2iE+Ph5NmzaFr68vABS6FetlKPUusHXr1mHbtm0Fyrdt24YNGzZUSKeIiIheNWlpaYiLi8Pbb78Nc3Nz6fHhhx8iLi4OQO5GhvPnz6NOnToYP348fvnll1IvR6FQYN26dbh16xYWLlwIFxcXLFiwAA0aNJCOT1JvAdImLi4OWVlZaNOmjVRmaGiIFi1a4PLlyxp11UEGAK5cuYL09HR06tRJY3xfffWVNL4xY8Zg8+bNaNKkCSZPnozffvut1OOrKKXeAhQeHo5Vq1YVKLe3t8eoUaMQFBRUIR0jIiIqwNA0d0uMrpZdDo8fPwaQuzXFz89PY5p6d1azZs1w7do17N69G/v370f//v0REBCgcRxNSbm4uGDo0KEYOnQo5s2bh9deew0rV65EWFiYxrFA5ZH3hujq8f38888FTopSKpUAgK5du+LGjRvYtWsX9u3bh44dO2Ls2LFYtGhRhfSnNEodgOLj4+Hh4VGg3M3NDfHx8RXSKSIiIq1ksnLvhtIVBwcHODs74+rVqxgyZEih9SwsLDBgwAAMGDAAffv2RZcuXfDgwQPY2NjA0NCwTGdyWVtbw8nJCWlpaQCARo0aITo6WusFjL28vGBkZIRjx45Ju+CysrJw6tQpTJgwodBl1K9fH0qlEvHx8WjXrl2h9ezs7BAUFISgoCC0bdsWkyZNqhoByN7eHn/88UeB/XYXLlxA9erVK6pfREREr5ywsDCMHz8elpaW6NKlCzIyMnD69Gk8fPgQISEhiIiIgJOTE5o2bQq5XI5t27bB0dERVlZWAHKPmYmOjkabNm2gVCq1nny0atUqnD9/Hr1794aXlxeePn2Kr776Cn/99Rc+//xzAEBoaCi8vb3x7rvvYvTo0TAyMsLBgwfRr18/2NraYsyYMZg0aRJsbGxQs2ZNLFy4EOnp6UVe7LhatWqYOHEiPvjgA6hUKvj7+yMlJQXHjh2DhYUFgoKCMGvWLPj4+KBBgwbIyMjATz/9hHr16r2Q17pYopQmT54s3NzcxIEDB0R2drbIzs4W0dHRws3NTfzvf/8rbXOVUkpKigAgUlJSdN0VIiK99eTJE3Hp0iXx5MkTXXelzNatWycsLS01yjZt2iSaNGkijIyMhLW1tXj99ddFVFSUEEKIL774QjRp0kSYmZkJCwsL0bFjR3H27Flp3h9++EHUqlVLGBgYCDc3N63LPHv2rPjvf/8rPDw8hFKpFNWrVxevv/66+OGHHzTqHTp0SLRu3VoolUphZWUlAgMDxcOHD4UQua/9uHHjhK2trVAqlaJNmzbi5MmT0rwHDx4UAKT6aiqVSkRGRoo6deoIQ0NDYWdnJwIDA8Wvv/4qhBBi3rx5ol69esLExETY2NiInj17iqtXr5bqNS3qfVGa32+ZEEKUJjBlZmZi6NCh2LZtm3TBI5VKhWHDhmHlypUwMjKq+JT2kqWmpsLS0hIpKSnSEfNERPRyPX36FNeuXYOHhweMjY113R2qJIp6X5Tm97vUZ4EZGRlhy5YtiImJwaZNmxAVFYW4uDisXbu2TOFn2bJlcHd3h7GxMfz8/HDy5Mki60dGRqJOnTowMTGBq6srPvjgAzx9+rRcbRIREZF+KfM1q2vXro3atWuXa+FbtmxBSEgIVq5cCT8/P0RGRiIwMBAxMTGwt7cvUP+bb77B1KlTsXbtWrRu3Rr//PMPhg8fDplMhoiIiDK1SURERPqn1FuA3nrrLXz88ccFyhcuXIh+/fqVqq2IiAiMHDkSwcHBqF+/PlauXAlTU1OsXbtWa/3ffvsNbdq0weDBg+Hu7o7OnTtj0KBBGlt4StsmERER6Z9SB6DDhw+jW7duBcq7du2Kw4cPl7idzMxMnDlzBgEBAc87I5cjICAAx48f1zpP69atcebMGSnwXL16Fbt27ZL6U5Y2gdyrV6ampmo8iIiI6NVV6l1gjx8/1nqsj6GhYamCw71795CTkwMHBweNcgcHB/z9999a5xk8eDDu3bsHf39/CCGQnZ2N0aNHY9q0aWVuE8i9uKO2ayEQEZHulfJcHXrFVdT7odRbgLy9vbFly5YC5Zs3b0b9+vUrpFOFOXToEBYsWIDly5fj7NmziIqKws8//4x58+aVq93Q0FCkpKRID/WN54iISHcMDQ0BAOnpOrr5KVVK6veD+v1RVqXeAjRz5kz06dMHcXFxeOONNwAA0dHR+Oabb0p1qW5bW1soFAokJSVplCclJRV6k7eZM2di6NCheOeddwDkhrG0tDSMGjUK06dPL1ObQO4lutWX6SYiospBoVDAysoKd+7cAQCYmppCVs67sVPVJYRAeno67ty5AysrK+n2IWVV6gDUo0cP7Ny5EwsWLMD27dthYmKCxo0b48CBA7CxsSlxO0ZGRvDx8UF0dDR69eoFIPd6QtHR0Xjvvfe0zpOeng65XHOjlfoFEEKUqU0iIqq81H+8qkMQkZWVVZEbNUqqTKfBd+/eHd27dweQe9Ghb7/9FhMnTsSZM2dKdY+SkJAQBAUFwdfXFy1atEBkZCTS0tIQHBwMABg2bBhcXFwQHh4OIDd8RUREoGnTpvDz88OVK1cwc+ZM9OjRQwpCxbVJRERVh0wmg5OTE+zt7ZGVlaXr7pCOGRoalnvLj1qZrwN0+PBhrFmzBjt27ICzszP69OmDZcuWlaqNAQMG4O7du5g1axYSExPRpEkT7NmzRzqIOT4+XmOLz4wZMyCTyTBjxgzcvn0bdnZ26NGjB+bPn1/iNomIqOpRKBQV9sNHBACluhVGYmIi1q9fjzVr1iA1NRX9+/fHypUrceHChRd+APTLxFthEBERVT0v5FYYPXr0QJ06dfDHH38gMjIS//77r3RXWSIiIqKqpMS7wHbv3o3x48djzJgx5b4FBhEREZEulXgL0NGjR/Ho0SP4+PjAz88PS5cuxb17915k34iIiIheiBIHoJYtW2L16tVISEjA//3f/2Hz5s1wdnaGSqXCvn378OjRoxfZTyIiIqIKU6qDoPOLiYnBmjVrsHHjRiQnJ6NTp0744YcfKrJ/OsGDoImIiKqeF3IQtDZ16tTBwoULcevWLXz77bflaYqIiIjopSnXFqBXFbcAERERVT0vbQsQERERUVXEAERERER6hwGIiIiI9A4DEBEREekdBiAiIiLSOwxAREREpHcYgIiIiEjvMAARERGR3mEAIiIiIr3DAERERER6hwGIiIiI9A4DEBEREekdBiAiIiLSOwxAREREpHcYgIiIiEjvMAARERGR3mEAIiIiIr3DAERERER6hwGIiIiI9A4DEBEREekdBiAiIiLSOwxAREREpHcYgIiIiEjvMAARERGR3mEAIiIiIr3DAERERER6hwGIiIiI9A4DEBEREekdBiAiIiLSO5UiAC1btgzu7u4wNjaGn58fTp48WWjd9u3bQyaTFXh0795dqjN8+PAC07t06fIyhkJERERVgIGuO7BlyxaEhIRg5cqV8PPzQ2RkJAIDAxETEwN7e/sC9aOiopCZmSk9v3//Pho3box+/fpp1OvSpQvWrVsnPVcqlS9uEERERFSl6HwLUEREBEaOHIng4GDUr18fK1euhKmpKdauXau1vo2NDRwdHaXHvn37YGpqWiAAKZVKjXrW1tYvYzhERERUBeg0AGVmZuLMmTMICAiQyuRyOQICAnD8+PEStbFmzRoMHDgQZmZmGuWHDh2Cvb096tSpgzFjxuD+/fsV2nciIiKqunS6C+zevXvIycmBg4ODRrmDgwP+/vvvYuc/efIkLl68iDVr1miUd+nSBX369IGHhwfi4uIwbdo0dO3aFcePH4dCoSjQTkZGBjIyMqTnqampZRwRERERVQU6PwaoPNasWQNvb2+0aNFCo3zgwIHS/729vdGoUSN4eXnh0KFD6NixY4F2wsPDERYW9sL7S0RERJWDTneB2draQqFQICkpSaM8KSkJjo6ORc6blpaGzZs34+233y52OZ6enrC1tcWVK1e0Tg8NDUVKSor0uHnzZskHQURERFWOTgOQkZERfHx8EB0dLZWpVCpER0ejVatWRc67bds2ZGRk4L///W+xy7l16xbu378PJycnrdOVSiUsLCw0HkRERPTq0vlZYCEhIVi9ejU2bNiAy5cvY8yYMUhLS0NwcDAAYNiwYQgNDS0w35o1a9CrVy9Ur15do/zx48eYNGkSfv/9d1y/fh3R0dHo2bMnatWqhcDAwJcyJiIiIqrcdH4M0IABA3D37l3MmjULiYmJaNKkCfbs2SMdGB0fHw+5XDOnxcTE4OjRo/jll18KtKdQKPDHH39gw4YNSE5OhrOzMzp37ox58+bxWkBEREQEAJAJIYSuO1HZpKamwtLSEikpKdwdRkREVEWU5vdb57vAiIiIiF42BiAiIiLSOwxAREREpHcYgIiIiEjvMAARERGR3mEAIiIiIr3DAERERER6hwGIiIiI9A4DEBEREekdBiAiIiLSOwxAREREpHcYgIiIiEjvMAARERGR3mEAIiIiIr3DAERERER6hwGIiIiI9A4DEBEREekdBiAiIiLSOwxAREREpHcYgIiIiEjvMAARERGR3mEAIiIiIr3DAERERER6hwGIiIiI9A4DEBEREekdBiAiIiLSOwxAREREpHcYgIiIiEjvMAARERGR3mEAIiIiIr3DAERERER6hwGIiIiI9A4DEBEREekdBiAiIiLSOwxAREREpHcYgIiIiEjvMAARERGR3qkUAWjZsmVwd3eHsbEx/Pz8cPLkyULrtm/fHjKZrMCje/fuUh0hBGbNmgUnJyeYmJggICAAsbGxL2MoREREVAXoPABt2bIFISEhmD17Ns6ePYvGjRsjMDAQd+7c0Vo/KioKCQkJ0uPixYtQKBTo16+fVGfhwoVYsmQJVq5ciRMnTsDMzAyBgYF4+vTpyxoWERERVWIyIYTQZQf8/PzQvHlzLF26FACgUqng6uqKcePGYerUqcXOHxkZiVmzZiEhIQFmZmYQQsDZ2Rn/+9//MHHiRABASkoKHBwcsH79egwcOLDYNlNTU2FpaYmUlBRYWFiUb4BERET0UpTm91unW4AyMzNx5swZBAQESGVyuRwBAQE4fvx4idpYs2YNBg4cCDMzMwDAtWvXkJiYqNGmpaUl/Pz8Cm0zIyMDqampGg8iIiJ6dek0AN27dw85OTlwcHDQKHdwcEBiYmKx8588eRIXL17EO++8I5Wp5ytNm+Hh4bC0tJQerq6upR0KERERVSE6PwaoPNasWQNvb2+0aNGiXO2EhoYiJSVFety8ebOCekhERESVkU4DkK2tLRQKBZKSkjTKk5KS4OjoWOS8aWlp2Lx5M95++22NcvV8pWlTqVTCwsJC40FERESvLp0GICMjI/j4+CA6OloqU6lUiI6ORqtWrYqcd9u2bcjIyMB///tfjXIPDw84OjpqtJmamooTJ04U2yYRERHpBwNddyAkJARBQUHw9fVFixYtEBkZibS0NAQHBwMAhg0bBhcXF4SHh2vMt2bNGvTq1QvVq1fXKJfJZJgwYQI+/PBD1K5dGx4eHpg5cyacnZ3Rq1evlzUsIiIiqsR0HoAGDBiAu3fvYtasWUhMTESTJk2wZ88e6SDm+Ph4yOWaG6piYmJw9OhR/PLLL1rbnDx5MtLS0jBq1CgkJyfD398fe/bsgbGx8QsfDxEREVV+Or8OUGXE6wARERFVPVXmOkBEREREusAARERERHqHAYiIiIj0DgMQERER6R0GICIiItI7DEBERESkdxiAiIiISO8wABEREZHeYQAiIiIivcMARERERHqHAYiIiIj0DgMQERER6R0GICIiItI7DEBERESkdxiAiIiISO8wABEREZHeMdB1B4iIiIolBJD+AHhwFXh4HTAwAswdnj+MTHXdQ6piGICIiKhyEAJIu5cbch5cBR7EPf///atARkrh8xpVA8ztgWqOuf+aO+T5N0+ZmS0gV7y8MVGlxQBEREQvjxBA2l3gfpyWoHMNyEgten6LGoC1O6DKAh4nAY+SgOwnQOYj4MGj3LaKIpMDZnZ5wpE6KDlqllVzAIzMAZmswoZOlQsDEBERVSwhcsPJg6tags41IPNxETPLAMsagI3n80d1r9x/rd0BQ5OCy8p4BDy+k7tMjced5yHpcVJu8BKq59PxZ9HjMDTNtzXJUXPLUrVnYcnMDlAYlvNFo5eNAYiIiEpPCOBRQp5dVHm24jy4CmSlFT6vTJ4n5HhpBh0rN8DQuOT9kMkAY4vch22touvmZAPp97UHpUeJeULUndwtSlnpuccbPbxefD9Mq2sekySFpHy75IytuFWpkmAAIiIi7VSqZyEnLl/QeRZysp8UPq9MDljVzLMlJ0/QsXYDDJQvbxxqCoPcrTbVHIqvm5mmuRVJCklJ+bY23QFETm6wSr8P3LlUTB+U+Y5Pyn/cUp5puniN9AgDEBGRPlOpgNTbBY/FuR8HPLwGZD8tfF6ZIjfkVPcqGHSsauaeqVVVGZk9H1NRVCrgyYPngehRkpaQ9OzxNAXIyQBS4nMfxTG2yheSHPIFpWcPE2tAzqvalBYDEBHRq06VA6TcynMsTt7Htdwf5cLIDXJ3S+U9Fkf9sKrJY1/k8twzy8xsAYcGRdfNegqk3ckTktRBKd/ut8dJQE4m8DQ593Evppg+GABm9s+PSdIWktRlvFyAhAGIiOhVoMoBUm7mOxYn7vl1c3IyC59Xbph7gLHGQcceuf+3rJm764jKz9A4NzRa1Sy6nhDAk4f5QlG+3W/qEPXkAaDKBh79m/sojtJCy4Hd+c5+M3fIPabpFb9cAN/VRERVRU527q4T9XVx8p5d9fBG7qnhhVEYPQs56q04Hs+36FjUYMipTGQywNQm92Fft+i62Zm5Z7dpPfstUXNXXPbT3MsMZKQC968U04e8lwso5Ow3dVkVvVwA3/FERJVJThaQHK/l7KqrQPKN3L/2C6NQPt9yk/80cguXV/4ver1kYARYuuQ+iiJdLqCYs9/KfLmA/Ge/adn9ZmZfqYJ25ekJEZG+yM58FnLyn111Nbdc5BQ+r4ExYO2huZtKvVXHwoUHw5J2GpcLqF103ZxsIP1eEWe/5TluKfPxs8sFXMt9FN2JPJcLsAcavgU0G1phQywtBiAiohchOyN3t1SBWzrE5R6rI1SFz2tgUnA3lTroVHNiyKEXS2GQe9ZZNcfi62Y8zndgtzok5d+ypL5cwL3cx52/gBq+L34sRWAAIiIqq6ynuQcYa7t3VcqtokOOodnzkJP/DKtqTlXymArSQ0rz3EdJLhegcRHKO4B9vZfTx0IwABERFSXrSW7I0XZLh5RbAETh8xqZPws4+a52bOOZuxuAIYf0hVwOmNvlPtBQ170BwABEVLzszNwLxaXcyn2k3wMgyz2gVCbXfEhleabJ5ZplRc6Xt55cS1uKEsynyP1h1Tqfehp/eDVkPjuGocC9q67mrvuiGFUDqmu52nF1r9yzaPhaE1VKDECk34TIvdBYyi0g+eazkJPv30eJKPKv/KpII4DlD07awlqeaflDnrywtooLhzItbeWZprUPZZkvT//VZU8eat7Sobjrpygt84ScfEHHzJYhh6gKYgCiV1vOswuEqbfeJMc//7865BR5Z+pnDIxzb95oWSP3VE6ZLPfCc0KVe2CfUOXu4xaqfGU5ecpU+cqKm08U0laeafnbKuqYk7xKU1dfGFvmBhttt3UwtWHIIXrFMABR1fY0teAWG2lLzq3c8FOSH3ozu+cBx7Jmnv/XyL1qq2n1qvEDKETZg5MUurSFt2fTyj1fRYXDYubT1ldVnmnq+zzlDTumNrpee0T0EjEAUeWlysnd/SSFmzzBRh1yMlKKb0dhlHt9FCtXwNL1WbDJ+68LYGjy4sfzMkjH98jBjzcRUeF0/g25bNkyfPLJJ0hMTETjxo3x+eefo0WLFoXWT05OxvTp0xEVFYUHDx7Azc0NkZGR6NatGwBgzpw5CAsL05inTp06+Pvvv1/oOKgMMh5r7orKG3BSbgKp/xZ91Vs1E5vnYcbKteCWHDM7XjeFiIg06DQAbdmyBSEhIVi5ciX8/PwQGRmJwMBAxMTEwN7evkD9zMxMdOrUCfb29ti+fTtcXFxw48YNWFlZadRr0KAB9u/fLz03MNB5ztM/KlXuxbEKHHeTJ+g8eVh8O3KD3K03lnmCjVW+rThGZi9+PERE9ErRaTKIiIjAyJEjERwcDABYuXIlfv75Z6xduxZTp04tUH/t2rV48OABfvvtNxgaGgIA3N3dC9QzMDCAo2MJrmBJZZeZ/uzU8PzH3agDzu2ib8yoZmz5LMi4FjzuxrJG7rVSeP8iIiKqYDoLQJmZmThz5gxCQ0OlMrlcjoCAABw/flzrPD/88ANatWqFsWPH4vvvv4ednR0GDx6MKVOmQKF4/iMZGxsLZ2dnGBsbo1WrVggPD0fNmjUL7UtGRgYyMjKk56mpqRUwwipMCCDtXu5dp/OeMZV3S076veLbkSkAC+c8wSb/8Tc1cu9LQ0RE9JLpLADdu3cPOTk5cHBw0Ch3cHAo9Hidq1ev4sCBAxgyZAh27dqFK1eu4N1330VWVhZmz54NAPDz88P69etRp04dJCQkICwsDG3btsXFixdRrVo1re2Gh4cXOG7olZb1NM+F/bScQZV6G8h+Wnw7RtXyHXOT7wyqak6V6s6/REREalXq10mlUsHe3h5ffPEFFAoFfHx8cPv2bXzyySdSAOratatUv1GjRvDz84Obmxu2bt2Kt99+W2u7oaGhCAkJkZ6npqbC1dX1xQ7mRRECSH9Q8IDivAEn7U4JGpLlBhhtx9yo/zW2rBqnhhMREeWjswBka2sLhUKBpKQkjfKkpKRCj99xcnKCoaGhxu6uevXqITExEZmZmTAyMiowj5WVFV577TVcuXKl0L4olUoolcoyjuQly87MvbZNciEBJ+UWkJVefDuGploOLM7z3MIFUBi++PEQERHpgM4CkJGREXx8fBAdHY1evXoByN3CEx0djffee0/rPG3atME333wDlUoF+bPTmv/55x84OTlpDT8A8PjxY8TFxWHo0KEvZBwVKu9tGaQDi/MFnZLelsHcoeBWm7xbckysufWGiIj0lk53gYWEhCAoKAi+vr5o0aIFIiMjkZaWJp0VNmzYMLi4uCA8PBwAMGbMGCxduhTvv/8+xo0bh9jYWCxYsADjx4+X2pw4cSJ69OgBNzc3/Pvvv5g9ezYUCgUGDRqkkzFqyMkGHiVoHnejsSXnFpD5qPh28t6WIf9xN1auuVtvDKrIFi0iIiId0GkAGjBgAO7evYtZs2YhMTERTZo0wZ49e6QDo+Pj46UtPQDg6uqKvXv34oMPPkCjRo3g4uKC999/H1OmTJHq3Lp1C4MGDcL9+/dhZ2cHf39//P7777Czs3vp4yvg4IfA0cXF1zO1Lfy4G0tX3nyRiIionGRCiFfsNtfll5qaCktLS6SkpMDCogJP0z71JbAn9NmF/fJc60YKOK/YbRmIiIheotL8fleps8CqvKbDAJ8RvC0DERGRjjEAvUwG2g/UJiIiopeLmyKIiIhI7zAAERERkd5hACIiIiK9wwBEREREeocBiIiIiPQOAxARERHpHQYgIiIi0jsMQERERKR3GICIiIhI7zAAERERkd5hACIiIiK9wwBEREREeocBiIiIiPQO7wavhRACAJCamqrjnhAREVFJqX+31b/jRWEA0uLRo0cAAFdXVx33hIiIiErr0aNHsLS0LLKOTJQkJukZlUqFf//9F9WqVYNMJqvQtlNTU+Hq6oqbN2/CwsKiQtuuDDi+qu9VHyPHV/W96mPk+MpOCIFHjx7B2dkZcnnRR/lwC5AWcrkcNWrUeKHLsLCweCXf2GocX9X3qo+R46v6XvUxcnxlU9yWHzUeBE1ERER6hwGIiIiI9A4D0EumVCoxe/ZsKJVKXXflheD4qr5XfYwcX9X3qo+R43s5eBA0ERER6R1uASIiIiK9wwBEREREeocBiIiIiPQOAxARERHpHQagCnD79m3897//RfXq1WFiYgJvb2+cPn1ami6EwKxZs+Dk5AQTExMEBAQgNjZWo40HDx5gyJAhsLCwgJWVFd5++208fvz4ZQ+lUMWNcfjw4ZDJZBqPLl26aLRRWcfo7u5eoO8ymQxjx44FADx9+hRjx45F9erVYW5ujrfeegtJSUkabcTHx6N79+4wNTWFvb09Jk2ahOzsbF0MR6vixti+ffsC00aPHq3RRmUeY05ODmbOnAkPDw+YmJjAy8sL8+bN07gfUFX+HJZkfFX5Mwjk3rpgwoQJcHNzg4mJCVq3bo1Tp05J06vy+lMrboxVaR0ePnwYPXr0gLOzM2QyGXbu3KkxvaLW1x9//IG2bdvC2NgYrq6uWLhwYcUNQlC5PHjwQLi5uYnhw4eLEydOiKtXr4q9e/eKK1euSHU++ugjYWlpKXbu3CkuXLgg/vOf/wgPDw/x5MkTqU6XLl1E48aNxe+//y6OHDkiatWqJQYNGqSLIRVQkjEGBQWJLl26iISEBOnx4MEDjXYq6xjv3Lmj0e99+/YJAOLgwYNCCCFGjx4tXF1dRXR0tDh9+rRo2bKlaN26tTR/dna2aNiwoQgICBDnzp0Tu3btEra2tiI0NFRHIyqouDG2a9dOjBw5UqNOSkqKNH9lH+P8+fNF9erVxU8//SSuXbsmtm3bJszNzcVnn30m1anKn8OSjK8qfwaFEKJ///6ifv364tdffxWxsbFi9uzZwsLCQty6dUsIUbXXn1pxY6xK63DXrl1i+vTpIioqSgAQ3333ncb0ilhfKSkpwsHBQQwZMkRcvHhRfPvtt8LExESsWrWqQsbAAFROU6ZMEf7+/oVOV6lUwtHRUXzyySdSWXJyslAqleLbb78VQghx6dIlAUCcOnVKqrN7924hk8nE7du3X1znS6i4MQqR+8Ht2bNnodMr+xjzev/994WXl5dQqVQiOTlZGBoaim3btknTL1++LACI48ePCyFyvwjkcrlITEyU6qxYsUJYWFiIjIyMl97/ksg7RiFyA9D7779faP3KPsbu3buLESNGaJT16dNHDBkyRAhR9T+HxY1PiKr9GUxPTxcKhUL89NNPGuXNmjUT06dPr/LrT4jixyhE1V2H+QNQRa2v5cuXC2tra43vmClTpog6depUSL+5C6ycfvjhB/j6+qJfv36wt7dH06ZNsXr1amn6tWvXkJiYiICAAKnM0tISfn5+OH78OADg+PHjsLKygq+vr1QnICAAcrkcJ06ceHmDKURxY1Q7dOgQ7O3tUadOHYwZMwb379+XplX2MaplZmbi66+/xogRIyCTyXDmzBlkZWVprL+6deuiZs2aGuvP29sbDg4OUp3AwECkpqbir7/+euljKE7+Mapt2rQJtra2aNiwIUJDQ5Geni5Nq+xjbN26NaKjo/HPP/8AAC5cuICjR4+ia9euAKr+57C48alV1c9gdnY2cnJyYGxsrFFuYmKCo0ePVvn1BxQ/RrWqug7zqqj1dfz4cbz++uswMjKS6gQGBiImJgYPHz4sdz95M9Ryunr1KlasWIGQkBBMmzYNp06dwvjx42FkZISgoCAkJiYCgMYPh/q5elpiYiLs7e01phsYGMDGxkaqo0vFjREAunTpgj59+sDDwwNxcXGYNm0aunbtiuPHj0OhUFT6Mart3LkTycnJGD58OIDcdWNkZAQrKyuNevnXn7b1q55W2eQfIwAMHjwYbm5ucHZ2xh9//IEpU6YgJiYGUVFRACr/GKdOnYrU1FTUrVsXCoUCOTk5mD9/PoYMGQIAVf5zWNz4gKr9GaxWrRpatWqFefPmoV69enBwcMC3336L48ePo1atWlV+/QHFjxGo2uswr4paX4mJifDw8CjQhnqatbV1ufrJAFROKpUKvr6+WLBgAQCgadOmuHjxIlauXCmFg6quJGMcOHCgVN/b2xuNGjWCl5cXDh06hI4dO+qk32WxZs0adO3aFc7OzrruygujbYyjRo2S/u/t7Q0nJyd07NgRcXFx8PLy0kU3S2Xr1q3YtGkTvvnmGzRo0ADnz5/HhAkT4Ozs/Ep8Dksyvqr+Gdy4cSNGjBgBFxcXKBQKNGvWDIMGDcKZM2d03bUKU9wYq/o6rGq4C6ycnJycUL9+fY2yevXqIT4+HgDg6OgIAAXOGkpKSpKmOTo64s6dOxrTs7Oz8eDBA6mOLhU3Rm08PT1ha2uLK1euAKj8YwSAGzduYP/+/XjnnXekMkdHR2RmZiI5OVmjbv71p239qqdVJtrGqI2fnx8AaKy/yjzGSZMmYerUqRg4cCC8vb0xdOhQfPDBBwgPDwdQ9T+HxY1Pm6r2GfTy8sKvv/6Kx48f4+bNmzh58iSysrLg6elZ5defWlFj1KaqrUO1ilpfL/p7hwGonNq0aYOYmBiNsn/++Qdubm4AAA8PDzg6OiI6OlqanpqaihMnTqBVq1YAgFatWiE5OVnjL50DBw5ApVJJP0S6VNwYtbl16xbu378PJycnAJV/jACwbt062Nvbo3v37lKZj48PDA0NNdZfTEwM4uPjNdbfn3/+qfFh3rdvHywsLAoER13TNkZtzp8/DwAa668yjzE9PR1yuebXmUKhgEqlAlD1P4fFjU+bqvgZBAAzMzM4OTnh4cOH2Lt3L3r27Fnl119+2saoTVVdhxW1vlq1aoXDhw8jKytLqrNv3z7UqVOn3Lu/APA0+PI6efKkMDAwEPPnzxexsbFi06ZNwtTUVHz99ddSnY8++khYWVmJ77//Xvzxxx+iZ8+eWk8HbNq0qThx4oQ4evSoqF27dqU5fbO4MT569EhMnDhRHD9+XFy7dk3s379fNGvWTNSuXVs8ffpUaqcyjzEnJ0fUrFlTTJkypcC00aNHi5o1a4oDBw6I06dPi1atWolWrVpJ09WniHfu3FmcP39e7NmzR9jZ2VWaU8TVChvjlStXxNy5c8Xp06fFtWvXxPfffy88PT3F66+/LtWp7GMMCgoSLi4u0mniUVFRwtbWVkyePFmqU5U/h8WN71X4DO7Zs0fs3r1bXL16Vfzyyy+icePGws/PT2RmZgohqvb6UytqjFVtHT569EicO3dOnDt3TgAQERER4ty5c+LGjRtCiIpZX8nJycLBwUEMHTpUXLx4UWzevFmYmpryNPjK5McffxQNGzYUSqVS1K1bV3zxxRca01UqlZg5c6ZwcHAQSqVSdOzYUcTExGjUuX//vhg0aJAwNzcXFhYWIjg4WDx69OhlDqNIRY0xPT1ddO7cWdjZ2QlDQ0Ph5uYmRo4cqXHKtBCVe4x79+4VAAqsFyGEePLkiXj33XeFtbW1MDU1Fb179xYJCQkada5fvy66du0qTExMhK2trfjf//4nsrKyXlb3S6SwMcbHx4vXX39d2NjYCKVSKWrVqiUmTZqkcR0gISr3GFNTU8X7778vatasKYyNjYWnp6eYPn26xumzVflzWNz4XoXP4JYtW4Snp6cwMjISjo6OYuzYsSI5OVmaXpXXn1pRY6xq6/DgwYMCQIFHUFCQEKLi1teFCxeEv7+/UCqVwsXFRXz00UcVNgaZEHkuJUpERESkB3gMEBEREekdBiAiIiLSOwxAREREpHcYgIiIiEjvMAARERGR3mEAIiIiIr3DAERERER6hwGIiF664cOHo1evXrruRoU6dOgQZDJZgfvGlZa7uzsiIyMrpE9EVDjeDZ6IKpRMJity+uzZs/HZZ5/hVbsGa+vWrZGQkABLS0tdd4WISoABiIgqVEJCgvT/LVu2YNasWRo30zU3N4e5ubkuuvbCZGVlwcjIqFLdkZuIisZdYERUoRwdHaWHpaUlZDKZRpm5uXmBXWDt27fHuHHjMGHCBFhbW8PBwQGrV69GWloagoODUa1aNdSqVQu7d+/WWNbFixfRtWtXmJubw8HBAUOHDsW9e/cK7dv69ethZWWFnTt3onbt2jA2NkZgYCBu3rypUe/7779Hs2bNYGxsDE9PT4SFhSE7O1uaLpPJsGLFCvznP/+BmZkZ5s+fr3UX2I4dO9CgQQMolUq4u7vj008/1VjOnTt30KNHD5iYmMDDwwObNm0qwytORGXBAERElcKGDRtga2uLkydPYty4cRgzZgz69euH1q1b4+zZs+jcuTOGDh2K9PR0AEBycjLeeOMNNG3aFKdPn8aePXuQlJSE/v37F7mc9PR0zJ8/H1999RWOHTuG5ORkDBw4UJp+5MgRDBs2DO+//z4uXbqEVatWYf369Zg/f75GO3PmzEHv3r3x559/YsSIEQWWc+bMGfTv3x8DBw7En3/+iTlz5mDmzJlYv369VGf48OG4efMmDh48iO3bt2P58uW4c+dOOV5FIiqxCrutKhFRPuvWrROWlpYFyoOCgkTPnj2l5+3atRP+/v7S8+zsbGFmZiaGDh0qlSUkJAgA4vjx40IIIebNmyc6d+6s0e7Nmze13vE+b38AiN9//10qu3z5sgAgTpw4IYQQomPHjmLBggUa823cuFE4OTlJzwGICRMmaNRR3x374cOHQgghBg8eLDp16qRRZ9KkSaJ+/fpCCCFiYmIEAHHy5MkCfVm8eLHW/hNRxeEWICKqFBo1aiT9X6FQoHr16vD29pbKHBwcAEDaQnLhwgUcPHhQOqbI3NwcdevWBQDExcUVuhwDAwM0b95cel63bl1YWVnh8uXLUrtz587VaHfkyJFISEiQtj4BgK+vb5HjuXz5Mtq0aaNR1qZNG8TGxiInJweXL1+GgYEBfHx8CvSFiF48HgRNRJWCoaGhxnOZTKZRpj67TKVSAQAeP36MHj164OOPPy7QlpOTU5n78fjxY4SFhaFPnz4FphkbG0v/NzMzK/MyiEj3GICIqEpq1qwZduzYAXd3dxgYlPyrLDs7G6dPn0aLFi0AADExMUhOTka9evWkdmNiYlCrVq1y9a9evXo4duyYRtmxY8fw2muvQaFQoG7dusjOzsaZM2ekLVLqvhDRi8ddYERUJY0dOxYPHjzAoEGDcOrUKcTFxWHv3r0IDg5GTk5OofMZGhpi3LhxOHHiBM6cOYPhw4ejZcuWUiCaNWsWvvrqK4SFheGvv/7C5cuXsXnzZsyYMaNU/fvf//6H6OhozJs3D//88w82bNiApUuXYuLEiQCAOnXqoEuXLvi///s/qS/vvPMOTExMyv6iEFGJMQARUZXk7OyMY8eOIScnB507d4a3tzcmTJgAKysryOWFf7WZmppiypQpGDx4MNq0aQNzc3Ns2bJFmh4YGIiffvoJv/zyC5o3b46WLVti8eLFcHNzK1X/mjVrhq1bt2Lz5s1o2LAhZs2ahblz52L48OFSnXXr1sHZ2Rnt2rVDnz59MGrUKNjb25f6tSCi0pMJ8YpdjpWIqBDr16/HhAkTuJuJiLgFiIiIiPQPAxARERHpHe4CIyIiIr3DLUBERESkdxiAiIiISO8wABEREZHeYQAiIiIivcMARERERHqHAYiIiIj0DgMQERER6R0GICIiItI7DEBERESkd/4fhdNKcLnBZ/IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create lists for x and y values\n",
    "x_values = [int(k) for k in long_time_train_scores.keys()] # convert keys to integer values\n",
    "train_scores = [v for v in long_time_train_scores.values()]\n",
    "test_scores = [v for v in long_time_test_scores.values()]\n",
    "\n",
    "# Plot the data\n",
    "plt.plot(x_values, train_scores, label='Train Scores')\n",
    "plt.plot(x_values, test_scores, label='Test Scores')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel('Time period')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Test Accuracy for time period between 500 and 1000')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
