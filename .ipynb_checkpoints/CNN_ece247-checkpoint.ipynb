{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SVW_3EQpDBAV",
    "outputId": "a2706db9-f7f5-4c25-9c53-f1b04e12d29a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "5DT3YzDfAoJG",
    "outputId": "8e99bb13-339b-42eb-bb37-12a01f850723"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb6bc1c9e50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAB3j0lEQVR4nO2ddZgcRfrHPzU+s57sxmXj7nKBQAgBAgES3N05OAgHh3NwHO52xw93DgsQ3CE4RCAkRCDusq7jXb8/qsd2dpOVSTa7W5/n2Wenq6u7q7tnvl391lvvK6SUaDQajablYmnuBmg0Go2maWgh12g0mhaOFnKNRqNp4Wgh12g0mhaOFnKNRqNp4dia46C5ubkyPz+/OQ6t0eyQP8z/A5q1FRpN7SxYsKBQSplXs7xZhDw/P5/58+c3x6E1mh0y2fw/pxnboNHUhRBiXW3l2rSi0Wg0LRwt5BqNRtPC0UKu0Wg0LZxmsZFrNJqGEQwG2bhxIz6fr7mbotkNuFwuunXrht1ur1d9LeQaTQtg48aNZGRkkJ+fjxCiuZuj2YVIKSkqKmLjxo306tWrXtto04pG0wLw+Xy0b99ei3gbQAhB+/btG/T2pYVco2khaBFvOzT0Xrc5IZeGQembbyIDgeZuikaj0aSENifkZW+/zZbrb6D4pZebuykaTYti69atnHjiifTp04cxY8Zw6KGH8ueff6Zk30888QQDBw5k4MCBjB8/nu+++y4l+41QWlrKo48+Wuf69PT0ne7j4YcfZtCgQZxyyinMnj2bpUuXprKJTaLNCXlgwwYAjKqqZm6JRtNykFJy1FFHMXnyZFatWsWCBQu444472LZtW5P3/f777/P444/z3XffsXz5ch577DFOPvlktm7dmoKWK3Ym5PXh0Ucf5bPPPuPll1/WQt7cGJVKwC0eTzO3RKNpOXz11VfY7XYuvPDCaNmIESPYd999mTNnDocffni0/G9/+xvPPfccAAsWLGC//fZjzJgxHHzwwWzZsiVp33fddRf33HMPubm5AIwePZozzjiD//73v4AK6XHTTTcxevRohg0bxvLlywH4+uuvGTlyJCNHjmTUqFFUVFQAcM899zBu3DiGDx/OTTfdBMA111zDqlWrGDlyJFdeeeUOz7W27S+88EJWr17NtGnTuO2223j33Xe58sorGTlyJKtWrWrMJU0pbc79UIZDAHh/X9zMLdFoGsfN7y1h6ebylO5zcJdMbpo+pM71v//+O2PGjGnQPoPBIJdccgnvvPMOeXl5vPbaa1x//fU888wzCfWWLFmStO+xY8fy/PPPR5dzc3P55ZdfePTRR7n33nt56qmnuPfee/nvf//LxIkTqaysxOVy8emnn7JixQrmzp2LlJIZM2bwzTffcOedd/L777+zcOHCHba5ru0fe+wxPv74Y7766ityc3NZsWIFhx9+OMcee2yDrsmuIiVCLoT4O3AuIIHFwFlSyj1y5oKs9gJQ8dHH8MADzdwajab18scff/D7779z0EEHARAOh+ncuXOj9nX00UcDMGbMGN566y0AJk6cyOWXX84pp5zC0UcfTbdu3fj000/59NNPGTVqFACVlZWsWLGCHj161Os4dW0/adKkRrV7d9FkIRdCdAUuBQZLKb1CiNeBE4HnmrrvXUG4sjL6WUqpXbo0LY4d9Zx3FUOGDGHWrFm1rrPZbBiGEV2O+D9LKRkyZAg//vjjDvc9ePBgFixYwJQpU6JlCxYsYMiQ2Hk6nU4ArFYroZB6q77mmms47LDD+PDDD5k4cSKffPIJUkquvfZaLrjggoRjrF27tl7nWdf2ezqpspHbALcQwgZ4gM0p2m/KMUw7GoBRntrXU42mtTJlyhT8fj9PPPFEtGzRokV8++239OzZk6VLl+L3+yktLeWLL74AYMCAARQUFESFPBgMsmTJkqR9X3XVVVx99dUUFRUBsHDhQp577jkuuuiiHbZp1apVDBs2jKuvvppx48axfPlyDj74YJ555hkqzQ7bpk2b2L59OxkZGVEb+o6oa/ua1Hd/u4sm98illJuEEPcC6wEv8KmU8tMmt2wXEa6MXfxwSQnWrKxmbI1G0zIQQvD2229z2WWXcdddd+FyucjPz+fBBx+ke/fuHH/88QwdOpRevXpFzRIOh4NZs2Zx6aWXUlZWRigU4rLLLkvoaQPMmDGDTZs2sffeeyOEICMjg5deemmnZpgHH3yQr776CovFwpAhQ5g2bRpOp5Nly5ax1157Acqt8KWXXqJPnz5MnDiRoUOHMm3aNO65555a9zl16tRat+/QoUNCvRNPPJHzzjuPhx9+mFmzZtGnT59GXddUIaSUTduBEDnAm8AJQCnwBjBLSvlSjXrnA+cD9OjRY8y6dbXGR9/lrDzwIMLl5Rjl5eS//hru4cObpR2aPZPJ5v85zdiG2li2bBmDBg1q7mZodiO13XMhxAIp5diadVNhWjkQWCOlLJBSBoG3gL1rVpJSPiGlHCulHJuXl5SpaLdhVFRgM49v6EhyGo2mFZAKIV8PTBBCeIQaOTwAWJaC/aYcKSXhykps7durZb+/mVuk0Wg0TafJQi6l/BmYBfyCcj20AE/scKNmQnq9EA5jMyce6B65RqNpDaTEj1xKeRNwUyr2tSspe/ddAGx5SsilXwfO0mg0LZ82NUV/679uBsDWSY2GS7/ukWs0mpZPmxLyCI5e+YA2rWg0mtZB2xTy7t0BkD492KnR1JfWHMa2JoceeiilpaU7rDN58mTmz5+fVL5w4UI+/PDDhjaxSbQpIbeZTv2Onj0BMHze5myORtNiaCthbKWUGIbBhx9+SHZ2dqOOpYV8F2NJTydj2iEImw3hcmFUVO58I41G06rD2K5du5YBAwZw+umnM3ToUDZs2EB+fj6FhYUA3HLLLQwYMIB99tmHk046iXvvvTe67RtvvMH48ePp378/3377LYFAgBtvvJHXXnuNkSNH8tprrzXputeXNhXGVgaDCLsdAGt2NuGysmZukUbTCD66BramOAxzp2Ew7c46V7f2MLYrVqzg+eefZ8KECQnl8+bN48033+S3334jGAwyevTohLaGQiHmzp3Lhx9+yM0338znn3/Ov//9b+bPn89//vOfBl2vptC2hXwnNjCNRtN4WlIY2549eyaJOMD333/PEUccgcvlwuVyMX369DrbVd8Ii7sCLeQaTUtjBz3nXUVrD2Oblpa2w/V1UVu7moM2ZSOXwSDCZgp5ZibhCh3GVqOpD20ljG1NJk6cyHvvvYfP56OyspL3339/p9s0R4jbNtsjt6SnR/N3ajSaHdNWwtjWZNy4ccyYMYPhw4fTsWNHhg0bRtZOQl/vv//+3HnnnYwcOZJrr72WE044oV7HagpNDmPbGMaOHStr87/c1SwbOoz2Z59Nh8v/ztbbbqds9mwGzJu729uh2XOZbP6f04xtqA0dxrb5qKysJD09nerqaiZNmsQTTzzB6NGjd/lxGxLGts30yKWUEArF9cjTMKqqdLo3jUazQ84//3yWLl2Kz+fjjDPO2C0i3lDajJATDAIwa/lLPPr843xkPxcMA+n1IjyeZm6cRqPZU/nf//7X3E3YKW1msNMIKCHfYKhBiLkb1Myr+GTMGo1G0xJpM0IuAyquSiDyDuJUYwPhktLmaZBGo9GkiLYj5KZva0CZyPnNpTxWwsVFzdUkjUajSQltRsgNX2KP/CeHmp4fKtRCrtFoWjZtRsgjppWgKeQVbvVfz+7UaOrHrgxjuyt58MEHqa6urnXdt99+y5AhQxg5ciReb8Oioa5du3aPGQhtO0IeMa2YQu4zTSzxoWyLnnmWsvd2PnNL0zjeW/UeH6/9uLmboWkEuzKM7a5mR0L+8ssvc+2117Jw4ULcbneD9tvqhFwIkS2EmCWEWC6EWCaE2CsV+00lhpmfM9IjD9pACjMhMxAqKWH73XezuUaIS03quO6767jya319WyK7Mozt2rVrmTJlCsOHD+eAAw5g/fr1AJx55plceuml7L333vTu3Tsa62XLli1MmjSJkSNHMnToUL799lsAPv30U/baay9Gjx7NcccdR2VlJQ8//DCbN29m//33Z//990847lNPPcXrr7/OP//5T0455RSklFx55ZUMHTqUYcOGRUPQ1lV+zTXX8O233zJy5EgeeOCBFF3pxpEqP/KHgI+llMcKIRzAHueYHcnPGbCZk3+EwG8Dw6vKQ3E9i/ip/JrUc9fcu9i7y97s223f5m5Ki+SuuXexvHh5Svc5sN1Arh5/dZ3rd2UY20suuYQzzjiDM844g2eeeYZLL72U2bNnA0q0IwknZsyYwbHHHsv//vc/Dj74YK6//nrC4TDV1dUUFhZy66238vnnn5OWlsZdd93F/fffz4033sj999/PV199FY13HuHcc8/lu+++4/DDD+fYY4/lzTffZOHChfz2228UFhYybtw4Jk2axA8//FBr+Z133sm9995br/gru5omC7kQIguYBJwJIKUMAHtcenqjhmkFwG8Ho1INesbbysNlZdhq3HRN06gIxIIIvbTsJV5a9hKLz0hxTG3NHkV9w9j++OOP0dC0p512GldddVV03ZFHHonFYmHw4MFRM864ceM4++yzCQaDHHnkkYwcOZKvv/6apUuXMnHiRAACgUA03kp9+e677zjppJOwWq107NiR/fbbj3nz5tVZnpmZ2ajrsitIRY+8F1AAPCuEGAEsAGZKKRMiUgkhzgfOB3YaG3hXIE3TSsAGJxbBq+2VkMutarCm7O23o3XDJSVayFPMzT/e3NxNaDXsqOe8q9iVYWx3RCRMbGR/AJMmTeKbb77hgw8+4Mwzz+Tyyy8nJyeHgw46iFdeeaXRx2rJpMJGbgNGA/8npRwFVAHX1KwkpXxCSjlWSjk2Ly8vBYdtGBHTStAqmerNACBkhWBhCQBl77wbrVv4+BPJO9A0ic2Vm5u7CZomsCvD2O699968+uqrgBp83HffHZvc1q1bR8eOHTnvvPM499xz+eWXX5gwYQLff/89K1euBKCqqirqUVPfsLL77rsvr732GuFwmIKCAr755hvGjx9fZ3lzhKuti1QI+UZgo5TyZ3N5FkrY9ygifuQZFgObNZ0xXh8dS6B62SZkINESVL4H2LxaG0EjmFTWHJE3NY0jEsb2888/p0+fPgwZMoRrr72WTp06JYSxPf7445PC2F599dWMGDGCkSNH8sMPPyTt+5FHHuHZZ59l+PDhvPjiizz00EM7bMucOXMYMWIEo0aN4rXXXmPmzJnk5eXx3HPPcdJJJzF8+HD22muvaG7P888/n0MOOSRpsLMmRx11FMOHD2fEiBFMmTKFu+++m06dOtVZPnz4cKxWKyNGjGj2wc6UhLEVQnwLnCul/EMI8S8gTUpZp3tCc4SxLXr6Gbbfcw93/C3MWWUD+S19IY7v09l/kaTvV1+yevoMso46ilBBARUff8zAZUt1VMQUcvjbh7OufF1C2bnDzmXm6JnN1KLamWz+n9OMbagNHca27dGQMLap8iO/BHhZCLEIGAncnqL9pgzDNK04hOR9ORGnlMzrp4Q6uHUrRmUltnY5uAYPBmJ+55rU4LElOzI9vfjpZmiJRtP6SIn7oZRyIZD0lNiTkD4/YQtYLBb+ev5FHPZ8AUM8anJK2bvKPm5JS0fY1SUJV1RgaeAEAU3dZDmzaOdqR7Yzm9VlqwGQaNOKRpMK2s7MTr+foBWs0kLfDhlkOD2UmflWS19RAy2WNA+WdDUQqtPApZagEaR3Vm9emPYCfbL6NHdzNJpWRZsRcsPvI2gHi1Q9bofVERXyCBa3G0tGuqpfuWeMRrcWgkYQh9VBljOLwe0HN3dzNJpWRZsRcukPELSCBSsAbqsHvyNxMPO6+f8m5HEAyrSiSR3BcBC7Rc2WvWLsFdFy7bmi0TSdNiTkPgI2sJrDAh5bcibsAirYGC4GwKjQmYNSSdCICXl7d3v+MfYfAFQE9QNTo2kqbUbIDZ8fvx1sppCn27MBePLg2CXw2wUbMYVcm1ZSSsgIRYUcINOhpjdXBvQDs6XQGsPY7mhdS6LNCLn0+wnYwGZRQp7pyAagOCNWp8oFFXY11Tise+QpIxgOsrZ8LVaLNVrmsSt3xOpgy/8RtQVaaxhbLeQtDMPnw28TOISygec48nBVdabaGbOTb20neHn9m0gBRkV5czW11fH80ucB+HTtp9GyiF95VUh7B7UEWmMY29rWvfLKKwwbNoyhQ4dy9dWxmDbp6elcf/31jBgxggkTJkQfYKtWrWLChAkMGzaMG264gfR05SzR1GvSUFIVxnaPJ+TzErCB06aEPN1pw7L5SIpzH02ot7piLSVp4Nm8gd0fEaZ1Uh5QD8WAEQuFkGZXLkNVQS3kDWXr7bfjX5baMLbOQQPpdN11da5vjWFsL7300oR1mzdv5uqrr2bBggXk5OQwdepUZs+ezZFHHklVVRUTJkzgtttu46qrruLJJ5/khhtuYObMmcycOZOTTjqJxx57LGXXpKG0GSEP+3wEbWC3KCH3OG0UhLoTTE+uW5QBtjVLyN+9TWy11DarM2Ja8QYbll5L03JoaWFs582bx+TJk4kE9TvllFP45ptvOPLII3E4HNEe9pgxY/jss8+ibY88dE4++WT+8Y9/pOSaNJQ2JeSBLHBYVVjMdKcVAws/btrAxqw8ci7+J8h7ASjOEHQ0oyJqmk5tQp5mM3vk2rTSYHbUc95VtPUwtna7PRp7yWq1EgqFdlh/V16T2mgzNnLp8xGwg90Uco9DPcNuC5xBn2kFtDvmsGjdSjfYKnWslVRhtypvlcndJkfLMp3Ka6XUV9oMLdI0lNYaxjZ+3fjx4/n6668pLCwkHA7zyiuvsN9+++2wLRMmTODNN98EiJ4D0ORr0lDajJBjTtF32FT8lNx0ZWKpkmr5+yVrolWrnWCv3uOSHLVYgmEVwvaWYRfCv7Lgz0/IdGTisDgo9BY2c+s09aG1hrGNX9e5c2fuvPNO9t9/f0aMGMGYMWM44ogjdtiWBx98kPvvv5/hw4ezcuVKsrLU/JSmXpOGkpIwtg2lOcLYLhkxgg9GBOk840BOO/Zh5q8t5tjHfuQQy1weczzIIf472TRQDXxeuqgL+3ywngGLfsPicOzWdrZGnlr8FA/98hDzRl2P660LYPARcPwLjH95PN6Ql0WnL9pjQgZPNv/PacY21IYOY7tnUl1djdvtRgjBq6++yiuvvMI777yTkn03RxjbPR4RChGygsPuAmBoV/XkrEItP+e4i67hk5mcfTm2rGwAjLKyZmlrayMQVm83jojJ0JwYNKT9EICUJxLWaHYXCxYsYOTIkQwfPpxHH32U++67r1na0SaEXEqJCBuELOByqEE2l93K02eMZY3sBEAnUULuSsF7P3agfQeVU7S0cBMvLHmBxbOfJVRc3Gztb+kEwgFswoYlkiXItJlfM15lBNxYubG5mqbRNIl9992X3377jUWLFvHNN9/Qt2/fZmlHmxByzBFmwyJw22MhD112KxtlzFv8JccdtKMcW0ZHQAn5I9/fje2au9n414t2b5tbEQEjgMPqgCXKxQxzdq3bHK/whrQLYn3QAcbaDg29121CyGU4DKhky25XzHHcYbMAgin+e6NlLgIsr1BTySuKtuA0O5GBDRt2W3tbG4GwKeSV280S9SWNCLkvpD2EdobL5aKoqEiLeRtASklRUREul6ve27QJP3Jp9sjDFvA4Y0Je4VMqvVp2iZa5RIAyiwrAUla0GZcp5MLWJi7VLsEf9ish95lxOfzK3Ssi5EXeouZqWouhW7dubNy4kYKCguZuimY34HK56NatW73rp0ydhBBWYD6wSUp5+M7q705kUKlx2JLYI9+rdy6HDOnE+F7tuO6jc7jd/jTZ9jDFIgeA9397DVc35U2hhbzxVAer1ZR8bykAVeUlhKqDpJk9jkd/e5RJ3SYxJHdIM7Zyz8Zut9OrV6/mboZmDyWVppWZwLIU7i91mD3ykBVccULudlh57LQxnL1PLw7aS8WR6NfeTknYHBANEO2Rh617hntcS6QqVEWazQMB1RP/c/1mjn3sh2gkSoA/S/b8cKgazZ5KSoRcCNENOAx4KhX7SzXxphW3K63WOvsPUZ4q7R0GxX43BuAMSlwBZZM0NmzaLW1taUgpoxN+6qI6WE2aNTbVur/YwMbthUy+56toWbqjlqA3Go2mXqSqR/4gcBVg1FVBCHG+EGK+EGL+7rbzxQu5zVG7kGNX9tocR5jSagjYwRlUvfIIesAzmScXP8nol0bXmSCiKljFr9t/pcrsjYeFjTTh53nHXawtisWBtrSNcXeNZpfQ5F+PEOJwYLuUcsGO6kkpn5BSjpVSjo1EF9tdyGDMtGK11yHkNmWvzXGEKa4O4LMrs8oVb9f5bNIAry5X8SUqg7UL+febvgfg99IVAGwzVIyV8ZY/6EAJvq1qOMUX1p4rGk1jSUU3aCIwQwixFngVmCKEeCkF+00d4YgfOVgdyZH4gGiPPNsexhc08Dlgr2WJrl4yoOOvxDPrz1kUeNXbVV3mlcjU+wH2HkgDCmR2dN3TjnsIVQwFlGeLRqNpHE0WcinltVLKblLKfOBE4Esp5alNblkKiZhWQhaw2euwxZrR+HIs6nW/Uymk1+gkGj7da4zn5h9vjn6uq0dd6i8F4ML/lrD89S6sLu4YXdfbUQZSDXhqX3KNpvG0CcNkvI3carXXXsnTDhBkUXfSZenXvcZ4hrYfGv1clxCX+VW8mq5FKr67Y0HsrcZqtSKluh+6R67RNJ6UCrmUcs6e5kMOMRt52EpCAuAELFZw59DJpmy9f590SfJ+dI8cgNf/eJ3hzw9P6IXX1SPfWrUVtzU2LlFmT+eswJUABDwdwVA98vsX3M+WyqbnLtRo2iJtpEeu7LchC1hFHUIO4GlPeqgUgOXtekaLvz5hAACGr+30Gr0hL6tLV9e67p559yCRbKveRq8sNUmlrh752vK1tHd2oyrTjDrZKZ0JvUYR6rgPWB1A7H5MfXNqak9Co2kjtAkhj0wIkhawiB2cclouVBdx6LBOCcXF/buq7f1tp0d+1TdXccQ7RxBY+13iinAQaZpBKgIVdE5T+QYjphEpJR+v/ZhAOICUkuXFy8m29cBuvhXZF/3KpPv+wdoXN+EImkmZiyfsprPSaFonbWLeeWSQMmjfyexMT3soXs3FR/blw8VbuWTyZQwsXkdxQRlH0bYGO+dsmANA0Ysz6Hz0MzDkSLVi869ghMGiHoinDDqFHzb/gDfk5d5599Le3Z77F9wPwDH9jqHMX0bncFesoXDC/oPFfhxm6AQZytwdp6TRtFrahpB7VZjU0M7O1tMeNswlzcznuTK7Gyuzu9GLbwGo3rqJ7F3Yzj2RqT26srgklgavqnIrfkvsrWZsR5WsZF35Op5f+nzCtm+uULkMf1vtxxJKjtpn8ZUAEmk4k9ZpNJr60yaEPDJIGbTVo0fuLSbNkWhHN1yZlHnAuX79rmrino2UsPILWPM1t5Ukzvvy2D3kunN5fNHjdW7ercSLkJDeN53KlXETh4wQ6XipqhgCnd7bVa3XaFo9bcJGbnhNIXfs5HSdGWCEyHPDv6YPjhZbhZ1t2RBqQ1P0c5w50c9hIwQvHQ3fP8SW4uTgVvFuiLXRs7wKgLypvRDOxN73mDyQoWz62I8B4Kh3jmL2ytlNbL1G07ZoG0JerYQkZN/J6UYCNwWqGNYtK1rsC1jYli0Ib2rF7nELnoNydX4hI0SpvxS36eHjk6FoNWeNxAaD/vkxpw85PWl3g9rFksZmVqmBUFuHvNjsWHPG52NH9yTDZcMRVrGXV5au5J/f/zM156TRtBHahJAHy9VklLB9B66HAJHp+4FKqgOxwbmC8hAF2cC2gtaZoaV0Pbw3E2adBcAFn12ARNLdph5s3i0Lo1UdcedvBLLxBsNs3NKJsC82Y9NusbNfZv/oco7XB0JibZerzDSAJU2FRHAHS3HaLMxd0mGXnZ5G09ppE0IeKishZJMISx2zOiNEIiMGqpjQuz1n7p3PLUcMwTDs+O0CDAOCOw7Z2iIpWqn+l6oxgLlb5wLQxZzIU73qi2jVNFOIe1s8+DedDEj+/toiqtfMpLN9FABBI0iH+c9Et+ngrcTmMhDpudEyi8d8aFZuo7AyAFjJz+i3K85Oo2n1tAkhD1eWEbKBRexkbDfOtGK3WvjXjCH0aJ8G0krA3NRojYGzyjebHxIHgztaldh6LbFyu5R4DIPZq5azkmu40/akucbC4LTp0Xq54VjUyDxfBTZ3GDy5dH9ahawPbS+keHV72DgvWu/Efuek8KQ0mrZDmxByo7yEkB0s9e6Rxzwr0hwqHkhEyFtlvJWAGkOgxmSpTjYl5FXCAlNvhYt+4u2MdKotlqjkn2ibE62fbsuOfs6L8xtv5yvH5jLUzNmJE8k66igAtv/igpWfc8tUlTM1LW77VmnC0mh2EW1CyKkoJmgDm62OWOQR4kwrETyWAAeLXwlGhLw1Tgry1x4orL1V2bFLrBbm5R1DVfaOc0Zm2mNx5nPDSshFWNCuuhybJwxp7dVKQ62ThoTyTRzzixos7e6JmVaCRis0YWk0u4g2IeTSW4XfDg6ra8cV40wrEbrNu4MrrG8TNMdJDX8rNK1EzjccgF9joeQnhNVJl1gtHPf0r/x91o8AnNp9KtSSoKODUcXVRSXcVlBEbjhM+6Cg49IDcQWDeHIDyk8fkBGzi/nPUxnxz7dzXP/jAB0NUaNpCK1SyGUgQMEj/4nO6JT+AAGbwGF17HjDWkwrjuqtOKSMmVYCrVBgIkIerIYvb8NtGJxeVk6731T2n5tzlQB/+edaAIb3OhC6jEzazbQlV3FqeQUzKquwATetyyatROVCtXuUjRxQg8a1EAob9MtRvfJFBYtSc24aTRugVQp56duzKfzvfyn8v8cAkIEQPrvAad3JVPBaTCs2DFxSxkwrrdlGHqhEOjz4hMBlSJxxZmpnhw+xOrcCkOXIIlzLwHFO1aqEZSdBPEFlirK4bNHrK2sIedClHhTBsIzm/rzw8wubfl4aTRuhVQo5UglF0RNPqMVACJ8d3PadCLk94kceE3KrgEzDiAq50RqF3K+iECINykM+pBBkmWJ7Wpla52j/DY4u/wMg05nJD5uSbdihuJC0f6aNZVgnFx4zvK0lMzs6CSj7qCNVJZsNxl+AMJS5KmgYFPuKU312dRIqLiZcUXciEY2mpdAqhVy4YrZwKSUEw/jsAo99JzZyi1WJeZxpRcgwLikxbErJgxs27pI2NyvVMfEsqN4GQJ45WFltSf6KZDoy2eBNvpbl4TivIJuLjIJfmBpW7oWWrNiU//T99iP7uOOw5eSAKxNrsAqQhMKSruldU3FG9WLF3hNZecCBu+14Gs2uonUKuS0mKEZVNYZfUuUEz8565KAGPCNeHFLCmq8BKGqvtvUuXJjq5jY/VQXQRU3mWWNXD6yI18lvlh5J1TMdmXxqjI0uL/qXSghRIjMAODVwLRbzHkwxFgJgzc5L2IfF4yFUUMCaez4Dw8CDn2DY4ORBJ0frbKzY9Q9No7x8lx9Do9nVNFnIhRDdhRBfCSGWCiGWCCFmpqJh9aEuX+N4O3aoYDsyICl316NHDpDeESpVr5QFz4FhxhlxOCjt4MGoqqxz0xZLVQF0Gg7Adx43NgQDTe+cXt6OSdWXbw4yxxjJPKM/BRmDyHTZOeUvPbBg8HF4HN8Zw3Chtg8HLGCViIzchH0Et6tr7FuzHQzIoJpg2MAiLDxxkDKJrStft8tOWaNpTaSiRx4CrpBSDgYmABcLIQbvZJsm8+Dnf9Lr2g8JG8liHu9Z4l+1EhCUu9n5YCdARif482P442NY+2202GNY8TnAqPamovnNQ8U2WPR6Ylk4BN4SyFCZfsotFvLtWWREpuIHeuDdfAz+7bE0bGc/p0LZFsos8iqWgZTcdtQwOrjBh+qJW62qZx8OWLA5DHBlxR+V0PaC6GcjLEgXXkJhdcz8zHwAtlTtuiBlrXKsQ9NmaXI8cinlFmCL+blCCLEM6Aosbeq+d8ST36h8ksu2lDO0a6JI+P74I/q5YrlqRrkbcusj5O37wsrP4JUTEorTwxKfTUZdGlsks86Gdd9B/r6QqYQbbzEgVZo7oFoIPHE+4tXSRqh8nFoQYXp228CKQGK2H9Z9D0aY9GABPtkXAJtNDXyGAwKr0wC7O2GT7KOPwrtAPRDWf9WeKb0WEAwfAoDLpt6cdpUv+dbbbsc1oP/OK2o0LYSU2siFEPnAKODnWtadL4SYL4SYX1BQkLRtQ6kyxaSgQv3Yvb8vYdnAQVT99DOlr74Wredbp7LbVLsk7hpiUisH3Bg1M8STHQ5SbTNatpBXmD3c0jiTRZV5L0whr7JY8DhjqdcqQqqHfcDADgQKD2LFwrOj6/4TUlPtee4weGEGdsOP3+yRFw06DYCw34LVYYAt0ayVfcwxdLnnHgB8JQ6O/uUb5q9TUSojb06BcOLkKykl98+/nyVFSxp1+pF9lLz4Iltu0KFyNa2HlAm5ECIdeBO4TEqZNIIkpXxCSjlWSjk2Ly8veQf15NMlW7nxnd+jy/6QcpOr+v57ANafeWZCff9WZYsNWiFtZ1P0QYWyPeCmpOJ2IR+V1hBGdXUjW97MhINQbPp5l8ZlOqoqJACM/+U23h58ANUWgccRE/JtPitnTczn5iOGJO1y6NCRSWUBU8hl3wPhxmLCgdqFHMDiSXywzlqgBjcjE7dq9sjf+PMNnl3yLP+Y84+dnm5dyNYY9EzT5klJqjchhB0l4i9LKd9KxT7r4vwXE1ONBczp3rbc3KS6QWHF2F6IE1PIa5lWXis17LkA/fwhvHYDf3lZg9u8R1C+KfZ5+7LY50AVxVYrXsPPjd4VdM3JJy3uzeVbYxgzM104bMnPfJ8l+Q3HgxLfTLcdLFbCMgOrsyjq2x+PxZ24fXtZygs/rmVk92wswpLUI7/lp1vUMSL+/o3AqKraeSWNpoWRCq8VATwNLJNS3t/0JjWMgNkjl0ai3fbpIYdR7vRAiRLekE00Scj7Brz47S10sPPPT+DdS2PL390Pyz9ESknFDwsoi/salAcr8Lhzodck/p5+N15cnDSuBw5r8ldFkpwD9TebSvuW4bIhpSRc5Vc98lqCYNUccJxruZgb31nCjP98j9PqTBByQxoI83hWsZMEITugIUJe8trrVP/yS6OPpdHsLlJhWpkInAZMEUIsNP8OTcF+60VUyL2JUQkr7S66OItxVigrT8jSgJ5cvJBn92Bu3jFkSD9+OwhfC3w1/9/xUX/4KF/dTuUn77Px7v/hWxp7wFUEKhjRcTSc8R6/MYBDh3Uiy2OvtUc+snt2bGHAYXDOZ5xz4ZVcekA/Mpw2jKpqMKQa7AwnX7e0vfYi89Bp0eVwwMKNthdIw4tA8PzS56NT9iuDlUiUV8umyk1J+/ppy0/18jtviJBvvekm1p18Sr3razTNRZOFXEr5nZRSSCmHSylHmn8fpqJxNflzW/J06oAZ97rmIGTAblcCIlUvLmgDj62eQp4el3bsrI8J29PJMLz47GDxB5JihbRIti1m+ztqwG+TPzGYWP+c/jz8xQpWF1bROUuZP+y19MjPmpgfW+gxAbqPZ0CnDC4/qD9CCIyyUgDVIw+Hkra3uFx0vf9+uv7zEkC5IZ5t+5jLbbOoDqmxiBeXvgioBwxA76zelAfKowIf4bxPz2PG7Bk7Pe3ahHxn4h76bLe/aO6RSCkJbt6884qa3U6Lmtn50k/JE0QiNnLDlyjkQYdNCXlk2crOox9GEAKOeBSOfRayuiId6bgx8DvUQ6HFxiTPG5iwuMFXCsCfrsSEGx09Hbn/sz8BorlLbZZEM8oHl+6DEAJspp17r78lHS5cqQTSYpexfKi1INKzAZBhdYxzbB9F10XMYREh75WlYqKX+EqidQzT/l6fGOYR0e586y10vlXZ3IM/vx3NJRrhnV//F/1c8sR9O91vXSwpWsL68vU7r9gCKHnxJVZOOQDfn382d1M0NWhRQh4MJ/eEo6aVGrbrQ90LVHoxk5AVbJYGjO2OOgWGHq0+OzOwI/GbetfiXBBzTZ/pfS5PKLaYl9MRAhmIxULJcmZhNYX79L16AijRNhnRPZshXUzz05Ur4JoNUEtMlohoWsafBvteUWfzLGlqar8RTra5R8xhEeHult4NgPJgzDHKG6rf/VhRsoKthWsBcI8YgSM/H4DAq5fD5l8T6tovuyX6eZVRzw5ALZz4/okc9vZhALyw5AXeXvF2o/fV3FTPU7lcA2vXNm9DNEm0KCEPhGK9pqk9baThjQq5UaOXfIxrjkovZhKyquzujcHqSscuwddShdyRBn0PhBGJk5ys5uXZf5HEX7RftFwIgcdh5cy98xnUOZOaPHvmuNiCMwNcyXWAaDgDy/hTkiYExSPaKXGWtQi5z4yeeOU3VwKxHnm8aSXSW98ZR797NA9/d5dqk8eDa/BghEXi3e5ICJQG0Gtb7PMS6dphb3/629MZ/eLoJBt9zQfMPfPv4cYfbqxzPxVffsXmG26o17k0CxZzkDkc3nG95mbLIqjc3tyt2K20KCEPxdmmn9h2PF84r8QfMa14qxO8KKx2I6FHHmxojzwOmysTu4zrkbc0X/JAdSxEr8lTWZmUxoWdDVXF0qwZhqTSHyLTlXy9hnbNpF1a/XqokR65NT19h/UsLjUBKL5Hvv96FcTLF1ZCXuZX3kf5WflAoni/vbL+vVyXOeZqCRZj8XiwuiQhvxW2LoZiNVu45oM6rwTmbplb6/5WlKxgbflagkaQ0z5Sk6DWnXoahY89xpbKukMMhA3JxpLE79HGiy6ibNabyD1UKIU5TiJDyeMdexSP7wuPTmjuVlDoLWTOhjnR5YIKP899v4YNxanXjxYl5AcOSgzg1EkUU1qlekrS68XrjnlfWJ0yoUcetDW+R273KCH3mfol92Qhr9gKTx4A2+JmPwarY2nsgEoheKhdNr/ZYiELhD8bgB5pA6gKhJASMmrYzn+7aSpv/XViQlm4ooJwLREEg5s2ESosAsCStmO3T+FSvfUNwdhEsYfC7wCqR37F679Fy7cVq7pry9dGy55Y9MQO9x+POyLkz+wD25YgrBIZBj65Dh5WDw//ypVJ26wqXUVtXPplzK2z0FsIQPX8+RQ8+BAl/pJatwG44MUF7HPXV3y3ojBp3Zbrrqv3+exWIvFzUhwxsvyTTwluT3EPurootftrAL4//2TF5P05+aXDuOTLSwiGlUatL67iX+8tZXVh6ucytCghP3x4Z7KoZOqgmFfJD6vVD8Hw+qg2Zw86MtWFs7nieuS2xvfIHZ5MbIDXqXqMkUG8PZKfH4dN82HxrFhZoDJhsLHU7Fm549y4XeEAFctuZf/MW9hapnrB7dPVk6viyy8JlZSQ5U52Q1wxcR/+HP+X2L7fnk3h40+w8oAD2XbrrcDOhTzSI3/cfzgXBC4DQABC2vCGvLz5ywYAjul7HBc9rwT1oV8eImzOHRjZTj1ccp1ddnxtAHdAgkUiLMDKz7FYDKSRaNKp6ZVkC8Prf7zG6R+dnrS/sIx9x7qld0vwgCk1B5Nrsr3Cx+fLlO3m5zUxwRHmBKmyd97d6XnsDCkla5ogGLXNgBVS/a6MstRNijN8PjbNnMn6s8/eeeV67bD5PcqKn3mW0NatDFiuzHURs5w3oNrmcTR+HkRdtCghF7+/yW+u83m0xxdUC8Et7XMo85VjGJJQdTVb3dk8NuwIeuynEiXY09SPbNawARgW0egeuTMtCwH4TCE3KvfkrDLmOIKIu7XxppXT32FRD+Wm5477rXpCfsDGym3VLN6kfqhDs614Fy9m40UXs+nviQOl0aPF/eBlIMCWa6+l4IEHEursvEduTt8PwyKjT2x/IsQLS18AoX4I6bY8wAKVKhaOb/2PLClcwvxC5SNf6i+hwrdjzxWXHwIRy9BnNyIskoqNbrZX2JncvStVZpKLeOxhWFexnl+3/5oUOjnedt4rqxdrToiNQ8T3yMNxE9bWFsd64evjX7Mzd2yCagj/fOd39r93DptLGz6eUzV3LsuHj6Dyu+8TyuUGNSBc8sqLjW5XcMsW1p1+BqESdW0iZqzAqtWN3mcC39xTr2rexb+z6cqr2HLzzfiWpji+nznwL8yvSkgqU5Q3qL4DbnsbF3J+eQEA29d3cFWHXF7PzMCa/jH/fn8pv6/aRpWw806ffaMCLif9jWlH3ssLYwep7RrZI/ekKw+NgNOM6LcnpwcLmMIQiakeDkHYHzOt9J7M59kqyqAnvkceUoJcHQyz3QxEZrv+CtYedzwAwfU7dqEzAgFKZs1KXmGxIGw7vu7WDOW1kh70UkHyoKiwmT2boOq524PKnv/d68dy4gcnRuuF8DLytteTtgcImXHlXUEw7HFibHbGt3+WS5HNytaqrUm9OlucyToi3IbfT/H//kc4FBNyX9hHYGXMBPPavKcBNX8hYusHeGTRndHP28tjN6Hcmbre5Ovz1MDrxhIvc/7Yzp0fLU/y+lq8sYx1RVWs3F5BdSBm9170+vsAVC5KTIAd9qrvSKiglFBREVLKqCDXl6Inn6J67lzK31PHMKrM72sduQUazJzbd7haSsmw54fx5zmnU/7ee5S+8irbH3ooNceOYHp8nf2pgZAyalqJXGPXLhDylMRa2W2cNhv+rdzkvjYDLrlEBc/9sJa9wwF8Ngd9O6SDacKz9VSv/EKoX2Jje+Q5OSo5sD/SI6/Yg5NLRLIbVahEyRSaIX0dHgq9hQgE6yuVKMf3yA9b8wPfdh2BN5BDSXUAh9WC/9c4l7w4MQ5u20b1/PlkTJ4cLQuXluKvzb+4Hq+6wm7HSEsny19FJW62ZI+mc+kvnFVazrPZmdgzVTtkWPXsy70W3Dnwj44xm7qUAiEkwlO7LdtrprNzB2Cby6LC9UoZ1Q+LqccWI0RNSbHHCXl1sBqH1cH2++6j5IUXmXHhCJ7PKaNvdl+6/bY1YbsOv65n+TAL1aFq3ln5TrR8YfHXgJrRWlwVuwkhT2zMYkvlFpw2J+1c7RL2WeYvI92ejtUSEwMpJdXz5uEZNy7qJup2WAl4Dd5ftJkXflTzL0qrA9x2cG+s6el4A2Gm/+e7hH1fMKk3f3NtIfv9NwB48ss/OenYSl5b/RAZ1aXMKNkKmJEp161n3cR9AOg75yvsnTolXfP6UDPI3a6mMmjOFDa8RK6sqCXURFMQ5tuwMwSdimOdCF+kR97WTStYLAQcAzGCsQtf2U71GpzhICGbg88u2wcsNhh+Igyazpl75+MyX6UbK+QOj3KvC9kFUuzhppU/PlD/I0L+1EHmCsH+r+/P5NcnUxJcC0BmtWSlGZb8yNXfcdmiN6kOhCmtCpLtsWPrGBtcFtbYl2/bnXey+Yp/UPjkk9Eyo6wsIXxwQzEys8gKVAGC3HOUkLQzvTeETV3vJz4yzUNG8n30bTwVAEfOjwnl64uqyb/mA2568zxAea14HfBKxIxh2seFFDx3fwhHWRlhe+LPIr5H/tZKFROu6huVdCREmKHth9LP1Z2TnlmTsJ3XAWM7qpR4d8y9o9bzLooT8jhXfaa+OZX9Xtsvoa4/7GefV/fhzrl3JpRXfPIp608/g9I33oiWZZgeRxERB5j32U/8OXYcpbNn8/StT+IKJca6efyb1VR+803svKsrufeTP3j1j1d5csPHGMHYdSmKu/dvfP5Sref28e9b+XL5NlaUrODI2Ufyw+Yfom80QSOIDIcJbqxHOr8VnxP4cykVj1+bOIgf4af/I/DHxwx7fhivZ+zYPBUZt5Bx19qS1vggbLUiEh8MMRu5Nq0AIMNhVr1QzqIfEyMd2tt9iysUwOrxIKqLVXq2rqMB+NeMIVwwWU1qaaxpBasNHw6c0krIbsXw7aHZZbwl4DMHogqWw0vHQrAqts7Eb1Tj8Um6FUCXTtV4hijf7DS7BW8gTEl1gByPA+GIuRkKW+zLF3EnLHrs8WjZ9geb9nqa1iGP/q4wP117APaMXDZ0PJAqQz1AHe1+Ir1a0rdUTQ+XNSbo5AZnEKpUYXat7o38WRyzt36+bBv7OL/hM1SZ2y/xOQSBDoO5q1025XE/AY8f3JUQDAVY0EdgmRKi/ZmnYAsRffV/YIGy/0cmxazZspQO1XbaVSb36tJ9cOGIC2s9X2FVPcPCSj8rtlUQKioie1ls+rswjxcyQnhDXqSUeIPKnvzqH68S/vAqAgtfxzAk4RL1tuH9dSHBTSoOjVFL5qy+pUo0t1xzLQe8/hDTV3+fVGeDMzv6OTNQzfLKrznqB4PX7whRHo59Byy22P7nLH42wWdeGgYbL53J0/e+yNnPzefX7b+yqmwVHyx+g8pX1cPmu03fUfrmmwnHDtc2iLphLrx8DKuOPJaND8xm0+lqctUt7y/l9GfmMv2R7+Dja6h47SRVntsueR9xFPvVtYo3K6b89xwn5I5QrEfuDaq30zYv5KFCNUjk3JzYI3N1/ABX2I/V44Yy05abGcvGHjJC2IQtYXZiQ/EJDxmGhZBNJOQE3aPwxf0QjKDKdBQhzmslKH3klqubb88M0f3mv5G2996EgmFWF1bxzYoCsj12jMo4E5I19hC0ZmcnHbpmUuruTz1F3t//Tt7f/16vptvbtyPfFqBTlhr4FO4s3MTszze/HOaROQ8C8NfRsVmoYz1dCRcfmLCvXzetjbXVIvittwr9k14t6bcFuhdKNnboy0tZmZSR+KMKWwQWA/wO8JxyITg8WIC9lseEK37As/dWyYU3zmP808nhhf76oUF+Zj6d0zonrfP0ij34fttYRvWnbySsj3gU/eOjsxj/8nheWvZSgp39iT9fwTH7PHpf9yHrzOKyt99m5QEHEioqotxXS2ybGqGEu7tgYt/2CWWf/hbrIXepKqDc/gwnfW3O1fBb8LZTvcpQcXG0Xk5lXBKQLb/he/5qKj79lL//qsYriqvV77bbD8uj2/y85WfKChPjtoSKihOWkRLeN78/5oOpfJ0yqT793Rq++bMgOjAfjPttb428Pa7/iTl/bGfEzZ+yvrAKfnyU0jLlAfVHV1XflpeLd/GilKX+C6xfT+lrsTdTR1D1yA2fD785HuCsJQBdU2lRQv76N/+Nfu61VfL07CrSvBJhSBxGGMPphG/uVRVyYxNcguEgdmvjzCoRvBY3WWFBwAaGfw+NtfLQCPV/0pWJ5e6chFgo1dYlZFWpH4bVZWDJ7Y6tcycs5nn5ggY5HkfCxCf/8uVRDxUZSPYMkab3QfqBBzBo+TLS95lI7gXnk3vB+fVqujUnm3DcwJndnUGFNWbT6G46evQwtnLIb1dHywP+cqr8IQbHzUC99ZeZBMNB/KEwN70bexU/eotq46b2giVVSkRCNTpHfiEREvw2sOUOIFSgDnzalzER/HZDLAHWjJ/Vdey8uva3Pet7X/Lv2zew7+9q+36bJJ2KJY8+WcK7Q30IARtLqhHfJ3pbXPy+qv9F4UIAvt7wdTSQGMASZ8yevvrnTxO2rS4pp9K/cyEPVVQkhSduZ4nVGViygZfvjd0DdwB8aep8qxfEBkI9fmX2eemndVQ9dhDB75VTQlpQfZ+e+kU9pFb6YwPmjhBU/pjo3RQuKyVoBDn5g5P5YdMPBP2VVG9fkjQOKl88mrWuk+kmYr7n3rhYQNHP3lLe+uADXrWfzCefXgefXMui9y8ClEeJJTdAqLiYcEEhxc+rNv+w6QdWl65GSsnWqq38URxLG1kfAmsSzWuOkCRkhFix32QOuupkPA4rFktqbfLQwoRcFMd6nMd/a5CxzMmURRJnRFfsAlZ8BlYntOsdrRs0go03q5h4LelkhQ38Non074GhbOOjC6YnTpz6etC/+OSPRO+CbLOzbXWFIS0Pi9tDBrF9hIJBpN9Pu7POipWVlAIgg8nnb1RXI1wuut5TP/evmtjatSNUUhLt7WZl5XBCRSmhyn5UrbkoWm9Wv6/JjBtAdVcWMCqwgH36JZrbNlRsYPmWxLGMLJ/a9zsTBKvK1KDorImJPwEBWCRkiDDvLZLRWYyGgFClykd6+Zz6vWUAFPzr32RVwyXvGRi+9tz2QpiHHw/ToQws99xMTu4qtpb5CPoTRXbUqkT16pjWkeKizWRUq/LcKoPNP2XTp2ojk8s+Sag7/f4vam2LtYaQp4X8CfMCLNJg/19UwLKwvXax+b5Tcofo6B8M/CE///lyJWnCHw214DBCdLB9g9+mHoYVcafkCkg21niIFD7yH0p8JSwuXMwFn1/AEbMO4oAeXSlYlJFQT6xS53eu9UNs5nfWF9cjL4/E/bHaGBH4leO7dubh4JdUCcETOcoDLbtKEnYApiePb+lSDGmo475zBIe/fTgHzTqIY987ttbrUCfmsT86WJl4nEEVmsEoK8MSDtG1KnkCWCpoUUKeHYh9ifJK1bfC5Zc4Tf1x2L3KpDDjEYjrgVcGK+ufVKIOSmx5ZIe9BKxyzzStxMf1iA/DCzzyYxEXxGVWuvCDMJeYPb6+tgB42mNxu3GG/Byy9if6lm7kx9/VK7a9U+yhIAPqvGUwiK1D4jFAuRHWzPpTX6zZORAMRifUuLI60MkI49pwHB5/bKJPzpYF5MVNYb+hsJinrHeQ5rAlmDBeWPoCtnCAk53PAjDuT4N931W92H5G7EH03dDEn4DFUEI+JuTj6QWllMd1HgIlewPQ0UwwvSMem5b803IuTXw7sfqDBHOfpLgqQDCg6m9qX0NApaRroSTdL0g79Dyefkid+9i5VsrWevjPZw9StS0xqXjElTSeiyb3MecKxMgTARzm2MfMA/oxvDDm8dNn/9pnWm7NSRZ4mwFPfLiA6kAIv7QRN0eKW76OTW7yxDXroF8lPX9SZjRXO7Wi6ocfCHpjbx0bwlVUWiwU/5E4gBmsslCxyYmDIG7Utv44Ia+YZAZo+/Sf/CUQe3ta4VCa4PZLehaAt2MIe5oSj9D27QlhH9ZX7CRi5XOHw4tHJxRtK/dRUqp6SGsdal+OEMzbOi9a54IfX97xfhtJixJya2VMrHqYD7ZTVvlwml8QYS/lmawMjMzEGX6VgUrS7U2bbFFi60COUY3fJlNmT0spwThzT40eeSmJ5z5lkXoICpcL6z8WgdWu8meGQsxcOIu7vvs/7pimJuYIT8y2HsmOJANBhD25ZxZqQlJta5YyjURnDWapQFozrD9y4byYb7hRshV33Lt2vtljHlH8Me8f9T6Vf9yClBaWbd8GZ5/MCbOUaeXKN2O90QG1JLmItsNQr925IkwZaZSYE6kyhCBcORgpLQxao342C/rW/YpcWEscseNXfJVcKCUT33sa7ya1r83t1JujYf4y910ieeDJMAfd+HFiO0XsGlRuTsyH6jYCfH75fhw1KjZOdNUhA0kLJk4OGpYBF+/fh0FZQc63f0S7QOyh5cyqfWJVtROCGcmxYH6duwBf0CCAPWGmbI8CcPsk7cLhaJwbgMy4pnSfFLON+8pr2MlJdjFf+V4nNn7bHidB3GZqQW+ckJdFOjLblzLQiNnlT+uiXCQjA51VadBragGuQQPx/vILxV8nDr7WxB8K8/Wf6ju+YMtctqyeQ2DNGjXzeetmDrj9Pa57XWWUKneqa+SoYeEaWLKecPzYU4poUUI+1NkrqSxcYqOdV/UqfnDO44F2OcwLJ8aCqAxWkumo5ZfVAMocHckwAgSsMin2+R5BfI/cmfgqWiCzo597b4n9KoTVisjpAYA1JzaA6An5GZmrPEMsHg/OQWpClTR7SzKohLzLvfeSe0lyHPLGYMlU9ycaxyNvAADn2T5gWFHMCyXienpVUQmPb431GicvvQGH1YE07Bjebiwt+w7L5k04wnDwgkSTwgCj7gexLazMK9Iq8OFg3qFnAOAulby3+HGE4eKcV1UArUpTP7d7shl4wmac2THxK/cki/wRq5XfthHnA+4IwfjFc/ButBOwST6YpO7d0u6Cv1QadCpW9yutKHG6fXAHjg+5VoNeHsEdRw9LKE8LJo7tyLVrGNAxg48OKCBtzo3ckq/mAfx8yjFY6th/lQv+doaDRfmCf50ck49bw09zmfgfIaxJUSzdAcgNhUnzSWrOKnh/nMDiiJUGyksT1lvDMtFXMI5xXdJ4sIe6phd3ir0hrqqOBSsrrWG+GbXS4L6P1Pe4yq5iMhmFqve9+P4dx52/86PlnPHMXOauWceZXTry2pqOrJp2KBsvupjVB0/hE+fV2M23xWpzzomzxvPQKg2qf/655q6bTIsScmtV8iBj2G/l8C3qF+U1vdJC7mzumXcPX67/ElCR8tIdTeuRlzs64pKSoE0Q3gMHOzcWqJ7MnPAIAu0HRctvCZ5CWVyPfPTKmJDHh/51jxqVsL+qk5Rt0Nm3H52uu1bVNwc0I0Kedfhh5F18cUrab81Utstwufl6mzcA6cxgjaUnWRkxc40RUj+Q08or2Ntb+32QRqKp4ZxPE+Ujl8QepTfOm9Fl/vACDjsgeOCHTXizVAXbqhXYROxNxOpVbz4+uwMhIHeoavvM861UJzYhgcqcmOikxZ3CtmzBKOcmFnVz4w5I9qv2kVlLfLa+BclCnj60knYDVU9v0uZF/Dl2LHLJYq6dNpD/nqxccT2hxOsVLitTA8zmJDJ3iRK00zxq8NSwJLswVrsEJRmCW0+ysrSnhSvOUQ3x+630z/wMv83LnzXma8xcVcGMyio6lkBhjXS47/3FQlXc23JNIe8bF0Byc07CKlzVJey9/RWCxLxWzvwcLB/+EK3zSE52wjbXvmHgWa1ujs8cB3C51et9sXPHs0uXbVGdjHNefAWAfnHjmmG/oKsowm66GpaaltzzPjEY94dBSRp8m9+VV867lfQpU3Z4nMbQooQ885CDeW3f5CZ3q1CBhyJPQSEELyx9gZlfzQRUj7ypppUKZ0dc0iBog/AemCHogmdUz+R/4Sn8443f8LvUrMcvs6uxZ/8EUnLaF2F6bo99WdP3i004cQ0YUOt+XQP6I9zKvJAg5HE+5v3nzSXvisvp+XLtE0PqQ8S0Uv7BB9Ey0WkE+8oFZFpjahYO7fwrK2XywPaaOGuTVSba8S/+a3L30xvnFRKyxvegY8cfkrGW5wYdwgt/USEPMrv52Hx2CVvaC6r9Ma+pmgSzYoo0ZXFs35vaC/avrsaf7WPAJhi0OMhf/kwWl+tfDhGo0eSn2mWyapgSkWHrlUdJ9YJfuGC/Pox84X6WjxxFtj/2Sr82Q12Q4OYtrL//fSo3OzFMTxdLtvrufHdK8ptnVY0HlNdc/tiRxt875nFQj6584la/tffGq9/joI89dAmF6FEg2dwusXddkiF4xxXbaaCshCHrDDqa7pMeX+z8F/RL3DajRClppNdtC0kOnRfigDdib3BvZaTTqVhy8Xth+mxOvJabXVZ+djnpNFaZlKQr8bt1zWthrn8tTIk50a3A8hkW52acNlXfqOVFwW0obaiKs3Zd+ZaBLQyV7TfTYcqWJrlB10VKhFwIcYgQ4g8hxEohxDWp2GdteMaNY8zMf0WXI+aAXkVmLANXbVupHnmGI6P2lfUk4MjGZaiY5Ia3lm5SM+MyB318OHj3t80s8it7YGGHBbg6zyYrUMX0uTJBGLrcfXfiPoYOTVhuf8EFgDKvgLKR+9esoXLOnATDpTUjg9zzzsMzZkyj2+/orbyMQkVx4UfN3o01FDOhyLhZve+G9wLAV2Jj+ZtdKHr6aXNN8g/FHmerPDJ8O8fkvErFsjvxbjyZ7QXnJdUvj/O739IjFgpg30Wx9vXvX8b8gYPwprmi7elk5pAtMobye34v8g8sgIzE9nTrlB39PGx1zHC8oougTyBIYa7aR9rcNLJrCWCY5oVgDRc2nx0WmNEqLebrfcTjpvz995E+HyPiBjN77q/idQcWfEHVsi1s+KYdBd+WAlCco8aY/tMtk5OusmI5qDS6XVWN31gk2UqVEXuy5Jar78bcATF5GV0UpGcBLO0Ra/e6Q9TJ3dUhLvz0R99w0/8MzvpKvUW1j3M8ctcY2jCKy3gsO5N/ZKtOyLi477ZPCKpMwTzqR4P9fpfc8Xzim9hXmW7O7dyRkFPizA6SViXpm60GstO8ktGrJSNWS7b+618sXF/CdvsbpPV+GIcp5PEWH08HPwW/pzNpiwq5XPONKcOnIrD+uvR12JbiIF2kQMiFEFbgv6jgEYOBk4QQg5u637qYPvQ4+s+fT+6ll9D1oQcBsJaqqxZ5nY3PHiOlpDJQ2WQhDzqycUuJ1wGyas8S8iWby3AJU8il+jE/4j80ut4aljjDiXbh3Iv+ijU90ZOnx7PP8FW3mIklz7R/W8y4Noa3msL/+z91nBRHjLM4nbjHjMGID0hm2v3DAQvuXHV+4dHnw9VreXf0U+SY93vNJx2QQdh+z730smwBKbCFEntf3R2dST/oIC6ccgWF1hxOnaDGBo4bdDg/X548+3KxuxfTRyhB2xBnfz3nMyUwC3sJci1hDulczX+OVan0ng9NJdufwQPrbATKxvP96BG4c4P0n5o48aXrLf8mc/p0jNwcBm+IlW/NgfaGwdo6ovEGzBcNrxPC5nT5m0+y8Pg0C5+MEXhNU4HNDNIkQ7UPWAJ0rVQBzgJzXjBLYqo0ueInit2mqcsq6BaMPQVrmowiMfpdcYeKDKb7416Mtr+jruGqzuDPUNcw1DW20QNHqvOp3qge2qMXWhCG5JRNsSfZ6zXexrcsyeS/Odn8kqnqdDI9bNflwX6hf3NDnprslFNHRI2IE9xKuwPhMnBVGfQzZ1/23pr4/bn47lhAuD5Zn9Nzm5pcFt1XwELh75kMKlDmqbAtuTMhBYQrtuySWOmp6JGPB1ZKKVdLKQPAq8ARKdhvnVjT08i76CJcA1Uy4ert6tsVsXWW+kujdZcWLyUkQ002rQQdGXgMlVxiT0ss8duGMroLNZpehDJRfGOMIN/3P7oWSl65O8x+WxJjkORdemnSfqwZGTww6vjociRqYcSlUHq92GtxO0wV1vR0wvFxbMacCUDYb4m6icm0HuDOYcaM4/jLYWdRwzWarxxX4DZEwhRsKSRyyxYsbhfrMjvTOy+Nvh0yeOmcv/CvGYPJTY+pkzMriDMryPeu4eSaPdzP3GPpuneiN0XEaeTS/sV0+enfAJSTRldRxIHGag6zzMUtVCOsdhkd0Ms67BDsa9+k6523Y+ucGGiqMt2BSO/Ims6CRfkxIajqrR5ixelQNtyL2w8T5qmf7pKegi9GWghbBV4bGAgs5tvSjjL5pGUqMakqrN2DYoOhHqLTKqv4Km1ktNxfw1npla1bMSwSV8D0hIoLDbCuI7jaJ3ajt7QT/HJcNf2P3pLgffSnOdOy/R9ro2Wvf+8jbbH67n05rCel6YniuMCT+FTxFKlOiNWA8k5f8bkZQ2VYLeETIBasuNhqocJtIasapqxRA9kDNyQK+VOf38+QdQZZlZJCq4W9lyV+8TbXMNfZbBb6HrGVtBGxe9B9u9mLz+5ea3uaQiqEvCsQ169go1mWgBDifCHEfCHE/IImuKnFY8lI7GVHegfvr34/WrakULmfNbVHbrc5cIbt6mHh9SfFpW5OVm6vZJzlD7bLbA6bPClanpvupIdpEz9s9by6Nk8gaLVTbUv8gUSE3Kj2RuNSdNwFuSUtGRmJkSXHno084lHCAQt2M23f9nvviwqUY9QJBM+tEWo1KHAZsSnuxekqIBZAxUcf89uNU/ngkn0B2KdfLk7Tj7rdGWewdMrReB1OrE6Dn4zYgPFvsi/Vgw5POI7VvP3Onx5ScW2Avt07UymV7WGkZSXZxHqTkfa3N16Az/4JC1/Cavb+litPS0rbu6ByO4dWVfFrn5j4ZGUpMfxgnIXS7FgbQhaZENcjaBEE42LiGOUVbPxbolfRik52CjPhhxwH0iZZ4Ktd5ALmfo+rqGS/9MW8OHAqBRm5GOHEDtGAYBCbVU3KO+2LMFeZbp4bckEKQadRMZdGwwKFWYIqh8DqkAlC7q9lvt6KVfkAfDzawhOTEscc/uySbKPOMH3xuxXB4JKVDNio9m+3JbrjrspSrzwVpvZ6hSDsCZFVBXmBMO8+W8WxvyY/BG/6n8GNr4TxC8E+qxPNNB3KEuu7wkHsboOl7phor+mkHrRk7DwBSkPZbYOdUsonpJRjpZRj8/Lydr5BPUgaNDCXf90eC7/qN00KTe2R260W7GEHXodASLlH9cqXby2nu6WQdbIjx47tES1Pc4rowy2vOiYqeZddtsP9nXrwP+n/80/RZeFwgM2G4fUSLi/D3q0b7U49JaXnAGDJSCdcVpbQk5Tp+UhDYI3zKFh50NRoXstwaWKgpfJ1bvqU9Ij2yJd3j31HZDBIlsdeaxjRjtdewzGP3kZ6j+EEOo7i7ANGkO6MqYulT+L4gaWWoFQ3HbcXr//lbYwOQ5hmnUu2iL1ddNunmOzJQ3FkmOcW8pPeRbXt/w61ctJVVra4KgHJhaXlXFYcm4nbOcvHuZda+WSshYG22EC7rYaSGQg8abGHcPmHH1DxeeIsz1cnh7noYhsXd+pAlZsE0048/r0vAcAuJXONgfxv4FT+ceRNVK26Es8fl3JtYTH/t3W7mglrk7i9bqbPlYwxvaL6Di7lDaMjrvZBNcMK2NZFXffIFPrsuIldNXv6AH23qABgzx5sx8ico67xKVZuOj6LSpcg3Ru7B39ZbjBlRayzcutLIW550RwrKCtN2O+NE87hnDOGUJSl2lFtsfBmngdnCNK3WPFtdSKqa/e/7F4IVRYL2cVx36sadV6d1hePOft4uUMJ+SejBG/sa2Ghywm2+uW8bQipEPJNQPy7QjezbI9gUYHqsfXM7Nmk/XicVjwha1QYw1W1jEI1E39uq6Cvo4RxI0bQo31skG5w6WpGm1O94z3JMqYeVHMXCXjtLqxZiX5iFrcbw1tNYOUqbCl6ENfEM3o0Rnk5Rc88Gy0Loo5lm3xutCy0ZQu+ZaoXHK6R2EBKeMnyGA9tVC5l3w6J/eCyjz+enWJ14HCnc/lB/enfMfYWlzZ8PLlDy8k85WBAXU9/Tv+ETTvl5nL2oXtj6T+VjpSQQ+ztwpERpvOwDbHETUaYDu2+YuYFFra0F4StsXYKIKdTzDbk7TKEjhtPw1j2T7zuxCBXDhH3sEFSHHfMsBlSIZ5AnO02YK/7rbK8mxq4tkvJpcG/cebe+SpFmeFi/LCxfFb0V0rlgbDP5RhdBuAsyk/Yvmeel4FVZQgBfQ9Tdu+iPNUFbmdOi+9nxuwxAu0I7iCChoxzF13WQ7CsTxVVbhVdEqBjieSKt2uPe9/b1Q1Z7WVDt9i98tmcbC47g8o/rwfgczmMYnNA2vg8O2H7m05JFvRqIbDFjQkEs2KNr/RY+XKEhxzzHJe178nM/S7h6YMtGOYDzBdKvddbKoR8HtBPCNFLCOEATgSannSwnqQfeEDC8k1/SXzlX1a8DID+NX50DSXb7QBsBB3mDW9uIf/mXlgym4qfnmd+6FjaBbdCWqLAXvrm/Rz8S/KPdUep1w4a3LHWcqOigpIXXsS3dCmZ06Y1re11kDV9OrZOnaKBh6RhENymzHD2cdMTK5uxZcKlpYntNN0D25tua/lxft+dbrqxQe05fHhsyr+nYx/yhlaS20+J0cZcgXP4UYkbRN4QnZnYRZhOosYsxYJlsc/Fq7DYJB08tQ9IOnNjPevfj3qRX4yhVJGGLU2y4dQSzvi7lYv/amVAu4HRegaCcLh2U0mEeMG0++uuu65CxTH/cvjDVOFGSsm1hw7imNHdmNw/j6+MUTzsPB8OvAlr+/bk+BN/D1aHBcrMMA9pYU4+5Ea29+rPPdsLOaNM+WPbAd+aC6le+1fS6pjnEU0DCEgjTjBdSsh7BoM88lhM6Ld0SrQ/3zVC6cG6MTFXW5/NAViQhtr3Z/buFNfxwr61hu+616Em+QgEIQt8OxKs1bE3yKcPdVAqluIzRbtcpPNnTs8EE1iRbw8c7JRShoC/AZ8Ay4DXpZS1RH/fNXR78MHo507SwrEDT0hYX+wtxmFxNDn6YZbbThAboaiQN7Np5ctb4I0zsH8XF6TKVb/Zq7acnDrXPXn6WNbeedgOt8+aMX2H65uCNTOTcIX6oa896SQ2nKt64vbOnelwTSzqYcS0EtyyJWH7kFd9pf0ldgwEb1Zdh72rGrKJT45RH+JNdyK9I9hcOJc/yupDq+g/ogQmzoQj/gv9DoaL48YgzPvQQ2znh/BgDvTfXXPXsF2J+u0FNX7UJ/4Ppt4G53xCp9MnkbbfJPYaGLOpWjBw2yVel6AgW9ArOxYcbpvIYNY+O/5JB+KE3FWLfTzyBvPowkdVnVy1/8KqAAcP6cR9x4+IJuX2mTZ+e24u2f4KwubrRudbb1HXIBj7jZS4MqkSaRxSVU3kl3iY/3aCvnxkOIMcZ+J3ctCJm3lq76Po9dZb0TIjGIs1Xmn2yA/IGpGw3eaOPRKWe4ayAXC0a8ft407l8+5jMCKvReZ8A0fOz0kDqdF2ZwjK48YxnQHoaXrDvjwljUem2bDGPYtLHepNaoU5z8Ivk3WnyLsHCjmAlPJDKWV/KWUfKeVtqdhnfRE2G9Z0F86cAJ9Z8pPWVwQrcNnqcDBvANkeO35shPeUHrmJqzLOyOlS5pC51x3A/BN7JNVd/JcODFy2NGEyT33JOEjF/HYOGFBrPPJUYc3MxDB7bL7fzIFMiwVbhw5kxM2Ii4TSrZ43H2e/PvQ9QmVECpnhGvw5k9mYnkeFI41es9+m7xefN61hQqiomsBhmWUc7K8GRxqMOhVOeR3y4t74XNkA5Fu2UUI6K2W35P2tU0kdeoRC9I+PpjnwMNj7b9BpGDnXPU6Pxx/HZbdyxl7KNLjA6E9anH0+koEIoMrVns9HWWqdNLfdtJSFrGAzf/Y1zRlBKzwyI/Fhd8CALhw6rBMXTY4lxc72qO9PmVfdA0deLp2ri7FKg3ZnnEH2scdGv4sA9FWmvEBcZskrg+ezRMbMnW67O2nm5o8dB+LsHQvLEfb2IFCsApdVutTvsG9Zn4RtylzZLIn76vtXrADA1akD33YdyX1jToqrHRPvYnfiW2r+1AI6T1eK/dbecREigVtN23uVXYn2srjbGzBNZBeWqLGbMtR+450t4r3qUkWLmtlZF/2++IBe5/aDfWoPL5oKIc90qR55JMuYUd2MQh6uwz/YqXqCHTJdFJyYbA/+ckb3Rs8q63L33eScdhodr7+uUdvXF0tmJuGKimjscwBb+/YIuz0hsmJkUla4vBxbx87Y3QaeDn5C1VYYfz6GxUOv7rl8f80UrBkZ0V55Q3n2zHHce5zZ67PU8+diCjlAqdy5t9QJHVVu2bdmvFVnnZumD+GbK/fnn6GzuLHyqmj5yA4jo5+X2JQZ6s19LGxMNKWzupO672ELnJCpHjo17b/2MLy6KfENJ8Pp5tFTxjCkS0yYB3ZS5xTJdOPIi4UQjqZNM7+LZHaDU2fxynkT2H+IUrwXQwfyRngy8UJa5C3ioSMT2xOUidfbv3U6/m0zqFp9GVl5+QB0feunhDpr/XbuOtbK8weobcveeQfhcPCXqXtRE6tFcGgvNd+iPNQ7YZ27XZDstBDHlFfy4XgLx19jJexOtMNn+NTy7SfE2h0yn1UHm2/sq6T63r0x/Q1mjp7Jr6f9yqRuk0g1rULIRVYXxDkfQ+/JANy+z+3cOvFWuqari+i2NS60ajxuh4WgjBPy5jSt+MprL3dlsbpsNevK19W6WmQ0PpSvxe2m0/XXkTZ+fKP3UR+sGRmEy8sS0n4JU8AjoQIAvAvVDDrp80YF3u4JE7R1hUPuQnp9ONM8dM1u2r3ff2AHjh1jdrlEPU0z+ROjH0vYubfUcbljWXjaQvrl1D2t32IRdMtx48fB7+GYa2SX9GRXtuE+f1RQAOYNl/z3cAu3H2/h/454mCvSlF19XUfBRRdZyewZ+y4PqZE0pLY8ty67lWfPHMf/zlMPIEtGzKQXHX/xm99RM7PUXn3aM/HwM6myZPBS+ECOHNmFsT1VF/yuY4bxxEFPRIOQRahC3bvhecMJVQwCqd6IDH8nRE91T9yrEx88xRYXPqfgm6GmR8pPP2HNbU9+5xz+fqB6gB08RI0DpTttUY2Q4dgD1zo05t+/ygx9ixB0feWJhGP9ZjmaYMVgOngOoLhjYt5PlzRYbORHl7umd+XcYec2OS9CXbQKIa/J9D7TOaLvEVFPFZe16T1yp82qQnSas+dChanxhW8UZgLZJDoP54jZKih+bVw29vJd16YUYUlLI7R5C0XPPRcti7xFRGaYAhQ9/jgyFMKo9qryU9/Cts8ZhIpLkaiAYKKRsdHrpPtf6lfP7oax5wBQKmsI+fSHlTkGoPNIOPopxISLsNYVbjCO2jLLOCwOrh53dUJZlmGwJa5Hfs9hdvwOwUkZxQz48m7sgdjbZFEmdPlLaazydVsYkTc8tn9r7Wa4/Qd2oHeeOjfhjNWJRLEkJ1/9P/Te2EaZXRhS/Th/yB58v6qIWX/dm7V3HsYJ43owoN0AbtzruWjVYb6nqEb9bl8+9GVuGh+3H6Cyd+25OVdmK2GuiIs+Gclqn+ZU1zhimfI4rFjMddOHxmLMh/8WS2RiiXMuzB4wKRoMa93ofVmSMYGs8vP48JSHGPL3fwJQYt5ulyGjsdJ3B61SyCNkOdXrYCpMK26HVQ12uiXVaTaqvv9h5xvtKso3116erYyDveKmF1e6oMdzz9Lp5psZ0K72wFh7EtJQ9sfip5+JFZomDVHDtGFUVyvBdrmh7wHYevaHYJDiF14gXF7W6CQXdXL0E0qI64MZJ+asw/bj+2umQJdR4GkPY85QA6THPgunvgnDj0vIh9pQhBCcOvhU9u26b7TMKSX/d0jyg2FaVTUEqiBQyXGmd+N4nz/mEgng8PDSobHkB7X1yGuSNX06afspc4EnEkXz2GfhtNnQL9HV9cETRgLQPi35ATFpjNo2LCxU4GHOPyZH1504Pmb4vufY4UnfBYDS599iXWZnKldcy4P7PUpgX+VCGRkY75WrVHiM+SZw0eQ+VJnJyYd2js1Y7jTuCJ6V01kz9ka8cRdHCBGNfePOTDQvZR95JNteuCQ6aOqWMho2I2qa24Xsmn7+HkIkBnkqhNxltxLAil3Aph4e2hUX73yjXcEPj8BnNwFgONKxxMWViXDXs+qL++0QwSMzrCyeMIG0CRN2azMbS235QEN1XGujqgrDGzOt2DqqH+P2O+8CwDNyZGob50xXQtxjAtSY/ZrElBsgLY+ufzlaZas6f07i+qFH17rZzuic5WJLmY/79nmCouDaaPm3m76Nfr6hsJjJPbtR7k70UlESI6FgOf8U7Ziw3/Xs4+wE3mJ49a+1Hq8+pgBhtdLj8ccJV1bF4vd42kGf/ZPqHjmqK3arheHdspLWWaxWXp90Cl/YlNtnfm7tpsDDh3dh4dzYcv5rr2LLy+MXnxNYjQxlcUD+vlSeaWHDt+dGJ5gdMKgjb1y4F2N65HDhfmqQ9KYflFnJY/fQ5b578f66kJw0B2fdrCJ53nj7nZzUNTGUAkCa6dte6Y+5Pmanx8YKXFJGk15MH5GcfDvVtGohj8zmTIVpxWWzEMCOSxpUO8EoSX2Wj3rxacxPftEpv3Hf40/youPOWqtaap8jsUcjgzEhzzz0UMo//JDso2sXPaOqCun1Itzq/taMAxONbZ5q8urxZpPeAQ74Z8oP/cp5E3h13gYO6j0AIZIH8EAF3npqyzbOv7SWuDhbFwMg7B6m5k+NFne45mqscbbufjn9WFGyokGD4zWDsNXFYcPrFraFI/dn/frSHW7vsif2xh29e2PNyGCoP8SgzpncfpSahWvvpAQ48+CDo3XH5SeaZCJvHNnObLIOm0rWYYmut0MDAW4vKCTzhFcByJt5KQUPPYxLmIG/4vLH5qTFBN+KikjaJy8tGgZiV9K6hdycZCBqCWvaUGxWC2Fhp0PIoNjq2yXpmnbK9ljaKnLy2V4Z4ltjOFvHX0vHzj2SzjLQNNf5ZqHdmWdQ/t57AGQccjCd77g9wV2y9wfvU/HZZxQ8+JCa3SklFpfZI++cOPAXWFf7oG9LJj83jWumDUwqf3D/B7nsq8vo4O4ArGeoPxCdSVgr/aYmLLY/88yE5VcPe5UC7+4fBzp0aGd+XV/KbUcNrbOOEILDex8OKC8fqxlzKc1p46OZcSamPn3InzUL1+BBte0GgEtHX0quO5cDehxQe4Wr1jBdGpCmetuO/Hz138x1FArHzJjdO6kEHh3NN4C7Qyfy8WWp91CpjVYt5Bl2dYODsu5wng0hZHHQIxhkux3CFbuot7cjCuKEHMG2CvXqZtnnMpaPH0Xl1E8hLiT48m6pD2C/q3EPGYK9Rw+C69djTU/H4kw0YTj79CFsmloqvlRxRFyDlLDZOyb2QLs9Uk97ditgSvcpXDzyYg7scSAsHUOalLx+2Gusq1zPtxu/VTGH0stgsZn/9LD7d7g/h9UR9ejYnZy7by9mjOxCx8wdv0Xv1WUvCv/+d4Kb6xgvMnEPHbLD9ZmOTC4ckRzGOIqnxqCqGRHUYWaY7pwVa6fFmc4nGzbhMiTvhyfwfPhgbrbunmHIVi3kkR55yKg7nGdD8FrS6euvZK2jHQQCGIEAlkZMrmk0cTPlEILt5T4sAuRzTwKQ/unPMNqK3y4I9+rKV8O31LGjPZuol0odoQQsZlq4io9UQuK67P/OPn1qLW+NCCGSBGlQ7mAG5Q7mkHyVwYiPr43UBnf2bm1ffRFC1Cnin18+idLqWKcs94Lzd1ezorjN5Cvtjjmah/IGM75XotB3OeUdpAzz6qeCx/fdfc4FrVrII7OpUibk1kx6BQPR4PpGZSWWdrW7QaUcXznMjh+QEmwr95Gb7qR89tvR0hFrJM6gpMPRp3JM/zUc2ffI3dO+VGJOpReu2r1OnH0SJ2/Em146XHUV2++uZUp8W8KVXbuLaseIuUJSZ3blPZi+HZoWijoV2Dt3ZtByFV6h1qQLvfZFAC/toJO/K2jV7ocem3LST5WQ+2wZ5IbD0TyFhmknN3w+AuvXp+QYtRIOwWP7JBUXVPjpkOkkfWJsAkok3ZWjR3f+tfe/Emb+tRRs5qClsNfez4gkvKiN9meftUva1KK4eC5c8E1yed8Dd39bNLuFVt0jj0xmCBqpsZH7bZm4pMTnsgBG1E6+aeZlVH79NQOXLqnVv7XJlKyB0hoDd3Y3hZUBctOdBFfH7PVdi5SQ18y/2ZLoet+9lH/yCY5evXZaN+uoo5LKOl53Xb22bbVkdFR/NUnfddmdNM1LqxbyNLuysea46o721xDC9jTlGeJ2AiG2/vNGnP36Ufn114BKhSZ2ECK20fgTB1YfC01n1LiZFH5WTtcO5fy48isic/GGrAdnv367NCXbrsbWvj3tTj65XnU733ZrUlm7009LdZNaB0LAvldAp+E7r6tpUbRqIe+T3Ycb97qxbteihmKLxPxwAFX4li5NSEJsVFfvMNZ3o6kx6efO0En0nlNFUWWA731Xc5Av0XRk75Ec+bC10eud2fj/+GPXvAG1Zg5oWEx2TcugVQs5wHH9j0vZvix2NZq+ylZ70CpjV6V/8ysh/zw8ilyhjl3mDRIIGzgBVwA2tYOu5gTI+k7MaMm4BgzANWDPDzmg0ewOWr2QpxKLQ41yltQR0C6wbh2Onk1LKVf7jpWQ3x46hdVSTXopqooF5HEFoCwtJuThyj0jVrpGo9k96PfSBmB1qJ7uFd2n1rp+w/kXUPziS3XGBmk0po28Uia74/XfKOlSAtXO2OSfmunPNBpN60YLeQPo2SEbAEvQIFiHG+62225j8zXXAGB4vayadihVc+fWXrk+vHYqfPpPvNJBMcl+tH97T80wcwdiU4Wl19v442k0mhZHk4RcCHGPEGK5EGKREOJtIUR2itq1R9K1gwryHPYH46IUJxNJiuBftZrAmjVsu7P2oFY7JRyCZe9BsIolMp9QDUuYsJVhMRuSmRlLvNz5jjsadzyNRtMiaWqP/DNgqJRyOPAncO1O6rdobA4zE03YiAooKF/m3h9+SKYZOc1qTiEXkaBFxo5kfwfEzc6rksnTltP63oXLNJUPyFKB8TOmHYJrQP+kuhqNpvXSpMFOKeWncYs/Acc2rTl7NjZnRMjD2MzolWl7702XO24HVPbw8g8+wNFdpaEKbNqkKoXDSfuqF/NjyRXyLMlBuoQwokIuHE76//TjrnF/1Gg0ezSptJGfDXxU10ohxPlCiPlCiPkFBc2YJq0JOO02/NKGPRzz2443Y1jcbmxdOmNUeyl5/XU2XXIpANJoZGDwr26LfsywBRnbM4cTxnZPqBIJF9Dp5puxZmcj7C0wdq1Go2kSOxVyIcTnQojfa/k7Iq7O9UAIeLmu/Ugpn5BSjpVSjs3Ly6ur2h6N3WrBjwN7XA/bmpOdUMfi9hAuK6PggQdjhY0R8lBivj+H4adjpoubjxjC3/ZXZpRuBZKsauDi05NCuGo0mrbDTk0rUsodRtoRQpwJHA4cIKVspDG4ZeCwWfBjxxEO8tEYwbQFMimMbbi0lMpVqxLKInkoG8Ty9xMWl4W6kJvuwGW38o+DB2C5/w6mrVP77dJzxzGXNRpN66apXiuHAFcBM6SUu2ha455DVMhDIZ6damXdRw8k1QmXlCSVNSpD0axYFL9zAldwafBv0fyAhtfLtHU/R9dHM5drNJo2SVNndv4HcAKfmckAfpJS7uZIvLsPh9VCmXTgCAfAjsq6EmHdD9B9Apa0NIwa2YMC69YRKinBlrOT4F0Ff8C672H0mQnFq3P2pbyomvOeuY6C7YcSWL06Yf1uTW6h0Wj2OJrqtdI3VQ1pCUR65M6QCosbFfL1P8Oz0yCjM1iyAci74nIK7oul0yp85D90unEnyXgf2wfCAUIFK6M35qnQNNYUVXPw4A7I2asp/M9/Ejb548RxDNyr9iS8Go2mbaBndjYAh9WCDwfOsBqIvOWnW9SKgNkDr9gSjcaXsf/+CdvK+rggmvu1/fzfaNEr4SkAZAVqt1yNvvzWBmU612g0rQ8t5A3AYbPgl3ZccR4lUspodEKArvfdTdrEidi7J7oJip2ZP0L+WosjE4GOfeqGpHWzzulHj8zWH7JWo9HsGC3kDcBqEQSEg4xALCiWL+wDX1l0OW1YP3o8/RQWp5Pe771Lz5dfAkCGgpS98w6ls2erit4SeOdimKsSJ7P0nVqPWY0S8ozSwoTypw+ysH5ELVlgNBpNm0OHsW0gldZs8nwLAdUTrgpW4Y4TcrzF0TRbzn791P/+/Sl95VVKX3kVgOwjj4S78lX9X1+C8efBW+clHatKOqnEjbOGTznAkp6CPlZnqk5Lo9G0YHSPvIEsc41IWK4KViX0yKnclrSNvWvXune4AzEe4n8WAwvdKtVMWEt6LBD6tmw4ceCJ9Wu0RqNp1WghbyDCmRhKdl35ukQhL9uUtI1r0MCE5fJPPgUzMTQdBu30mKO3/wFAzoknAPB7T0HQLtin6z4NabpGo2mlaCFvIE5XYnKHi7+4WAl5ptnrfuciqEyMJZP7t7/R4eqro8ubZs4EYV76cDCh7rb9741tl+5k5a2HcHLJIiz9+pNx8CEAFCWHJddoNG0YLeQNxGpPNoVIbwmkxcWP2fBzwnphseAekWiSMXyml0rYD8FYIohNHaZEP+d47FBRjmvLRtofdijuYUOx3X8zL+1v4ai+R6XgbDQaTWtAC3kDiSRgfm9MbHLPM4HN4MqKVarFTm7Nzk5Yri5QppXyykr1IAAYfwHbw7EwtBN6t8eoUvk3bR1UUKzwhOGUpQv267Zfk89Fo9G0DrSQNxCrKeTpcZfuQWsFhiMd2vVRBf7k2OG2XJVdKH2K6nGHfGr7TP9WNnz5FNKA7d+W8+rHv/Jk6FC25h/BPw8fjFGpfNQt6Urgg6Ypxm7V4Wo1Go1CC3kDiZhW0moEwiq0O+GvP6iFkC95u8xM+n37DV3uUmnfwj4rpVKJc4+F91Fd4KDo7a/Z9/2nuS10KlknP4vDZokKuTVDGcaDhinkFi3kGo1GoYW8gVgdqkfuCCfGGPfbnWB3KW+UWoQcwJaXhzUjA+FyEvJZKJUxd0IZVg+GvbcuYUTBCopvuBYZDFLwHzVdf5NRwsvLXtZCrtFoktATghqI3RTyUDBRrAM2cxDU5qpzun0EW3YmIV8JXmLT9uMjud/5/eOUAzknnED1Tz8BcPHcq9jaTnDbPiprkDataDSaCLpH3kBsppAH/T5+PvlnHtjvPgD8USF3UlJezos/rq1zH9asdMI+K+XEBja3/JKc4SdcVh79XGSGHL/+u+sB3SPXaDQxtJA3EIfTA0Ao4MVj9+AxL2HAZkdKidfm4svF6/nnO0swDAmzL1LT8SMuhr+9SihcTMhvYbNsH91vuCo5OmJo29bo56At0SbvsOgY5BqNRqGFvIEITxYBaUVWKBdDh1S2cr/Vzht/vsH4doK9nN/jxkeFLwQLX1YBsuaoQU7evoB0YzMhn4UvN4/ECAkCldZaj7X15n8D8M5eyeu1aUWj0UTQQt5AXA4722Q7RLmaiu8ybdt+i4VP130KwFqbnb0tS9hWEWdH98ZSwFldBmGflYu+f5u5i8ey6v1YFMPq3E5Jx/xgLIzpOCahzCpqF3+NRtP20ELeQNx2K9vIwVIV6ZErk0cAkZCbs52oYNoDX8U2jPSghRWbM+bx4iqI2cEfG3YE8299MumYpemCrukqBIBN2Hj0gEfpltEtZeek0WhaNikRciHEFUIIKYTITcX+9mRcdivl0oMwJ/04UV3yv695nZ+2KA8TBLjxk0Ms4QSRwUlhYW1eLDWbJRCLtVLqTMfjtNHnk4+TjjsiT03xH9VxFPt22zeVp6TRaFo4TXY/FEJ0B6YC65venD0ft93KVtxYgmog0i2Sn4XFFgs32l7kR2NItKw8IMkMB8EIMictk2lmub0yZn4pc6Thcdhw9Ezubbd3t2f2EbNp52qX2hPSaDQtnlT0yB8ArgLkziq2Blx2C5XSjdXM09nBmpZU59oOuYQsknwR8zqZv6ECNs4DoMri5tL9ZiZt57U56d+x9tCGbqubPtl9yHHlpOI0NBpNK6JJQi6EOALYJKX8rR51zxdCzBdCzC8oKNhZ9T0Wl91KBW6sQdNsEvbTJRhKqldmsXC8dU502WK1wbOqH+7DyYqc7qRNiplIfhg1lD/a9WRwl8zaj2tzpewcNBpN62KnQi6E+FwI8Xstf0cA1wE31udAUsonpJRjpZRj8/Lydr7BHorLbqVSurEbPgiHIBSgwpJ8GSssFg6y/hJdbh+M9c4rpPJFT98nlhji1p6n0ycvDatFDZgW/ucqAN4fp5adNp3WTaPR1M5ObeRSygNrKxdCDAN6Ab8JIQC6Ab8IIcZLKbfWtk1roF2ag0rM5BKBCti0gC6hEH9YEyfoVFhiHixl0sOw4k+iyx8b4wAQDiXOmcccw/GjenLqhJ6xbXrncdG1sduTaa+9p67RaDSNNq1IKRdLKTtIKfOllPnARmB0axZxAKtF0KOz6evtr4Cv7+TRbQX8e9hFCfUivfQTAzcQiHtelsh0AtjpnOVCOJT4C8PgrmOHM6xbLKZ5uV+5Jf5rr38xc/RM7W6o0WjqRAfNagRhuznAabogdgiHeeRNF/SP1Sm1qgk7i41eVEsXCCXMb4RVQojT98onc3xnqr77jryZlybu3whzx9w7AJiaP5UMh87tptFo6iZlQm72ytsERkRY4xJIBAxB5YprELYK0nr9l/mZ7Xk1I51TeuZTuqAzPYPbAbgzdJLah5RYPB663n9f0v63V2+PfvbYPLvwTDQaTWtAz+xsBDIi5B9cES0rlhnIUDaGrzsuaxpvO2Gxy8mgPhvw2rKj9Qzzkp81Mb/O/VcE1QPivv3uw2rRU/E1Gs2O0ULeCMJuM2rhtt8B+L77BVQTcw/02N3Rz0EjiLAlDoQO7ZqJx1H3y1CF6aOuTSoajaY+aCFvBNVp3ROW5xcI8jKUB0rXbDfnDD0ruu7Wn27lk7SyhPoWkRiSNp5FBYs48+MzAS3kGo2mfujBzkawtTwxO9DGSsFx+3TDYbOw/4AO/Fa+MbpOInnDvTXB2X7RxkRhj2fe1nnRz1rINRpNfdA98kZwzj69EpaDhqBXbhqXHdifEd2zObLfkbVut3Wvm3a671x3LO5YB09y1iCNRqOpiRbyRtArNzG+ihcnvfNiZZmOTBafsZheWXGCP+x4Ou13Li67hQMH1S3Q/rDK9zm993TcNned9TQajSaCNq00Aqct8fn3mTGGu/OSzSC+UMwEUzDtdvJcmSz79yGIHdjII0J+9firU9RajUbT2tE98kYghODO4InR5Qsn9yPLk5x67Y5974h+fnzR49Ftd8R7q94DwGnVsVU0Gk390D3yRvJYeAaTLIt419ibE4ckp2eDxPRs9TGTrCpdxbLiZYAWco1GU390j7yRfDRzX04O3sCr4Sl0ya47xGx+Zj4AafbkuOU12Va9Lfp5Zz13jUajiaCFvJEM6hyLRpjpqjuj/dMHPw3AxoqNCeWVgcqkutXB6hS1TqPRtCW0kKcAl73uafQRF8J3Vr2DlCqJ0sdrP2avV/ZiefHyhLpVwapd10iNRtNq0UK+G9lUuQmArzd8DZAk5HO3zgXggckP7N6GaTSaFo0W8iZw3aEDOXp0153WO3/4+QBMe2sa87fO5/3V7wMgECwpXEJBdQHPL3med1e9C8A+Xfepc18ajUZTE+210gTOn9SnXvUOzj+YJxY9AcBZn8TisCwrXsYN39/A5O6TmbNhTrRce6xoNJqGoHvku4EsR1at5bNXzgZgzoY5OCwqQuKs6bO0x4pGo2kQWsh3A1nO2oU8fnAzYAQ4ut/RDGg3YHc1S6PRtBK0kO8GXLa6/czjybDraIcajabhNFnIhRCXCCGWCyGWCCHuTkWj2gJH9zsagP45/RmeOxzQYWs1Gk3jaJKQCyH2B44ARkgphwD3pqRVrZCvjv8q+vm7E7/jqnFX4bF5uGTUJeRn5QOQ48ppptZpNJqWTFO9Vv4K3Cml9ANIKbfvpH6bJdedy+373I435I3azH8+5WcAvlj/BQDtIynkNBqNpgE0Vcj7A/sKIW4DfMA/pJTzdrJNm2V6n+m1ls8cPZMcVw6Tuk3azS3SaDStgZ0KuRDic6C28H7Xm9u3AyYA44DXhRC9ZWQueuJ+zgfOB+jRo0dT2tzqyHXncvmYy5u7GRqNpoWyUyGXUh5Y1zohxF+Bt0zhniuEMIBcoKCW/TwBPAEwduzYJKHXaDQaTeNoqtfKbGB/ACFEf8ABFDZxnxqNRqNpAE21kT8DPCOE+B0IAGfUZlbRaDQaza6jSUIupQwAp6aoLRqNRqNpBHpmp0aj0bRwtJBrNBpNC0cLuUaj0bRwtJBrNBpNC0c0h5OJEKIAWNfIzXNpey6O+pzbBvqc2wZNOeeeUsq8moXNIuRNQQgxX0o5trnbsTvR59w20OfcNtgV56xNKxqNRtPC0UKu0Wg0LZyWKORPNHcDmgF9zm0Dfc5tg5Sfc4uzkWs0Go0mkZbYI9doNBpNHFrINRqNpoXTooRcCHGIEOIPIcRKIcQ1zd2eVCCE6C6E+EoIsdRMYD3TLG8nhPhMCLHC/J9jlgshxMPmNVgkhBjdvGfQeIQQViHEr0KI983lXkKIn81ze00I4TDLnebySnN9frM2vJEIIbKFELPMZOXLhBB7tfb7LIT4u/m9/l0I8YoQwtXa7rMQ4hkhxHYzCmykrMH3VQhxhll/hRDijIa0ocUIuRDCCvwXmAYMBk4SQgxu3lalhBBwhZRyMCrT0sXmeV0DfCGl7Ad8YS6DOv9+5t/5wP/t/ianjJnAsrjlu4AHpJR9gRLgHLP8HKDELH/ArNcSeQj4WEo5EBiBOvdWe5+FEF2BS4GxUsqhgBU4kdZ3n58DDqlR1qD7KoRoB9wE/AUYD9wUEf96IaVsEX/AXsAnccvXAtc2d7t2wXm+AxwE/AF0Nss6A3+Ynx8HToqrH63Xkv6AbuYXfArwPiBQs91sNe838Amwl/nZZtYTzX0ODTzfLGBNzXa35vsMdAU2oNJB2sz7fHBrvM9APvB7Y+8rcBLweFx5Qr2d/bWYHjmxL0WEjWZZq8F8lRwF/Ax0lFJuMVdtBTqan1vLdXgQuAowzOX2QKmUMmQux59X9JzN9WVm/ZZEL1QKxGdNc9JTQog0WvF9llJuAu4F1gNbUPdtAa37Pkdo6H1t0v1uSULeqhFCpANvApdJKcvj10n1iG41fqJCiMOB7VLKBc3dlt2IDRgN/J+UchRQRex1G2iV9zkHOAL1EOsCpJFsgmj17I772pKEfBPQPW65m1nW4hFC2FEi/rKU8i2zeJsQorO5vjOw3SxvDddhIjBDCLEWeBVlXnkIyBZCRLJWxZ9X9JzN9VlA0e5scArYCGyUUv5sLs9CCXtrvs8HAmuklAVSyiDwFuret+b7HKGh97VJ97slCfk8oJ854u1ADZq828xtajJCCAE8DSyTUt4ft+pdIDJyfQbKdh4pP90c/Z4AlMW9wrUIpJTXSim7SSnzUffxSynlKcBXwLFmtZrnHLkWx5r1W1TPVUq5FdgghBhgFh0ALKUV32eUSWWCEMJjfs8j59xq73McDb2vnwBThRA55pvMVLOsfjT3IEEDBxQOBf4EVgHXN3d7UnRO+6BeuxYBC82/Q1G2wS+AFcDnQDuzvkB576wCFqM8Apr9PJpw/pOB983PvYG5wErgDcBplrvM5ZXm+t7N3e5GnutIYL55r2cDOa39PgM3A8uB34EXAWdru8/AK6gxgCDqzeucxtxX4Gzz3FcCZzWkDXqKvkaj0bRwWpJpRaPRaDS1oIVco9FoWjhayDUajaaFo4Vco9FoWjhayDUajaaFo4Vco9FoWjhayDUajaaF8//xzrnP0GDDgAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.layers.reshaping.flatten import Flatten\n",
    "from keras.layers.core.activation import Activation\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Reshape\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_test = np.load(\"/content/drive/MyDrive/final/X_test.npy\")\n",
    "y_test = np.load(\"/content/drive/MyDrive/final/y_test.npy\")\n",
    "person_train_valid = np.load(\"/content/drive/MyDrive/final/person_train_valid.npy\")\n",
    "X_train_valid = np.load(\"/content/drive/MyDrive/final/X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"/content/drive/MyDrive/final/y_train_valid.npy\")\n",
    "person_test = np.load(\"/content/drive/MyDrive/final/person_test.npy\")\n",
    "\n",
    "# X_test = torch.tensor(X_test)\n",
    "# y_test = torch.tensor(y_test)\n",
    "# person_train_valid = torch.tensor(person_train_valid)\n",
    "# X_train_valid = torch.tensor(X_train_valid)\n",
    "# y_train_valid = torch.tensor(y_train_valid)\n",
    "# person_test = torch.tensor(person_test)\n",
    "y_train_valid -= 769\n",
    "y_test -= 769\n",
    "\n",
    "## Visualizing the data\n",
    "\n",
    "ch_data = X_train_valid[:,8,:] # extracts the 9th channel from the data\n",
    "\n",
    "\n",
    "class_0_ind = np.where(y_train_valid == 0) # finds the indices where the label is 0\n",
    "ch_data_class_0 = ch_data[class_0_ind] # finds the data where label is 0\n",
    "avg_ch_data_class_0 = np.mean(ch_data_class_0,axis=0) # finds the average representation of the 9th channel when label is 0\n",
    "\n",
    "\n",
    "class_1_ind = np.where(y_train_valid == 1)\n",
    "ch_data_class_1 = ch_data[class_1_ind]\n",
    "avg_ch_data_class_1 = np.mean(ch_data_class_1,axis=0)\n",
    "\n",
    "class_2_ind = np.where(y_train_valid == 2)\n",
    "ch_data_class_2 = ch_data[class_2_ind]\n",
    "avg_ch_data_class_2 = np.mean(ch_data_class_2,axis=0)\n",
    "\n",
    "class_3_ind = np.where(y_train_valid == 3)\n",
    "ch_data_class_3 = ch_data[class_3_ind]\n",
    "avg_ch_data_class_3 = np.mean(ch_data_class_3,axis=0)\n",
    "\n",
    "\n",
    "plt.plot(np.arange(1000),avg_ch_data_class_0)\n",
    "plt.plot(np.arange(1000),avg_ch_data_class_1)\n",
    "plt.plot(np.arange(1000),avg_ch_data_class_2)\n",
    "plt.plot(np.arange(1000),avg_ch_data_class_3)\n",
    "plt.axvline(x=500, label='line at t=500',c='cyan')\n",
    "\n",
    "plt.legend([\"Cue Onset left\", \"Cue Onset right\", \"Cue onset foot\", \"Cue onset tongue\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BvkwSOkwZCH2"
   },
   "outputs": [],
   "source": [
    "def data_prep(X,y,sub_sample,average,noise,period):\n",
    "    \n",
    "    total_X = None\n",
    "    total_y = None\n",
    "    \n",
    "    # Trimming the data (sample,22,1000) -> (sample,22,500)\n",
    "    X = X[:,:,0:period]\n",
    "\n",
    "    \n",
    "    # Maxpooling the data (sample,22,1000) -> (sample,22,500/sub_sample)\n",
    "    X_reshape = X.reshape(X.shape[0], X.shape[1], -1, sub_sample)\n",
    "    X_max = np.max(X_reshape, axis=3)\n",
    "    \n",
    "    total_X = X_max\n",
    "    total_y = y\n",
    "    \n",
    "    # Averaging + noise \n",
    "    X_average = np.mean(X.reshape(X.shape[0], X.shape[1], -1, average),axis=3)\n",
    "    if noise:\n",
    "      X_average = X_average + np.random.normal(0.0, 0.5, X_average.shape)\n",
    "    \n",
    "    total_X = np.vstack((total_X, X_average))\n",
    "    total_y = np.hstack((total_y, y))\n",
    "    \n",
    "    # Subsampling\n",
    "    \n",
    "    for i in range(sub_sample):\n",
    "        \n",
    "        X_subsample = X[:, :, i::sub_sample] + \\\n",
    "                            (np.random.normal(0.0, 0.5, X[:, :,i::sub_sample].shape) if noise else 0.0)\n",
    "            \n",
    "        total_X = np.vstack((total_X, X_subsample))\n",
    "        total_y = np.hstack((total_y, y))\n",
    "\n",
    "    return total_X,total_y\n",
    "        \n",
    "def data_finalize(period, total_number, takeout_sample, y_test=y_test): \n",
    "    ind_valid = np.random.choice(total_number, takeout_sample, replace=False)  # get 375 out of 2115 samples and no repetitation\n",
    "    ind_train = np.array(list(set(range(total_number)).difference(set(ind_valid)))) # a set(unordered) different with another set, set = set1 - set2\n",
    "\n",
    "    # Creating the training and validation sets using the generated indices\n",
    "    (X_train, X_valid) = X_train_valid[ind_train], X_train_valid[ind_valid] \n",
    "    (y_train, y_valid) = y_train_valid[ind_train], y_train_valid[ind_valid]\n",
    "    x_train,y_train = data_prep(X_train,y_train,2,2,True, period=period)\n",
    "    x_valid,y_valid = data_prep(X_valid,y_valid,2,2,True, period=period)\n",
    "    X_test_prep,y_test_prep = data_prep(X_test,y_test,2,2,True, period=period)\n",
    "\n",
    "    # Converting the labels to categorical variables for multiclass classification\n",
    "    y_train = to_categorical(y_train, 4)\n",
    "    y_valid = to_categorical(y_valid, 4)\n",
    "    y_test = to_categorical(y_test_prep, 4)\n",
    "\n",
    "    # Adding width of the segment to be 1\n",
    "    x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "    x_valid = x_valid.reshape(x_valid.shape[0], x_valid.shape[1], x_train.shape[2], 1)\n",
    "    x_test = X_test_prep.reshape(X_test_prep.shape[0], X_test_prep.shape[1], X_test_prep.shape[2], 1)\n",
    "\n",
    "\n",
    "    # Reshaping the training and validation dataset\n",
    "    x_train = np.swapaxes(x_train, 1,3)\n",
    "    x_train = np.swapaxes(x_train, 1,2)\n",
    "    x_valid = np.swapaxes(x_valid, 1,3)\n",
    "    x_valid = np.swapaxes(x_valid, 1,2)\n",
    "    x_test = np.swapaxes(x_test, 1,3)\n",
    "    x_test = np.swapaxes(x_test, 1,2)\n",
    "\n",
    "    return x_train, x_valid, x_test, y_train, y_valid, y_test\n",
    "\n",
    "\n",
    "\n",
    "X_train_valid_prep,y_train_valid_prep = data_prep(X_train_valid,y_train_valid,2,2,noise=True, period=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "73oNi5FjCAS2"
   },
   "source": [
    "# **Train the model on subject 1 data only and test it on both subject 1 test set and all subject test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XYDsW_1zCTPr"
   },
   "outputs": [],
   "source": [
    "# get subject 1 data for training and validation set\n",
    "person_train_valid = person_train_valid.flatten()\n",
    "X_train_valid=X_train_valid[np.where(person_train_valid==0)]\n",
    "y_train_valid=y_train_valid[np.where(person_train_valid==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v8NrEhQEFWWf",
    "outputId": "2b993fae-67c0-4708-e91f-250fb25ecbc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(237, 22, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_valid.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RmMo3NY9Ghca"
   },
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "learning_rate = 7e-4\n",
    "epochs = 50\n",
    "cnn_optimizer = keras.optimizers.Adam(lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hYlZ34JSOGbg",
    "outputId": "8af28f30-0c32-4b43-aa95-375ac2ba6773"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(780, 500, 1, 22)\n",
      "(168, 500, 1, 22)\n",
      "(1772, 500, 1, 22)\n",
      "(780, 4)\n",
      "(168, 4)\n",
      "(1772, 256, 4, 4, 4)\n",
      "(50, 500, 1, 22)\n",
      "(50, 256, 4, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_valid, x_test, y_train, y_valid, y_test = data_finalize(total_number=237, takeout_sample=42, period=1000, y_test=y_test)\n",
    "print(x_train.shape)\n",
    "print(x_valid.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_valid.shape)\n",
    "print(y_test.shape)\n",
    "person_test=person_test.flatten()\n",
    "X_test_sub1 = x_test[np.where(person_test==0)]\n",
    "y_test_sub1 = y_test[np.where(person_test==0)]\n",
    "print(X_test_sub1.shape)\n",
    "print(y_test_sub1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8qr-vDpgzEAE",
    "outputId": "bc647a37-3334-4e57-f430-6c55f720b041"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 500, 1, 25)        5525      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 250, 1, 25)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 250, 1, 25)       100       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 250, 1, 25)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 250, 1, 50)        12550     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 125, 1, 50)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 125, 1, 50)       200       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 125, 1, 50)        0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 125, 1, 100)       50100     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 63, 1, 100)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 63, 1, 100)       400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 63, 1, 100)        0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 6300)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 25204     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 94,079\n",
      "Trainable params: 93,729\n",
      "Non-trainable params: 350\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - 4s 96ms/step - loss: 2.0844 - accuracy: 0.3346 - val_loss: 4.6185 - val_accuracy: 0.2857\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 5s 158ms/step - loss: 1.2585 - accuracy: 0.5385 - val_loss: 3.3516 - val_accuracy: 0.2560\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 3s 96ms/step - loss: 0.9075 - accuracy: 0.6654 - val_loss: 2.4846 - val_accuracy: 0.2857\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 3s 89ms/step - loss: 0.6816 - accuracy: 0.7577 - val_loss: 2.0177 - val_accuracy: 0.3095\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 3s 93ms/step - loss: 0.5445 - accuracy: 0.7897 - val_loss: 1.9031 - val_accuracy: 0.4583\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 4s 132ms/step - loss: 0.4203 - accuracy: 0.8397 - val_loss: 2.2840 - val_accuracy: 0.4464\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 4s 111ms/step - loss: 0.3405 - accuracy: 0.8833 - val_loss: 2.7396 - val_accuracy: 0.4405\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 3s 88ms/step - loss: 0.2702 - accuracy: 0.9051 - val_loss: 2.7374 - val_accuracy: 0.4524\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 3s 88ms/step - loss: 0.1991 - accuracy: 0.9244 - val_loss: 2.8820 - val_accuracy: 0.4464\n",
      "Epoch 10/50\n",
      "19/32 [================>.............] - ETA: 1s - loss: 0.1661 - accuracy: 0.9495"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-10b2ebc936bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m   \u001b[0;31m# Training and validating the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m basic_cnn_model_results = basic_cnn_model.fit(x_train,\n\u001b[0m\u001b[1;32m     46\u001b[0m               \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m       (concrete_function,\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "period_accuracy={}\n",
    "x_train, x_valid, x_test, y_train, y_valid, y_test = data_finalize(total_number=237, takeout_sample=42, period=1000, y_test=y_test)\n",
    "# get subject 1 data for test set\n",
    "person_test=person_test.flatten()\n",
    "X_test_sub1 = x_test[np.where(person_test==0)]\n",
    "y_test_sub1 = y_test[np.where(person_test==0)]\n",
    "\n",
    "basic_cnn_model = Sequential([\n",
    "\n",
    "      # Conv. block 1\n",
    "      keras.layers.Conv2D(filters=25, kernel_size=(10,1), padding='same', activation='relu', input_shape=(x_train.shape[1],1,22)),\n",
    "      keras.layers.MaxPooling2D(pool_size=(2,1), padding='same'), # Read the keras documentation\n",
    "      keras.layers.BatchNormalization(),\n",
    "      keras.layers.Dropout(0.5),\n",
    "\n",
    "      # Conv. block 2\n",
    "      keras.layers.Conv2D(filters=50, kernel_size=(10,1), padding='same', activation='relu'),\n",
    "      keras.layers.MaxPooling2D(pool_size=(2,1), padding='same'),\n",
    "      keras.layers.BatchNormalization(),\n",
    "      keras.layers.Dropout(0.5),\n",
    "\n",
    "      # Conv. block 3\n",
    "      keras.layers.Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='relu'),\n",
    "      keras.layers.MaxPooling2D(pool_size=(2,1), padding='same'),\n",
    "      keras.layers.BatchNormalization(),\n",
    "      keras.layers.Dropout(0.5),\n",
    "\n",
    "      # Output layer with Softmax activation\n",
    "      keras.layers.Flatten(), # Flattens the input\n",
    "      keras.layers.Dense(4, activation='softmax') # Output FC layer with softmax activation\n",
    "\n",
    "  ])\n",
    "\n",
    "  # Printing the model summary\n",
    "basic_cnn_model.summary()\n",
    "\n",
    "  \n",
    "\n",
    "basic_cnn_model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer=cnn_optimizer,\n",
    "                 metrics=['accuracy'])\n",
    "  \n",
    "\n",
    "  # Training and validating the model\n",
    "basic_cnn_model_results = basic_cnn_model.fit(x_train,\n",
    "              y_train,\n",
    "              batch_size=25,\n",
    "              epochs=50,\n",
    "              validation_data=(x_valid, y_valid), verbose=True)\n",
    "\n",
    "val_acc = basic_cnn_model_results.history['val_accuracy'][49]\n",
    "period_accuracy['Sub1'] = val_acc\n",
    "print(period_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8W33IzSUCpBs",
    "outputId": "5e83e080-eaba-4dc3-ff80-6a83c4d3c072"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 500, 1, 22)\n",
      "(1772, 500, 1, 22)\n",
      "(50, 4)\n",
      "(1772, 4)\n",
      "Test accuracy of the basic CNN model: 0.3199999928474426\n"
     ]
    }
   ],
   "source": [
    "print(X_test_sub1.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test_sub1.shape)\n",
    "print(y_test.shape)\n",
    "cnn_score = basic_cnn_model.evaluate(X_test_sub1, y_test_sub1, verbose=0)\n",
    "print('Test accuracy of the basic CNN model:',cnn_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PijIvZpwCpna",
    "outputId": "2db08eb0-927a-4fd3-f98d-4db5fdefb0ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of the basic CNN model: 0.33747178316116333\n"
     ]
    }
   ],
   "source": [
    "cnn_score = basic_cnn_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test accuracy of the basic CNN model:',cnn_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jeXROCIqUe_7",
    "outputId": "60049651-600e-4f2d-f333-6ed2eac0922f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1740, 22, 300)\n",
      "(375, 22, 300)\n",
      "(443, 22, 300)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 150, 1, 25)        5525      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 75, 1, 25)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 75, 1, 25)        100       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 75, 1, 25)         0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 75, 1, 50)         10050     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 38, 1, 50)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 38, 1, 50)        200       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 38, 1, 50)         0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 38, 1, 100)        40100     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 19, 1, 100)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 19, 1, 100)       400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 19, 1, 100)        0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 19, 1, 200)        160200    \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 10, 1, 200)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 10, 1, 200)       800       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 10, 1, 200)        0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2000)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 50)                100050    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 204       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 317,629\n",
      "Trainable params: 316,879\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "145/145 [==============================] - 16s 101ms/step - loss: 1.5529 - accuracy: 0.2971 - val_loss: 1.3556 - val_accuracy: 0.3393\n",
      "Epoch 2/50\n",
      "145/145 [==============================] - 16s 114ms/step - loss: 1.3572 - accuracy: 0.3364 - val_loss: 1.3602 - val_accuracy: 0.3073\n",
      "Epoch 3/50\n",
      "145/145 [==============================] - 15s 102ms/step - loss: 1.3186 - accuracy: 0.3609 - val_loss: 1.3300 - val_accuracy: 0.3387\n",
      "Epoch 4/50\n",
      "145/145 [==============================] - 15s 104ms/step - loss: 1.2700 - accuracy: 0.4045 - val_loss: 1.4097 - val_accuracy: 0.3253\n",
      "Epoch 5/50\n",
      "145/145 [==============================] - 17s 115ms/step - loss: 1.2148 - accuracy: 0.4476 - val_loss: 1.3439 - val_accuracy: 0.3933\n",
      "Epoch 6/50\n",
      "145/145 [==============================] - 14s 98ms/step - loss: 1.1316 - accuracy: 0.4968 - val_loss: 1.1803 - val_accuracy: 0.4767\n",
      "Epoch 7/50\n",
      "145/145 [==============================] - 14s 99ms/step - loss: 1.0715 - accuracy: 0.5398 - val_loss: 1.1280 - val_accuracy: 0.5140\n",
      "Epoch 8/50\n",
      "145/145 [==============================] - 14s 99ms/step - loss: 1.0332 - accuracy: 0.5658 - val_loss: 1.3519 - val_accuracy: 0.4640\n",
      "Epoch 9/50\n",
      "145/145 [==============================] - 16s 113ms/step - loss: 0.9670 - accuracy: 0.5892 - val_loss: 1.2983 - val_accuracy: 0.4827\n",
      "Epoch 10/50\n",
      "145/145 [==============================] - 14s 99ms/step - loss: 0.9063 - accuracy: 0.6193 - val_loss: 1.2119 - val_accuracy: 0.5287\n",
      "Epoch 11/50\n",
      "145/145 [==============================] - 14s 100ms/step - loss: 0.8915 - accuracy: 0.6287 - val_loss: 1.1245 - val_accuracy: 0.5513\n",
      "Epoch 12/50\n",
      "145/145 [==============================] - 16s 113ms/step - loss: 0.8308 - accuracy: 0.6606 - val_loss: 1.0942 - val_accuracy: 0.5707\n",
      "Epoch 13/50\n",
      "145/145 [==============================] - 14s 100ms/step - loss: 0.7987 - accuracy: 0.6767 - val_loss: 1.0859 - val_accuracy: 0.5547\n",
      "Epoch 14/50\n",
      "145/145 [==============================] - 14s 99ms/step - loss: 0.7628 - accuracy: 0.6944 - val_loss: 1.1919 - val_accuracy: 0.5240\n",
      "Epoch 15/50\n",
      "145/145 [==============================] - 14s 99ms/step - loss: 0.7357 - accuracy: 0.7030 - val_loss: 1.1033 - val_accuracy: 0.5700\n",
      "Epoch 16/50\n",
      "145/145 [==============================] - 16s 114ms/step - loss: 0.6803 - accuracy: 0.7260 - val_loss: 1.1057 - val_accuracy: 0.5560\n",
      "Epoch 17/50\n",
      "145/145 [==============================] - 14s 99ms/step - loss: 0.6410 - accuracy: 0.7489 - val_loss: 1.1294 - val_accuracy: 0.5533\n",
      "Epoch 18/50\n",
      "145/145 [==============================] - 14s 99ms/step - loss: 0.6106 - accuracy: 0.7629 - val_loss: 1.1173 - val_accuracy: 0.5627\n",
      "Epoch 19/50\n",
      "145/145 [==============================] - 16s 113ms/step - loss: 0.5873 - accuracy: 0.7740 - val_loss: 1.1969 - val_accuracy: 0.5600\n",
      "Epoch 20/50\n",
      "145/145 [==============================] - 14s 99ms/step - loss: 0.5613 - accuracy: 0.7753 - val_loss: 1.1965 - val_accuracy: 0.5540\n",
      "Epoch 21/50\n",
      "145/145 [==============================] - 14s 99ms/step - loss: 0.5154 - accuracy: 0.7968 - val_loss: 1.1972 - val_accuracy: 0.5533\n",
      "Epoch 22/50\n",
      "145/145 [==============================] - 14s 99ms/step - loss: 0.5158 - accuracy: 0.8029 - val_loss: 1.1533 - val_accuracy: 0.5800\n",
      "Epoch 23/50\n",
      "145/145 [==============================] - 17s 115ms/step - loss: 0.4755 - accuracy: 0.8103 - val_loss: 1.2222 - val_accuracy: 0.5407\n",
      "Epoch 24/50\n",
      "145/145 [==============================] - 14s 98ms/step - loss: 0.4625 - accuracy: 0.8223 - val_loss: 1.2122 - val_accuracy: 0.5813\n",
      "Epoch 25/50\n",
      "145/145 [==============================] - 19s 131ms/step - loss: 0.4460 - accuracy: 0.8261 - val_loss: 1.2245 - val_accuracy: 0.5627\n",
      "Epoch 26/50\n",
      "145/145 [==============================] - 20s 140ms/step - loss: 0.4209 - accuracy: 0.8399 - val_loss: 1.1882 - val_accuracy: 0.5733\n",
      "Epoch 27/50\n",
      "145/145 [==============================] - 14s 99ms/step - loss: 0.4118 - accuracy: 0.8417 - val_loss: 1.2062 - val_accuracy: 0.5800\n",
      "Epoch 28/50\n",
      "145/145 [==============================] - 14s 99ms/step - loss: 0.3709 - accuracy: 0.8556 - val_loss: 1.2167 - val_accuracy: 0.5920\n",
      "Epoch 29/50\n",
      "145/145 [==============================] - 16s 112ms/step - loss: 0.3631 - accuracy: 0.8614 - val_loss: 1.1736 - val_accuracy: 0.5967\n",
      "Epoch 30/50\n",
      "145/145 [==============================] - 14s 99ms/step - loss: 0.3445 - accuracy: 0.8697 - val_loss: 1.1922 - val_accuracy: 0.5893\n",
      "Epoch 31/50\n",
      "145/145 [==============================] - 14s 100ms/step - loss: 0.3497 - accuracy: 0.8647 - val_loss: 1.2409 - val_accuracy: 0.5767\n",
      "Epoch 32/50\n",
      "145/145 [==============================] - 14s 98ms/step - loss: 0.3179 - accuracy: 0.8776 - val_loss: 1.2718 - val_accuracy: 0.5760\n",
      "Epoch 33/50\n",
      "145/145 [==============================] - 17s 114ms/step - loss: 0.3067 - accuracy: 0.8845 - val_loss: 1.2753 - val_accuracy: 0.5853\n",
      "Epoch 34/50\n",
      "145/145 [==============================] - 14s 100ms/step - loss: 0.2906 - accuracy: 0.8899 - val_loss: 1.3409 - val_accuracy: 0.5867\n",
      "Epoch 35/50\n",
      "145/145 [==============================] - 14s 99ms/step - loss: 0.3008 - accuracy: 0.8869 - val_loss: 1.3228 - val_accuracy: 0.5780\n",
      "Epoch 36/50\n",
      "145/145 [==============================] - 16s 114ms/step - loss: 0.2861 - accuracy: 0.8921 - val_loss: 1.2885 - val_accuracy: 0.5967\n",
      "Epoch 37/50\n",
      "145/145 [==============================] - 14s 100ms/step - loss: 0.2564 - accuracy: 0.9032 - val_loss: 1.2919 - val_accuracy: 0.6027\n",
      "Epoch 38/50\n",
      "145/145 [==============================] - 15s 100ms/step - loss: 0.2562 - accuracy: 0.9049 - val_loss: 1.2743 - val_accuracy: 0.6120\n",
      "Epoch 39/50\n",
      "145/145 [==============================] - 14s 99ms/step - loss: 0.2659 - accuracy: 0.8981 - val_loss: 1.3117 - val_accuracy: 0.5753\n",
      "Epoch 40/50\n",
      "145/145 [==============================] - 17s 114ms/step - loss: 0.2429 - accuracy: 0.9078 - val_loss: 1.3614 - val_accuracy: 0.5940\n",
      "Epoch 41/50\n",
      "145/145 [==============================] - 14s 100ms/step - loss: 0.2549 - accuracy: 0.9023 - val_loss: 1.3066 - val_accuracy: 0.5820\n",
      "Epoch 42/50\n",
      "145/145 [==============================] - 14s 99ms/step - loss: 0.2400 - accuracy: 0.9109 - val_loss: 1.2798 - val_accuracy: 0.5973\n",
      "Epoch 43/50\n",
      "145/145 [==============================] - 16s 114ms/step - loss: 0.2278 - accuracy: 0.9142 - val_loss: 1.4350 - val_accuracy: 0.5947\n",
      "Epoch 44/50\n",
      "145/145 [==============================] - 14s 98ms/step - loss: 0.2356 - accuracy: 0.9170 - val_loss: 1.4796 - val_accuracy: 0.5840\n",
      "Epoch 45/50\n",
      "145/145 [==============================] - 15s 101ms/step - loss: 0.2330 - accuracy: 0.9125 - val_loss: 1.3663 - val_accuracy: 0.5927\n",
      "Epoch 46/50\n",
      "145/145 [==============================] - 15s 102ms/step - loss: 0.2254 - accuracy: 0.9145 - val_loss: 1.4678 - val_accuracy: 0.5813\n",
      "Epoch 47/50\n",
      "145/145 [==============================] - 16s 109ms/step - loss: 0.2153 - accuracy: 0.9224 - val_loss: 1.4471 - val_accuracy: 0.5840\n",
      "Epoch 48/50\n",
      "145/145 [==============================] - 14s 98ms/step - loss: 0.2092 - accuracy: 0.9223 - val_loss: 1.3431 - val_accuracy: 0.5880\n",
      "Epoch 49/50\n",
      "145/145 [==============================] - 14s 99ms/step - loss: 0.1995 - accuracy: 0.9259 - val_loss: 1.4043 - val_accuracy: 0.5887\n",
      "Epoch 50/50\n",
      "145/145 [==============================] - 17s 116ms/step - loss: 0.2026 - accuracy: 0.9290 - val_loss: 1.4821 - val_accuracy: 0.6027\n",
      "(1740, 22, 350)\n",
      "(375, 22, 350)\n",
      "(443, 22, 350)\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 175, 1, 25)        5525      \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 88, 1, 25)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 88, 1, 25)        100       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 88, 1, 25)         0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 88, 1, 50)         10050     \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 44, 1, 50)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 44, 1, 50)        200       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 44, 1, 50)         0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 44, 1, 100)        40100     \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 22, 1, 100)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 22, 1, 100)       400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 22, 1, 100)        0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 22, 1, 200)        160200    \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 11, 1, 200)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 11, 1, 200)       800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 11, 1, 200)        0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 2200)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 50)                110050    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 4)                 204       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 327,629\n",
      "Trainable params: 326,879\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "145/145 [==============================] - 17s 110ms/step - loss: 1.4470 - accuracy: 0.3187 - val_loss: 1.3187 - val_accuracy: 0.3513\n",
      "Epoch 2/50\n",
      "145/145 [==============================] - 16s 108ms/step - loss: 1.2906 - accuracy: 0.3826 - val_loss: 1.2909 - val_accuracy: 0.3413\n",
      "Epoch 3/50\n",
      "145/145 [==============================] - 18s 124ms/step - loss: 1.2020 - accuracy: 0.4546 - val_loss: 1.2337 - val_accuracy: 0.4200\n",
      "Epoch 4/50\n",
      "145/145 [==============================] - 16s 113ms/step - loss: 1.1457 - accuracy: 0.4849 - val_loss: 1.2144 - val_accuracy: 0.4273\n",
      "Epoch 5/50\n",
      "145/145 [==============================] - 16s 109ms/step - loss: 1.0835 - accuracy: 0.5159 - val_loss: 1.2298 - val_accuracy: 0.4293\n",
      "Epoch 6/50\n",
      "145/145 [==============================] - 18s 128ms/step - loss: 1.0325 - accuracy: 0.5457 - val_loss: 1.1832 - val_accuracy: 0.4867\n",
      "Epoch 7/50\n",
      "145/145 [==============================] - 17s 114ms/step - loss: 0.9895 - accuracy: 0.5803 - val_loss: 1.1649 - val_accuracy: 0.4993\n",
      "Epoch 8/50\n",
      "145/145 [==============================] - 17s 115ms/step - loss: 0.9293 - accuracy: 0.6056 - val_loss: 1.1901 - val_accuracy: 0.4700\n",
      "Epoch 9/50\n",
      "145/145 [==============================] - 18s 123ms/step - loss: 0.8726 - accuracy: 0.6414 - val_loss: 1.1341 - val_accuracy: 0.5373\n",
      "Epoch 10/50\n",
      "145/145 [==============================] - 16s 108ms/step - loss: 0.8157 - accuracy: 0.6652 - val_loss: 1.1574 - val_accuracy: 0.5247\n",
      "Epoch 11/50\n",
      "145/145 [==============================] - 17s 114ms/step - loss: 0.7836 - accuracy: 0.6769 - val_loss: 1.0919 - val_accuracy: 0.5273\n",
      "Epoch 12/50\n",
      "145/145 [==============================] - 19s 131ms/step - loss: 0.7153 - accuracy: 0.7089 - val_loss: 1.1737 - val_accuracy: 0.5520\n",
      "Epoch 13/50\n",
      "145/145 [==============================] - 16s 108ms/step - loss: 0.6977 - accuracy: 0.7190 - val_loss: 1.0885 - val_accuracy: 0.5667\n",
      "Epoch 14/50\n",
      "145/145 [==============================] - 16s 109ms/step - loss: 0.6521 - accuracy: 0.7364 - val_loss: 1.1145 - val_accuracy: 0.5953\n",
      "Epoch 15/50\n",
      "145/145 [==============================] - 18s 124ms/step - loss: 0.6055 - accuracy: 0.7563 - val_loss: 1.1569 - val_accuracy: 0.5773\n",
      "Epoch 16/50\n",
      "145/145 [==============================] - 16s 114ms/step - loss: 0.5829 - accuracy: 0.7720 - val_loss: 1.2283 - val_accuracy: 0.5653\n",
      "Epoch 17/50\n",
      "145/145 [==============================] - 16s 114ms/step - loss: 0.5473 - accuracy: 0.7818 - val_loss: 1.1584 - val_accuracy: 0.6047\n",
      "Epoch 18/50\n",
      "145/145 [==============================] - 20s 137ms/step - loss: 0.5175 - accuracy: 0.8010 - val_loss: 1.1775 - val_accuracy: 0.5973\n",
      "Epoch 19/50\n",
      "145/145 [==============================] - 16s 110ms/step - loss: 0.4940 - accuracy: 0.8052 - val_loss: 1.1742 - val_accuracy: 0.6033\n",
      "Epoch 20/50\n",
      "145/145 [==============================] - 16s 109ms/step - loss: 0.4517 - accuracy: 0.8264 - val_loss: 1.2500 - val_accuracy: 0.5873\n",
      "Epoch 21/50\n",
      "145/145 [==============================] - 18s 124ms/step - loss: 0.4440 - accuracy: 0.8280 - val_loss: 1.2109 - val_accuracy: 0.5960\n",
      "Epoch 22/50\n",
      "145/145 [==============================] - 16s 113ms/step - loss: 0.4184 - accuracy: 0.8374 - val_loss: 1.2104 - val_accuracy: 0.6040\n",
      "Epoch 23/50\n",
      "145/145 [==============================] - 16s 109ms/step - loss: 0.4112 - accuracy: 0.8425 - val_loss: 1.2307 - val_accuracy: 0.6287\n",
      "Epoch 24/50\n",
      "145/145 [==============================] - 18s 127ms/step - loss: 0.3896 - accuracy: 0.8499 - val_loss: 1.2647 - val_accuracy: 0.6027\n",
      "Epoch 25/50\n",
      "145/145 [==============================] - 16s 109ms/step - loss: 0.3741 - accuracy: 0.8579 - val_loss: 1.2374 - val_accuracy: 0.6000\n",
      "Epoch 26/50\n",
      "145/145 [==============================] - 16s 113ms/step - loss: 0.3684 - accuracy: 0.8602 - val_loss: 1.3016 - val_accuracy: 0.5873\n",
      "Epoch 27/50\n",
      "145/145 [==============================] - 20s 136ms/step - loss: 0.3508 - accuracy: 0.8688 - val_loss: 1.3037 - val_accuracy: 0.5793\n",
      "Epoch 28/50\n",
      "145/145 [==============================] - 16s 109ms/step - loss: 0.3347 - accuracy: 0.8728 - val_loss: 1.2663 - val_accuracy: 0.6093\n",
      "Epoch 29/50\n",
      "145/145 [==============================] - 16s 109ms/step - loss: 0.3203 - accuracy: 0.8763 - val_loss: 1.3131 - val_accuracy: 0.6033\n",
      "Epoch 30/50\n",
      "145/145 [==============================] - 18s 125ms/step - loss: 0.3037 - accuracy: 0.8865 - val_loss: 1.2855 - val_accuracy: 0.6120\n",
      "Epoch 31/50\n",
      "145/145 [==============================] - 16s 109ms/step - loss: 0.2815 - accuracy: 0.8951 - val_loss: 1.3119 - val_accuracy: 0.6060\n",
      "Epoch 32/50\n",
      "145/145 [==============================] - 16s 109ms/step - loss: 0.2825 - accuracy: 0.8966 - val_loss: 1.3101 - val_accuracy: 0.6047\n",
      "Epoch 33/50\n",
      "145/145 [==============================] - 18s 124ms/step - loss: 0.2735 - accuracy: 0.8983 - val_loss: 1.3509 - val_accuracy: 0.5980\n",
      "Epoch 34/50\n",
      "145/145 [==============================] - 16s 113ms/step - loss: 0.2708 - accuracy: 0.8977 - val_loss: 1.3690 - val_accuracy: 0.6000\n",
      "Epoch 35/50\n",
      "145/145 [==============================] - 16s 109ms/step - loss: 0.2524 - accuracy: 0.9055 - val_loss: 1.4295 - val_accuracy: 0.6040\n",
      "Epoch 36/50\n",
      "145/145 [==============================] - 18s 124ms/step - loss: 0.2575 - accuracy: 0.9055 - val_loss: 1.3572 - val_accuracy: 0.6113\n",
      "Epoch 37/50\n",
      "145/145 [==============================] - 16s 113ms/step - loss: 0.2458 - accuracy: 0.9066 - val_loss: 1.3364 - val_accuracy: 0.6180\n",
      "Epoch 38/50\n",
      "145/145 [==============================] - 16s 109ms/step - loss: 0.2385 - accuracy: 0.9119 - val_loss: 1.4754 - val_accuracy: 0.6033\n",
      "Epoch 39/50\n",
      "145/145 [==============================] - 17s 115ms/step - loss: 0.2225 - accuracy: 0.9154 - val_loss: 1.3730 - val_accuracy: 0.6040\n",
      "Epoch 40/50\n",
      "145/145 [==============================] - 17s 118ms/step - loss: 0.2190 - accuracy: 0.9182 - val_loss: 1.4515 - val_accuracy: 0.6140\n",
      "Epoch 41/50\n",
      "145/145 [==============================] - 17s 116ms/step - loss: 0.2002 - accuracy: 0.9267 - val_loss: 1.4856 - val_accuracy: 0.5973\n",
      "Epoch 42/50\n",
      "145/145 [==============================] - 17s 114ms/step - loss: 0.2073 - accuracy: 0.9231 - val_loss: 1.4629 - val_accuracy: 0.6107\n",
      "Epoch 43/50\n",
      "145/145 [==============================] - 18s 124ms/step - loss: 0.2154 - accuracy: 0.9213 - val_loss: 1.4534 - val_accuracy: 0.6160\n",
      "Epoch 44/50\n",
      "145/145 [==============================] - 16s 109ms/step - loss: 0.1846 - accuracy: 0.9343 - val_loss: 1.4598 - val_accuracy: 0.6067\n",
      "Epoch 45/50\n",
      "145/145 [==============================] - 16s 108ms/step - loss: 0.1889 - accuracy: 0.9299 - val_loss: 1.5578 - val_accuracy: 0.5960\n",
      "Epoch 46/50\n",
      "145/145 [==============================] - 18s 123ms/step - loss: 0.1753 - accuracy: 0.9362 - val_loss: 1.4895 - val_accuracy: 0.6020\n",
      "Epoch 47/50\n",
      "145/145 [==============================] - 16s 109ms/step - loss: 0.1837 - accuracy: 0.9328 - val_loss: 1.5521 - val_accuracy: 0.5873\n",
      "Epoch 48/50\n",
      "145/145 [==============================] - 16s 114ms/step - loss: 0.1702 - accuracy: 0.9395 - val_loss: 1.6386 - val_accuracy: 0.5793\n",
      "Epoch 49/50\n",
      "145/145 [==============================] - 22s 150ms/step - loss: 0.1590 - accuracy: 0.9402 - val_loss: 1.6082 - val_accuracy: 0.5840\n",
      "Epoch 50/50\n",
      "145/145 [==============================] - 16s 110ms/step - loss: 0.1711 - accuracy: 0.9386 - val_loss: 1.6393 - val_accuracy: 0.5960\n",
      "(1740, 22, 400)\n",
      "(375, 22, 400)\n",
      "(443, 22, 400)\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 200, 1, 25)        5525      \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 100, 1, 25)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 100, 1, 25)       100       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 100, 1, 25)        0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 100, 1, 50)        10050     \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 50, 1, 50)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 50, 1, 50)        200       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 50, 1, 50)         0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 50, 1, 100)        40100     \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 25, 1, 100)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 25, 1, 100)       400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 25, 1, 100)        0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 25, 1, 200)        160200    \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 13, 1, 200)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 13, 1, 200)       800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 13, 1, 200)        0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 2600)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 50)                130050    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 4)                 204       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 347,629\n",
      "Trainable params: 346,879\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "145/145 [==============================] - 21s 139ms/step - loss: 1.4408 - accuracy: 0.3326 - val_loss: 1.3010 - val_accuracy: 0.3993\n",
      "Epoch 2/50\n",
      "145/145 [==============================] - 18s 123ms/step - loss: 1.2757 - accuracy: 0.3888 - val_loss: 1.3505 - val_accuracy: 0.3787\n",
      "Epoch 3/50\n",
      "145/145 [==============================] - 19s 131ms/step - loss: 1.2207 - accuracy: 0.4366 - val_loss: 1.3080 - val_accuracy: 0.4093\n",
      "Epoch 4/50\n",
      "145/145 [==============================] - 21s 142ms/step - loss: 1.1466 - accuracy: 0.4911 - val_loss: 1.2697 - val_accuracy: 0.3987\n",
      "Epoch 5/50\n",
      "145/145 [==============================] - 18s 124ms/step - loss: 1.0871 - accuracy: 0.5124 - val_loss: 1.2258 - val_accuracy: 0.4687\n",
      "Epoch 6/50\n",
      "145/145 [==============================] - 18s 124ms/step - loss: 1.0257 - accuracy: 0.5559 - val_loss: 1.2551 - val_accuracy: 0.4620\n",
      "Epoch 7/50\n",
      "145/145 [==============================] - 20s 141ms/step - loss: 0.9757 - accuracy: 0.5822 - val_loss: 1.2265 - val_accuracy: 0.4660\n",
      "Epoch 8/50\n",
      "145/145 [==============================] - 19s 129ms/step - loss: 0.9064 - accuracy: 0.6214 - val_loss: 1.2443 - val_accuracy: 0.5053\n",
      "Epoch 9/50\n",
      "145/145 [==============================] - 19s 134ms/step - loss: 0.8611 - accuracy: 0.6450 - val_loss: 1.2220 - val_accuracy: 0.5093\n",
      "Epoch 10/50\n",
      "145/145 [==============================] - 18s 123ms/step - loss: 0.8135 - accuracy: 0.6648 - val_loss: 1.2599 - val_accuracy: 0.4673\n",
      "Epoch 11/50\n",
      "145/145 [==============================] - 18s 127ms/step - loss: 0.7648 - accuracy: 0.6966 - val_loss: 1.2169 - val_accuracy: 0.5387\n",
      "Epoch 12/50\n",
      "145/145 [==============================] - 21s 144ms/step - loss: 0.7189 - accuracy: 0.7086 - val_loss: 1.3139 - val_accuracy: 0.5227\n",
      "Epoch 13/50\n",
      "145/145 [==============================] - 18s 122ms/step - loss: 0.6789 - accuracy: 0.7272 - val_loss: 1.2895 - val_accuracy: 0.5240\n",
      "Epoch 14/50\n",
      "145/145 [==============================] - 17s 119ms/step - loss: 0.6596 - accuracy: 0.7338 - val_loss: 1.2576 - val_accuracy: 0.5380\n",
      "Epoch 15/50\n",
      "145/145 [==============================] - 19s 135ms/step - loss: 0.5959 - accuracy: 0.7698 - val_loss: 1.3094 - val_accuracy: 0.5153\n",
      "Epoch 16/50\n",
      "145/145 [==============================] - 19s 130ms/step - loss: 0.5562 - accuracy: 0.7786 - val_loss: 1.3281 - val_accuracy: 0.5200\n",
      "Epoch 17/50\n",
      "145/145 [==============================] - 18s 122ms/step - loss: 0.5292 - accuracy: 0.7911 - val_loss: 1.4437 - val_accuracy: 0.5067\n",
      "Epoch 18/50\n",
      "145/145 [==============================] - 20s 138ms/step - loss: 0.4968 - accuracy: 0.8039 - val_loss: 1.3768 - val_accuracy: 0.5287\n",
      "Epoch 19/50\n",
      "145/145 [==============================] - 17s 120ms/step - loss: 0.4666 - accuracy: 0.8210 - val_loss: 1.3506 - val_accuracy: 0.5613\n",
      "Epoch 20/50\n",
      "145/145 [==============================] - 18s 127ms/step - loss: 0.4365 - accuracy: 0.8346 - val_loss: 1.4087 - val_accuracy: 0.5540\n",
      "Epoch 21/50\n",
      "145/145 [==============================] - 21s 142ms/step - loss: 0.4120 - accuracy: 0.8443 - val_loss: 1.3234 - val_accuracy: 0.5627\n",
      "Epoch 22/50\n",
      "145/145 [==============================] - 17s 120ms/step - loss: 0.4070 - accuracy: 0.8409 - val_loss: 1.4261 - val_accuracy: 0.5580\n",
      "Epoch 23/50\n",
      "145/145 [==============================] - 19s 133ms/step - loss: 0.3534 - accuracy: 0.8658 - val_loss: 1.4448 - val_accuracy: 0.5500\n",
      "Epoch 24/50\n",
      "145/145 [==============================] - 17s 120ms/step - loss: 0.3520 - accuracy: 0.8664 - val_loss: 1.3860 - val_accuracy: 0.5920\n",
      "Epoch 25/50\n",
      "145/145 [==============================] - 19s 132ms/step - loss: 0.3270 - accuracy: 0.8793 - val_loss: 1.4323 - val_accuracy: 0.5707\n",
      "Epoch 26/50\n",
      "145/145 [==============================] - 21s 144ms/step - loss: 0.3203 - accuracy: 0.8799 - val_loss: 1.5445 - val_accuracy: 0.5500\n",
      "Epoch 27/50\n",
      "145/145 [==============================] - 17s 119ms/step - loss: 0.2929 - accuracy: 0.8897 - val_loss: 1.5094 - val_accuracy: 0.5667\n",
      "Epoch 28/50\n",
      "145/145 [==============================] - 18s 124ms/step - loss: 0.2821 - accuracy: 0.8941 - val_loss: 1.5270 - val_accuracy: 0.5427\n",
      "Epoch 29/50\n",
      "145/145 [==============================] - 20s 137ms/step - loss: 0.2639 - accuracy: 0.9033 - val_loss: 1.5240 - val_accuracy: 0.5627\n",
      "Epoch 30/50\n",
      "145/145 [==============================] - 19s 132ms/step - loss: 0.2580 - accuracy: 0.9034 - val_loss: 1.5921 - val_accuracy: 0.5607\n",
      "Epoch 31/50\n",
      "145/145 [==============================] - 17s 120ms/step - loss: 0.2433 - accuracy: 0.9106 - val_loss: 1.5051 - val_accuracy: 0.5707\n",
      "Epoch 32/50\n",
      "145/145 [==============================] - 19s 135ms/step - loss: 0.2277 - accuracy: 0.9154 - val_loss: 1.5264 - val_accuracy: 0.5673\n",
      "Epoch 33/50\n",
      "145/145 [==============================] - 21s 148ms/step - loss: 0.2141 - accuracy: 0.9228 - val_loss: 1.5568 - val_accuracy: 0.5807\n",
      "Epoch 34/50\n",
      "145/145 [==============================] - 21s 144ms/step - loss: 0.2055 - accuracy: 0.9270 - val_loss: 1.5495 - val_accuracy: 0.5907\n",
      "Epoch 35/50\n",
      "145/145 [==============================] - 19s 128ms/step - loss: 0.2153 - accuracy: 0.9218 - val_loss: 1.5958 - val_accuracy: 0.5813\n",
      "Epoch 36/50\n",
      "145/145 [==============================] - 18s 123ms/step - loss: 0.2083 - accuracy: 0.9249 - val_loss: 1.5090 - val_accuracy: 0.5580\n",
      "Epoch 37/50\n",
      "145/145 [==============================] - 20s 139ms/step - loss: 0.2022 - accuracy: 0.9283 - val_loss: 1.6689 - val_accuracy: 0.5487\n",
      "Epoch 38/50\n",
      "145/145 [==============================] - 18s 124ms/step - loss: 0.1951 - accuracy: 0.9272 - val_loss: 1.6988 - val_accuracy: 0.5467\n",
      "Epoch 39/50\n",
      "145/145 [==============================] - 19s 131ms/step - loss: 0.1826 - accuracy: 0.9295 - val_loss: 1.6870 - val_accuracy: 0.5513\n",
      "Epoch 40/50\n",
      "145/145 [==============================] - 20s 138ms/step - loss: 0.1794 - accuracy: 0.9342 - val_loss: 1.6379 - val_accuracy: 0.5667\n",
      "Epoch 41/50\n",
      "145/145 [==============================] - 17s 120ms/step - loss: 0.1632 - accuracy: 0.9424 - val_loss: 1.6788 - val_accuracy: 0.5620\n",
      "Epoch 42/50\n",
      "145/145 [==============================] - 19s 131ms/step - loss: 0.1710 - accuracy: 0.9381 - val_loss: 1.5484 - val_accuracy: 0.5767\n",
      "Epoch 43/50\n",
      "145/145 [==============================] - 19s 132ms/step - loss: 0.1625 - accuracy: 0.9441 - val_loss: 1.7053 - val_accuracy: 0.5760\n",
      "Epoch 44/50\n",
      "145/145 [==============================] - 19s 128ms/step - loss: 0.1484 - accuracy: 0.9450 - val_loss: 1.6830 - val_accuracy: 0.5660\n",
      "Epoch 45/50\n",
      "145/145 [==============================] - 19s 135ms/step - loss: 0.1527 - accuracy: 0.9451 - val_loss: 1.7041 - val_accuracy: 0.5567\n",
      "Epoch 46/50\n",
      "145/145 [==============================] - 17s 120ms/step - loss: 0.1567 - accuracy: 0.9420 - val_loss: 1.7232 - val_accuracy: 0.5613\n",
      "Epoch 47/50\n",
      "145/145 [==============================] - 18s 124ms/step - loss: 0.1393 - accuracy: 0.9513 - val_loss: 1.7759 - val_accuracy: 0.5667\n",
      "Epoch 48/50\n",
      "145/145 [==============================] - 22s 149ms/step - loss: 0.1542 - accuracy: 0.9470 - val_loss: 1.6988 - val_accuracy: 0.5740\n",
      "Epoch 49/50\n",
      "145/145 [==============================] - 17s 120ms/step - loss: 0.1418 - accuracy: 0.9523 - val_loss: 1.6918 - val_accuracy: 0.5767\n",
      "Epoch 50/50\n",
      "145/145 [==============================] - 17s 120ms/step - loss: 0.1376 - accuracy: 0.9494 - val_loss: 1.7491 - val_accuracy: 0.5813\n",
      "(1740, 22, 450)\n",
      "(375, 22, 450)\n",
      "(443, 22, 450)\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_16 (Conv2D)          (None, 225, 1, 25)        5525      \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 113, 1, 25)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 113, 1, 25)       100       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 113, 1, 25)        0         \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 113, 1, 50)        10050     \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 57, 1, 50)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 57, 1, 50)        200       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 57, 1, 50)         0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 57, 1, 100)        40100     \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 29, 1, 100)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 29, 1, 100)       400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 29, 1, 100)        0         \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 29, 1, 200)        160200    \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 15, 1, 200)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 15, 1, 200)       800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 15, 1, 200)        0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 3000)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 50)                150050    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 4)                 204       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 367,629\n",
      "Trainable params: 366,879\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "145/145 [==============================] - 23s 153ms/step - loss: 1.4191 - accuracy: 0.3322 - val_loss: 1.2927 - val_accuracy: 0.3827\n",
      "Epoch 2/50\n",
      "145/145 [==============================] - 21s 145ms/step - loss: 1.2542 - accuracy: 0.4195 - val_loss: 1.3151 - val_accuracy: 0.4047\n",
      "Epoch 3/50\n",
      "145/145 [==============================] - 21s 146ms/step - loss: 1.1505 - accuracy: 0.4862 - val_loss: 1.1911 - val_accuracy: 0.4673\n",
      "Epoch 4/50\n",
      "145/145 [==============================] - 21s 148ms/step - loss: 1.0762 - accuracy: 0.5319 - val_loss: 1.2593 - val_accuracy: 0.4227\n",
      "Epoch 5/50\n",
      "145/145 [==============================] - 20s 135ms/step - loss: 1.0012 - accuracy: 0.5687 - val_loss: 1.1879 - val_accuracy: 0.4813\n",
      "Epoch 6/50\n",
      "145/145 [==============================] - 22s 151ms/step - loss: 0.9359 - accuracy: 0.5989 - val_loss: 1.1943 - val_accuracy: 0.5053\n",
      "Epoch 7/50\n",
      "145/145 [==============================] - 21s 143ms/step - loss: 0.8735 - accuracy: 0.6319 - val_loss: 1.2328 - val_accuracy: 0.4900\n",
      "Epoch 8/50\n",
      "145/145 [==============================] - 22s 151ms/step - loss: 0.8076 - accuracy: 0.6644 - val_loss: 1.1834 - val_accuracy: 0.5280\n",
      "Epoch 9/50\n",
      "145/145 [==============================] - 20s 135ms/step - loss: 0.7481 - accuracy: 0.6994 - val_loss: 1.1718 - val_accuracy: 0.5333\n",
      "Epoch 10/50\n",
      "145/145 [==============================] - 21s 146ms/step - loss: 0.7040 - accuracy: 0.7167 - val_loss: 1.1533 - val_accuracy: 0.5660\n",
      "Epoch 11/50\n",
      "145/145 [==============================] - 21s 146ms/step - loss: 0.6478 - accuracy: 0.7435 - val_loss: 1.1876 - val_accuracy: 0.5353\n",
      "Epoch 12/50\n",
      "145/145 [==============================] - 20s 141ms/step - loss: 0.6029 - accuracy: 0.7658 - val_loss: 1.2160 - val_accuracy: 0.5807\n",
      "Epoch 13/50\n",
      "145/145 [==============================] - 23s 158ms/step - loss: 0.5583 - accuracy: 0.7846 - val_loss: 1.2157 - val_accuracy: 0.5700\n",
      "Epoch 14/50\n",
      "145/145 [==============================] - 20s 136ms/step - loss: 0.5071 - accuracy: 0.8069 - val_loss: 1.2546 - val_accuracy: 0.5273\n",
      "Epoch 15/50\n",
      "145/145 [==============================] - 22s 151ms/step - loss: 0.4881 - accuracy: 0.8093 - val_loss: 1.1835 - val_accuracy: 0.5640\n",
      "Epoch 16/50\n",
      "145/145 [==============================] - 21s 146ms/step - loss: 0.4584 - accuracy: 0.8240 - val_loss: 1.1475 - val_accuracy: 0.5887\n",
      "Epoch 17/50\n",
      "145/145 [==============================] - 21s 143ms/step - loss: 0.4250 - accuracy: 0.8375 - val_loss: 1.2047 - val_accuracy: 0.5693\n",
      "Epoch 18/50\n",
      "145/145 [==============================] - 22s 149ms/step - loss: 0.3995 - accuracy: 0.8467 - val_loss: 1.3117 - val_accuracy: 0.5500\n",
      "Epoch 19/50\n",
      "145/145 [==============================] - 20s 136ms/step - loss: 0.3817 - accuracy: 0.8598 - val_loss: 1.3721 - val_accuracy: 0.5680\n",
      "Epoch 20/50\n",
      "145/145 [==============================] - 21s 146ms/step - loss: 0.3430 - accuracy: 0.8688 - val_loss: 1.2567 - val_accuracy: 0.6060\n",
      "Epoch 21/50\n",
      "145/145 [==============================] - 21s 147ms/step - loss: 0.3373 - accuracy: 0.8740 - val_loss: 1.3283 - val_accuracy: 0.5887\n",
      "Epoch 22/50\n",
      "145/145 [==============================] - 20s 135ms/step - loss: 0.3117 - accuracy: 0.8843 - val_loss: 1.3438 - val_accuracy: 0.5913\n",
      "Epoch 23/50\n",
      "145/145 [==============================] - 23s 162ms/step - loss: 0.2890 - accuracy: 0.8879 - val_loss: 1.4277 - val_accuracy: 0.5513\n",
      "Epoch 24/50\n",
      "145/145 [==============================] - 20s 136ms/step - loss: 0.2852 - accuracy: 0.8940 - val_loss: 1.2788 - val_accuracy: 0.6033\n",
      "Epoch 25/50\n",
      "145/145 [==============================] - 22s 153ms/step - loss: 0.2665 - accuracy: 0.9004 - val_loss: 1.4225 - val_accuracy: 0.5807\n",
      "Epoch 26/50\n",
      "145/145 [==============================] - 21s 147ms/step - loss: 0.2640 - accuracy: 0.9020 - val_loss: 1.4490 - val_accuracy: 0.5760\n",
      "Epoch 27/50\n",
      "145/145 [==============================] - 20s 138ms/step - loss: 0.2276 - accuracy: 0.9111 - val_loss: 1.4079 - val_accuracy: 0.5833\n",
      "Epoch 28/50\n",
      "145/145 [==============================] - 24s 163ms/step - loss: 0.2208 - accuracy: 0.9172 - val_loss: 1.3632 - val_accuracy: 0.5960\n",
      "Epoch 29/50\n",
      "145/145 [==============================] - 23s 162ms/step - loss: 0.2238 - accuracy: 0.9165 - val_loss: 1.4881 - val_accuracy: 0.5733\n",
      "Epoch 30/50\n",
      "145/145 [==============================] - 21s 147ms/step - loss: 0.2088 - accuracy: 0.9239 - val_loss: 1.5271 - val_accuracy: 0.5827\n",
      "Epoch 31/50\n",
      "145/145 [==============================] - 22s 149ms/step - loss: 0.2113 - accuracy: 0.9210 - val_loss: 1.4871 - val_accuracy: 0.5913\n",
      "Epoch 32/50\n",
      "145/145 [==============================] - 21s 147ms/step - loss: 0.2007 - accuracy: 0.9256 - val_loss: 1.5942 - val_accuracy: 0.5547\n",
      "Epoch 33/50\n",
      "145/145 [==============================] - 22s 152ms/step - loss: 0.1743 - accuracy: 0.9369 - val_loss: 1.5912 - val_accuracy: 0.5633\n",
      "Epoch 34/50\n",
      "145/145 [==============================] - 20s 136ms/step - loss: 0.1776 - accuracy: 0.9376 - val_loss: 1.5441 - val_accuracy: 0.5627\n",
      "Epoch 35/50\n",
      "145/145 [==============================] - 22s 154ms/step - loss: 0.1759 - accuracy: 0.9382 - val_loss: 1.5334 - val_accuracy: 0.5867\n",
      "Epoch 36/50\n",
      "145/145 [==============================] - 21s 144ms/step - loss: 0.1664 - accuracy: 0.9394 - val_loss: 1.5879 - val_accuracy: 0.5847\n",
      "Epoch 37/50\n",
      "145/145 [==============================] - 19s 134ms/step - loss: 0.1786 - accuracy: 0.9339 - val_loss: 1.6552 - val_accuracy: 0.5873\n",
      "Epoch 38/50\n",
      "145/145 [==============================] - 23s 161ms/step - loss: 0.1537 - accuracy: 0.9453 - val_loss: 1.7215 - val_accuracy: 0.5700\n",
      "Epoch 39/50\n",
      "145/145 [==============================] - 20s 137ms/step - loss: 0.1421 - accuracy: 0.9494 - val_loss: 1.6523 - val_accuracy: 0.5660\n",
      "Epoch 40/50\n",
      "145/145 [==============================] - 23s 157ms/step - loss: 0.1488 - accuracy: 0.9470 - val_loss: 1.6760 - val_accuracy: 0.5740\n",
      "Epoch 41/50\n",
      "145/145 [==============================] - 21s 141ms/step - loss: 0.1477 - accuracy: 0.9453 - val_loss: 1.7639 - val_accuracy: 0.5547\n",
      "Epoch 42/50\n",
      "145/145 [==============================] - 19s 133ms/step - loss: 0.1391 - accuracy: 0.9477 - val_loss: 1.7610 - val_accuracy: 0.5880\n",
      "Epoch 43/50\n",
      "145/145 [==============================] - 23s 162ms/step - loss: 0.1411 - accuracy: 0.9507 - val_loss: 1.7648 - val_accuracy: 0.5753\n",
      "Epoch 44/50\n",
      "145/145 [==============================] - 20s 136ms/step - loss: 0.1359 - accuracy: 0.9504 - val_loss: 1.7093 - val_accuracy: 0.5753\n",
      "Epoch 45/50\n",
      "145/145 [==============================] - 21s 145ms/step - loss: 0.1325 - accuracy: 0.9524 - val_loss: 1.6701 - val_accuracy: 0.5760\n",
      "Epoch 46/50\n",
      "145/145 [==============================] - 22s 152ms/step - loss: 0.1237 - accuracy: 0.9573 - val_loss: 1.7321 - val_accuracy: 0.5687\n",
      "Epoch 47/50\n",
      "145/145 [==============================] - 20s 136ms/step - loss: 0.1143 - accuracy: 0.9588 - val_loss: 1.8136 - val_accuracy: 0.5913\n",
      "Epoch 48/50\n",
      "145/145 [==============================] - 24s 167ms/step - loss: 0.1125 - accuracy: 0.9602 - val_loss: 1.7746 - val_accuracy: 0.5587\n",
      "Epoch 49/50\n",
      "145/145 [==============================] - 20s 137ms/step - loss: 0.1230 - accuracy: 0.9579 - val_loss: 1.7377 - val_accuracy: 0.5813\n",
      "Epoch 50/50\n",
      "145/145 [==============================] - 22s 155ms/step - loss: 0.1272 - accuracy: 0.9570 - val_loss: 1.7488 - val_accuracy: 0.5820\n",
      "(1740, 22, 500)\n",
      "(375, 22, 500)\n",
      "(443, 22, 500)\n"
     ]
    }
   ],
   "source": [
    "period_accuracy={}\n",
    "for i in range(300, 550, 50):\n",
    "  x_train, x_valid, x_test, y_train, y_valid, y_test = data_finalize(period=i, y_test=y_test)\n",
    "\n",
    "  basic_cnn_model = Sequential([\n",
    "\n",
    "      # Conv. block 1\n",
    "      keras.layers.Conv2D(filters=25, kernel_size=(10,1), padding='same', activation='relu', input_shape=(x_train.shape[1],1,22)),\n",
    "      keras.layers.MaxPooling2D(pool_size=(2,1), padding='same'), # Read the keras documentation\n",
    "      keras.layers.BatchNormalization(),\n",
    "      keras.layers.Dropout(0.5),\n",
    "\n",
    "      # Conv. block 2\n",
    "      keras.layers.Conv2D(filters=50, kernel_size=(8,1), padding='same', activation='relu'),\n",
    "      keras.layers.MaxPooling2D(pool_size=(2,1), padding='same'),\n",
    "      keras.layers.BatchNormalization(),\n",
    "      keras.layers.Dropout(0.5),\n",
    "\n",
    "      # Conv. block 3\n",
    "      keras.layers.Conv2D(filters=100, kernel_size=(8,1), padding='same', activation='relu'),\n",
    "      keras.layers.MaxPooling2D(pool_size=(2,1), padding='same'),\n",
    "      keras.layers.BatchNormalization(),\n",
    "      keras.layers.Dropout(0.5),\n",
    "\n",
    "      # Conv. block 4\n",
    "      keras.layers.Conv2D(filters=200, kernel_size=(8,1), padding='same', activation='relu'),\n",
    "      keras.layers.MaxPooling2D(pool_size=(2,1), padding='same'),\n",
    "      keras.layers.BatchNormalization(),\n",
    "      keras.layers.Dropout(0.5),\n",
    "\n",
    "      # Output layer with Softmax activation\n",
    "      keras.layers.Flatten(), # Flattens the input\n",
    "      keras.layers.Dense(50, activation='relu'), \n",
    "      keras.layers.Dense(4, activation='softmax') # Output FC layer with softmax activation\n",
    "\n",
    "  ])\n",
    "\n",
    "  # Printing the model summary\n",
    "  basic_cnn_model.summary()\n",
    "\n",
    "  \n",
    "\n",
    "  basic_cnn_model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer=cnn_optimizer,\n",
    "                 metrics=['accuracy'])\n",
    "  \n",
    "\n",
    "  # Training and validating the model\n",
    "  basic_cnn_model_results = basic_cnn_model.fit(x_train,\n",
    "              y_train,\n",
    "              batch_size=48,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_valid, y_valid), verbose=True)\n",
    "\n",
    "  val_acc = basic_cnn_model_results.history['val_accuracy'][49]\n",
    "  period_accuracy[str(i)] = val_acc\n",
    "print(period_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WqMPuChAH1va"
   },
   "outputs": [],
   "source": [
    "cnn_score = basic_cnn_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test accuracy of the basic CNN model:',cnn_score[1])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
