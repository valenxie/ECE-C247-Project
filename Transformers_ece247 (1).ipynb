{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "dkDKXTXzs-8C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3a295f5-ea72-417d-893a-b9fccaa8a195"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "id": "5DT3YzDfAoJG",
        "outputId": "294ffdb3-13f6-43e9-938d-5d4e7c29157a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.19.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typeguard>=2.7\n",
            "  Downloading typeguard-3.0.1-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow-addons) (23.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.9/dist-packages (from typeguard>=2.7->tensorflow-addons) (4.5.0)\n",
            "Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.9/dist-packages (from typeguard>=2.7->tensorflow-addons) (6.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=3.6->typeguard>=2.7->tensorflow-addons) (3.15.0)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.19.0 typeguard-3.0.1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7efed46f9430>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "!pip install -U tensorflow-addons\n",
        "from keras.layers.reshaping.flatten import Flatten\n",
        "from keras.layers.core.activation import Activation\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout\n",
        "from keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Reshape\n",
        "from keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "X_test = np.load(\"/content/drive/MyDrive/final/X_test.npy\")\n",
        "y_test = np.load(\"/content/drive/MyDrive/final/y_test.npy\")\n",
        "person_train_valid = np.load(\"/content/drive/MyDrive/final/person_train_valid.npy\")\n",
        "X_train_valid = np.load(\"/content/drive/MyDrive/final/X_train_valid.npy\")\n",
        "y_train_valid = np.load(\"/content/drive/MyDrive/final/y_train_valid.npy\")\n",
        "person_test = np.load(\"/content/drive/MyDrive/final/person_test.npy\")\n",
        "\n",
        "# X_test = torch.tensor(X_test)\n",
        "# y_test = torch.tensor(y_test)\n",
        "# person_train_valid = torch.tensor(person_train_valid)\n",
        "# X_train_valid = torch.tensor(X_train_valid)\n",
        "# y_train_valid = torch.tensor(y_train_valid)\n",
        "# person_test = torch.tensor(person_test)\n",
        "y_train_valid -= 769\n",
        "y_test -= 769\n",
        "\n",
        "## Visualizing the data\n",
        "\n",
        "ch_data = X_train_valid[:,8,:] # extracts the 9th channel from the data\n",
        "\n",
        "\n",
        "class_0_ind = np.where(y_train_valid == 0) # finds the indices where the label is 0\n",
        "ch_data_class_0 = ch_data[class_0_ind] # finds the data where label is 0\n",
        "avg_ch_data_class_0 = np.mean(ch_data_class_0,axis=0) # finds the average representation of the 9th channel when label is 0\n",
        "\n",
        "\n",
        "class_1_ind = np.where(y_train_valid == 1)\n",
        "ch_data_class_1 = ch_data[class_1_ind]\n",
        "avg_ch_data_class_1 = np.mean(ch_data_class_1,axis=0)\n",
        "\n",
        "class_2_ind = np.where(y_train_valid == 2)\n",
        "ch_data_class_2 = ch_data[class_2_ind]\n",
        "avg_ch_data_class_2 = np.mean(ch_data_class_2,axis=0)\n",
        "\n",
        "class_3_ind = np.where(y_train_valid == 3)\n",
        "ch_data_class_3 = ch_data[class_3_ind]\n",
        "avg_ch_data_class_3 = np.mean(ch_data_class_3,axis=0)\n",
        "\n",
        "\n",
        "plt.plot(np.arange(1000),avg_ch_data_class_0)\n",
        "plt.plot(np.arange(1000),avg_ch_data_class_1)\n",
        "plt.plot(np.arange(1000),avg_ch_data_class_2)\n",
        "plt.plot(np.arange(1000),avg_ch_data_class_3)\n",
        "plt.axvline(x=500, label='line at t=500',c='cyan')\n",
        "\n",
        "plt.legend([\"Cue Onset left\", \"Cue Onset right\", \"Cue onset foot\", \"Cue onset tongue\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvkwSOkwZCH2"
      },
      "outputs": [],
      "source": [
        "def data_prep(X,y,sub_sample,average,noise,period):\n",
        "    \n",
        "    total_X = None\n",
        "    total_y = None\n",
        "    \n",
        "    # Trimming the data (sample,22,1000) -> (sample,22,500)\n",
        "    X = X[:,:,0:period]\n",
        "\n",
        "    \n",
        "    # Maxpooling the data (sample,22,1000) -> (sample,22,500/sub_sample)\n",
        "    X_reshape = X.reshape(X.shape[0], X.shape[1], -1, sub_sample)\n",
        "    X_max = np.max(X_reshape, axis=3)\n",
        "    \n",
        "    total_X = X_max\n",
        "    total_y = y\n",
        "    \n",
        "    # Averaging + noise \n",
        "    X_average = np.mean(X.reshape(X.shape[0], X.shape[1], -1, average),axis=3)\n",
        "    if noise:\n",
        "      X_average = X_average + np.random.normal(0.0, 0.5, X_average.shape)\n",
        "    \n",
        "    total_X = np.vstack((total_X, X_average))\n",
        "    total_y = np.hstack((total_y, y))\n",
        "    \n",
        "    # Subsampling\n",
        "    \n",
        "    for i in range(sub_sample):\n",
        "        \n",
        "        X_subsample = X[:, :, i::sub_sample] + \\\n",
        "                            (np.random.normal(0.0, 0.5, X[:, :,i::sub_sample].shape) if noise else 0.0)\n",
        "            \n",
        "        total_X = np.vstack((total_X, X_subsample))\n",
        "        total_y = np.hstack((total_y, y))\n",
        "\n",
        "    return total_X,total_y\n",
        "        \n",
        "def data_finalize(period, total_number, takeout_sample, y_test=y_test): \n",
        "    ind_valid = np.random.choice(total_number, takeout_sample, replace=False)  # get 375 out of 2115 samples and no repetitation\n",
        "    ind_train = np.array(list(set(range(total_number)).difference(set(ind_valid)))) # a set(unordered) different with another set, set = set1 - set2\n",
        "\n",
        "    # Creating the training and validation sets using the generated indices\n",
        "    (X_train, X_valid) = X_train_valid[ind_train], X_train_valid[ind_valid] \n",
        "    (y_train, y_valid) = y_train_valid[ind_train], y_train_valid[ind_valid]\n",
        "    x_train,y_train = data_prep(X_train,y_train,2,2,True, period=period)\n",
        "    x_valid,y_valid = data_prep(X_valid,y_valid,2,2,True, period=period)\n",
        "    X_test_prep,y_test_prep = data_prep(X_test,y_test,2,2,True, period=period)\n",
        "\n",
        "    # Converting the labels to categorical variables for multiclass classification\n",
        "    y_train = to_categorical(y_train, 4)\n",
        "    y_valid = to_categorical(y_valid, 4)\n",
        "    y_test = to_categorical(y_test_prep, 4)\n",
        "\n",
        "    # Adding width of the segment to be 1\n",
        "    x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
        "    x_valid = x_valid.reshape(x_valid.shape[0], x_valid.shape[1], x_train.shape[2], 1)\n",
        "    x_test = X_test_prep.reshape(X_test_prep.shape[0], X_test_prep.shape[1], X_test_prep.shape[2], 1)\n",
        "\n",
        "\n",
        "    # Reshaping the training and validation dataset\n",
        "    x_train = np.swapaxes(x_train, 1,3)\n",
        "    x_train = np.swapaxes(x_train, 1,2)\n",
        "    x_valid = np.swapaxes(x_valid, 1,3)\n",
        "    x_valid = np.swapaxes(x_valid, 1,2)\n",
        "    x_test = np.swapaxes(x_test, 1,3)\n",
        "    x_test = np.swapaxes(x_test, 1,2)\n",
        "\n",
        "    return x_train, x_valid, x_test, y_train, y_valid, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HA3y2eIHspwj"
      },
      "outputs": [],
      "source": [
        "class Patches(layers.Layer):\n",
        "    def __init__(self, patch_size, channels):\n",
        "        super(Patches, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "        self.channels = channels\n",
        "\n",
        "    def call(self, images):\n",
        "        num_samples = tf.shape(images)[0]\n",
        "        \n",
        "        # Create a function to apply patchify_image with the given patch_size and channels\n",
        "        \n",
        "        patchify_image(image, patch_size, channels)\n",
        "        patches = tf.map_fn(process_image, images, fn_output_signature=tf.TensorSpec((None, None), tf.float32))\n",
        "        return patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEkII0VMaDB7"
      },
      "outputs": [],
      "source": [
        "def create_mlp(dim, hidden_dim, dropout=0.1):\n",
        "    return tf.keras.Sequential([\n",
        "        layers.Dense(hidden_dim, activation=tf.nn.gelu),\n",
        "        layers.Dropout(dropout),\n",
        "        layers.Dense(dim),\n",
        "        layers.Dropout(dropout)\n",
        "    ])\n",
        "\n",
        "\n",
        "def patchify_image(image, patch_size, channels):\n",
        "    h, w = image.shape[0], image.shape[1]\n",
        "    patches = tf.image.extract_patches(images=tf.expand_dims(image, 0),\n",
        "                                       sizes=[1, patch_size, patch_size, 1],\n",
        "                                       strides=[1, patch_size, patch_size, 1],\n",
        "                                       rates=[1, 1, 1, 1],\n",
        "                                       padding='VALID')\n",
        "    return tf.reshape(patches, (-1, patch_size * patch_size * channels))\n",
        "\n",
        "\n",
        "class Patches(layers.Layer):\n",
        "    def __init__(self, patch_size, channels):\n",
        "        super(Patches, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "        self.channels = channels\n",
        "\n",
        "    def call(self, images):\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        patches = tf.map_fn(lambda img: patchify_image(img, self.patch_size, self.channels), images, fn_output_signature=tf.TensorSpec((None, None), tf.float32))\n",
        "        return patches\n",
        "\n",
        "\n",
        "class ViTModel(tf.keras.Model):\n",
        "    def __init__(self, num_classes, height, width, patch_size, num_layers, num_heads, hidden_dim, mlp_dim, channels, dropout=0.1):\n",
        "        super(ViTModel, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        num_patches_h = height // patch_size\n",
        "        num_patches_w = 1\n",
        "        num_patches = num_patches_h * num_patches_w\n",
        "        patch_dim = channels * patch_size ** 2\n",
        "\n",
        "        self.patch_layer = Patches(patch_size, channels)\n",
        "        self.position_embeddings = layers.Embedding(input_dim=num_patches, output_dim=patch_dim)\n",
        "        self.class_token = tf.Variable(initial_value=tf.zeros(shape=(1, 1, patch_dim)), trainable=True)\n",
        "\n",
        "        self.transformer_layers = [\n",
        "            layers.MultiHeadAttention(num_heads=num_heads, key_dim=patch_dim, dropout=dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ]\n",
        "        self.norm_layers = [layers.LayerNormalization(epsilon=1e-6) for _ in range(num_layers)]\n",
        "        self.mlp_layers = [create_mlp(dim=patch_dim, hidden_dim=mlp_dim, dropout=dropout) for _ in range(num_layers)]\n",
        "\n",
        "        self.pooling = layers.GlobalAveragePooling1D()\n",
        "        self.classification = layers.Dense(num_classes, activation='softmax')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        patches = self.patch_layer(inputs)\n",
        "        position_embeddings = self.position_embeddings(tf.range(0, tf.shape(patches)[1]))\n",
        "        x = patches + position_embeddings\n",
        "        class_tokens = tf.broadcast_to(self.class_token, [batch_size, 1, self.class_token.shape[-1]])\n",
        "        x = tf.concat([class_tokens, x], axis=1)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            attention_output = self.transformer_layers[i](x, x)\n",
        "            x = x + attention_output\n",
        "            x = self.norm_layers[i](x)\n",
        "            mlp_output = self.mlp_layers[i](x)\n",
        "            x = x + mlp_output\n",
        "\n",
        "        x = self.pooling(x)\n",
        "        x = self.classification(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def create_vit_classifier(num_classes, height, width=1, patch_size=1, num_layers=3, num_heads=8, hidden_dim=200, mlp_dim=300, channels=22, dropout=0.5):\n",
        "    return ViTModel(num_classes=num_classes, height=height, width=width, patch_size=patch_size, num_layers=num_layers, num_heads=num_heads, hidden_dim=hidden_dim, mlp_dim=mlp_dim, channels=channels, dropout=dropout)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwRihWgQspwk"
      },
      "outputs": [],
      "source": [
        "# get subject 1 data for training and validation set\n",
        "person_train_valid = person_train_valid.flatten()\n",
        "X_train_valid=X_train_valid[np.where(person_train_valid==0)]\n",
        "y_train_valid=y_train_valid[np.where(person_train_valid==0)]\n",
        "\n",
        "x_train, x_valid, x_test, y_train, y_valid, y_test = data_finalize(total_number=237, takeout_sample=42, period=1000, y_test=y_test)\n",
        "\n",
        "# get subject 1 data for test set\n",
        "person_test=person_test.flatten()\n",
        "X_test_sub1 = x_test[np.where(person_test==0)]\n",
        "y_test_sub1 = y_test[np.where(person_test==0)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dehE9Yf9aC_o",
        "outputId": "720aa6c1-9fd6-4dee-f899-51b5b87314b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "25/25 [==============================] - 14s 278ms/step - loss: 1.3661 - accuracy: 0.3192 - val_loss: 1.5289 - val_accuracy: 0.2440\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 5s 212ms/step - loss: 1.2899 - accuracy: 0.4038 - val_loss: 1.5955 - val_accuracy: 0.2857\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 5s 214ms/step - loss: 1.1851 - accuracy: 0.4936 - val_loss: 2.0767 - val_accuracy: 0.2798\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 4s 179ms/step - loss: 1.1794 - accuracy: 0.4654 - val_loss: 1.5901 - val_accuracy: 0.3452\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 5s 190ms/step - loss: 0.9937 - accuracy: 0.5897 - val_loss: 1.7021 - val_accuracy: 0.3155\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.9978 - accuracy: 0.5615 - val_loss: 1.6252 - val_accuracy: 0.3631\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 5s 190ms/step - loss: 0.8611 - accuracy: 0.6449 - val_loss: 1.7605 - val_accuracy: 0.3869\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 4s 176ms/step - loss: 0.8093 - accuracy: 0.6641 - val_loss: 1.6848 - val_accuracy: 0.3690\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 5s 184ms/step - loss: 0.7324 - accuracy: 0.7077 - val_loss: 1.8838 - val_accuracy: 0.4107\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 5s 189ms/step - loss: 0.6646 - accuracy: 0.7410 - val_loss: 2.1490 - val_accuracy: 0.3869\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - 4s 175ms/step - loss: 0.5160 - accuracy: 0.7910 - val_loss: 2.2621 - val_accuracy: 0.4048\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 5s 184ms/step - loss: 0.5386 - accuracy: 0.7872 - val_loss: 2.3637 - val_accuracy: 0.4226\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 4s 175ms/step - loss: 0.4814 - accuracy: 0.8090 - val_loss: 2.3639 - val_accuracy: 0.3929\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 4s 175ms/step - loss: 0.4126 - accuracy: 0.8346 - val_loss: 2.7689 - val_accuracy: 0.4226\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.3922 - accuracy: 0.8513 - val_loss: 2.4760 - val_accuracy: 0.4821\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - 5s 188ms/step - loss: 0.4291 - accuracy: 0.8397 - val_loss: 2.4074 - val_accuracy: 0.4226\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - 4s 174ms/step - loss: 0.2452 - accuracy: 0.9179 - val_loss: 3.1008 - val_accuracy: 0.4167\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.3773 - accuracy: 0.8679 - val_loss: 3.2722 - val_accuracy: 0.3929\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - 4s 175ms/step - loss: 0.4294 - accuracy: 0.8282 - val_loss: 2.7407 - val_accuracy: 0.4048\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - 4s 174ms/step - loss: 0.2654 - accuracy: 0.9115 - val_loss: 2.6906 - val_accuracy: 0.4226\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - 5s 185ms/step - loss: 0.1298 - accuracy: 0.9577 - val_loss: 3.5329 - val_accuracy: 0.4643\n",
            "Epoch 22/50\n",
            "25/25 [==============================] - 4s 174ms/step - loss: 0.1810 - accuracy: 0.9333 - val_loss: 3.6127 - val_accuracy: 0.4702\n",
            "Epoch 23/50\n",
            "25/25 [==============================] - 4s 174ms/step - loss: 0.2497 - accuracy: 0.9115 - val_loss: 3.4450 - val_accuracy: 0.4048\n",
            "Epoch 24/50\n",
            "25/25 [==============================] - 5s 186ms/step - loss: 0.1260 - accuracy: 0.9564 - val_loss: 3.6215 - val_accuracy: 0.3988\n",
            "Epoch 25/50\n",
            "25/25 [==============================] - 5s 187ms/step - loss: 0.1126 - accuracy: 0.9615 - val_loss: 3.7878 - val_accuracy: 0.4345\n",
            "Epoch 26/50\n",
            "25/25 [==============================] - 4s 175ms/step - loss: 0.1556 - accuracy: 0.9385 - val_loss: 3.9769 - val_accuracy: 0.4702\n",
            "Epoch 27/50\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.1442 - accuracy: 0.9397 - val_loss: 3.9411 - val_accuracy: 0.4643\n",
            "Epoch 28/50\n",
            "25/25 [==============================] - 5s 188ms/step - loss: 0.1637 - accuracy: 0.9385 - val_loss: 3.7568 - val_accuracy: 0.4286\n",
            "Epoch 29/50\n",
            "25/25 [==============================] - 4s 176ms/step - loss: 0.1264 - accuracy: 0.9423 - val_loss: 3.9750 - val_accuracy: 0.4405\n",
            "Epoch 30/50\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0810 - accuracy: 0.9654 - val_loss: 3.7101 - val_accuracy: 0.4643\n",
            "Epoch 31/50\n",
            "25/25 [==============================] - 4s 176ms/step - loss: 0.0886 - accuracy: 0.9718 - val_loss: 4.3570 - val_accuracy: 0.3631\n",
            "Epoch 32/50\n",
            "25/25 [==============================] - 4s 174ms/step - loss: 0.0695 - accuracy: 0.9782 - val_loss: 4.4819 - val_accuracy: 0.4345\n",
            "Epoch 33/50\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0568 - accuracy: 0.9782 - val_loss: 4.5752 - val_accuracy: 0.4107\n",
            "Epoch 34/50\n",
            "25/25 [==============================] - 4s 174ms/step - loss: 0.0656 - accuracy: 0.9718 - val_loss: 5.1544 - val_accuracy: 0.3571\n",
            "Epoch 35/50\n",
            "25/25 [==============================] - 4s 175ms/step - loss: 0.1913 - accuracy: 0.9346 - val_loss: 4.1941 - val_accuracy: 0.4107\n",
            "Epoch 36/50\n",
            "25/25 [==============================] - 5s 186ms/step - loss: 0.1609 - accuracy: 0.9372 - val_loss: 4.5952 - val_accuracy: 0.4405\n",
            "Epoch 37/50\n",
            "25/25 [==============================] - 4s 175ms/step - loss: 0.1122 - accuracy: 0.9564 - val_loss: 4.1487 - val_accuracy: 0.4167\n",
            "Epoch 38/50\n",
            "25/25 [==============================] - 4s 174ms/step - loss: 0.0659 - accuracy: 0.9782 - val_loss: 3.9415 - val_accuracy: 0.4762\n",
            "Epoch 39/50\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0273 - accuracy: 0.9910 - val_loss: 4.6611 - val_accuracy: 0.4167\n",
            "Epoch 40/50\n",
            "25/25 [==============================] - 4s 175ms/step - loss: 0.0237 - accuracy: 0.9910 - val_loss: 4.6851 - val_accuracy: 0.4643\n",
            "Epoch 41/50\n",
            "25/25 [==============================] - 4s 175ms/step - loss: 0.0284 - accuracy: 0.9897 - val_loss: 4.8515 - val_accuracy: 0.4286\n",
            "Epoch 42/50\n",
            "25/25 [==============================] - 5s 184ms/step - loss: 0.0203 - accuracy: 0.9936 - val_loss: 5.2086 - val_accuracy: 0.4583\n",
            "Epoch 43/50\n",
            "25/25 [==============================] - 4s 174ms/step - loss: 0.0162 - accuracy: 0.9949 - val_loss: 5.0072 - val_accuracy: 0.4048\n",
            "Epoch 44/50\n",
            "25/25 [==============================] - 4s 175ms/step - loss: 0.0253 - accuracy: 0.9897 - val_loss: 5.1086 - val_accuracy: 0.3869\n",
            "Epoch 45/50\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0175 - accuracy: 0.9949 - val_loss: 5.1174 - val_accuracy: 0.4226\n",
            "Epoch 46/50\n",
            "25/25 [==============================] - 4s 175ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 5.4103 - val_accuracy: 0.4286\n",
            "Epoch 47/50\n",
            "25/25 [==============================] - 4s 176ms/step - loss: 0.0065 - accuracy: 0.9987 - val_loss: 5.2909 - val_accuracy: 0.4524\n",
            "Epoch 48/50\n",
            "25/25 [==============================] - 5s 185ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 5.4325 - val_accuracy: 0.4286\n",
            "Epoch 49/50\n",
            "25/25 [==============================] - 4s 175ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 5.4239 - val_accuracy: 0.4345\n",
            "Epoch 50/50\n",
            "25/25 [==============================] - 4s 175ms/step - loss: 8.2607e-04 - accuracy: 1.0000 - val_loss: 5.4173 - val_accuracy: 0.4405\n"
          ]
        }
      ],
      "source": [
        "num_classes = 4  \n",
        "height = x_train.shape[1]\n",
        "width = 1\n",
        "channel = 22\n",
        "input_shape = (height, width, channel)\n",
        "# Create the ViT model\n",
        "vit_classifier = create_vit_classifier(num_classes, height=height, width=width)\n",
        "\n",
        "# Compile the model\n",
        "vit_classifier.build(input_shape=(None, *input_shape))\n",
        "vit_classifier.compile(optimizer=tfa.optimizers.AdamW(learning_rate=1e-3, weight_decay=1e-4),\n",
        "                       loss='categorical_crossentropy',\n",
        "                       metrics=['accuracy'])\n",
        "epochs = 50  # Set the number of epochs you want to train for\n",
        "batch_size = 32  # Set the batch size for training\n",
        "\n",
        "history = vit_classifier.fit(x_train, y_train,\n",
        "                             batch_size=batch_size,\n",
        "                             epochs=epochs,\n",
        "                             verbose=True,\n",
        "                             validation_data=(x_valid, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6XiKUluaC9b",
        "outputId": "b4153764-c3cb-4366-bce9-c413fa750455",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy of the basic CNN model: 0.25999999046325684\n"
          ]
        }
      ],
      "source": [
        "transformer_score = vit_classifier.evaluate(X_test_sub1, y_test_sub1, verbose=0)\n",
        "print('Test accuracy of the basic CNN model:',transformer_score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkKFeDckaC6u",
        "outputId": "0a2ded38-1d81-484f-a66c-66c6a18e19f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "218/218 [==============================] - 43s 185ms/step - loss: 1.3791 - accuracy: 0.2874 - val_loss: 1.4226 - val_accuracy: 0.2493\n",
            "Epoch 2/50\n",
            "218/218 [==============================] - 39s 180ms/step - loss: 1.3663 - accuracy: 0.3080 - val_loss: 1.4194 - val_accuracy: 0.3093\n",
            "Epoch 3/50\n",
            "218/218 [==============================] - 39s 180ms/step - loss: 1.3566 - accuracy: 0.3208 - val_loss: 1.4312 - val_accuracy: 0.3073\n",
            "Epoch 4/50\n",
            "218/218 [==============================] - 42s 191ms/step - loss: 1.3463 - accuracy: 0.3297 - val_loss: 1.4200 - val_accuracy: 0.2873\n",
            "Epoch 5/50\n",
            "218/218 [==============================] - 39s 179ms/step - loss: 1.3353 - accuracy: 0.3486 - val_loss: 1.3900 - val_accuracy: 0.3127\n",
            "Epoch 6/50\n",
            "218/218 [==============================] - 41s 190ms/step - loss: 1.3305 - accuracy: 0.3552 - val_loss: 1.5155 - val_accuracy: 0.3233\n",
            "Epoch 7/50\n",
            "218/218 [==============================] - 41s 190ms/step - loss: 1.3207 - accuracy: 0.3714 - val_loss: 1.4640 - val_accuracy: 0.3213\n",
            "Epoch 8/50\n",
            "218/218 [==============================] - 39s 180ms/step - loss: 1.3067 - accuracy: 0.3685 - val_loss: 1.4281 - val_accuracy: 0.3127\n",
            "Epoch 9/50\n",
            "218/218 [==============================] - 39s 179ms/step - loss: 1.2837 - accuracy: 0.3978 - val_loss: 1.3855 - val_accuracy: 0.3167\n",
            "Epoch 10/50\n",
            "218/218 [==============================] - 39s 179ms/step - loss: 1.2685 - accuracy: 0.4063 - val_loss: 1.5157 - val_accuracy: 0.3233\n",
            "Epoch 11/50\n",
            "218/218 [==============================] - 39s 179ms/step - loss: 1.2504 - accuracy: 0.4289 - val_loss: 1.3907 - val_accuracy: 0.3307\n",
            "Epoch 12/50\n",
            "218/218 [==============================] - 39s 178ms/step - loss: 1.2254 - accuracy: 0.4366 - val_loss: 1.4208 - val_accuracy: 0.3340\n",
            "Epoch 13/50\n",
            "218/218 [==============================] - 41s 190ms/step - loss: 1.2016 - accuracy: 0.4591 - val_loss: 1.5427 - val_accuracy: 0.3447\n",
            "Epoch 14/50\n",
            "218/218 [==============================] - 39s 179ms/step - loss: 1.1905 - accuracy: 0.4645 - val_loss: 1.5254 - val_accuracy: 0.3100\n",
            "Epoch 15/50\n",
            "218/218 [==============================] - 41s 190ms/step - loss: 1.1714 - accuracy: 0.4707 - val_loss: 1.4189 - val_accuracy: 0.3173\n",
            "Epoch 16/50\n",
            "218/218 [==============================] - 39s 179ms/step - loss: 1.1450 - accuracy: 0.5000 - val_loss: 1.4720 - val_accuracy: 0.3440\n",
            "Epoch 17/50\n",
            "218/218 [==============================] - 42s 191ms/step - loss: 1.1179 - accuracy: 0.5136 - val_loss: 1.5614 - val_accuracy: 0.3267\n",
            "Epoch 18/50\n",
            "218/218 [==============================] - 41s 190ms/step - loss: 1.0941 - accuracy: 0.5217 - val_loss: 1.4868 - val_accuracy: 0.3307\n",
            "Epoch 19/50\n",
            "218/218 [==============================] - 39s 180ms/step - loss: 1.0687 - accuracy: 0.5381 - val_loss: 1.5422 - val_accuracy: 0.3593\n",
            "Epoch 20/50\n",
            "218/218 [==============================] - 39s 179ms/step - loss: 1.0496 - accuracy: 0.5448 - val_loss: 1.7281 - val_accuracy: 0.3147\n",
            "Epoch 21/50\n",
            "218/218 [==============================] - 42s 191ms/step - loss: 1.0228 - accuracy: 0.5611 - val_loss: 1.6493 - val_accuracy: 0.3300\n",
            "Epoch 22/50\n",
            "218/218 [==============================] - 39s 180ms/step - loss: 1.0172 - accuracy: 0.5672 - val_loss: 1.8199 - val_accuracy: 0.3247\n",
            "Epoch 23/50\n",
            "218/218 [==============================] - 42s 191ms/step - loss: 1.0064 - accuracy: 0.5720 - val_loss: 1.5586 - val_accuracy: 0.3533\n",
            "Epoch 24/50\n",
            "218/218 [==============================] - 39s 179ms/step - loss: 0.9856 - accuracy: 0.5835 - val_loss: 1.7060 - val_accuracy: 0.3493\n",
            "Epoch 25/50\n",
            "218/218 [==============================] - 42s 191ms/step - loss: 0.9443 - accuracy: 0.6033 - val_loss: 1.7286 - val_accuracy: 0.3673\n",
            "Epoch 26/50\n",
            "218/218 [==============================] - 39s 179ms/step - loss: 0.9370 - accuracy: 0.6032 - val_loss: 1.7626 - val_accuracy: 0.3633\n",
            "Epoch 27/50\n",
            "218/218 [==============================] - 41s 190ms/step - loss: 0.9201 - accuracy: 0.6162 - val_loss: 1.7532 - val_accuracy: 0.3440\n",
            "Epoch 28/50\n",
            "218/218 [==============================] - 39s 179ms/step - loss: 0.9058 - accuracy: 0.6231 - val_loss: 1.8898 - val_accuracy: 0.3500\n",
            "Epoch 29/50\n",
            "218/218 [==============================] - 41s 190ms/step - loss: 0.8767 - accuracy: 0.6397 - val_loss: 1.9261 - val_accuracy: 0.3567\n",
            "Epoch 30/50\n",
            "218/218 [==============================] - 41s 190ms/step - loss: 0.8747 - accuracy: 0.6359 - val_loss: 2.2131 - val_accuracy: 0.3613\n",
            "Epoch 31/50\n",
            "218/218 [==============================] - 39s 179ms/step - loss: 0.8580 - accuracy: 0.6513 - val_loss: 1.7905 - val_accuracy: 0.3527\n",
            "Epoch 32/50\n",
            "218/218 [==============================] - 41s 190ms/step - loss: 0.8363 - accuracy: 0.6552 - val_loss: 2.0062 - val_accuracy: 0.3420\n",
            "Epoch 33/50\n",
            "218/218 [==============================] - 41s 190ms/step - loss: 0.8174 - accuracy: 0.6682 - val_loss: 1.7789 - val_accuracy: 0.3560\n",
            "Epoch 34/50\n",
            "218/218 [==============================] - 41s 190ms/step - loss: 0.7882 - accuracy: 0.6770 - val_loss: 2.1235 - val_accuracy: 0.3533\n",
            "Epoch 35/50\n",
            "218/218 [==============================] - 39s 178ms/step - loss: 0.7805 - accuracy: 0.6833 - val_loss: 1.9739 - val_accuracy: 0.3707\n",
            "Epoch 36/50\n",
            "218/218 [==============================] - 41s 190ms/step - loss: 0.7853 - accuracy: 0.6836 - val_loss: 2.0218 - val_accuracy: 0.3540\n",
            "Epoch 37/50\n",
            "218/218 [==============================] - 39s 178ms/step - loss: 0.7492 - accuracy: 0.7075 - val_loss: 1.9513 - val_accuracy: 0.3587\n",
            "Epoch 38/50\n",
            "218/218 [==============================] - 41s 190ms/step - loss: 0.7564 - accuracy: 0.6943 - val_loss: 2.0858 - val_accuracy: 0.3727\n",
            "Epoch 39/50\n",
            "218/218 [==============================] - 41s 190ms/step - loss: 0.7459 - accuracy: 0.6984 - val_loss: 1.8872 - val_accuracy: 0.3833\n",
            "Epoch 40/50\n",
            "218/218 [==============================] - 41s 190ms/step - loss: 0.7475 - accuracy: 0.7001 - val_loss: 1.9129 - val_accuracy: 0.3780\n",
            "Epoch 41/50\n",
            "218/218 [==============================] - 39s 179ms/step - loss: 0.7055 - accuracy: 0.7217 - val_loss: 2.0564 - val_accuracy: 0.3607\n",
            "Epoch 42/50\n",
            "218/218 [==============================] - 39s 178ms/step - loss: 0.7025 - accuracy: 0.7144 - val_loss: 2.0167 - val_accuracy: 0.3600\n",
            "Epoch 43/50\n",
            "218/218 [==============================] - 41s 190ms/step - loss: 0.6746 - accuracy: 0.7320 - val_loss: 2.1014 - val_accuracy: 0.3593\n",
            "Epoch 44/50\n",
            "218/218 [==============================] - 41s 190ms/step - loss: 0.6876 - accuracy: 0.7234 - val_loss: 1.9134 - val_accuracy: 0.3773\n",
            "Epoch 45/50\n",
            "218/218 [==============================] - 41s 190ms/step - loss: 0.6800 - accuracy: 0.7264 - val_loss: 2.2897 - val_accuracy: 0.3647\n",
            "Epoch 46/50\n",
            "218/218 [==============================] - 39s 178ms/step - loss: 0.6501 - accuracy: 0.7480 - val_loss: 2.3798 - val_accuracy: 0.3520\n",
            "Epoch 47/50\n",
            "218/218 [==============================] - 41s 190ms/step - loss: 0.6588 - accuracy: 0.7348 - val_loss: 2.4054 - val_accuracy: 0.3600\n",
            "Epoch 48/50\n",
            "218/218 [==============================] - 41s 190ms/step - loss: 0.6499 - accuracy: 0.7441 - val_loss: 2.0076 - val_accuracy: 0.3867\n",
            "Epoch 49/50\n",
            "218/218 [==============================] - 41s 190ms/step - loss: 0.6148 - accuracy: 0.7523 - val_loss: 2.3038 - val_accuracy: 0.3733\n",
            "Epoch 50/50\n",
            "218/218 [==============================] - 39s 178ms/step - loss: 0.6281 - accuracy: 0.7503 - val_loss: 2.2711 - val_accuracy: 0.3827\n"
          ]
        }
      ],
      "source": [
        "X_test = np.load(\"/content/drive/MyDrive/final/X_test.npy\")\n",
        "y_test = np.load(\"/content/drive/MyDrive/final/y_test.npy\")\n",
        "X_train_valid = np.load(\"/content/drive/MyDrive/final/X_train_valid.npy\")\n",
        "y_train_valid = np.load(\"/content/drive/MyDrive/final/y_train_valid.npy\")\n",
        "y_train_valid -= 769\n",
        "y_test -= 769\n",
        "x_train, x_valid, x_test, y_train, y_valid, y_test = data_finalize(total_number=2115, takeout_sample=375, period=1000, y_test=y_test)\n",
        "num_classes = 4  \n",
        "height = x_train.shape[1]\n",
        "width = 1\n",
        "channel = 22\n",
        "input_shape = (height, width, channel)\n",
        "# Create the ViT model\n",
        "vit_classifier = create_vit_classifier(num_classes, height=height, width=width)\n",
        "\n",
        "# Compile the model\n",
        "vit_classifier.build(input_shape=(None, *input_shape))\n",
        "vit_classifier.compile(optimizer=tfa.optimizers.AdamW(learning_rate=1e-3, weight_decay=1e-4),\n",
        "                       loss='categorical_crossentropy',\n",
        "                       metrics=['accuracy'])\n",
        "epochs = 50  # Set the number of epochs you want to train for\n",
        "batch_size = 32  # Set the batch size for training\n",
        "\n",
        "history = vit_classifier.fit(x_train, y_train,\n",
        "                             batch_size=batch_size,\n",
        "                             epochs=epochs,\n",
        "                             verbose=True,\n",
        "                             validation_data=(x_valid, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GoXsiLSuaC0M",
        "outputId": "8288644f-79e9-4d94-ff4a-04c6e0aa78ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50, 500, 1, 22) (50, 4)\n",
            "Test accuracy of the basic CNN model: 0.4399999976158142\n"
          ]
        }
      ],
      "source": [
        "print(X_test_sub1.shape, y_test_sub1.shape)\n",
        "transformer_score = vit_classifier.evaluate(X_test_sub1, y_test_sub1, verbose=0)\n",
        "print('Test accuracy of the basic CNN model:',transformer_score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqMPuChAH1va",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7045e8a-dda4-454e-a7a5-a8b168fcacd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1772, 500, 1, 22) (1772, 4)\n",
            "Test accuracy of the basic CNN model: 0.42607223987579346\n"
          ]
        }
      ],
      "source": [
        "print(x_test.shape, y_test.shape)\n",
        "transformer_score = vit_classifier.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test accuracy of the basic CNN model:',transformer_score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9PZ82UOspwm",
        "outputId": "77532142-0588-4611-b08b-2d99102c8af4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "218/218 [==============================] - 9s 26ms/step - loss: 1.3748 - accuracy: 0.3167 - val_loss: 1.3931 - val_accuracy: 0.2987\n",
            "Epoch 2/50\n",
            "218/218 [==============================] - 5s 22ms/step - loss: 1.3501 - accuracy: 0.3358 - val_loss: 1.3534 - val_accuracy: 0.3173\n",
            "Epoch 3/50\n",
            "218/218 [==============================] - 6s 27ms/step - loss: 1.3331 - accuracy: 0.3569 - val_loss: 1.3679 - val_accuracy: 0.3027\n",
            "Epoch 4/50\n",
            "218/218 [==============================] - 5s 22ms/step - loss: 1.3234 - accuracy: 0.3616 - val_loss: 1.3780 - val_accuracy: 0.3160\n",
            "Epoch 5/50\n",
            "218/218 [==============================] - 6s 27ms/step - loss: 1.3125 - accuracy: 0.3740 - val_loss: 1.3787 - val_accuracy: 0.3127\n",
            "Epoch 6/50\n",
            "218/218 [==============================] - 5s 22ms/step - loss: 1.3030 - accuracy: 0.3795 - val_loss: 1.3723 - val_accuracy: 0.3213\n",
            "Epoch 7/50\n",
            "218/218 [==============================] - 5s 22ms/step - loss: 1.2992 - accuracy: 0.3945 - val_loss: 1.3698 - val_accuracy: 0.3393\n",
            "Epoch 8/50\n",
            "218/218 [==============================] - 6s 27ms/step - loss: 1.2893 - accuracy: 0.3963 - val_loss: 1.4109 - val_accuracy: 0.3307\n",
            "Epoch 9/50\n",
            "218/218 [==============================] - 5s 22ms/step - loss: 1.2852 - accuracy: 0.3948 - val_loss: 1.4416 - val_accuracy: 0.2813\n",
            "Epoch 10/50\n",
            "218/218 [==============================] - 6s 27ms/step - loss: 1.2764 - accuracy: 0.4007 - val_loss: 1.4271 - val_accuracy: 0.3053\n",
            "Epoch 11/50\n",
            "218/218 [==============================] - 5s 22ms/step - loss: 1.2739 - accuracy: 0.4086 - val_loss: 1.4110 - val_accuracy: 0.3367\n",
            "Epoch 12/50\n",
            "218/218 [==============================] - 5s 25ms/step - loss: 1.2720 - accuracy: 0.4052 - val_loss: 1.4064 - val_accuracy: 0.3247\n",
            "Epoch 13/50\n",
            "218/218 [==============================] - 5s 25ms/step - loss: 1.2622 - accuracy: 0.4237 - val_loss: 1.4450 - val_accuracy: 0.3313\n",
            "Epoch 14/50\n",
            "218/218 [==============================] - 5s 22ms/step - loss: 1.2546 - accuracy: 0.4253 - val_loss: 1.4338 - val_accuracy: 0.3120\n",
            "Epoch 15/50\n",
            "218/218 [==============================] - 6s 27ms/step - loss: 1.2399 - accuracy: 0.4307 - val_loss: 1.4780 - val_accuracy: 0.3260\n",
            "Epoch 16/50\n",
            "218/218 [==============================] - 5s 22ms/step - loss: 1.2357 - accuracy: 0.4319 - val_loss: 1.4166 - val_accuracy: 0.3353\n",
            "Epoch 17/50\n",
            "218/218 [==============================] - 6s 26ms/step - loss: 1.2282 - accuracy: 0.4368 - val_loss: 1.4613 - val_accuracy: 0.3233\n",
            "Epoch 18/50\n",
            "218/218 [==============================] - 5s 23ms/step - loss: 1.2176 - accuracy: 0.4477 - val_loss: 1.4543 - val_accuracy: 0.3113\n",
            "Epoch 19/50\n",
            "218/218 [==============================] - 5s 22ms/step - loss: 1.2103 - accuracy: 0.4605 - val_loss: 1.4458 - val_accuracy: 0.2993\n",
            "Epoch 20/50\n",
            "218/218 [==============================] - 6s 27ms/step - loss: 1.1987 - accuracy: 0.4606 - val_loss: 1.4911 - val_accuracy: 0.3107\n",
            "Epoch 21/50\n",
            "218/218 [==============================] - 5s 22ms/step - loss: 1.1914 - accuracy: 0.4642 - val_loss: 1.5434 - val_accuracy: 0.2827\n",
            "Epoch 22/50\n",
            "218/218 [==============================] - 6s 27ms/step - loss: 1.1853 - accuracy: 0.4700 - val_loss: 1.5232 - val_accuracy: 0.3087\n",
            "Epoch 23/50\n",
            "218/218 [==============================] - 5s 22ms/step - loss: 1.1710 - accuracy: 0.4753 - val_loss: 1.4997 - val_accuracy: 0.3053\n",
            "Epoch 24/50\n",
            "218/218 [==============================] - 5s 22ms/step - loss: 1.1566 - accuracy: 0.4898 - val_loss: 1.5576 - val_accuracy: 0.3180\n",
            "Epoch 25/50\n",
            "218/218 [==============================] - 6s 27ms/step - loss: 1.1435 - accuracy: 0.4993 - val_loss: 1.6559 - val_accuracy: 0.3020\n",
            "Epoch 26/50\n",
            "218/218 [==============================] - 5s 22ms/step - loss: 1.1206 - accuracy: 0.5037 - val_loss: 1.5736 - val_accuracy: 0.3253\n",
            "Epoch 27/50\n",
            "218/218 [==============================] - 6s 29ms/step - loss: 1.1169 - accuracy: 0.5080 - val_loss: 1.6087 - val_accuracy: 0.3040\n",
            "Epoch 28/50\n",
            "218/218 [==============================] - 5s 22ms/step - loss: 1.1039 - accuracy: 0.5118 - val_loss: 1.5788 - val_accuracy: 0.3100\n",
            "Epoch 29/50\n",
            "218/218 [==============================] - 5s 23ms/step - loss: 1.1025 - accuracy: 0.5234 - val_loss: 1.5849 - val_accuracy: 0.2833\n",
            "Epoch 30/50\n",
            "218/218 [==============================] - 6s 27ms/step - loss: 1.0678 - accuracy: 0.5346 - val_loss: 1.6787 - val_accuracy: 0.2993\n",
            "Epoch 31/50\n",
            "218/218 [==============================] - 5s 22ms/step - loss: 1.0552 - accuracy: 0.5453 - val_loss: 1.6498 - val_accuracy: 0.3280\n",
            "Epoch 32/50\n",
            "218/218 [==============================] - 6s 28ms/step - loss: 1.0424 - accuracy: 0.5539 - val_loss: 1.6526 - val_accuracy: 0.2980\n",
            "Epoch 33/50\n",
            "218/218 [==============================] - 5s 22ms/step - loss: 1.0356 - accuracy: 0.5543 - val_loss: 1.6595 - val_accuracy: 0.3267\n",
            "Epoch 34/50\n",
            "218/218 [==============================] - 5s 25ms/step - loss: 1.0148 - accuracy: 0.5648 - val_loss: 1.7711 - val_accuracy: 0.3033\n",
            "Epoch 35/50\n",
            "218/218 [==============================] - 6s 25ms/step - loss: 1.0006 - accuracy: 0.5858 - val_loss: 1.7593 - val_accuracy: 0.2993\n",
            "Epoch 36/50\n",
            "218/218 [==============================] - 5s 22ms/step - loss: 0.9904 - accuracy: 0.5799 - val_loss: 1.7411 - val_accuracy: 0.2887\n",
            "Epoch 37/50\n",
            "218/218 [==============================] - 6s 27ms/step - loss: 0.9684 - accuracy: 0.5980 - val_loss: 1.8161 - val_accuracy: 0.3073\n",
            "Epoch 38/50\n",
            "218/218 [==============================] - 5s 22ms/step - loss: 0.9597 - accuracy: 0.5961 - val_loss: 1.7355 - val_accuracy: 0.2980\n",
            "Epoch 39/50\n",
            "218/218 [==============================] - 6s 26ms/step - loss: 0.9520 - accuracy: 0.6056 - val_loss: 1.7800 - val_accuracy: 0.3147\n",
            "Epoch 40/50\n",
            "218/218 [==============================] - 5s 23ms/step - loss: 0.9435 - accuracy: 0.6112 - val_loss: 1.7899 - val_accuracy: 0.3173\n",
            "Epoch 41/50\n",
            "218/218 [==============================] - 5s 22ms/step - loss: 0.9480 - accuracy: 0.6022 - val_loss: 1.7275 - val_accuracy: 0.3413\n",
            "Epoch 42/50\n",
            "218/218 [==============================] - 6s 27ms/step - loss: 0.9161 - accuracy: 0.6226 - val_loss: 1.8177 - val_accuracy: 0.3260\n",
            "Epoch 43/50\n",
            "218/218 [==============================] - 5s 22ms/step - loss: 0.9141 - accuracy: 0.6251 - val_loss: 1.9589 - val_accuracy: 0.3127\n",
            "Epoch 44/50\n",
            "218/218 [==============================] - 6s 28ms/step - loss: 0.8915 - accuracy: 0.6233 - val_loss: 1.8968 - val_accuracy: 0.3073\n",
            "Epoch 45/50\n",
            "218/218 [==============================] - 5s 22ms/step - loss: 0.9043 - accuracy: 0.6318 - val_loss: 1.8167 - val_accuracy: 0.3327\n",
            "Epoch 46/50\n",
            "218/218 [==============================] - 5s 22ms/step - loss: 0.8828 - accuracy: 0.6374 - val_loss: 1.9202 - val_accuracy: 0.3273\n",
            "Epoch 47/50\n",
            "218/218 [==============================] - 6s 27ms/step - loss: 0.8726 - accuracy: 0.6339 - val_loss: 1.8902 - val_accuracy: 0.3233\n",
            "Epoch 48/50\n",
            "218/218 [==============================] - 5s 22ms/step - loss: 0.8598 - accuracy: 0.6431 - val_loss: 1.9130 - val_accuracy: 0.2993\n",
            "Epoch 49/50\n",
            "218/218 [==============================] - 6s 27ms/step - loss: 0.8515 - accuracy: 0.6480 - val_loss: 1.8925 - val_accuracy: 0.3060\n",
            "Epoch 50/50\n",
            "218/218 [==============================] - 5s 22ms/step - loss: 0.8312 - accuracy: 0.6601 - val_loss: 1.9870 - val_accuracy: 0.3187\n",
            "218/218 [==============================] - 3s 13ms/step - loss: 0.6448 - accuracy: 0.7468\n",
            "56/56 [==============================] - 1s 13ms/step - loss: 1.9298 - accuracy: 0.3341\n",
            "Epoch 1/50\n",
            "218/218 [==============================] - 9s 26ms/step - loss: 1.3595 - accuracy: 0.3296 - val_loss: 1.3527 - val_accuracy: 0.3480\n",
            "Epoch 2/50\n",
            "218/218 [==============================] - 6s 26ms/step - loss: 1.3355 - accuracy: 0.3450 - val_loss: 1.3543 - val_accuracy: 0.3747\n",
            "Epoch 3/50\n",
            "218/218 [==============================] - 6s 26ms/step - loss: 1.3135 - accuracy: 0.3743 - val_loss: 1.3601 - val_accuracy: 0.3733\n",
            "Epoch 4/50\n",
            "218/218 [==============================] - 5s 22ms/step - loss: 1.2981 - accuracy: 0.3830 - val_loss: 1.4114 - val_accuracy: 0.3627\n",
            "Epoch 5/50\n",
            "218/218 [==============================] - 6s 28ms/step - loss: 1.2952 - accuracy: 0.3905 - val_loss: 1.3600 - val_accuracy: 0.3853\n",
            "Epoch 6/50\n",
            "218/218 [==============================] - 5s 23ms/step - loss: 1.2811 - accuracy: 0.3941 - val_loss: 1.4387 - val_accuracy: 0.3687\n",
            "Epoch 7/50\n",
            "218/218 [==============================] - 6s 28ms/step - loss: 1.2681 - accuracy: 0.4114 - val_loss: 1.3875 - val_accuracy: 0.3880\n",
            "Epoch 8/50\n",
            "218/218 [==============================] - 5s 23ms/step - loss: 1.2654 - accuracy: 0.4106 - val_loss: 1.3426 - val_accuracy: 0.3753\n",
            "Epoch 9/50\n",
            "218/218 [==============================] - 5s 24ms/step - loss: 1.2543 - accuracy: 0.4167 - val_loss: 1.3556 - val_accuracy: 0.3727\n",
            "Epoch 10/50\n",
            "218/218 [==============================] - 6s 27ms/step - loss: 1.2380 - accuracy: 0.4332 - val_loss: 1.3893 - val_accuracy: 0.3940\n",
            "Epoch 11/50\n",
            "218/218 [==============================] - 5s 23ms/step - loss: 1.2357 - accuracy: 0.4358 - val_loss: 1.3948 - val_accuracy: 0.3713\n",
            "Epoch 12/50\n",
            "218/218 [==============================] - 6s 29ms/step - loss: 1.2310 - accuracy: 0.4425 - val_loss: 1.3459 - val_accuracy: 0.3867\n",
            "Epoch 13/50\n",
            "218/218 [==============================] - 5s 22ms/step - loss: 1.2170 - accuracy: 0.4522 - val_loss: 1.3586 - val_accuracy: 0.3920\n",
            "Epoch 14/50\n",
            "218/218 [==============================] - 6s 29ms/step - loss: 1.2178 - accuracy: 0.4543 - val_loss: 1.4122 - val_accuracy: 0.3527\n",
            "Epoch 15/50\n",
            "218/218 [==============================] - 5s 23ms/step - loss: 1.2016 - accuracy: 0.4634 - val_loss: 1.3694 - val_accuracy: 0.3847\n",
            "Epoch 16/50\n",
            "218/218 [==============================] - 5s 22ms/step - loss: 1.1719 - accuracy: 0.4769 - val_loss: 1.3945 - val_accuracy: 0.3667\n",
            "Epoch 17/50\n",
            "218/218 [==============================] - 6s 28ms/step - loss: 1.1631 - accuracy: 0.4839 - val_loss: 1.4057 - val_accuracy: 0.3660\n",
            "Epoch 18/50\n",
            "218/218 [==============================] - 5s 24ms/step - loss: 1.1432 - accuracy: 0.4977 - val_loss: 1.4275 - val_accuracy: 0.3580\n",
            "Epoch 19/50\n",
            "218/218 [==============================] - 6s 29ms/step - loss: 1.1182 - accuracy: 0.5121 - val_loss: 1.4335 - val_accuracy: 0.3687\n",
            "Epoch 20/50\n",
            "218/218 [==============================] - 5s 23ms/step - loss: 1.0942 - accuracy: 0.5247 - val_loss: 1.4584 - val_accuracy: 0.3967\n",
            "Epoch 21/50\n",
            "218/218 [==============================] - 6s 29ms/step - loss: 1.0819 - accuracy: 0.5349 - val_loss: 1.4537 - val_accuracy: 0.3833\n",
            "Epoch 22/50\n",
            "218/218 [==============================] - 5s 23ms/step - loss: 1.0538 - accuracy: 0.5443 - val_loss: 1.4901 - val_accuracy: 0.3673\n",
            "Epoch 23/50\n",
            "218/218 [==============================] - 5s 23ms/step - loss: 1.0453 - accuracy: 0.5516 - val_loss: 1.5086 - val_accuracy: 0.3633\n",
            "Epoch 24/50\n",
            "218/218 [==============================] - 6s 28ms/step - loss: 1.0327 - accuracy: 0.5565 - val_loss: 1.5015 - val_accuracy: 0.3673\n",
            "Epoch 25/50\n",
            "218/218 [==============================] - 5s 23ms/step - loss: 1.0177 - accuracy: 0.5701 - val_loss: 1.4885 - val_accuracy: 0.4147\n",
            "Epoch 26/50\n",
            "218/218 [==============================] - 6s 28ms/step - loss: 0.9840 - accuracy: 0.5864 - val_loss: 1.5537 - val_accuracy: 0.3807\n",
            "Epoch 27/50\n",
            "218/218 [==============================] - 5s 23ms/step - loss: 0.9606 - accuracy: 0.5859 - val_loss: 1.6060 - val_accuracy: 0.3913\n",
            "Epoch 28/50\n",
            "218/218 [==============================] - 6s 28ms/step - loss: 0.9462 - accuracy: 0.6013 - val_loss: 1.7344 - val_accuracy: 0.3560\n",
            "Epoch 29/50\n",
            "218/218 [==============================] - 5s 24ms/step - loss: 0.9184 - accuracy: 0.6109 - val_loss: 1.6193 - val_accuracy: 0.3773\n",
            "Epoch 30/50\n",
            "218/218 [==============================] - 5s 23ms/step - loss: 0.9059 - accuracy: 0.6267 - val_loss: 1.7272 - val_accuracy: 0.3807\n",
            "Epoch 31/50\n",
            "218/218 [==============================] - 6s 28ms/step - loss: 0.8794 - accuracy: 0.6375 - val_loss: 1.5855 - val_accuracy: 0.4087\n",
            "Epoch 32/50\n",
            "218/218 [==============================] - 5s 23ms/step - loss: 0.8678 - accuracy: 0.6447 - val_loss: 1.6792 - val_accuracy: 0.3700\n",
            "Epoch 33/50\n",
            "218/218 [==============================] - 6s 28ms/step - loss: 0.8385 - accuracy: 0.6575 - val_loss: 1.8282 - val_accuracy: 0.3973\n",
            "Epoch 34/50\n",
            "218/218 [==============================] - 5s 23ms/step - loss: 0.8446 - accuracy: 0.6481 - val_loss: 1.6134 - val_accuracy: 0.3807\n",
            "Epoch 35/50\n",
            "218/218 [==============================] - 6s 29ms/step - loss: 0.8193 - accuracy: 0.6615 - val_loss: 1.7549 - val_accuracy: 0.3620\n",
            "Epoch 36/50\n",
            "218/218 [==============================] - 5s 23ms/step - loss: 0.8155 - accuracy: 0.6682 - val_loss: 1.7838 - val_accuracy: 0.3933\n",
            "Epoch 37/50\n",
            "218/218 [==============================] - 5s 23ms/step - loss: 0.7758 - accuracy: 0.6878 - val_loss: 1.8157 - val_accuracy: 0.3647\n",
            "Epoch 38/50\n",
            "218/218 [==============================] - 6s 28ms/step - loss: 0.7476 - accuracy: 0.7007 - val_loss: 1.8228 - val_accuracy: 0.3867\n",
            "Epoch 39/50\n",
            "218/218 [==============================] - 5s 23ms/step - loss: 0.7425 - accuracy: 0.7022 - val_loss: 1.8231 - val_accuracy: 0.3993\n",
            "Epoch 40/50\n",
            "218/218 [==============================] - 6s 28ms/step - loss: 0.7298 - accuracy: 0.6996 - val_loss: 1.8841 - val_accuracy: 0.3947\n",
            "Epoch 41/50\n",
            "218/218 [==============================] - 5s 23ms/step - loss: 0.7150 - accuracy: 0.7142 - val_loss: 1.9900 - val_accuracy: 0.3780\n",
            "Epoch 42/50\n",
            "218/218 [==============================] - 6s 29ms/step - loss: 0.6879 - accuracy: 0.7228 - val_loss: 1.9128 - val_accuracy: 0.3933\n",
            "Epoch 43/50\n",
            "218/218 [==============================] - 5s 23ms/step - loss: 0.6818 - accuracy: 0.7221 - val_loss: 1.9842 - val_accuracy: 0.3953\n",
            "Epoch 44/50\n",
            "218/218 [==============================] - 6s 26ms/step - loss: 0.6730 - accuracy: 0.7277 - val_loss: 1.9060 - val_accuracy: 0.4000\n",
            "Epoch 45/50\n",
            "218/218 [==============================] - 6s 25ms/step - loss: 0.6838 - accuracy: 0.7296 - val_loss: 1.8598 - val_accuracy: 0.3727\n",
            "Epoch 46/50\n",
            "218/218 [==============================] - 5s 22ms/step - loss: 0.6529 - accuracy: 0.7386 - val_loss: 1.9597 - val_accuracy: 0.4127\n",
            "Epoch 47/50\n",
            "218/218 [==============================] - 6s 28ms/step - loss: 0.6536 - accuracy: 0.7349 - val_loss: 1.9471 - val_accuracy: 0.3887\n",
            "Epoch 48/50\n",
            "218/218 [==============================] - 5s 22ms/step - loss: 0.6270 - accuracy: 0.7549 - val_loss: 2.1237 - val_accuracy: 0.3913\n",
            "Epoch 49/50\n",
            "218/218 [==============================] - 6s 28ms/step - loss: 0.6338 - accuracy: 0.7451 - val_loss: 1.9742 - val_accuracy: 0.3913\n",
            "Epoch 50/50\n",
            "218/218 [==============================] - 5s 23ms/step - loss: 0.6188 - accuracy: 0.7570 - val_loss: 2.0347 - val_accuracy: 0.3913\n",
            "218/218 [==============================] - 3s 14ms/step - loss: 0.4026 - accuracy: 0.8527\n",
            "56/56 [==============================] - 1s 14ms/step - loss: 1.8915 - accuracy: 0.4170\n",
            "Epoch 1/50\n",
            "218/218 [==============================] - 10s 28ms/step - loss: 1.3512 - accuracy: 0.3386 - val_loss: 1.3358 - val_accuracy: 0.3620\n",
            "Epoch 2/50\n",
            "218/218 [==============================] - 6s 29ms/step - loss: 1.3121 - accuracy: 0.3721 - val_loss: 1.3540 - val_accuracy: 0.3900\n",
            "Epoch 3/50\n",
            "218/218 [==============================] - 5s 25ms/step - loss: 1.3045 - accuracy: 0.3805 - val_loss: 1.3427 - val_accuracy: 0.3633\n",
            "Epoch 4/50\n",
            "218/218 [==============================] - 6s 30ms/step - loss: 1.2845 - accuracy: 0.3951 - val_loss: 1.3057 - val_accuracy: 0.3933\n",
            "Epoch 5/50\n",
            "218/218 [==============================] - 5s 25ms/step - loss: 1.2662 - accuracy: 0.4152 - val_loss: 1.4164 - val_accuracy: 0.3753\n",
            "Epoch 6/50\n",
            "218/218 [==============================] - 6s 27ms/step - loss: 1.2594 - accuracy: 0.4223 - val_loss: 1.3477 - val_accuracy: 0.3613\n",
            "Epoch 7/50\n",
            "218/218 [==============================] - 6s 27ms/step - loss: 1.2364 - accuracy: 0.4374 - val_loss: 1.4442 - val_accuracy: 0.3780\n",
            "Epoch 8/50\n",
            "218/218 [==============================] - 5s 25ms/step - loss: 1.2305 - accuracy: 0.4454 - val_loss: 1.4004 - val_accuracy: 0.3647\n",
            "Epoch 9/50\n",
            "218/218 [==============================] - 6s 30ms/step - loss: 1.2252 - accuracy: 0.4470 - val_loss: 1.3967 - val_accuracy: 0.3613\n",
            "Epoch 10/50\n",
            "218/218 [==============================] - 5s 25ms/step - loss: 1.2058 - accuracy: 0.4629 - val_loss: 1.3800 - val_accuracy: 0.3787\n",
            "Epoch 11/50\n",
            "218/218 [==============================] - 6s 29ms/step - loss: 1.1974 - accuracy: 0.4631 - val_loss: 1.3675 - val_accuracy: 0.3753\n",
            "Epoch 12/50\n",
            "218/218 [==============================] - 5s 25ms/step - loss: 1.1939 - accuracy: 0.4698 - val_loss: 1.4379 - val_accuracy: 0.3600\n",
            "Epoch 13/50\n",
            "218/218 [==============================] - 6s 29ms/step - loss: 1.1754 - accuracy: 0.4825 - val_loss: 1.4052 - val_accuracy: 0.3787\n",
            "Epoch 14/50\n",
            "218/218 [==============================] - 5s 25ms/step - loss: 1.1614 - accuracy: 0.4852 - val_loss: 1.4127 - val_accuracy: 0.3733\n",
            "Epoch 15/50\n",
            "218/218 [==============================] - 6s 29ms/step - loss: 1.1406 - accuracy: 0.5059 - val_loss: 1.3829 - val_accuracy: 0.3893\n",
            "Epoch 16/50\n",
            "218/218 [==============================] - 6s 25ms/step - loss: 1.1363 - accuracy: 0.5022 - val_loss: 1.5665 - val_accuracy: 0.3687\n",
            "Epoch 17/50\n",
            "218/218 [==============================] - 6s 27ms/step - loss: 1.1232 - accuracy: 0.5111 - val_loss: 1.4168 - val_accuracy: 0.3780\n",
            "Epoch 18/50\n",
            "218/218 [==============================] - 6s 27ms/step - loss: 1.1040 - accuracy: 0.5190 - val_loss: 1.4610 - val_accuracy: 0.3767\n",
            "Epoch 19/50\n",
            "218/218 [==============================] - 5s 24ms/step - loss: 1.0928 - accuracy: 0.5216 - val_loss: 1.4521 - val_accuracy: 0.3847\n",
            "Epoch 20/50\n",
            "218/218 [==============================] - 7s 31ms/step - loss: 1.0985 - accuracy: 0.5277 - val_loss: 1.4571 - val_accuracy: 0.3820\n",
            "Epoch 21/50\n",
            "218/218 [==============================] - 5s 24ms/step - loss: 1.0637 - accuracy: 0.5408 - val_loss: 1.4760 - val_accuracy: 0.3720\n",
            "Epoch 22/50\n",
            "218/218 [==============================] - 6s 30ms/step - loss: 1.0556 - accuracy: 0.5473 - val_loss: 1.4630 - val_accuracy: 0.3753\n",
            "Epoch 23/50\n",
            "218/218 [==============================] - 5s 24ms/step - loss: 1.0339 - accuracy: 0.5649 - val_loss: 1.4732 - val_accuracy: 0.3827\n",
            "Epoch 24/50\n",
            "218/218 [==============================] - 6s 29ms/step - loss: 0.9987 - accuracy: 0.5797 - val_loss: 1.4755 - val_accuracy: 0.3713\n",
            "Epoch 25/50\n",
            "218/218 [==============================] - 5s 25ms/step - loss: 0.9989 - accuracy: 0.5797 - val_loss: 1.5288 - val_accuracy: 0.4100\n",
            "Epoch 26/50\n",
            "218/218 [==============================] - 6s 29ms/step - loss: 0.9785 - accuracy: 0.5845 - val_loss: 1.7218 - val_accuracy: 0.3760\n",
            "Epoch 27/50\n",
            "218/218 [==============================] - 6s 25ms/step - loss: 0.9647 - accuracy: 0.5971 - val_loss: 1.5533 - val_accuracy: 0.3760\n",
            "Epoch 28/50\n",
            "218/218 [==============================] - 6s 28ms/step - loss: 0.9253 - accuracy: 0.6148 - val_loss: 1.6756 - val_accuracy: 0.4027\n",
            "Epoch 29/50\n",
            "218/218 [==============================] - 6s 27ms/step - loss: 0.9054 - accuracy: 0.6277 - val_loss: 1.6110 - val_accuracy: 0.3887\n",
            "Epoch 30/50\n",
            "218/218 [==============================] - 6s 28ms/step - loss: 0.8910 - accuracy: 0.6299 - val_loss: 1.6527 - val_accuracy: 0.3933\n",
            "Epoch 31/50\n",
            "218/218 [==============================] - 6s 28ms/step - loss: 0.8719 - accuracy: 0.6444 - val_loss: 1.6708 - val_accuracy: 0.3940\n",
            "Epoch 32/50\n",
            "218/218 [==============================] - 5s 25ms/step - loss: 0.8565 - accuracy: 0.6501 - val_loss: 1.6631 - val_accuracy: 0.4073\n",
            "Epoch 33/50\n",
            "218/218 [==============================] - 6s 30ms/step - loss: 0.8356 - accuracy: 0.6647 - val_loss: 1.6840 - val_accuracy: 0.3827\n",
            "Epoch 34/50\n",
            "218/218 [==============================] - 5s 24ms/step - loss: 0.8279 - accuracy: 0.6654 - val_loss: 1.8057 - val_accuracy: 0.3987\n",
            "Epoch 35/50\n",
            "218/218 [==============================] - 6s 30ms/step - loss: 0.7861 - accuracy: 0.6855 - val_loss: 1.8157 - val_accuracy: 0.4060\n",
            "Epoch 36/50\n",
            "218/218 [==============================] - 5s 25ms/step - loss: 0.7694 - accuracy: 0.6869 - val_loss: 1.7437 - val_accuracy: 0.4060\n",
            "Epoch 37/50\n",
            "218/218 [==============================] - 6s 29ms/step - loss: 0.7661 - accuracy: 0.6882 - val_loss: 1.7352 - val_accuracy: 0.4233\n",
            "Epoch 38/50\n",
            "218/218 [==============================] - 5s 24ms/step - loss: 0.7295 - accuracy: 0.7082 - val_loss: 1.7809 - val_accuracy: 0.3960\n",
            "Epoch 39/50\n",
            "218/218 [==============================] - 6s 29ms/step - loss: 0.7376 - accuracy: 0.7082 - val_loss: 1.7819 - val_accuracy: 0.4453\n",
            "Epoch 40/50\n",
            "218/218 [==============================] - 6s 25ms/step - loss: 0.7162 - accuracy: 0.7184 - val_loss: 1.6274 - val_accuracy: 0.4173\n",
            "Epoch 41/50\n",
            "218/218 [==============================] - 6s 27ms/step - loss: 0.7104 - accuracy: 0.7158 - val_loss: 1.8416 - val_accuracy: 0.4160\n",
            "Epoch 42/50\n",
            "218/218 [==============================] - 6s 28ms/step - loss: 0.6593 - accuracy: 0.7376 - val_loss: 2.0079 - val_accuracy: 0.4027\n",
            "Epoch 43/50\n",
            "218/218 [==============================] - 5s 25ms/step - loss: 0.6540 - accuracy: 0.7379 - val_loss: 1.9702 - val_accuracy: 0.4213\n",
            "Epoch 44/50\n",
            "218/218 [==============================] - 7s 30ms/step - loss: 0.6547 - accuracy: 0.7409 - val_loss: 1.9050 - val_accuracy: 0.4273\n",
            "Epoch 45/50\n",
            "218/218 [==============================] - 5s 24ms/step - loss: 0.6393 - accuracy: 0.7480 - val_loss: 1.8771 - val_accuracy: 0.4527\n",
            "Epoch 46/50\n",
            "218/218 [==============================] - 7s 30ms/step - loss: 0.6401 - accuracy: 0.7478 - val_loss: 2.1221 - val_accuracy: 0.3667\n",
            "Epoch 47/50\n",
            "218/218 [==============================] - 5s 25ms/step - loss: 0.6024 - accuracy: 0.7641 - val_loss: 2.1176 - val_accuracy: 0.4287\n",
            "Epoch 48/50\n",
            "218/218 [==============================] - 6s 29ms/step - loss: 0.6031 - accuracy: 0.7618 - val_loss: 1.9807 - val_accuracy: 0.4207\n",
            "Epoch 49/50\n",
            "218/218 [==============================] - 6s 25ms/step - loss: 0.5861 - accuracy: 0.7681 - val_loss: 2.0302 - val_accuracy: 0.3947\n",
            "Epoch 50/50\n",
            "218/218 [==============================] - 7s 30ms/step - loss: 0.5549 - accuracy: 0.7816 - val_loss: 2.2250 - val_accuracy: 0.4160\n",
            "218/218 [==============================] - 3s 15ms/step - loss: 0.4018 - accuracy: 0.8494\n",
            "56/56 [==============================] - 1s 15ms/step - loss: 2.0299 - accuracy: 0.4357\n",
            "Epoch 1/50\n",
            "218/218 [==============================] - 10s 31ms/step - loss: 1.3261 - accuracy: 0.3658 - val_loss: 1.3587 - val_accuracy: 0.3973\n",
            "Epoch 2/50\n",
            "218/218 [==============================] - 7s 33ms/step - loss: 1.2880 - accuracy: 0.4001 - val_loss: 1.3325 - val_accuracy: 0.3867\n",
            "Epoch 3/50\n",
            "218/218 [==============================] - 6s 29ms/step - loss: 1.2673 - accuracy: 0.4162 - val_loss: 1.3660 - val_accuracy: 0.3467\n",
            "Epoch 4/50\n",
            "218/218 [==============================] - 7s 33ms/step - loss: 1.2449 - accuracy: 0.4335 - val_loss: 1.3839 - val_accuracy: 0.3680\n",
            "Epoch 5/50\n",
            "218/218 [==============================] - 6s 29ms/step - loss: 1.2332 - accuracy: 0.4484 - val_loss: 1.4333 - val_accuracy: 0.3533\n",
            "Epoch 6/50\n",
            "218/218 [==============================] - 7s 33ms/step - loss: 1.2209 - accuracy: 0.4526 - val_loss: 1.2856 - val_accuracy: 0.4287\n",
            "Epoch 7/50\n",
            "218/218 [==============================] - 6s 28ms/step - loss: 1.2101 - accuracy: 0.4624 - val_loss: 1.3732 - val_accuracy: 0.3813\n",
            "Epoch 8/50\n",
            "218/218 [==============================] - 7s 33ms/step - loss: 1.1874 - accuracy: 0.4784 - val_loss: 1.3535 - val_accuracy: 0.4020\n",
            "Epoch 9/50\n",
            "218/218 [==============================] - 7s 31ms/step - loss: 1.1750 - accuracy: 0.4805 - val_loss: 1.3373 - val_accuracy: 0.4193\n",
            "Epoch 10/50\n",
            "218/218 [==============================] - 7s 31ms/step - loss: 1.1646 - accuracy: 0.4920 - val_loss: 1.3561 - val_accuracy: 0.3807\n",
            "Epoch 11/50\n",
            "218/218 [==============================] - 7s 33ms/step - loss: 1.1532 - accuracy: 0.4954 - val_loss: 1.3552 - val_accuracy: 0.3940\n",
            "Epoch 12/50\n",
            "218/218 [==============================] - 7s 30ms/step - loss: 1.1283 - accuracy: 0.5132 - val_loss: 1.3480 - val_accuracy: 0.4160\n",
            "Epoch 13/50\n",
            "218/218 [==============================] - 7s 34ms/step - loss: 1.1262 - accuracy: 0.5147 - val_loss: 1.3436 - val_accuracy: 0.4207\n",
            "Epoch 14/50\n",
            "218/218 [==============================] - 6s 29ms/step - loss: 1.1142 - accuracy: 0.5182 - val_loss: 1.4206 - val_accuracy: 0.3800\n",
            "Epoch 15/50\n",
            "218/218 [==============================] - 7s 32ms/step - loss: 1.0980 - accuracy: 0.5332 - val_loss: 1.3651 - val_accuracy: 0.4220\n",
            "Epoch 16/50\n",
            "218/218 [==============================] - 6s 28ms/step - loss: 1.0824 - accuracy: 0.5417 - val_loss: 1.3959 - val_accuracy: 0.3927\n",
            "Epoch 17/50\n",
            "218/218 [==============================] - 7s 32ms/step - loss: 1.0591 - accuracy: 0.5547 - val_loss: 1.4277 - val_accuracy: 0.4047\n",
            "Epoch 18/50\n",
            "218/218 [==============================] - 6s 29ms/step - loss: 1.0477 - accuracy: 0.5563 - val_loss: 1.3512 - val_accuracy: 0.4467\n",
            "Epoch 19/50\n",
            "218/218 [==============================] - 7s 32ms/step - loss: 1.0307 - accuracy: 0.5727 - val_loss: 1.3577 - val_accuracy: 0.4193\n",
            "Epoch 20/50\n",
            "218/218 [==============================] - 6s 28ms/step - loss: 1.0120 - accuracy: 0.5705 - val_loss: 1.4186 - val_accuracy: 0.4260\n",
            "Epoch 21/50\n",
            "218/218 [==============================] - 7s 33ms/step - loss: 0.9872 - accuracy: 0.5793 - val_loss: 1.4362 - val_accuracy: 0.4280\n",
            "Epoch 22/50\n",
            "218/218 [==============================] - 6s 29ms/step - loss: 0.9585 - accuracy: 0.6020 - val_loss: 1.4646 - val_accuracy: 0.4320\n",
            "Epoch 23/50\n",
            "218/218 [==============================] - 7s 33ms/step - loss: 0.9420 - accuracy: 0.6119 - val_loss: 1.4100 - val_accuracy: 0.4220\n",
            "Epoch 24/50\n",
            "218/218 [==============================] - 6s 29ms/step - loss: 0.9000 - accuracy: 0.6269 - val_loss: 1.4853 - val_accuracy: 0.4120\n",
            "Epoch 25/50\n",
            "218/218 [==============================] - 7s 33ms/step - loss: 0.8977 - accuracy: 0.6296 - val_loss: 1.4886 - val_accuracy: 0.3973\n",
            "Epoch 26/50\n",
            "218/218 [==============================] - 6s 28ms/step - loss: 0.8615 - accuracy: 0.6486 - val_loss: 1.5455 - val_accuracy: 0.4460\n",
            "Epoch 27/50\n",
            "218/218 [==============================] - 7s 33ms/step - loss: 0.8477 - accuracy: 0.6511 - val_loss: 1.5508 - val_accuracy: 0.4347\n",
            "Epoch 28/50\n",
            "218/218 [==============================] - 7s 31ms/step - loss: 0.8053 - accuracy: 0.6741 - val_loss: 1.5858 - val_accuracy: 0.4353\n",
            "Epoch 29/50\n",
            "218/218 [==============================] - 7s 32ms/step - loss: 0.7851 - accuracy: 0.6859 - val_loss: 1.6654 - val_accuracy: 0.4233\n",
            "Epoch 30/50\n",
            "218/218 [==============================] - 7s 31ms/step - loss: 0.7657 - accuracy: 0.6930 - val_loss: 1.6153 - val_accuracy: 0.4053\n",
            "Epoch 31/50\n",
            "218/218 [==============================] - 7s 31ms/step - loss: 0.7536 - accuracy: 0.7014 - val_loss: 1.6231 - val_accuracy: 0.4187\n",
            "Epoch 32/50\n",
            "218/218 [==============================] - 7s 31ms/step - loss: 0.7387 - accuracy: 0.6994 - val_loss: 1.7072 - val_accuracy: 0.4213\n",
            "Epoch 33/50\n",
            "218/218 [==============================] - 7s 30ms/step - loss: 0.7113 - accuracy: 0.7158 - val_loss: 1.7287 - val_accuracy: 0.3827\n",
            "Epoch 34/50\n",
            "218/218 [==============================] - 7s 33ms/step - loss: 0.6840 - accuracy: 0.7267 - val_loss: 1.7890 - val_accuracy: 0.4173\n",
            "Epoch 35/50\n",
            "218/218 [==============================] - 6s 29ms/step - loss: 0.6676 - accuracy: 0.7333 - val_loss: 1.7914 - val_accuracy: 0.3900\n",
            "Epoch 36/50\n",
            "218/218 [==============================] - 7s 33ms/step - loss: 0.6572 - accuracy: 0.7411 - val_loss: 1.7713 - val_accuracy: 0.4327\n",
            "Epoch 37/50\n",
            "218/218 [==============================] - 6s 29ms/step - loss: 0.6447 - accuracy: 0.7411 - val_loss: 1.7380 - val_accuracy: 0.4200\n",
            "Epoch 38/50\n",
            "218/218 [==============================] - 7s 33ms/step - loss: 0.6100 - accuracy: 0.7599 - val_loss: 1.7522 - val_accuracy: 0.3940\n",
            "Epoch 39/50\n",
            "218/218 [==============================] - 6s 29ms/step - loss: 0.6147 - accuracy: 0.7556 - val_loss: 1.8400 - val_accuracy: 0.4033\n",
            "Epoch 40/50\n",
            "218/218 [==============================] - 7s 33ms/step - loss: 0.5807 - accuracy: 0.7717 - val_loss: 1.9138 - val_accuracy: 0.4100\n",
            "Epoch 41/50\n",
            "218/218 [==============================] - 6s 29ms/step - loss: 0.5645 - accuracy: 0.7753 - val_loss: 1.9833 - val_accuracy: 0.3953\n",
            "Epoch 42/50\n",
            "218/218 [==============================] - 7s 33ms/step - loss: 0.5580 - accuracy: 0.7839 - val_loss: 2.1329 - val_accuracy: 0.4093\n",
            "Epoch 43/50\n",
            "218/218 [==============================] - 6s 29ms/step - loss: 0.5389 - accuracy: 0.7927 - val_loss: 2.0281 - val_accuracy: 0.4193\n",
            "Epoch 44/50\n",
            "218/218 [==============================] - 7s 33ms/step - loss: 0.5222 - accuracy: 0.7912 - val_loss: 2.2927 - val_accuracy: 0.3907\n",
            "Epoch 45/50\n",
            "218/218 [==============================] - 6s 29ms/step - loss: 0.5067 - accuracy: 0.8062 - val_loss: 2.1108 - val_accuracy: 0.3853\n",
            "Epoch 46/50\n",
            "218/218 [==============================] - 7s 32ms/step - loss: 0.4728 - accuracy: 0.8144 - val_loss: 2.3041 - val_accuracy: 0.3740\n",
            "Epoch 47/50\n",
            "218/218 [==============================] - 7s 32ms/step - loss: 0.4699 - accuracy: 0.8185 - val_loss: 2.1799 - val_accuracy: 0.4053\n",
            "Epoch 48/50\n",
            "218/218 [==============================] - 7s 33ms/step - loss: 0.4701 - accuracy: 0.8197 - val_loss: 2.2970 - val_accuracy: 0.3853\n",
            "Epoch 49/50\n",
            "218/218 [==============================] - 6s 29ms/step - loss: 0.4505 - accuracy: 0.8257 - val_loss: 2.2158 - val_accuracy: 0.3833\n",
            "Epoch 50/50\n",
            "218/218 [==============================] - 7s 33ms/step - loss: 0.4537 - accuracy: 0.8289 - val_loss: 2.4128 - val_accuracy: 0.3900\n",
            "218/218 [==============================] - 4s 17ms/step - loss: 0.2615 - accuracy: 0.9075\n",
            "56/56 [==============================] - 1s 17ms/step - loss: 2.0481 - accuracy: 0.4430\n",
            "Epoch 1/50\n",
            "218/218 [==============================] - 12s 38ms/step - loss: 1.3288 - accuracy: 0.3599 - val_loss: 1.2966 - val_accuracy: 0.3753\n",
            "Epoch 2/50\n",
            "218/218 [==============================] - 8s 37ms/step - loss: 1.2914 - accuracy: 0.4009 - val_loss: 1.3366 - val_accuracy: 0.3813\n",
            "Epoch 3/50\n",
            "218/218 [==============================] - 7s 34ms/step - loss: 1.2684 - accuracy: 0.4239 - val_loss: 1.3204 - val_accuracy: 0.3673\n",
            "Epoch 4/50\n",
            "218/218 [==============================] - 8s 37ms/step - loss: 1.2437 - accuracy: 0.4361 - val_loss: 1.2861 - val_accuracy: 0.4607\n",
            "Epoch 5/50\n",
            "218/218 [==============================] - 8s 37ms/step - loss: 1.2243 - accuracy: 0.4582 - val_loss: 1.2893 - val_accuracy: 0.4033\n",
            "Epoch 6/50\n",
            "218/218 [==============================] - 7s 33ms/step - loss: 1.2141 - accuracy: 0.4635 - val_loss: 1.2548 - val_accuracy: 0.4253\n",
            "Epoch 7/50\n",
            "218/218 [==============================] - 8s 37ms/step - loss: 1.1862 - accuracy: 0.4889 - val_loss: 1.3140 - val_accuracy: 0.4280\n",
            "Epoch 8/50\n",
            "218/218 [==============================] - 7s 34ms/step - loss: 1.1699 - accuracy: 0.4899 - val_loss: 1.3000 - val_accuracy: 0.4273\n",
            "Epoch 9/50\n",
            "218/218 [==============================] - 9s 40ms/step - loss: 1.1493 - accuracy: 0.5085 - val_loss: 1.3214 - val_accuracy: 0.4273\n",
            "Epoch 10/50\n",
            "218/218 [==============================] - 8s 37ms/step - loss: 1.1352 - accuracy: 0.5065 - val_loss: 1.2775 - val_accuracy: 0.4547\n",
            "Epoch 11/50\n",
            "218/218 [==============================] - 7s 34ms/step - loss: 1.1200 - accuracy: 0.5217 - val_loss: 1.2971 - val_accuracy: 0.4300\n",
            "Epoch 12/50\n",
            "218/218 [==============================] - 8s 37ms/step - loss: 1.1164 - accuracy: 0.5194 - val_loss: 1.3267 - val_accuracy: 0.4427\n",
            "Epoch 13/50\n",
            "218/218 [==============================] - 8s 36ms/step - loss: 1.0900 - accuracy: 0.5319 - val_loss: 1.3192 - val_accuracy: 0.4607\n",
            "Epoch 14/50\n",
            "218/218 [==============================] - 8s 35ms/step - loss: 1.0763 - accuracy: 0.5414 - val_loss: 1.3059 - val_accuracy: 0.4380\n",
            "Epoch 15/50\n",
            "218/218 [==============================] - 8s 37ms/step - loss: 1.0484 - accuracy: 0.5556 - val_loss: 1.3168 - val_accuracy: 0.4420\n",
            "Epoch 16/50\n",
            "218/218 [==============================] - 7s 34ms/step - loss: 1.0361 - accuracy: 0.5638 - val_loss: 1.3850 - val_accuracy: 0.4167\n",
            "Epoch 17/50\n",
            "218/218 [==============================] - 8s 37ms/step - loss: 1.0101 - accuracy: 0.5761 - val_loss: 1.3939 - val_accuracy: 0.4313\n",
            "Epoch 18/50\n",
            "218/218 [==============================] - 8s 36ms/step - loss: 1.0033 - accuracy: 0.5800 - val_loss: 1.3001 - val_accuracy: 0.4720\n",
            "Epoch 19/50\n",
            "218/218 [==============================] - 8s 35ms/step - loss: 0.9868 - accuracy: 0.5878 - val_loss: 1.3153 - val_accuracy: 0.4713\n",
            "Epoch 20/50\n",
            "218/218 [==============================] - 8s 37ms/step - loss: 0.9758 - accuracy: 0.5968 - val_loss: 1.3158 - val_accuracy: 0.4733\n",
            "Epoch 21/50\n",
            "218/218 [==============================] - 7s 33ms/step - loss: 0.9336 - accuracy: 0.6194 - val_loss: 1.4123 - val_accuracy: 0.4760\n",
            "Epoch 22/50\n",
            "218/218 [==============================] - 8s 37ms/step - loss: 0.9254 - accuracy: 0.6203 - val_loss: 1.4165 - val_accuracy: 0.4847\n",
            "Epoch 23/50\n",
            "218/218 [==============================] - 8s 37ms/step - loss: 0.8823 - accuracy: 0.6408 - val_loss: 1.4835 - val_accuracy: 0.4447\n",
            "Epoch 24/50\n",
            "218/218 [==============================] - 7s 34ms/step - loss: 0.8690 - accuracy: 0.6392 - val_loss: 1.5019 - val_accuracy: 0.4667\n",
            "Epoch 25/50\n",
            "218/218 [==============================] - 8s 37ms/step - loss: 0.8665 - accuracy: 0.6438 - val_loss: 1.5251 - val_accuracy: 0.4493\n",
            "Epoch 26/50\n",
            "218/218 [==============================] - 7s 33ms/step - loss: 0.8340 - accuracy: 0.6591 - val_loss: 1.6080 - val_accuracy: 0.4413\n",
            "Epoch 27/50\n",
            "218/218 [==============================] - 9s 40ms/step - loss: 0.8187 - accuracy: 0.6670 - val_loss: 1.5118 - val_accuracy: 0.4500\n",
            "Epoch 28/50\n",
            "218/218 [==============================] - 8s 37ms/step - loss: 0.7868 - accuracy: 0.6833 - val_loss: 1.5170 - val_accuracy: 0.4467\n",
            "Epoch 29/50\n",
            "218/218 [==============================] - 8s 37ms/step - loss: 0.7696 - accuracy: 0.6889 - val_loss: 1.5699 - val_accuracy: 0.4540\n",
            "Epoch 30/50\n",
            "218/218 [==============================] - 8s 37ms/step - loss: 0.7441 - accuracy: 0.7047 - val_loss: 1.5863 - val_accuracy: 0.4640\n",
            "Epoch 31/50\n",
            "218/218 [==============================] - 8s 36ms/step - loss: 0.7226 - accuracy: 0.7095 - val_loss: 1.5877 - val_accuracy: 0.4480\n",
            "Epoch 32/50\n",
            "218/218 [==============================] - 8s 36ms/step - loss: 0.7186 - accuracy: 0.7152 - val_loss: 1.6027 - val_accuracy: 0.4213\n",
            "Epoch 33/50\n",
            "218/218 [==============================] - 8s 37ms/step - loss: 0.6901 - accuracy: 0.7266 - val_loss: 1.7431 - val_accuracy: 0.4360\n",
            "Epoch 34/50\n",
            "218/218 [==============================] - 7s 34ms/step - loss: 0.6743 - accuracy: 0.7346 - val_loss: 1.7104 - val_accuracy: 0.4380\n",
            "Epoch 35/50\n",
            "218/218 [==============================] - 8s 37ms/step - loss: 0.6391 - accuracy: 0.7490 - val_loss: 1.8792 - val_accuracy: 0.4593\n",
            "Epoch 36/50\n",
            "218/218 [==============================] - 8s 36ms/step - loss: 0.6269 - accuracy: 0.7553 - val_loss: 1.7191 - val_accuracy: 0.4713\n",
            "Epoch 37/50\n",
            "218/218 [==============================] - 8s 35ms/step - loss: 0.6236 - accuracy: 0.7529 - val_loss: 1.7049 - val_accuracy: 0.4733\n",
            "Epoch 38/50\n",
            "218/218 [==============================] - 8s 37ms/step - loss: 0.6003 - accuracy: 0.7675 - val_loss: 1.8031 - val_accuracy: 0.4353\n",
            "Epoch 39/50\n",
            "218/218 [==============================] - 7s 34ms/step - loss: 0.5979 - accuracy: 0.7638 - val_loss: 1.8409 - val_accuracy: 0.4707\n",
            "Epoch 40/50\n",
            "218/218 [==============================] - 8s 37ms/step - loss: 0.5806 - accuracy: 0.7700 - val_loss: 1.9114 - val_accuracy: 0.4527\n",
            "Epoch 41/50\n",
            "218/218 [==============================] - 8s 37ms/step - loss: 0.5540 - accuracy: 0.7852 - val_loss: 1.9276 - val_accuracy: 0.4493\n",
            "Epoch 42/50\n",
            "218/218 [==============================] - 8s 37ms/step - loss: 0.5613 - accuracy: 0.7784 - val_loss: 1.8004 - val_accuracy: 0.4600\n",
            "Epoch 43/50\n",
            "218/218 [==============================] - 8s 37ms/step - loss: 0.5385 - accuracy: 0.7898 - val_loss: 1.8610 - val_accuracy: 0.4440\n",
            "Epoch 44/50\n",
            "218/218 [==============================] - 7s 33ms/step - loss: 0.5165 - accuracy: 0.7955 - val_loss: 2.0495 - val_accuracy: 0.4553\n",
            "Epoch 45/50\n",
            "218/218 [==============================] - 8s 37ms/step - loss: 0.5145 - accuracy: 0.7997 - val_loss: 2.1082 - val_accuracy: 0.4353\n",
            "Epoch 46/50\n",
            "218/218 [==============================] - 8s 38ms/step - loss: 0.4982 - accuracy: 0.8033 - val_loss: 2.1557 - val_accuracy: 0.4540\n",
            "Epoch 47/50\n",
            "218/218 [==============================] - 7s 34ms/step - loss: 0.5054 - accuracy: 0.8083 - val_loss: 2.0400 - val_accuracy: 0.4667\n",
            "Epoch 48/50\n",
            "218/218 [==============================] - 8s 37ms/step - loss: 0.4922 - accuracy: 0.8052 - val_loss: 2.0983 - val_accuracy: 0.4573\n",
            "Epoch 49/50\n",
            "218/218 [==============================] - 7s 34ms/step - loss: 0.4666 - accuracy: 0.8181 - val_loss: 2.1331 - val_accuracy: 0.4520\n",
            "Epoch 50/50\n",
            "218/218 [==============================] - 8s 37ms/step - loss: 0.4594 - accuracy: 0.8247 - val_loss: 1.9773 - val_accuracy: 0.4707\n",
            "218/218 [==============================] - 4s 19ms/step - loss: 0.2757 - accuracy: 0.9033\n",
            "56/56 [==============================] - 1s 26ms/step - loss: 1.8419 - accuracy: 0.4774\n",
            "Epoch 1/50\n",
            "218/218 [==============================] - 12s 44ms/step - loss: 1.3498 - accuracy: 0.3346 - val_loss: 1.3167 - val_accuracy: 0.3853\n",
            "Epoch 2/50\n",
            "218/218 [==============================] - 9s 41ms/step - loss: 1.2985 - accuracy: 0.3848 - val_loss: 1.3511 - val_accuracy: 0.3847\n",
            "Epoch 3/50\n",
            "218/218 [==============================] - 9s 41ms/step - loss: 1.2772 - accuracy: 0.4129 - val_loss: 1.3148 - val_accuracy: 0.4240\n",
            "Epoch 4/50\n",
            "218/218 [==============================] - 9s 43ms/step - loss: 1.2381 - accuracy: 0.4478 - val_loss: 1.3205 - val_accuracy: 0.3960\n",
            "Epoch 5/50\n",
            "218/218 [==============================] - 9s 43ms/step - loss: 1.2141 - accuracy: 0.4621 - val_loss: 1.2722 - val_accuracy: 0.4293\n",
            "Epoch 6/50\n",
            "218/218 [==============================] - 9s 39ms/step - loss: 1.1838 - accuracy: 0.4843 - val_loss: 1.2858 - val_accuracy: 0.4127\n",
            "Epoch 7/50\n",
            "218/218 [==============================] - 9s 43ms/step - loss: 1.1661 - accuracy: 0.4848 - val_loss: 1.3339 - val_accuracy: 0.4313\n",
            "Epoch 8/50\n",
            "218/218 [==============================] - 9s 43ms/step - loss: 1.1460 - accuracy: 0.5040 - val_loss: 1.2796 - val_accuracy: 0.4527\n",
            "Epoch 9/50\n",
            "218/218 [==============================] - 9s 39ms/step - loss: 1.1249 - accuracy: 0.5216 - val_loss: 1.2314 - val_accuracy: 0.4753\n",
            "Epoch 10/50\n",
            "218/218 [==============================] - 9s 43ms/step - loss: 1.0995 - accuracy: 0.5283 - val_loss: 1.2485 - val_accuracy: 0.4567\n",
            "Epoch 11/50\n",
            "218/218 [==============================] - 9s 42ms/step - loss: 1.0743 - accuracy: 0.5443 - val_loss: 1.3166 - val_accuracy: 0.4633\n",
            "Epoch 12/50\n",
            "218/218 [==============================] - 9s 41ms/step - loss: 1.0551 - accuracy: 0.5579 - val_loss: 1.3033 - val_accuracy: 0.4613\n",
            "Epoch 13/50\n",
            "218/218 [==============================] - 9s 41ms/step - loss: 1.0368 - accuracy: 0.5661 - val_loss: 1.2867 - val_accuracy: 0.4680\n",
            "Epoch 14/50\n",
            "218/218 [==============================] - 9s 43ms/step - loss: 1.0042 - accuracy: 0.5757 - val_loss: 1.2831 - val_accuracy: 0.4767\n",
            "Epoch 15/50\n",
            "218/218 [==============================] - 9s 43ms/step - loss: 0.9811 - accuracy: 0.5894 - val_loss: 1.2962 - val_accuracy: 0.4853\n",
            "Epoch 16/50\n",
            "218/218 [==============================] - 9s 39ms/step - loss: 0.9602 - accuracy: 0.6057 - val_loss: 1.3411 - val_accuracy: 0.4873\n",
            "Epoch 17/50\n",
            "218/218 [==============================] - 9s 43ms/step - loss: 0.9440 - accuracy: 0.6080 - val_loss: 1.3733 - val_accuracy: 0.4840\n",
            "Epoch 18/50\n",
            "218/218 [==============================] - 9s 42ms/step - loss: 0.9126 - accuracy: 0.6243 - val_loss: 1.2775 - val_accuracy: 0.4853\n",
            "Epoch 19/50\n",
            "218/218 [==============================] - 9s 39ms/step - loss: 0.8953 - accuracy: 0.6273 - val_loss: 1.3490 - val_accuracy: 0.4733\n",
            "Epoch 20/50\n",
            "218/218 [==============================] - 9s 42ms/step - loss: 0.8575 - accuracy: 0.6471 - val_loss: 1.4230 - val_accuracy: 0.4993\n",
            "Epoch 21/50\n",
            "218/218 [==============================] - 9s 42ms/step - loss: 0.8268 - accuracy: 0.6662 - val_loss: 1.4346 - val_accuracy: 0.4653\n",
            "Epoch 22/50\n",
            "218/218 [==============================] - 9s 41ms/step - loss: 0.8062 - accuracy: 0.6724 - val_loss: 1.4121 - val_accuracy: 0.4627\n",
            "Epoch 23/50\n",
            "218/218 [==============================] - 9s 41ms/step - loss: 0.7963 - accuracy: 0.6830 - val_loss: 1.3951 - val_accuracy: 0.4907\n",
            "Epoch 24/50\n",
            "218/218 [==============================] - 9s 43ms/step - loss: 0.7678 - accuracy: 0.6958 - val_loss: 1.3554 - val_accuracy: 0.4893\n",
            "Epoch 25/50\n",
            "218/218 [==============================] - 9s 43ms/step - loss: 0.7510 - accuracy: 0.6961 - val_loss: 1.4076 - val_accuracy: 0.4853\n",
            "Epoch 26/50\n",
            "218/218 [==============================] - 9s 40ms/step - loss: 0.7618 - accuracy: 0.6918 - val_loss: 1.4347 - val_accuracy: 0.4693\n",
            "Epoch 27/50\n",
            "218/218 [==============================] - 9s 42ms/step - loss: 0.6959 - accuracy: 0.7266 - val_loss: 1.3941 - val_accuracy: 0.4967\n",
            "Epoch 28/50\n",
            "218/218 [==============================] - 9s 42ms/step - loss: 0.6728 - accuracy: 0.7325 - val_loss: 1.3415 - val_accuracy: 0.5200\n",
            "Epoch 29/50\n",
            "218/218 [==============================] - 9s 40ms/step - loss: 0.6433 - accuracy: 0.7517 - val_loss: 1.5606 - val_accuracy: 0.4967\n",
            "Epoch 30/50\n",
            "218/218 [==============================] - 9s 43ms/step - loss: 0.6355 - accuracy: 0.7470 - val_loss: 1.5215 - val_accuracy: 0.5107\n",
            "Epoch 31/50\n",
            "218/218 [==============================] - 9s 43ms/step - loss: 0.6009 - accuracy: 0.7641 - val_loss: 1.5634 - val_accuracy: 0.5100\n",
            "Epoch 32/50\n",
            "218/218 [==============================] - 9s 43ms/step - loss: 0.5919 - accuracy: 0.7685 - val_loss: 1.4880 - val_accuracy: 0.5067\n",
            "Epoch 33/50\n",
            "218/218 [==============================] - 9s 41ms/step - loss: 0.5741 - accuracy: 0.7749 - val_loss: 1.4764 - val_accuracy: 0.5160\n",
            "Epoch 34/50\n",
            "218/218 [==============================] - 9s 43ms/step - loss: 0.5645 - accuracy: 0.7841 - val_loss: 1.5915 - val_accuracy: 0.5007\n",
            "Epoch 35/50\n",
            "218/218 [==============================] - 9s 43ms/step - loss: 0.5518 - accuracy: 0.7868 - val_loss: 1.5322 - val_accuracy: 0.5253\n",
            "Epoch 36/50\n",
            "218/218 [==============================] - 9s 40ms/step - loss: 0.5085 - accuracy: 0.7993 - val_loss: 1.6848 - val_accuracy: 0.4987\n",
            "Epoch 37/50\n",
            "218/218 [==============================] - 9s 43ms/step - loss: 0.4975 - accuracy: 0.8132 - val_loss: 1.7483 - val_accuracy: 0.5220\n",
            "Epoch 38/50\n",
            "218/218 [==============================] - 9s 43ms/step - loss: 0.4831 - accuracy: 0.8135 - val_loss: 1.9583 - val_accuracy: 0.4713\n",
            "Epoch 39/50\n",
            "218/218 [==============================] - 9s 41ms/step - loss: 0.4916 - accuracy: 0.8056 - val_loss: 1.7511 - val_accuracy: 0.5160\n",
            "Epoch 40/50\n",
            "218/218 [==============================] - 9s 42ms/step - loss: 0.4538 - accuracy: 0.8277 - val_loss: 1.7624 - val_accuracy: 0.5107\n",
            "Epoch 41/50\n",
            "218/218 [==============================] - 9s 43ms/step - loss: 0.4592 - accuracy: 0.8231 - val_loss: 1.7166 - val_accuracy: 0.4980\n",
            "Epoch 42/50\n",
            "218/218 [==============================] - 9s 43ms/step - loss: 0.4394 - accuracy: 0.8296 - val_loss: 1.9515 - val_accuracy: 0.4780\n",
            "Epoch 43/50\n",
            "218/218 [==============================] - 9s 40ms/step - loss: 0.4178 - accuracy: 0.8405 - val_loss: 1.8244 - val_accuracy: 0.4867\n",
            "Epoch 44/50\n",
            "218/218 [==============================] - 9s 43ms/step - loss: 0.4104 - accuracy: 0.8409 - val_loss: 1.8281 - val_accuracy: 0.5020\n",
            "Epoch 45/50\n",
            "218/218 [==============================] - 9s 43ms/step - loss: 0.4205 - accuracy: 0.8438 - val_loss: 1.7985 - val_accuracy: 0.5007\n",
            "Epoch 46/50\n",
            "218/218 [==============================] - 9s 39ms/step - loss: 0.3976 - accuracy: 0.8491 - val_loss: 1.7631 - val_accuracy: 0.5320\n",
            "Epoch 47/50\n",
            "218/218 [==============================] - 10s 45ms/step - loss: 0.3619 - accuracy: 0.8619 - val_loss: 1.9674 - val_accuracy: 0.4980\n",
            "Epoch 48/50\n",
            "218/218 [==============================] - 9s 43ms/step - loss: 0.3850 - accuracy: 0.8566 - val_loss: 1.7879 - val_accuracy: 0.4833\n",
            "Epoch 49/50\n",
            "218/218 [==============================] - 9s 43ms/step - loss: 0.3673 - accuracy: 0.8612 - val_loss: 2.0327 - val_accuracy: 0.4913\n",
            "Epoch 50/50\n",
            "218/218 [==============================] - 9s 41ms/step - loss: 0.3511 - accuracy: 0.8691 - val_loss: 1.9443 - val_accuracy: 0.5153\n",
            "218/218 [==============================] - 5s 22ms/step - loss: 0.2256 - accuracy: 0.9174\n",
            "56/56 [==============================] - 2s 30ms/step - loss: 2.0189 - accuracy: 0.4938\n",
            "Epoch 1/50\n",
            "218/218 [==============================] - 14s 50ms/step - loss: 1.3653 - accuracy: 0.3191 - val_loss: 1.3559 - val_accuracy: 0.3267\n",
            "Epoch 2/50\n",
            "218/218 [==============================] - 10s 48ms/step - loss: 1.3308 - accuracy: 0.3662 - val_loss: 1.3325 - val_accuracy: 0.3747\n",
            "Epoch 3/50\n",
            "218/218 [==============================] - 10s 46ms/step - loss: 1.2995 - accuracy: 0.3968 - val_loss: 1.3006 - val_accuracy: 0.3940\n",
            "Epoch 4/50\n",
            "218/218 [==============================] - 10s 46ms/step - loss: 1.2761 - accuracy: 0.4068 - val_loss: 1.3119 - val_accuracy: 0.3940\n",
            "Epoch 5/50\n",
            "218/218 [==============================] - 10s 47ms/step - loss: 1.2622 - accuracy: 0.4185 - val_loss: 1.3074 - val_accuracy: 0.3820\n",
            "Epoch 6/50\n",
            "218/218 [==============================] - 10s 47ms/step - loss: 1.2378 - accuracy: 0.4342 - val_loss: 1.2476 - val_accuracy: 0.4347\n",
            "Epoch 7/50\n",
            "218/218 [==============================] - 10s 46ms/step - loss: 1.2039 - accuracy: 0.4557 - val_loss: 1.2764 - val_accuracy: 0.4307\n",
            "Epoch 8/50\n",
            "218/218 [==============================] - 10s 45ms/step - loss: 1.1627 - accuracy: 0.4828 - val_loss: 1.2467 - val_accuracy: 0.4287\n",
            "Epoch 9/50\n",
            "218/218 [==============================] - 11s 49ms/step - loss: 1.1484 - accuracy: 0.4907 - val_loss: 1.2274 - val_accuracy: 0.4447\n",
            "Epoch 10/50\n",
            "218/218 [==============================] - 10s 47ms/step - loss: 1.1301 - accuracy: 0.5075 - val_loss: 1.2283 - val_accuracy: 0.4407\n",
            "Epoch 11/50\n",
            "218/218 [==============================] - 11s 49ms/step - loss: 1.1056 - accuracy: 0.5200 - val_loss: 1.2770 - val_accuracy: 0.4453\n",
            "Epoch 12/50\n",
            "218/218 [==============================] - 10s 46ms/step - loss: 1.0703 - accuracy: 0.5359 - val_loss: 1.2321 - val_accuracy: 0.4627\n",
            "Epoch 13/50\n",
            "218/218 [==============================] - 10s 48ms/step - loss: 1.0557 - accuracy: 0.5552 - val_loss: 1.2318 - val_accuracy: 0.4580\n",
            "Epoch 14/50\n",
            "218/218 [==============================] - 10s 47ms/step - loss: 1.0164 - accuracy: 0.5693 - val_loss: 1.1606 - val_accuracy: 0.4793\n",
            "Epoch 15/50\n",
            "218/218 [==============================] - 10s 47ms/step - loss: 0.9890 - accuracy: 0.5769 - val_loss: 1.2517 - val_accuracy: 0.4553\n",
            "Epoch 16/50\n",
            "218/218 [==============================] - 10s 47ms/step - loss: 0.9539 - accuracy: 0.5999 - val_loss: 1.2098 - val_accuracy: 0.4733\n",
            "Epoch 17/50\n",
            "218/218 [==============================] - 10s 46ms/step - loss: 0.9571 - accuracy: 0.5989 - val_loss: 1.2049 - val_accuracy: 0.4760\n",
            "Epoch 18/50\n",
            "218/218 [==============================] - 10s 46ms/step - loss: 0.9038 - accuracy: 0.6261 - val_loss: 1.3370 - val_accuracy: 0.4660\n",
            "Epoch 19/50\n",
            "218/218 [==============================] - 10s 47ms/step - loss: 0.8770 - accuracy: 0.6375 - val_loss: 1.2060 - val_accuracy: 0.4913\n",
            "Epoch 20/50\n",
            "218/218 [==============================] - 10s 47ms/step - loss: 0.8559 - accuracy: 0.6507 - val_loss: 1.2557 - val_accuracy: 0.4860\n",
            "Epoch 21/50\n",
            "218/218 [==============================] - 10s 47ms/step - loss: 0.8302 - accuracy: 0.6569 - val_loss: 1.3278 - val_accuracy: 0.4793\n",
            "Epoch 22/50\n",
            "218/218 [==============================] - 10s 44ms/step - loss: 0.8072 - accuracy: 0.6651 - val_loss: 1.3113 - val_accuracy: 0.4760\n",
            "Epoch 23/50\n",
            "218/218 [==============================] - 10s 47ms/step - loss: 0.7836 - accuracy: 0.6818 - val_loss: 1.2348 - val_accuracy: 0.5040\n",
            "Epoch 24/50\n",
            "218/218 [==============================] - 10s 47ms/step - loss: 0.7580 - accuracy: 0.6964 - val_loss: 1.2960 - val_accuracy: 0.4760\n",
            "Epoch 25/50\n",
            "218/218 [==============================] - 10s 47ms/step - loss: 0.7365 - accuracy: 0.7032 - val_loss: 1.3329 - val_accuracy: 0.4840\n",
            "Epoch 26/50\n",
            "218/218 [==============================] - 10s 45ms/step - loss: 0.7148 - accuracy: 0.7159 - val_loss: 1.3950 - val_accuracy: 0.4787\n",
            "Epoch 27/50\n",
            "218/218 [==============================] - 10s 46ms/step - loss: 0.7096 - accuracy: 0.7170 - val_loss: 1.6164 - val_accuracy: 0.4573\n",
            "Epoch 28/50\n",
            "218/218 [==============================] - 10s 47ms/step - loss: 0.6674 - accuracy: 0.7326 - val_loss: 1.4820 - val_accuracy: 0.4773\n",
            "Epoch 29/50\n",
            "218/218 [==============================] - 10s 47ms/step - loss: 0.6619 - accuracy: 0.7299 - val_loss: 1.3183 - val_accuracy: 0.5027\n",
            "Epoch 30/50\n",
            "218/218 [==============================] - 10s 47ms/step - loss: 0.6276 - accuracy: 0.7522 - val_loss: 1.3290 - val_accuracy: 0.4960\n",
            "Epoch 31/50\n",
            "218/218 [==============================] - 10s 44ms/step - loss: 0.6191 - accuracy: 0.7589 - val_loss: 1.3647 - val_accuracy: 0.4840\n",
            "Epoch 32/50\n",
            "218/218 [==============================] - 10s 47ms/step - loss: 0.6014 - accuracy: 0.7611 - val_loss: 1.4451 - val_accuracy: 0.4873\n",
            "Epoch 33/50\n",
            "218/218 [==============================] - 11s 49ms/step - loss: 0.5627 - accuracy: 0.7816 - val_loss: 1.5105 - val_accuracy: 0.4727\n",
            "Epoch 34/50\n",
            "218/218 [==============================] - 10s 48ms/step - loss: 0.5786 - accuracy: 0.7751 - val_loss: 1.4866 - val_accuracy: 0.4893\n",
            "Epoch 35/50\n",
            "218/218 [==============================] - 10s 46ms/step - loss: 0.5510 - accuracy: 0.7866 - val_loss: 1.4379 - val_accuracy: 0.5013\n",
            "Epoch 36/50\n",
            "218/218 [==============================] - 10s 45ms/step - loss: 0.5379 - accuracy: 0.7872 - val_loss: 1.5806 - val_accuracy: 0.4873\n",
            "Epoch 37/50\n",
            "218/218 [==============================] - 10s 48ms/step - loss: 0.4915 - accuracy: 0.8085 - val_loss: 1.6569 - val_accuracy: 0.4927\n",
            "Epoch 38/50\n",
            "218/218 [==============================] - 10s 47ms/step - loss: 0.5261 - accuracy: 0.7968 - val_loss: 1.4622 - val_accuracy: 0.4967\n",
            "Epoch 39/50\n",
            "218/218 [==============================] - 10s 47ms/step - loss: 0.4879 - accuracy: 0.8154 - val_loss: 1.5902 - val_accuracy: 0.5047\n",
            "Epoch 40/50\n",
            "218/218 [==============================] - 10s 44ms/step - loss: 0.4503 - accuracy: 0.8266 - val_loss: 1.6919 - val_accuracy: 0.4773\n",
            "Epoch 41/50\n",
            "218/218 [==============================] - 10s 47ms/step - loss: 0.4477 - accuracy: 0.8223 - val_loss: 1.6563 - val_accuracy: 0.4807\n",
            "Epoch 42/50\n",
            "218/218 [==============================] - 10s 47ms/step - loss: 0.4368 - accuracy: 0.8299 - val_loss: 1.7216 - val_accuracy: 0.4893\n",
            "Epoch 43/50\n",
            "218/218 [==============================] - 10s 47ms/step - loss: 0.4287 - accuracy: 0.8391 - val_loss: 1.7112 - val_accuracy: 0.5040\n",
            "Epoch 44/50\n",
            "218/218 [==============================] - 10s 46ms/step - loss: 0.4297 - accuracy: 0.8341 - val_loss: 1.5934 - val_accuracy: 0.4940\n",
            "Epoch 45/50\n",
            "218/218 [==============================] - 10s 45ms/step - loss: 0.4172 - accuracy: 0.8394 - val_loss: 1.6379 - val_accuracy: 0.5047\n",
            "Epoch 46/50\n",
            "218/218 [==============================] - 10s 48ms/step - loss: 0.3893 - accuracy: 0.8497 - val_loss: 1.7768 - val_accuracy: 0.4927\n",
            "Epoch 47/50\n",
            "218/218 [==============================] - 10s 47ms/step - loss: 0.3790 - accuracy: 0.8560 - val_loss: 1.6374 - val_accuracy: 0.5213\n",
            "Epoch 48/50\n",
            "218/218 [==============================] - 10s 48ms/step - loss: 0.3890 - accuracy: 0.8494 - val_loss: 1.6846 - val_accuracy: 0.4967\n",
            "Epoch 49/50\n",
            "218/218 [==============================] - 10s 45ms/step - loss: 0.3630 - accuracy: 0.8595 - val_loss: 1.8359 - val_accuracy: 0.5120\n",
            "Epoch 50/50\n",
            "218/218 [==============================] - 10s 47ms/step - loss: 0.3442 - accuracy: 0.8684 - val_loss: 1.8065 - val_accuracy: 0.4953\n",
            "218/218 [==============================] - 5s 22ms/step - loss: 0.2332 - accuracy: 0.9178\n",
            "56/56 [==============================] - 1s 21ms/step - loss: 2.1357 - accuracy: 0.4723\n",
            "Epoch 1/50\n",
            "218/218 [==============================] - 18s 65ms/step - loss: 1.3762 - accuracy: 0.2986 - val_loss: 1.4269 - val_accuracy: 0.2813\n",
            "Epoch 2/50\n",
            "218/218 [==============================] - 12s 56ms/step - loss: 1.3484 - accuracy: 0.3302 - val_loss: 1.3942 - val_accuracy: 0.2987\n",
            "Epoch 3/50\n",
            "218/218 [==============================] - 12s 55ms/step - loss: 1.3377 - accuracy: 0.3466 - val_loss: 1.3773 - val_accuracy: 0.3320\n",
            "Epoch 4/50\n",
            "218/218 [==============================] - 14s 62ms/step - loss: 1.3091 - accuracy: 0.3740 - val_loss: 1.4255 - val_accuracy: 0.3087\n",
            "Epoch 5/50\n",
            "218/218 [==============================] - 13s 58ms/step - loss: 1.2858 - accuracy: 0.3930 - val_loss: 1.4047 - val_accuracy: 0.3400\n",
            "Epoch 6/50\n",
            "218/218 [==============================] - 14s 63ms/step - loss: 1.2636 - accuracy: 0.4170 - val_loss: 1.4137 - val_accuracy: 0.3493\n",
            "Epoch 7/50\n",
            "218/218 [==============================] - 12s 57ms/step - loss: 1.2417 - accuracy: 0.4272 - val_loss: 1.3880 - val_accuracy: 0.3473\n",
            "Epoch 8/50\n",
            "218/218 [==============================] - 13s 62ms/step - loss: 1.2313 - accuracy: 0.4392 - val_loss: 1.3891 - val_accuracy: 0.3627\n",
            "Epoch 9/50\n",
            "218/218 [==============================] - 12s 56ms/step - loss: 1.2177 - accuracy: 0.4546 - val_loss: 1.4426 - val_accuracy: 0.3613\n",
            "Epoch 10/50\n",
            "218/218 [==============================] - 13s 61ms/step - loss: 1.1861 - accuracy: 0.4728 - val_loss: 1.3859 - val_accuracy: 0.3847\n",
            "Epoch 11/50\n",
            "218/218 [==============================] - 12s 56ms/step - loss: 1.1695 - accuracy: 0.4803 - val_loss: 1.3694 - val_accuracy: 0.3860\n",
            "Epoch 12/50\n",
            "218/218 [==============================] - 12s 56ms/step - loss: 1.1444 - accuracy: 0.4974 - val_loss: 1.3147 - val_accuracy: 0.4187\n",
            "Epoch 13/50\n",
            "218/218 [==============================] - 13s 61ms/step - loss: 1.1424 - accuracy: 0.4996 - val_loss: 1.4246 - val_accuracy: 0.3813\n",
            "Epoch 14/50\n",
            "218/218 [==============================] - 13s 62ms/step - loss: 1.1229 - accuracy: 0.5046 - val_loss: 1.3476 - val_accuracy: 0.4287\n",
            "Epoch 15/50\n",
            "218/218 [==============================] - 12s 56ms/step - loss: 1.0979 - accuracy: 0.5286 - val_loss: 1.4024 - val_accuracy: 0.3993\n",
            "Epoch 16/50\n",
            "218/218 [==============================] - 12s 57ms/step - loss: 1.0709 - accuracy: 0.5358 - val_loss: 1.3655 - val_accuracy: 0.4227\n",
            "Epoch 17/50\n",
            "218/218 [==============================] - 12s 56ms/step - loss: 1.0421 - accuracy: 0.5614 - val_loss: 1.3536 - val_accuracy: 0.4227\n",
            "Epoch 18/50\n",
            "218/218 [==============================] - 14s 62ms/step - loss: 1.0277 - accuracy: 0.5684 - val_loss: 1.2530 - val_accuracy: 0.4680\n",
            "Epoch 19/50\n",
            "218/218 [==============================] - 14s 63ms/step - loss: 1.0065 - accuracy: 0.5757 - val_loss: 1.3170 - val_accuracy: 0.4753\n",
            "Epoch 20/50\n",
            "218/218 [==============================] - 12s 57ms/step - loss: 0.9933 - accuracy: 0.5836 - val_loss: 1.3884 - val_accuracy: 0.4293\n",
            "Epoch 21/50\n",
            "218/218 [==============================] - 12s 56ms/step - loss: 0.9829 - accuracy: 0.5869 - val_loss: 1.4284 - val_accuracy: 0.4573\n",
            "Epoch 22/50\n",
            "218/218 [==============================] - 13s 60ms/step - loss: 0.9640 - accuracy: 0.5973 - val_loss: 1.4363 - val_accuracy: 0.4513\n",
            "Epoch 23/50\n",
            "218/218 [==============================] - 13s 62ms/step - loss: 0.9352 - accuracy: 0.6135 - val_loss: 1.4009 - val_accuracy: 0.4613\n",
            "Epoch 24/50\n",
            "218/218 [==============================] - 12s 56ms/step - loss: 0.9027 - accuracy: 0.6280 - val_loss: 1.3630 - val_accuracy: 0.4673\n",
            "Epoch 25/50\n",
            "218/218 [==============================] - 13s 62ms/step - loss: 0.8958 - accuracy: 0.6336 - val_loss: 1.3654 - val_accuracy: 0.4780\n",
            "Epoch 26/50\n",
            "218/218 [==============================] - 12s 57ms/step - loss: 0.8678 - accuracy: 0.6470 - val_loss: 1.3436 - val_accuracy: 0.4913\n",
            "Epoch 27/50\n",
            "218/218 [==============================] - 13s 61ms/step - loss: 0.8510 - accuracy: 0.6536 - val_loss: 1.4369 - val_accuracy: 0.4687\n",
            "Epoch 28/50\n",
            "218/218 [==============================] - 12s 56ms/step - loss: 0.8161 - accuracy: 0.6693 - val_loss: 1.4723 - val_accuracy: 0.4987\n",
            "Epoch 29/50\n",
            "218/218 [==============================] - 13s 60ms/step - loss: 0.8119 - accuracy: 0.6734 - val_loss: 1.5987 - val_accuracy: 0.4513\n",
            "Epoch 30/50\n",
            "218/218 [==============================] - 12s 57ms/step - loss: 0.7987 - accuracy: 0.6767 - val_loss: 1.4785 - val_accuracy: 0.4747\n",
            "Epoch 31/50\n",
            "218/218 [==============================] - 13s 61ms/step - loss: 0.7771 - accuracy: 0.6902 - val_loss: 1.4462 - val_accuracy: 0.4940\n",
            "Epoch 32/50\n",
            "218/218 [==============================] - 12s 56ms/step - loss: 0.7440 - accuracy: 0.7013 - val_loss: 1.4384 - val_accuracy: 0.4867\n",
            "Epoch 33/50\n",
            "218/218 [==============================] - 12s 56ms/step - loss: 0.7383 - accuracy: 0.7052 - val_loss: 1.5689 - val_accuracy: 0.4747\n",
            "Epoch 34/50\n",
            "218/218 [==============================] - 13s 61ms/step - loss: 0.7251 - accuracy: 0.7082 - val_loss: 1.4895 - val_accuracy: 0.4793\n",
            "Epoch 35/50\n",
            "218/218 [==============================] - 12s 56ms/step - loss: 0.7089 - accuracy: 0.7210 - val_loss: 1.5624 - val_accuracy: 0.4760\n",
            "Epoch 36/50\n",
            "218/218 [==============================] - 13s 61ms/step - loss: 0.6977 - accuracy: 0.7240 - val_loss: 1.5500 - val_accuracy: 0.5013\n",
            "Epoch 37/50\n",
            "218/218 [==============================] - 12s 57ms/step - loss: 0.6803 - accuracy: 0.7431 - val_loss: 1.6364 - val_accuracy: 0.5047\n",
            "Epoch 38/50\n",
            "218/218 [==============================] - 13s 61ms/step - loss: 0.6655 - accuracy: 0.7368 - val_loss: 1.5094 - val_accuracy: 0.4880\n",
            "Epoch 39/50\n",
            "218/218 [==============================] - 14s 62ms/step - loss: 0.6493 - accuracy: 0.7443 - val_loss: 1.6055 - val_accuracy: 0.4907\n",
            "Epoch 40/50\n",
            "218/218 [==============================] - 12s 56ms/step - loss: 0.6155 - accuracy: 0.7639 - val_loss: 1.7266 - val_accuracy: 0.4933\n",
            "Epoch 41/50\n",
            "218/218 [==============================] - 12s 56ms/step - loss: 0.6161 - accuracy: 0.7557 - val_loss: 1.6260 - val_accuracy: 0.4773\n",
            "Epoch 42/50\n",
            "218/218 [==============================] - 13s 61ms/step - loss: 0.6201 - accuracy: 0.7540 - val_loss: 1.5514 - val_accuracy: 0.4947\n",
            "Epoch 43/50\n",
            "218/218 [==============================] - 12s 56ms/step - loss: 0.5862 - accuracy: 0.7711 - val_loss: 1.6955 - val_accuracy: 0.4840\n",
            "Epoch 44/50\n",
            "218/218 [==============================] - 13s 61ms/step - loss: 0.5688 - accuracy: 0.7793 - val_loss: 1.7279 - val_accuracy: 0.4813\n",
            "Epoch 45/50\n",
            "218/218 [==============================] - 12s 56ms/step - loss: 0.5728 - accuracy: 0.7779 - val_loss: 1.8137 - val_accuracy: 0.4867\n",
            "Epoch 46/50\n",
            "218/218 [==============================] - 13s 61ms/step - loss: 0.5736 - accuracy: 0.7739 - val_loss: 1.8154 - val_accuracy: 0.4767\n",
            "Epoch 47/50\n",
            "218/218 [==============================] - 12s 57ms/step - loss: 0.5268 - accuracy: 0.7977 - val_loss: 1.7171 - val_accuracy: 0.5140\n",
            "Epoch 48/50\n",
            "218/218 [==============================] - 13s 61ms/step - loss: 0.5420 - accuracy: 0.7912 - val_loss: 1.7926 - val_accuracy: 0.4920\n",
            "Epoch 49/50\n",
            "218/218 [==============================] - 12s 56ms/step - loss: 0.5030 - accuracy: 0.8109 - val_loss: 1.7517 - val_accuracy: 0.4913\n",
            "Epoch 50/50\n",
            "218/218 [==============================] - 14s 62ms/step - loss: 0.5090 - accuracy: 0.8070 - val_loss: 1.7910 - val_accuracy: 0.5013\n",
            "218/218 [==============================] - 6s 26ms/step - loss: 0.3566 - accuracy: 0.8685\n",
            "56/56 [==============================] - 2s 30ms/step - loss: 1.7493 - accuracy: 0.4977\n",
            "Epoch 1/50\n",
            "218/218 [==============================] - 17s 66ms/step - loss: 1.3747 - accuracy: 0.2987 - val_loss: 1.4036 - val_accuracy: 0.3047\n",
            "Epoch 2/50\n",
            "218/218 [==============================] - 14s 64ms/step - loss: 1.3528 - accuracy: 0.3401 - val_loss: 1.3610 - val_accuracy: 0.3347\n",
            "Epoch 3/50\n",
            "218/218 [==============================] - 14s 64ms/step - loss: 1.3392 - accuracy: 0.3477 - val_loss: 1.3687 - val_accuracy: 0.3367\n",
            "Epoch 4/50\n",
            "218/218 [==============================] - 14s 64ms/step - loss: 1.3185 - accuracy: 0.3718 - val_loss: 1.3737 - val_accuracy: 0.3427\n",
            "Epoch 5/50\n",
            "218/218 [==============================] - 14s 65ms/step - loss: 1.2953 - accuracy: 0.3997 - val_loss: 1.3058 - val_accuracy: 0.3747\n",
            "Epoch 6/50\n",
            "218/218 [==============================] - 14s 65ms/step - loss: 1.2708 - accuracy: 0.4129 - val_loss: 1.3348 - val_accuracy: 0.3627\n",
            "Epoch 7/50\n",
            "218/218 [==============================] - 14s 65ms/step - loss: 1.2458 - accuracy: 0.4254 - val_loss: 1.3546 - val_accuracy: 0.3633\n",
            "Epoch 8/50\n",
            "218/218 [==============================] - 14s 64ms/step - loss: 1.2376 - accuracy: 0.4333 - val_loss: 1.2955 - val_accuracy: 0.3933\n",
            "Epoch 9/50\n",
            "218/218 [==============================] - 14s 64ms/step - loss: 1.2070 - accuracy: 0.4602 - val_loss: 1.3719 - val_accuracy: 0.3613\n",
            "Epoch 10/50\n",
            "218/218 [==============================] - 14s 65ms/step - loss: 1.1724 - accuracy: 0.4747 - val_loss: 1.3871 - val_accuracy: 0.3507\n",
            "Epoch 11/50\n",
            "218/218 [==============================] - 14s 64ms/step - loss: 1.1503 - accuracy: 0.4911 - val_loss: 1.4119 - val_accuracy: 0.3780\n",
            "Epoch 12/50\n",
            "218/218 [==============================] - 14s 64ms/step - loss: 1.1360 - accuracy: 0.4977 - val_loss: 1.4024 - val_accuracy: 0.3880\n",
            "Epoch 13/50\n",
            "218/218 [==============================] - 14s 64ms/step - loss: 1.1061 - accuracy: 0.5217 - val_loss: 1.3714 - val_accuracy: 0.4033\n",
            "Epoch 14/50\n",
            "218/218 [==============================] - 14s 64ms/step - loss: 1.0947 - accuracy: 0.5283 - val_loss: 1.4764 - val_accuracy: 0.4040\n",
            "Epoch 15/50\n",
            "218/218 [==============================] - 14s 64ms/step - loss: 1.0664 - accuracy: 0.5382 - val_loss: 1.2666 - val_accuracy: 0.4233\n",
            "Epoch 16/50\n",
            "218/218 [==============================] - 14s 65ms/step - loss: 1.0375 - accuracy: 0.5537 - val_loss: 1.3468 - val_accuracy: 0.4553\n",
            "Epoch 17/50\n",
            "218/218 [==============================] - 14s 64ms/step - loss: 1.0152 - accuracy: 0.5724 - val_loss: 1.4226 - val_accuracy: 0.4053\n",
            "Epoch 18/50\n",
            "218/218 [==============================] - 14s 64ms/step - loss: 0.9862 - accuracy: 0.5862 - val_loss: 1.3087 - val_accuracy: 0.4493\n",
            "Epoch 19/50\n",
            "218/218 [==============================] - 14s 65ms/step - loss: 0.9696 - accuracy: 0.5921 - val_loss: 1.4452 - val_accuracy: 0.3833\n",
            "Epoch 20/50\n",
            "218/218 [==============================] - 15s 71ms/step - loss: 0.9486 - accuracy: 0.6078 - val_loss: 1.4101 - val_accuracy: 0.4633\n",
            "Epoch 21/50\n",
            "218/218 [==============================] - 14s 64ms/step - loss: 0.9142 - accuracy: 0.6201 - val_loss: 1.4756 - val_accuracy: 0.4153\n",
            "Epoch 22/50\n",
            "218/218 [==============================] - 14s 64ms/step - loss: 0.9074 - accuracy: 0.6207 - val_loss: 1.5877 - val_accuracy: 0.4260\n",
            "Epoch 23/50\n",
            "218/218 [==============================] - 14s 65ms/step - loss: 0.8825 - accuracy: 0.6333 - val_loss: 1.5389 - val_accuracy: 0.4167\n",
            "Epoch 24/50\n",
            "218/218 [==============================] - 14s 64ms/step - loss: 0.8510 - accuracy: 0.6506 - val_loss: 1.4951 - val_accuracy: 0.4247\n",
            "Epoch 25/50\n",
            "218/218 [==============================] - 14s 64ms/step - loss: 0.8490 - accuracy: 0.6468 - val_loss: 1.3973 - val_accuracy: 0.4533\n",
            "Epoch 26/50\n",
            "218/218 [==============================] - 14s 64ms/step - loss: 0.8255 - accuracy: 0.6664 - val_loss: 1.4864 - val_accuracy: 0.4360\n",
            "Epoch 27/50\n",
            "218/218 [==============================] - 14s 64ms/step - loss: 0.8213 - accuracy: 0.6668 - val_loss: 1.5282 - val_accuracy: 0.4553\n",
            "Epoch 28/50\n",
            "218/218 [==============================] - 14s 64ms/step - loss: 0.7847 - accuracy: 0.6853 - val_loss: 1.5656 - val_accuracy: 0.4680\n",
            "Epoch 29/50\n",
            "218/218 [==============================] - 14s 64ms/step - loss: 0.7696 - accuracy: 0.6928 - val_loss: 1.5390 - val_accuracy: 0.4727\n",
            "Epoch 30/50\n",
            "218/218 [==============================] - 14s 64ms/step - loss: 0.7460 - accuracy: 0.7096 - val_loss: 1.6346 - val_accuracy: 0.4560\n",
            "Epoch 31/50\n",
            "218/218 [==============================] - 14s 63ms/step - loss: 0.7558 - accuracy: 0.6940 - val_loss: 1.4727 - val_accuracy: 0.4380\n",
            "Epoch 32/50\n",
            "218/218 [==============================] - 14s 64ms/step - loss: 0.7136 - accuracy: 0.7172 - val_loss: 1.5096 - val_accuracy: 0.4860\n",
            "Epoch 33/50\n",
            "218/218 [==============================] - 14s 64ms/step - loss: 0.7048 - accuracy: 0.7224 - val_loss: 1.5519 - val_accuracy: 0.4660\n",
            "Epoch 34/50\n",
            "218/218 [==============================] - 15s 70ms/step - loss: 0.6930 - accuracy: 0.7267 - val_loss: 1.5701 - val_accuracy: 0.4780\n",
            "Epoch 35/50\n",
            "218/218 [==============================] - 14s 64ms/step - loss: 0.6822 - accuracy: 0.7336 - val_loss: 1.5539 - val_accuracy: 0.4787\n",
            "Epoch 36/50\n",
            "218/218 [==============================] - 14s 64ms/step - loss: 0.6451 - accuracy: 0.7420 - val_loss: 1.6162 - val_accuracy: 0.4633\n",
            "Epoch 37/50\n",
            "218/218 [==============================] - 14s 64ms/step - loss: 0.6361 - accuracy: 0.7490 - val_loss: 1.5893 - val_accuracy: 0.4740\n",
            "Epoch 38/50\n",
            "218/218 [==============================] - 14s 63ms/step - loss: 0.6234 - accuracy: 0.7527 - val_loss: 1.7572 - val_accuracy: 0.4587\n",
            "Epoch 39/50\n",
            "218/218 [==============================] - 14s 64ms/step - loss: 0.6263 - accuracy: 0.7563 - val_loss: 1.5666 - val_accuracy: 0.4933\n",
            "Epoch 40/50\n",
            "218/218 [==============================] - 14s 63ms/step - loss: 0.6013 - accuracy: 0.7695 - val_loss: 1.6307 - val_accuracy: 0.4980\n",
            "Epoch 41/50\n",
            "218/218 [==============================] - 14s 64ms/step - loss: 0.5960 - accuracy: 0.7668 - val_loss: 1.7040 - val_accuracy: 0.4820\n",
            "Epoch 42/50\n",
            "218/218 [==============================] - 14s 64ms/step - loss: 0.5773 - accuracy: 0.7749 - val_loss: 1.6180 - val_accuracy: 0.5113\n",
            "Epoch 43/50\n",
            "218/218 [==============================] - 14s 64ms/step - loss: 0.5525 - accuracy: 0.7829 - val_loss: 1.6880 - val_accuracy: 0.5000\n",
            "Epoch 44/50\n",
            "218/218 [==============================] - 14s 64ms/step - loss: 0.5686 - accuracy: 0.7793 - val_loss: 1.6616 - val_accuracy: 0.4793\n",
            "Epoch 45/50\n",
            "218/218 [==============================] - 14s 64ms/step - loss: 0.5341 - accuracy: 0.7897 - val_loss: 1.7296 - val_accuracy: 0.5220\n",
            "Epoch 46/50\n",
            "218/218 [==============================] - 14s 65ms/step - loss: 0.5377 - accuracy: 0.7891 - val_loss: 1.6047 - val_accuracy: 0.5167\n",
            "Epoch 47/50\n",
            "218/218 [==============================] - 14s 66ms/step - loss: 0.5180 - accuracy: 0.7955 - val_loss: 1.6960 - val_accuracy: 0.5287\n",
            "Epoch 48/50\n",
            "218/218 [==============================] - 14s 66ms/step - loss: 0.4967 - accuracy: 0.8092 - val_loss: 1.6723 - val_accuracy: 0.5180\n",
            "Epoch 49/50\n",
            "218/218 [==============================] - 14s 64ms/step - loss: 0.5037 - accuracy: 0.8047 - val_loss: 1.8779 - val_accuracy: 0.4600\n",
            "Epoch 50/50\n",
            "218/218 [==============================] - 14s 64ms/step - loss: 0.4728 - accuracy: 0.8172 - val_loss: 1.8785 - val_accuracy: 0.4660\n",
            "218/218 [==============================] - 6s 30ms/step - loss: 0.4512 - accuracy: 0.8293\n",
            "56/56 [==============================] - 2s 27ms/step - loss: 2.0274 - accuracy: 0.4690\n",
            "Epoch 1/50\n",
            "218/218 [==============================] - 20s 74ms/step - loss: 1.3785 - accuracy: 0.2940 - val_loss: 1.3685 - val_accuracy: 0.3053\n",
            "Epoch 2/50\n",
            "218/218 [==============================] - 16s 71ms/step - loss: 1.3580 - accuracy: 0.3155 - val_loss: 1.3622 - val_accuracy: 0.3353\n",
            "Epoch 3/50\n",
            "218/218 [==============================] - 15s 71ms/step - loss: 1.3338 - accuracy: 0.3483 - val_loss: 1.3832 - val_accuracy: 0.3053\n",
            "Epoch 4/50\n",
            "218/218 [==============================] - 17s 78ms/step - loss: 1.3264 - accuracy: 0.3575 - val_loss: 1.3816 - val_accuracy: 0.3407\n",
            "Epoch 5/50\n",
            "218/218 [==============================] - 16s 71ms/step - loss: 1.3068 - accuracy: 0.3783 - val_loss: 1.3750 - val_accuracy: 0.3473\n",
            "Epoch 6/50\n",
            "218/218 [==============================] - 15s 71ms/step - loss: 1.2751 - accuracy: 0.3907 - val_loss: 1.3397 - val_accuracy: 0.3753\n",
            "Epoch 7/50\n",
            "218/218 [==============================] - 16s 72ms/step - loss: 1.2525 - accuracy: 0.4152 - val_loss: 1.4147 - val_accuracy: 0.3633\n",
            "Epoch 8/50\n",
            "218/218 [==============================] - 15s 71ms/step - loss: 1.2218 - accuracy: 0.4407 - val_loss: 1.3242 - val_accuracy: 0.3940\n",
            "Epoch 9/50\n",
            "218/218 [==============================] - 16s 74ms/step - loss: 1.2002 - accuracy: 0.4593 - val_loss: 1.3636 - val_accuracy: 0.4067\n",
            "Epoch 10/50\n",
            "218/218 [==============================] - 16s 71ms/step - loss: 1.1836 - accuracy: 0.4695 - val_loss: 1.3551 - val_accuracy: 0.3713\n",
            "Epoch 11/50\n",
            "218/218 [==============================] - 16s 72ms/step - loss: 1.1716 - accuracy: 0.4741 - val_loss: 1.2979 - val_accuracy: 0.3947\n",
            "Epoch 12/50\n",
            "218/218 [==============================] - 15s 71ms/step - loss: 1.1437 - accuracy: 0.4981 - val_loss: 1.3099 - val_accuracy: 0.3960\n",
            "Epoch 13/50\n",
            "218/218 [==============================] - 15s 71ms/step - loss: 1.1238 - accuracy: 0.5085 - val_loss: 1.3843 - val_accuracy: 0.3853\n",
            "Epoch 14/50\n",
            "218/218 [==============================] - 17s 78ms/step - loss: 1.1181 - accuracy: 0.5068 - val_loss: 1.3140 - val_accuracy: 0.3940\n",
            "Epoch 15/50\n",
            "218/218 [==============================] - 16s 71ms/step - loss: 1.0880 - accuracy: 0.5313 - val_loss: 1.3761 - val_accuracy: 0.4013\n",
            "Epoch 16/50\n",
            "218/218 [==============================] - 16s 72ms/step - loss: 1.0697 - accuracy: 0.5375 - val_loss: 1.3961 - val_accuracy: 0.4107\n",
            "Epoch 17/50\n",
            "218/218 [==============================] - 16s 71ms/step - loss: 1.0520 - accuracy: 0.5513 - val_loss: 1.4132 - val_accuracy: 0.3853\n",
            "Epoch 18/50\n",
            "218/218 [==============================] - 16s 72ms/step - loss: 1.0274 - accuracy: 0.5647 - val_loss: 1.3450 - val_accuracy: 0.4260\n",
            "Epoch 19/50\n",
            "218/218 [==============================] - 16s 73ms/step - loss: 0.9874 - accuracy: 0.5843 - val_loss: 1.4757 - val_accuracy: 0.4173\n",
            "Epoch 20/50\n",
            "218/218 [==============================] - 16s 72ms/step - loss: 0.9840 - accuracy: 0.5922 - val_loss: 1.4514 - val_accuracy: 0.4113\n",
            "Epoch 21/50\n",
            "218/218 [==============================] - 16s 72ms/step - loss: 0.9547 - accuracy: 0.6030 - val_loss: 1.3601 - val_accuracy: 0.4353\n",
            "Epoch 22/50\n",
            "218/218 [==============================] - 16s 72ms/step - loss: 0.9263 - accuracy: 0.6218 - val_loss: 1.2913 - val_accuracy: 0.4660\n",
            "Epoch 23/50\n",
            "218/218 [==============================] - 17s 78ms/step - loss: 0.9153 - accuracy: 0.6282 - val_loss: 1.4154 - val_accuracy: 0.4380\n",
            "Epoch 24/50\n",
            "218/218 [==============================] - 16s 72ms/step - loss: 0.8968 - accuracy: 0.6386 - val_loss: 1.4589 - val_accuracy: 0.4407\n",
            "Epoch 25/50\n",
            "218/218 [==============================] - 15s 71ms/step - loss: 0.8799 - accuracy: 0.6375 - val_loss: 1.4653 - val_accuracy: 0.4413\n",
            "Epoch 26/50\n",
            "218/218 [==============================] - 16s 72ms/step - loss: 0.8515 - accuracy: 0.6595 - val_loss: 1.3241 - val_accuracy: 0.4567\n",
            "Epoch 27/50\n",
            "218/218 [==============================] - 16s 72ms/step - loss: 0.8383 - accuracy: 0.6612 - val_loss: 1.3415 - val_accuracy: 0.4507\n",
            "Epoch 28/50\n",
            "218/218 [==============================] - 16s 74ms/step - loss: 0.8068 - accuracy: 0.6760 - val_loss: 1.5682 - val_accuracy: 0.4407\n",
            "Epoch 29/50\n",
            "218/218 [==============================] - 16s 72ms/step - loss: 0.7892 - accuracy: 0.6879 - val_loss: 1.2986 - val_accuracy: 0.4753\n",
            "Epoch 30/50\n",
            "218/218 [==============================] - 15s 71ms/step - loss: 0.7910 - accuracy: 0.6908 - val_loss: 1.4135 - val_accuracy: 0.4427\n",
            "Epoch 31/50\n",
            "218/218 [==============================] - 16s 72ms/step - loss: 0.7704 - accuracy: 0.6957 - val_loss: 1.3930 - val_accuracy: 0.4793\n",
            "Epoch 32/50\n",
            "218/218 [==============================] - 16s 72ms/step - loss: 0.7520 - accuracy: 0.7042 - val_loss: 1.4510 - val_accuracy: 0.4693\n",
            "Epoch 33/50\n",
            "218/218 [==============================] - 16s 73ms/step - loss: 0.7483 - accuracy: 0.7026 - val_loss: 1.3835 - val_accuracy: 0.5073\n",
            "Epoch 34/50\n",
            "218/218 [==============================] - 16s 71ms/step - loss: 0.7427 - accuracy: 0.7079 - val_loss: 1.3458 - val_accuracy: 0.4640\n",
            "Epoch 35/50\n",
            "218/218 [==============================] - 16s 72ms/step - loss: 0.7227 - accuracy: 0.7172 - val_loss: 1.3368 - val_accuracy: 0.4933\n",
            "Epoch 36/50\n",
            "218/218 [==============================] - 16s 71ms/step - loss: 0.6843 - accuracy: 0.7398 - val_loss: 1.3453 - val_accuracy: 0.4980\n",
            "Epoch 37/50\n",
            "218/218 [==============================] - 15s 71ms/step - loss: 0.6911 - accuracy: 0.7307 - val_loss: 1.3439 - val_accuracy: 0.4947\n",
            "Epoch 38/50\n",
            "218/218 [==============================] - 16s 74ms/step - loss: 0.6790 - accuracy: 0.7341 - val_loss: 1.3206 - val_accuracy: 0.4860\n",
            "Epoch 39/50\n",
            "218/218 [==============================] - 15s 71ms/step - loss: 0.6546 - accuracy: 0.7438 - val_loss: 1.3923 - val_accuracy: 0.4807\n",
            "Epoch 40/50\n",
            "218/218 [==============================] - 16s 72ms/step - loss: 0.6272 - accuracy: 0.7527 - val_loss: 1.4406 - val_accuracy: 0.4847\n",
            "Epoch 41/50\n",
            "218/218 [==============================] - 16s 71ms/step - loss: 0.6416 - accuracy: 0.7540 - val_loss: 1.4781 - val_accuracy: 0.4820\n",
            "Epoch 42/50\n",
            "218/218 [==============================] - 16s 72ms/step - loss: 0.6187 - accuracy: 0.7596 - val_loss: 1.5013 - val_accuracy: 0.4753\n",
            "Epoch 43/50\n",
            "218/218 [==============================] - 17s 78ms/step - loss: 0.6315 - accuracy: 0.7569 - val_loss: 1.4246 - val_accuracy: 0.4833\n",
            "Epoch 44/50\n",
            "218/218 [==============================] - 16s 72ms/step - loss: 0.6045 - accuracy: 0.7622 - val_loss: 1.5188 - val_accuracy: 0.4780\n",
            "Epoch 45/50\n",
            "218/218 [==============================] - 16s 72ms/step - loss: 0.5960 - accuracy: 0.7688 - val_loss: 1.5533 - val_accuracy: 0.4993\n",
            "Epoch 46/50\n",
            "218/218 [==============================] - 16s 72ms/step - loss: 0.5642 - accuracy: 0.7828 - val_loss: 1.5507 - val_accuracy: 0.4880\n",
            "Epoch 47/50\n",
            "218/218 [==============================] - 16s 73ms/step - loss: 0.5711 - accuracy: 0.7764 - val_loss: 1.5235 - val_accuracy: 0.5140\n",
            "Epoch 48/50\n",
            "218/218 [==============================] - 16s 73ms/step - loss: 0.5595 - accuracy: 0.7853 - val_loss: 1.4960 - val_accuracy: 0.5153\n",
            "Epoch 49/50\n",
            "218/218 [==============================] - 16s 71ms/step - loss: 0.5512 - accuracy: 0.7838 - val_loss: 1.5187 - val_accuracy: 0.4960\n",
            "Epoch 50/50\n",
            "218/218 [==============================] - 16s 72ms/step - loss: 0.5519 - accuracy: 0.7891 - val_loss: 1.6198 - val_accuracy: 0.5087\n",
            "218/218 [==============================] - 7s 32ms/step - loss: 0.5444 - accuracy: 0.7971\n",
            "56/56 [==============================] - 2s 29ms/step - loss: 1.8479 - accuracy: 0.4678\n",
            "Epoch 1/50\n",
            "218/218 [==============================] - 21s 83ms/step - loss: 1.3702 - accuracy: 0.3055 - val_loss: 1.3867 - val_accuracy: 0.2927\n",
            "Epoch 2/50\n",
            "218/218 [==============================] - 19s 86ms/step - loss: 1.3531 - accuracy: 0.3318 - val_loss: 1.4342 - val_accuracy: 0.2820\n",
            "Epoch 3/50\n",
            "218/218 [==============================] - 17s 80ms/step - loss: 1.3317 - accuracy: 0.3593 - val_loss: 1.3987 - val_accuracy: 0.2840\n",
            "Epoch 4/50\n",
            "218/218 [==============================] - 17s 79ms/step - loss: 1.3048 - accuracy: 0.3826 - val_loss: 1.4205 - val_accuracy: 0.3387\n",
            "Epoch 5/50\n",
            "218/218 [==============================] - 18s 81ms/step - loss: 1.2816 - accuracy: 0.4049 - val_loss: 1.4037 - val_accuracy: 0.3433\n",
            "Epoch 6/50\n",
            "218/218 [==============================] - 17s 79ms/step - loss: 1.2614 - accuracy: 0.4178 - val_loss: 1.4485 - val_accuracy: 0.3100\n",
            "Epoch 7/50\n",
            "218/218 [==============================] - 17s 79ms/step - loss: 1.2366 - accuracy: 0.4339 - val_loss: 1.3546 - val_accuracy: 0.3673\n",
            "Epoch 8/50\n",
            "218/218 [==============================] - 18s 81ms/step - loss: 1.2080 - accuracy: 0.4601 - val_loss: 1.4112 - val_accuracy: 0.3707\n",
            "Epoch 9/50\n",
            "218/218 [==============================] - 17s 79ms/step - loss: 1.1924 - accuracy: 0.4690 - val_loss: 1.4961 - val_accuracy: 0.3427\n",
            "Epoch 10/50\n",
            "218/218 [==============================] - 17s 79ms/step - loss: 1.1656 - accuracy: 0.4839 - val_loss: 1.4615 - val_accuracy: 0.3793\n",
            "Epoch 11/50\n",
            "218/218 [==============================] - 18s 82ms/step - loss: 1.1504 - accuracy: 0.4935 - val_loss: 1.3602 - val_accuracy: 0.4027\n",
            "Epoch 12/50\n",
            "218/218 [==============================] - 17s 80ms/step - loss: 1.1146 - accuracy: 0.5122 - val_loss: 1.4704 - val_accuracy: 0.3987\n",
            "Epoch 13/50\n",
            "218/218 [==============================] - 17s 79ms/step - loss: 1.0950 - accuracy: 0.5307 - val_loss: 1.4310 - val_accuracy: 0.3673\n",
            "Epoch 14/50\n",
            "218/218 [==============================] - 18s 81ms/step - loss: 1.0741 - accuracy: 0.5381 - val_loss: 1.4429 - val_accuracy: 0.4020\n",
            "Epoch 15/50\n",
            "218/218 [==============================] - 17s 79ms/step - loss: 1.0580 - accuracy: 0.5394 - val_loss: 1.5079 - val_accuracy: 0.3687\n",
            "Epoch 16/50\n",
            "218/218 [==============================] - 17s 79ms/step - loss: 1.0332 - accuracy: 0.5657 - val_loss: 1.4839 - val_accuracy: 0.4013\n",
            "Epoch 17/50\n",
            "218/218 [==============================] - 18s 81ms/step - loss: 1.0067 - accuracy: 0.5764 - val_loss: 1.4492 - val_accuracy: 0.3940\n",
            "Epoch 18/50\n",
            "218/218 [==============================] - 17s 79ms/step - loss: 0.9747 - accuracy: 0.5891 - val_loss: 1.4999 - val_accuracy: 0.3973\n",
            "Epoch 19/50\n",
            "218/218 [==============================] - 17s 79ms/step - loss: 0.9545 - accuracy: 0.6034 - val_loss: 1.3879 - val_accuracy: 0.4107\n",
            "Epoch 20/50\n",
            "218/218 [==============================] - 18s 81ms/step - loss: 0.9249 - accuracy: 0.6180 - val_loss: 1.5551 - val_accuracy: 0.3987\n",
            "Epoch 21/50\n",
            "218/218 [==============================] - 17s 79ms/step - loss: 0.9207 - accuracy: 0.6180 - val_loss: 1.5908 - val_accuracy: 0.3953\n",
            "Epoch 22/50\n",
            "218/218 [==============================] - 17s 79ms/step - loss: 0.8947 - accuracy: 0.6267 - val_loss: 1.6519 - val_accuracy: 0.3927\n",
            "Epoch 23/50\n",
            "218/218 [==============================] - 18s 82ms/step - loss: 0.8678 - accuracy: 0.6404 - val_loss: 1.4686 - val_accuracy: 0.4180\n",
            "Epoch 24/50\n",
            "218/218 [==============================] - 17s 79ms/step - loss: 0.8504 - accuracy: 0.6586 - val_loss: 1.6209 - val_accuracy: 0.4260\n",
            "Epoch 25/50\n",
            "218/218 [==============================] - 17s 79ms/step - loss: 0.8372 - accuracy: 0.6579 - val_loss: 1.5869 - val_accuracy: 0.4153\n",
            "Epoch 26/50\n",
            "218/218 [==============================] - 19s 86ms/step - loss: 0.8322 - accuracy: 0.6592 - val_loss: 1.4905 - val_accuracy: 0.4460\n",
            "Epoch 27/50\n",
            "218/218 [==============================] - 17s 80ms/step - loss: 0.8098 - accuracy: 0.6718 - val_loss: 1.5012 - val_accuracy: 0.4140\n",
            "Epoch 28/50\n",
            "218/218 [==============================] - 17s 80ms/step - loss: 0.8004 - accuracy: 0.6751 - val_loss: 1.6082 - val_accuracy: 0.4200\n",
            "Epoch 29/50\n",
            "218/218 [==============================] - 18s 81ms/step - loss: 0.7762 - accuracy: 0.6872 - val_loss: 1.5992 - val_accuracy: 0.4253\n",
            "Epoch 30/50\n",
            "218/218 [==============================] - 17s 79ms/step - loss: 0.7637 - accuracy: 0.6955 - val_loss: 1.7302 - val_accuracy: 0.4607\n",
            "Epoch 31/50\n",
            "218/218 [==============================] - 17s 79ms/step - loss: 0.7555 - accuracy: 0.6931 - val_loss: 1.7727 - val_accuracy: 0.4307\n",
            "Epoch 32/50\n",
            "218/218 [==============================] - 18s 81ms/step - loss: 0.7270 - accuracy: 0.7114 - val_loss: 1.8463 - val_accuracy: 0.4307\n",
            "Epoch 33/50\n",
            "218/218 [==============================] - 17s 79ms/step - loss: 0.7242 - accuracy: 0.7170 - val_loss: 1.7055 - val_accuracy: 0.4287\n",
            "Epoch 34/50\n",
            "218/218 [==============================] - 17s 79ms/step - loss: 0.7059 - accuracy: 0.7241 - val_loss: 1.7521 - val_accuracy: 0.4260\n",
            "Epoch 35/50\n",
            "218/218 [==============================] - 18s 81ms/step - loss: 0.7150 - accuracy: 0.7145 - val_loss: 1.6846 - val_accuracy: 0.4020\n",
            "Epoch 36/50\n",
            "218/218 [==============================] - 17s 79ms/step - loss: 0.6981 - accuracy: 0.7218 - val_loss: 1.7491 - val_accuracy: 0.4273\n",
            "Epoch 37/50\n",
            "218/218 [==============================] - 17s 79ms/step - loss: 0.6558 - accuracy: 0.7424 - val_loss: 1.7681 - val_accuracy: 0.4227\n",
            "Epoch 38/50\n",
            "218/218 [==============================] - 18s 81ms/step - loss: 0.6540 - accuracy: 0.7404 - val_loss: 1.7283 - val_accuracy: 0.4353\n",
            "Epoch 39/50\n",
            "218/218 [==============================] - 17s 80ms/step - loss: 0.6401 - accuracy: 0.7451 - val_loss: 1.7043 - val_accuracy: 0.4293\n",
            "Epoch 40/50\n",
            "218/218 [==============================] - 17s 79ms/step - loss: 0.6307 - accuracy: 0.7526 - val_loss: 1.8183 - val_accuracy: 0.4340\n",
            "Epoch 41/50\n",
            "218/218 [==============================] - 18s 81ms/step - loss: 0.6186 - accuracy: 0.7573 - val_loss: 1.9475 - val_accuracy: 0.4333\n",
            "Epoch 42/50\n",
            "218/218 [==============================] - 17s 79ms/step - loss: 0.6062 - accuracy: 0.7680 - val_loss: 1.7476 - val_accuracy: 0.4347\n",
            "Epoch 43/50\n",
            "218/218 [==============================] - 17s 79ms/step - loss: 0.5752 - accuracy: 0.7720 - val_loss: 1.8862 - val_accuracy: 0.4313\n",
            "Epoch 44/50\n",
            "218/218 [==============================] - 18s 81ms/step - loss: 0.5705 - accuracy: 0.7806 - val_loss: 1.9832 - val_accuracy: 0.4427\n",
            "Epoch 45/50\n",
            "218/218 [==============================] - 17s 79ms/step - loss: 0.5779 - accuracy: 0.7691 - val_loss: 1.8544 - val_accuracy: 0.4180\n",
            "Epoch 46/50\n",
            "218/218 [==============================] - 17s 79ms/step - loss: 0.5566 - accuracy: 0.7835 - val_loss: 1.9538 - val_accuracy: 0.4320\n",
            "Epoch 47/50\n",
            "218/218 [==============================] - 18s 81ms/step - loss: 0.5578 - accuracy: 0.7795 - val_loss: 1.9122 - val_accuracy: 0.4167\n",
            "Epoch 48/50\n",
            "218/218 [==============================] - 17s 79ms/step - loss: 0.5447 - accuracy: 0.7875 - val_loss: 2.1939 - val_accuracy: 0.4227\n",
            "Epoch 49/50\n",
            "218/218 [==============================] - 17s 79ms/step - loss: 0.5382 - accuracy: 0.7954 - val_loss: 1.8859 - val_accuracy: 0.4460\n",
            "Epoch 50/50\n",
            "218/218 [==============================] - 18s 81ms/step - loss: 0.5310 - accuracy: 0.7924 - val_loss: 2.0368 - val_accuracy: 0.4520\n",
            "218/218 [==============================] - 7s 31ms/step - loss: 0.4738 - accuracy: 0.8168\n",
            "56/56 [==============================] - 2s 38ms/step - loss: 1.9861 - accuracy: 0.4447\n",
            "Epoch 1/50\n",
            "218/218 [==============================] - 23s 96ms/step - loss: 1.3752 - accuracy: 0.2945 - val_loss: 1.4114 - val_accuracy: 0.2780\n",
            "Epoch 2/50\n",
            "218/218 [==============================] - 19s 87ms/step - loss: 1.3568 - accuracy: 0.3256 - val_loss: 1.4050 - val_accuracy: 0.3067\n",
            "Epoch 3/50\n",
            "218/218 [==============================] - 19s 89ms/step - loss: 1.3370 - accuracy: 0.3625 - val_loss: 1.3660 - val_accuracy: 0.3180\n",
            "Epoch 4/50\n",
            "218/218 [==============================] - 19s 88ms/step - loss: 1.3078 - accuracy: 0.3851 - val_loss: 1.3760 - val_accuracy: 0.3053\n",
            "Epoch 5/50\n",
            "218/218 [==============================] - 20s 90ms/step - loss: 1.2959 - accuracy: 0.3967 - val_loss: 1.3706 - val_accuracy: 0.3433\n",
            "Epoch 6/50\n",
            "218/218 [==============================] - 19s 88ms/step - loss: 1.2632 - accuracy: 0.4197 - val_loss: 1.3880 - val_accuracy: 0.3420\n",
            "Epoch 7/50\n",
            "218/218 [==============================] - 20s 90ms/step - loss: 1.2652 - accuracy: 0.4141 - val_loss: 1.3439 - val_accuracy: 0.3347\n",
            "Epoch 8/50\n",
            "218/218 [==============================] - 19s 88ms/step - loss: 1.2344 - accuracy: 0.4430 - val_loss: 1.3395 - val_accuracy: 0.3540\n",
            "Epoch 9/50\n",
            "218/218 [==============================] - 20s 90ms/step - loss: 1.2048 - accuracy: 0.4530 - val_loss: 1.3116 - val_accuracy: 0.3960\n",
            "Epoch 10/50\n",
            "218/218 [==============================] - 19s 88ms/step - loss: 1.1803 - accuracy: 0.4759 - val_loss: 1.2993 - val_accuracy: 0.3913\n",
            "Epoch 11/50\n",
            "218/218 [==============================] - 20s 90ms/step - loss: 1.1495 - accuracy: 0.4868 - val_loss: 1.4143 - val_accuracy: 0.3993\n",
            "Epoch 12/50\n",
            "218/218 [==============================] - 19s 88ms/step - loss: 1.1382 - accuracy: 0.5019 - val_loss: 1.2683 - val_accuracy: 0.3840\n",
            "Epoch 13/50\n",
            "218/218 [==============================] - 20s 90ms/step - loss: 1.1085 - accuracy: 0.5165 - val_loss: 1.4097 - val_accuracy: 0.3833\n",
            "Epoch 14/50\n",
            "218/218 [==============================] - 19s 88ms/step - loss: 1.0792 - accuracy: 0.5349 - val_loss: 1.4062 - val_accuracy: 0.3860\n",
            "Epoch 15/50\n",
            "218/218 [==============================] - 20s 90ms/step - loss: 1.0549 - accuracy: 0.5399 - val_loss: 1.3523 - val_accuracy: 0.4153\n",
            "Epoch 16/50\n",
            "218/218 [==============================] - 19s 88ms/step - loss: 1.0330 - accuracy: 0.5614 - val_loss: 1.3397 - val_accuracy: 0.3907\n",
            "Epoch 17/50\n",
            "218/218 [==============================] - 20s 93ms/step - loss: 1.0136 - accuracy: 0.5670 - val_loss: 1.3277 - val_accuracy: 0.4213\n",
            "Epoch 18/50\n",
            "218/218 [==============================] - 20s 94ms/step - loss: 0.9852 - accuracy: 0.5812 - val_loss: 1.4119 - val_accuracy: 0.3920\n",
            "Epoch 19/50\n",
            "218/218 [==============================] - 21s 96ms/step - loss: 0.9897 - accuracy: 0.5786 - val_loss: 1.4978 - val_accuracy: 0.4127\n",
            "Epoch 20/50\n",
            "218/218 [==============================] - 19s 89ms/step - loss: 0.9536 - accuracy: 0.5986 - val_loss: 1.4069 - val_accuracy: 0.4293\n",
            "Epoch 21/50\n",
            "218/218 [==============================] - 19s 89ms/step - loss: 0.9181 - accuracy: 0.6129 - val_loss: 1.4638 - val_accuracy: 0.4273\n",
            "Epoch 22/50\n",
            "218/218 [==============================] - 19s 88ms/step - loss: 0.9032 - accuracy: 0.6264 - val_loss: 1.5430 - val_accuracy: 0.4147\n",
            "Epoch 23/50\n",
            "218/218 [==============================] - 19s 89ms/step - loss: 0.8742 - accuracy: 0.6447 - val_loss: 1.3181 - val_accuracy: 0.4413\n",
            "Epoch 24/50\n",
            "218/218 [==============================] - 19s 87ms/step - loss: 0.8727 - accuracy: 0.6409 - val_loss: 1.4968 - val_accuracy: 0.4233\n",
            "Epoch 25/50\n",
            "218/218 [==============================] - 20s 90ms/step - loss: 0.8389 - accuracy: 0.6611 - val_loss: 1.3932 - val_accuracy: 0.4587\n",
            "Epoch 26/50\n",
            "218/218 [==============================] - 19s 89ms/step - loss: 0.8218 - accuracy: 0.6697 - val_loss: 1.6723 - val_accuracy: 0.4460\n",
            "Epoch 27/50\n",
            "218/218 [==============================] - 20s 90ms/step - loss: 0.7920 - accuracy: 0.6776 - val_loss: 1.4969 - val_accuracy: 0.4400\n",
            "Epoch 28/50\n",
            "218/218 [==============================] - 19s 88ms/step - loss: 0.7790 - accuracy: 0.6843 - val_loss: 1.4216 - val_accuracy: 0.4473\n",
            "Epoch 29/50\n",
            "218/218 [==============================] - 20s 90ms/step - loss: 0.7579 - accuracy: 0.6931 - val_loss: 1.5232 - val_accuracy: 0.4687\n",
            "Epoch 30/50\n",
            "218/218 [==============================] - 19s 88ms/step - loss: 0.7695 - accuracy: 0.6869 - val_loss: 1.5418 - val_accuracy: 0.4427\n",
            "Epoch 31/50\n",
            "218/218 [==============================] - 20s 90ms/step - loss: 0.7236 - accuracy: 0.7032 - val_loss: 1.7016 - val_accuracy: 0.4507\n",
            "Epoch 32/50\n",
            "218/218 [==============================] - 19s 88ms/step - loss: 0.7157 - accuracy: 0.7060 - val_loss: 1.3976 - val_accuracy: 0.4820\n",
            "Epoch 33/50\n",
            "218/218 [==============================] - 20s 90ms/step - loss: 0.7011 - accuracy: 0.7198 - val_loss: 1.4149 - val_accuracy: 0.4573\n",
            "Epoch 34/50\n",
            "218/218 [==============================] - 19s 88ms/step - loss: 0.6813 - accuracy: 0.7313 - val_loss: 1.6579 - val_accuracy: 0.4307\n",
            "Epoch 35/50\n",
            "218/218 [==============================] - 20s 91ms/step - loss: 0.6539 - accuracy: 0.7489 - val_loss: 1.6568 - val_accuracy: 0.4520\n",
            "Epoch 36/50\n",
            "218/218 [==============================] - 19s 88ms/step - loss: 0.6426 - accuracy: 0.7484 - val_loss: 1.6454 - val_accuracy: 0.4447\n",
            "Epoch 37/50\n",
            "218/218 [==============================] - 20s 94ms/step - loss: 0.6414 - accuracy: 0.7501 - val_loss: 1.6551 - val_accuracy: 0.4640\n",
            "Epoch 38/50\n",
            "218/218 [==============================] - 19s 88ms/step - loss: 0.6179 - accuracy: 0.7645 - val_loss: 1.6151 - val_accuracy: 0.4667\n",
            "Epoch 39/50\n",
            "218/218 [==============================] - 20s 90ms/step - loss: 0.6110 - accuracy: 0.7559 - val_loss: 1.6886 - val_accuracy: 0.4620\n",
            "Epoch 40/50\n",
            "218/218 [==============================] - 19s 88ms/step - loss: 0.5786 - accuracy: 0.7733 - val_loss: 1.7517 - val_accuracy: 0.4580\n",
            "Epoch 41/50\n",
            "218/218 [==============================] - 20s 90ms/step - loss: 0.5993 - accuracy: 0.7588 - val_loss: 1.6681 - val_accuracy: 0.4613\n",
            "Epoch 42/50\n",
            "218/218 [==============================] - 19s 88ms/step - loss: 0.5532 - accuracy: 0.7842 - val_loss: 1.8122 - val_accuracy: 0.4653\n",
            "Epoch 43/50\n",
            "218/218 [==============================] - 20s 90ms/step - loss: 0.5481 - accuracy: 0.7843 - val_loss: 1.7679 - val_accuracy: 0.4607\n",
            "Epoch 44/50\n",
            "218/218 [==============================] - 19s 88ms/step - loss: 0.5554 - accuracy: 0.7754 - val_loss: 1.6404 - val_accuracy: 0.4560\n",
            "Epoch 45/50\n",
            "218/218 [==============================] - 20s 90ms/step - loss: 0.5370 - accuracy: 0.7914 - val_loss: 1.7174 - val_accuracy: 0.4733\n",
            "Epoch 46/50\n",
            "218/218 [==============================] - 19s 88ms/step - loss: 0.5199 - accuracy: 0.7924 - val_loss: 1.7635 - val_accuracy: 0.4593\n",
            "Epoch 47/50\n",
            "218/218 [==============================] - 20s 90ms/step - loss: 0.5029 - accuracy: 0.8017 - val_loss: 1.7518 - val_accuracy: 0.4673\n",
            "Epoch 48/50\n",
            "218/218 [==============================] - 19s 88ms/step - loss: 0.4632 - accuracy: 0.8194 - val_loss: 1.9321 - val_accuracy: 0.4513\n",
            "Epoch 49/50\n",
            "218/218 [==============================] - 20s 90ms/step - loss: 0.4951 - accuracy: 0.8103 - val_loss: 1.8558 - val_accuracy: 0.4567\n",
            "Epoch 50/50\n",
            "218/218 [==============================] - 19s 88ms/step - loss: 0.4869 - accuracy: 0.8111 - val_loss: 1.8851 - val_accuracy: 0.4507\n",
            "218/218 [==============================] - 7s 34ms/step - loss: 0.4190 - accuracy: 0.8355\n",
            "56/56 [==============================] - 2s 34ms/step - loss: 2.0443 - accuracy: 0.4650\n",
            "{'50': 0.7468391060829163, '100': 0.852729856967926, '150': 0.8494253158569336, '200': 0.907471239566803, '250': 0.9033045768737793, '300': 0.9173850417137146, '350': 0.9178161025047302, '400': 0.868534505367279, '450': 0.8293103575706482, '500': 0.7971264123916626, '550': 0.8168103694915771, '600': 0.835488498210907}\n",
            "{'50': 0.3340857923030853, '100': 0.41704288125038147, '150': 0.43566590547561646, '200': 0.44300225377082825, '250': 0.4774266481399536, '300': 0.493792325258255, '350': 0.472347617149353, '400': 0.4977426528930664, '450': 0.468961626291275, '500': 0.4678329527378082, '550': 0.44469526410102844, '600': 0.4650112986564636}\n"
          ]
        }
      ],
      "source": [
        "X_test = np.load(\"/content/drive/MyDrive/final/X_test.npy\")\n",
        "X_train_valid = np.load(\"/content/drive/MyDrive/final/X_train_valid.npy\")\n",
        "y_train_valid = np.load(\"/content/drive/MyDrive/final/y_train_valid.npy\")\n",
        "y_train_valid -= 769\n",
        "short_time_train_scores = {}\n",
        "short_time_test_scores = {}\n",
        "for i in range(50, 650, 50):\n",
        "    y_test = np.load(\"/content/drive/MyDrive/final/y_test.npy\")\n",
        "    y_test -= 769\n",
        "    x_train, x_valid, x_test, y_train, y_valid, y_test = data_finalize(total_number=2115, takeout_sample=375, period=i, y_test=y_test)\n",
        "    num_classes = 4  \n",
        "    height = x_train.shape[1]\n",
        "    width = 1\n",
        "    channel = 22\n",
        "    input_shape = (height, width, channel)\n",
        "    # Create the ViT model\n",
        "    vit_classifier = create_vit_classifier(num_classes, height=height, width=width)\n",
        "\n",
        "    # Compile the model\n",
        "    vit_classifier.build(input_shape=(None, *input_shape))\n",
        "    vit_classifier.compile(optimizer=tfa.optimizers.AdamW(learning_rate=1e-3, weight_decay=1e-4),\n",
        "                           loss='categorical_crossentropy',\n",
        "                           metrics=['accuracy'])\n",
        "    epochs = 50  # Set the number of epochs you want to train for\n",
        "    batch_size = 32  # Set the batch size for training\n",
        "\n",
        "    history = vit_classifier.fit(x_train, y_train,\n",
        "                                 batch_size=batch_size,\n",
        "                                 epochs=epochs,\n",
        "                                 verbose=True,\n",
        "                                 validation_data=(x_valid, y_valid))\n",
        "    short_time_train_scores[str(i)] = vit_classifier.evaluate(x_train, y_train)[1]\n",
        "    short_time_test_scores[str(i)] = vit_classifier.evaluate(x_test, y_test)[1]\n",
        "print(short_time_train_scores)\n",
        "print(short_time_test_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHtYT8Mlspwm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b02c379b-0ab3-4538-f6d2-5f3d780f5221"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "218/218 [==============================] - 37s 113ms/step - loss: 1.3788 - accuracy: 0.3016 - val_loss: 1.3947 - val_accuracy: 0.2947\n",
            "Epoch 2/50\n",
            "218/218 [==============================] - 23s 105ms/step - loss: 1.3600 - accuracy: 0.3220 - val_loss: 1.3935 - val_accuracy: 0.2880\n",
            "Epoch 3/50\n",
            "218/218 [==============================] - 24s 108ms/step - loss: 1.3470 - accuracy: 0.3296 - val_loss: 1.3941 - val_accuracy: 0.2847\n",
            "Epoch 4/50\n",
            "218/218 [==============================] - 24s 110ms/step - loss: 1.3325 - accuracy: 0.3466 - val_loss: 1.3910 - val_accuracy: 0.3180\n",
            "Epoch 5/50\n",
            "218/218 [==============================] - 23s 106ms/step - loss: 1.3062 - accuracy: 0.3750 - val_loss: 1.4161 - val_accuracy: 0.3113\n",
            "Epoch 6/50\n",
            "218/218 [==============================] - 24s 109ms/step - loss: 1.2862 - accuracy: 0.3940 - val_loss: 1.3654 - val_accuracy: 0.3580\n",
            "Epoch 7/50\n",
            "218/218 [==============================] - 24s 108ms/step - loss: 1.2640 - accuracy: 0.4174 - val_loss: 1.3471 - val_accuracy: 0.3593\n",
            "Epoch 8/50\n",
            "218/218 [==============================] - 24s 109ms/step - loss: 1.2489 - accuracy: 0.4223 - val_loss: 1.3239 - val_accuracy: 0.3827\n",
            "Epoch 9/50\n",
            "218/218 [==============================] - 23s 106ms/step - loss: 1.2235 - accuracy: 0.4464 - val_loss: 1.3308 - val_accuracy: 0.3820\n",
            "Epoch 10/50\n",
            "218/218 [==============================] - 24s 109ms/step - loss: 1.2089 - accuracy: 0.4499 - val_loss: 1.4200 - val_accuracy: 0.3560\n",
            "Epoch 11/50\n",
            "218/218 [==============================] - 23s 104ms/step - loss: 1.1808 - accuracy: 0.4710 - val_loss: 1.3735 - val_accuracy: 0.3660\n",
            "Epoch 12/50\n",
            "218/218 [==============================] - 24s 111ms/step - loss: 1.1585 - accuracy: 0.4901 - val_loss: 1.4184 - val_accuracy: 0.3733\n",
            "Epoch 13/50\n",
            "218/218 [==============================] - 23s 106ms/step - loss: 1.1402 - accuracy: 0.4986 - val_loss: 1.3634 - val_accuracy: 0.3887\n",
            "Epoch 14/50\n",
            "218/218 [==============================] - 24s 109ms/step - loss: 1.1231 - accuracy: 0.5112 - val_loss: 1.4659 - val_accuracy: 0.3620\n",
            "Epoch 15/50\n",
            "218/218 [==============================] - 23s 105ms/step - loss: 1.0980 - accuracy: 0.5218 - val_loss: 1.4073 - val_accuracy: 0.3793\n",
            "Epoch 16/50\n",
            "218/218 [==============================] - 23s 106ms/step - loss: 1.0836 - accuracy: 0.5399 - val_loss: 1.4503 - val_accuracy: 0.3727\n",
            "Epoch 17/50\n",
            "218/218 [==============================] - 23s 107ms/step - loss: 1.0639 - accuracy: 0.5418 - val_loss: 1.3623 - val_accuracy: 0.4093\n",
            "Epoch 18/50\n",
            "218/218 [==============================] - 23s 104ms/step - loss: 1.0255 - accuracy: 0.5635 - val_loss: 1.5752 - val_accuracy: 0.3720\n",
            "Epoch 19/50\n",
            "218/218 [==============================] - 24s 110ms/step - loss: 1.0007 - accuracy: 0.5830 - val_loss: 1.5898 - val_accuracy: 0.4040\n",
            "Epoch 20/50\n",
            "218/218 [==============================] - 24s 110ms/step - loss: 1.0093 - accuracy: 0.5783 - val_loss: 1.5029 - val_accuracy: 0.3767\n",
            "Epoch 21/50\n",
            "218/218 [==============================] - 24s 109ms/step - loss: 0.9789 - accuracy: 0.5927 - val_loss: 1.5623 - val_accuracy: 0.3793\n",
            "Epoch 22/50\n",
            "218/218 [==============================] - 24s 108ms/step - loss: 0.9553 - accuracy: 0.6023 - val_loss: 1.4831 - val_accuracy: 0.4067\n",
            "Epoch 23/50\n",
            "218/218 [==============================] - 24s 110ms/step - loss: 0.9403 - accuracy: 0.6106 - val_loss: 1.5293 - val_accuracy: 0.3760\n",
            "Epoch 24/50\n",
            "218/218 [==============================] - 24s 110ms/step - loss: 0.9069 - accuracy: 0.6272 - val_loss: 1.5132 - val_accuracy: 0.4100\n",
            "Epoch 25/50\n",
            "218/218 [==============================] - 24s 109ms/step - loss: 0.9034 - accuracy: 0.6240 - val_loss: 1.5053 - val_accuracy: 0.4080\n",
            "Epoch 26/50\n",
            "218/218 [==============================] - 23s 103ms/step - loss: 0.8767 - accuracy: 0.6408 - val_loss: 1.5816 - val_accuracy: 0.4093\n",
            "Epoch 27/50\n",
            "218/218 [==============================] - 23s 105ms/step - loss: 0.8648 - accuracy: 0.6450 - val_loss: 1.5851 - val_accuracy: 0.3813\n",
            "Epoch 28/50\n",
            "218/218 [==============================] - 23s 105ms/step - loss: 0.8371 - accuracy: 0.6658 - val_loss: 1.5640 - val_accuracy: 0.4113\n",
            "Epoch 29/50\n",
            "218/218 [==============================] - 23s 103ms/step - loss: 0.8414 - accuracy: 0.6580 - val_loss: 1.5345 - val_accuracy: 0.4120\n",
            "Epoch 30/50\n",
            "218/218 [==============================] - 23s 105ms/step - loss: 0.8169 - accuracy: 0.6638 - val_loss: 1.7402 - val_accuracy: 0.4140\n",
            "Epoch 31/50\n",
            "218/218 [==============================] - 23s 105ms/step - loss: 0.8109 - accuracy: 0.6710 - val_loss: 1.7852 - val_accuracy: 0.3873\n",
            "Epoch 32/50\n",
            "218/218 [==============================] - 23s 107ms/step - loss: 0.8038 - accuracy: 0.6723 - val_loss: 1.6322 - val_accuracy: 0.4160\n",
            "Epoch 33/50\n",
            "218/218 [==============================] - 24s 108ms/step - loss: 0.7782 - accuracy: 0.6872 - val_loss: 1.5114 - val_accuracy: 0.4213\n",
            "Epoch 34/50\n",
            "218/218 [==============================] - 23s 104ms/step - loss: 0.7750 - accuracy: 0.6899 - val_loss: 1.7332 - val_accuracy: 0.4027\n",
            "Epoch 35/50\n",
            "218/218 [==============================] - 23s 105ms/step - loss: 0.7225 - accuracy: 0.7126 - val_loss: 1.7002 - val_accuracy: 0.4287\n",
            "Epoch 36/50\n",
            "218/218 [==============================] - 23s 108ms/step - loss: 0.7111 - accuracy: 0.7240 - val_loss: 1.6272 - val_accuracy: 0.4153\n",
            "Epoch 37/50\n",
            "218/218 [==============================] - 23s 104ms/step - loss: 0.7092 - accuracy: 0.7175 - val_loss: 1.6790 - val_accuracy: 0.4207\n",
            "Epoch 38/50\n",
            "218/218 [==============================] - 24s 109ms/step - loss: 0.7064 - accuracy: 0.7194 - val_loss: 1.7598 - val_accuracy: 0.4160\n",
            "Epoch 39/50\n",
            "218/218 [==============================] - 23s 105ms/step - loss: 0.6757 - accuracy: 0.7365 - val_loss: 1.7412 - val_accuracy: 0.4273\n",
            "Epoch 40/50\n",
            "218/218 [==============================] - 23s 105ms/step - loss: 0.6811 - accuracy: 0.7352 - val_loss: 1.8236 - val_accuracy: 0.4113\n",
            "Epoch 41/50\n",
            "218/218 [==============================] - 23s 104ms/step - loss: 0.6857 - accuracy: 0.7250 - val_loss: 1.8288 - val_accuracy: 0.3960\n",
            "Epoch 42/50\n",
            "218/218 [==============================] - 23s 104ms/step - loss: 0.6432 - accuracy: 0.7454 - val_loss: 1.9281 - val_accuracy: 0.4033\n",
            "Epoch 43/50\n",
            "218/218 [==============================] - 23s 105ms/step - loss: 0.6326 - accuracy: 0.7542 - val_loss: 1.8805 - val_accuracy: 0.4200\n",
            "Epoch 44/50\n",
            "218/218 [==============================] - 23s 104ms/step - loss: 0.6379 - accuracy: 0.7516 - val_loss: 1.8590 - val_accuracy: 0.3973\n",
            "Epoch 45/50\n",
            "218/218 [==============================] - 24s 108ms/step - loss: 0.6115 - accuracy: 0.7586 - val_loss: 1.7118 - val_accuracy: 0.4187\n",
            "Epoch 46/50\n",
            "218/218 [==============================] - 23s 103ms/step - loss: 0.5891 - accuracy: 0.7751 - val_loss: 1.9244 - val_accuracy: 0.4393\n",
            "Epoch 47/50\n",
            "218/218 [==============================] - 24s 109ms/step - loss: 0.5915 - accuracy: 0.7718 - val_loss: 1.8243 - val_accuracy: 0.4253\n",
            "Epoch 48/50\n",
            "218/218 [==============================] - 24s 109ms/step - loss: 0.5824 - accuracy: 0.7711 - val_loss: 1.9435 - val_accuracy: 0.4207\n",
            "Epoch 49/50\n",
            "218/218 [==============================] - 24s 109ms/step - loss: 0.5891 - accuracy: 0.7664 - val_loss: 2.0010 - val_accuracy: 0.4193\n",
            "Epoch 50/50\n",
            "218/218 [==============================] - 24s 109ms/step - loss: 0.5704 - accuracy: 0.7754 - val_loss: 1.8045 - val_accuracy: 0.4287\n",
            "218/218 [==============================] - 9s 40ms/step - loss: 0.5644 - accuracy: 0.7783\n",
            "56/56 [==============================] - 2s 37ms/step - loss: 1.8247 - accuracy: 0.4295\n",
            "Epoch 1/50\n",
            "218/218 [==============================] - 32s 133ms/step - loss: 1.3862 - accuracy: 0.2795 - val_loss: 1.3981 - val_accuracy: 0.2940\n",
            "Epoch 2/50\n",
            "218/218 [==============================] - 28s 126ms/step - loss: 1.3647 - accuracy: 0.3159 - val_loss: 1.3819 - val_accuracy: 0.2793\n",
            "Epoch 3/50\n",
            "218/218 [==============================] - 28s 126ms/step - loss: 1.3541 - accuracy: 0.3286 - val_loss: 1.3395 - val_accuracy: 0.3233\n",
            "Epoch 4/50\n",
            "218/218 [==============================] - 28s 130ms/step - loss: 1.3439 - accuracy: 0.3435 - val_loss: 1.3745 - val_accuracy: 0.3033\n",
            "Epoch 5/50\n",
            "218/218 [==============================] - 28s 127ms/step - loss: 1.3298 - accuracy: 0.3599 - val_loss: 1.3644 - val_accuracy: 0.3387\n",
            "Epoch 6/50\n",
            "218/218 [==============================] - 28s 127ms/step - loss: 1.2979 - accuracy: 0.3905 - val_loss: 1.3293 - val_accuracy: 0.3613\n",
            "Epoch 7/50\n",
            "218/218 [==============================] - 28s 127ms/step - loss: 1.2875 - accuracy: 0.3981 - val_loss: 1.3544 - val_accuracy: 0.3893\n",
            "Epoch 8/50\n",
            "218/218 [==============================] - 28s 130ms/step - loss: 1.2573 - accuracy: 0.4204 - val_loss: 1.3153 - val_accuracy: 0.4173\n",
            "Epoch 9/50\n",
            "218/218 [==============================] - 28s 127ms/step - loss: 1.2378 - accuracy: 0.4404 - val_loss: 1.3229 - val_accuracy: 0.4027\n",
            "Epoch 10/50\n",
            "218/218 [==============================] - 28s 130ms/step - loss: 1.2080 - accuracy: 0.4569 - val_loss: 1.3906 - val_accuracy: 0.3927\n",
            "Epoch 11/50\n",
            "218/218 [==============================] - 28s 127ms/step - loss: 1.1981 - accuracy: 0.4595 - val_loss: 1.4003 - val_accuracy: 0.3827\n",
            "Epoch 12/50\n",
            "218/218 [==============================] - 28s 130ms/step - loss: 1.1711 - accuracy: 0.4773 - val_loss: 1.3478 - val_accuracy: 0.4273\n",
            "Epoch 13/50\n",
            "218/218 [==============================] - 28s 130ms/step - loss: 1.1409 - accuracy: 0.5036 - val_loss: 1.3441 - val_accuracy: 0.4133\n",
            "Epoch 14/50\n",
            "218/218 [==============================] - 28s 130ms/step - loss: 1.1237 - accuracy: 0.5122 - val_loss: 1.3691 - val_accuracy: 0.3913\n",
            "Epoch 15/50\n",
            "218/218 [==============================] - 28s 130ms/step - loss: 1.1030 - accuracy: 0.5190 - val_loss: 1.3390 - val_accuracy: 0.4473\n",
            "Epoch 16/50\n",
            "218/218 [==============================] - 28s 127ms/step - loss: 1.0484 - accuracy: 0.5503 - val_loss: 1.4505 - val_accuracy: 0.3913\n",
            "Epoch 17/50\n",
            "218/218 [==============================] - 28s 130ms/step - loss: 1.0335 - accuracy: 0.5592 - val_loss: 1.4617 - val_accuracy: 0.4007\n",
            "Epoch 18/50\n",
            "218/218 [==============================] - 28s 130ms/step - loss: 1.0342 - accuracy: 0.5592 - val_loss: 1.4419 - val_accuracy: 0.4553\n",
            "Epoch 19/50\n",
            "218/218 [==============================] - 28s 131ms/step - loss: 0.9994 - accuracy: 0.5757 - val_loss: 1.4173 - val_accuracy: 0.4187\n",
            "Epoch 20/50\n",
            "218/218 [==============================] - 28s 130ms/step - loss: 0.9775 - accuracy: 0.5901 - val_loss: 1.4961 - val_accuracy: 0.4147\n",
            "Epoch 21/50\n",
            "218/218 [==============================] - 28s 130ms/step - loss: 0.9440 - accuracy: 0.6085 - val_loss: 1.4720 - val_accuracy: 0.4353\n",
            "Epoch 22/50\n",
            "218/218 [==============================] - 28s 127ms/step - loss: 0.9445 - accuracy: 0.6026 - val_loss: 1.4797 - val_accuracy: 0.4220\n",
            "Epoch 23/50\n",
            "218/218 [==============================] - 28s 127ms/step - loss: 0.9057 - accuracy: 0.6306 - val_loss: 1.4881 - val_accuracy: 0.4433\n",
            "Epoch 24/50\n",
            "218/218 [==============================] - 28s 127ms/step - loss: 0.8939 - accuracy: 0.6356 - val_loss: 1.4185 - val_accuracy: 0.4493\n",
            "Epoch 25/50\n",
            "218/218 [==============================] - 28s 131ms/step - loss: 0.8728 - accuracy: 0.6389 - val_loss: 1.5771 - val_accuracy: 0.4307\n",
            "Epoch 26/50\n",
            "218/218 [==============================] - 28s 128ms/step - loss: 0.8487 - accuracy: 0.6578 - val_loss: 1.4844 - val_accuracy: 0.4407\n",
            "Epoch 27/50\n",
            "218/218 [==============================] - 28s 128ms/step - loss: 0.8338 - accuracy: 0.6553 - val_loss: 1.5323 - val_accuracy: 0.4460\n",
            "Epoch 28/50\n",
            "218/218 [==============================] - 28s 131ms/step - loss: 0.8222 - accuracy: 0.6628 - val_loss: 1.6663 - val_accuracy: 0.4527\n",
            "Epoch 29/50\n",
            "218/218 [==============================] - 28s 127ms/step - loss: 0.8322 - accuracy: 0.6606 - val_loss: 1.4980 - val_accuracy: 0.4353\n",
            "Epoch 30/50\n",
            "218/218 [==============================] - 28s 127ms/step - loss: 0.7897 - accuracy: 0.6763 - val_loss: 1.5023 - val_accuracy: 0.4760\n",
            "Epoch 31/50\n",
            "218/218 [==============================] - 28s 128ms/step - loss: 0.7690 - accuracy: 0.6875 - val_loss: 1.4961 - val_accuracy: 0.4533\n",
            "Epoch 32/50\n",
            "218/218 [==============================] - 28s 128ms/step - loss: 0.7628 - accuracy: 0.6937 - val_loss: 1.5666 - val_accuracy: 0.4633\n",
            "Epoch 33/50\n",
            "218/218 [==============================] - 28s 128ms/step - loss: 0.7330 - accuracy: 0.7053 - val_loss: 1.5429 - val_accuracy: 0.4447\n",
            "Epoch 34/50\n",
            "218/218 [==============================] - 28s 127ms/step - loss: 0.7148 - accuracy: 0.7136 - val_loss: 1.5658 - val_accuracy: 0.4187\n",
            "Epoch 35/50\n",
            "218/218 [==============================] - 28s 131ms/step - loss: 0.6939 - accuracy: 0.7259 - val_loss: 1.7209 - val_accuracy: 0.4447\n",
            "Epoch 36/50\n",
            "218/218 [==============================] - 28s 128ms/step - loss: 0.6912 - accuracy: 0.7266 - val_loss: 1.5767 - val_accuracy: 0.4487\n",
            "Epoch 37/50\n",
            "218/218 [==============================] - 28s 131ms/step - loss: 0.6784 - accuracy: 0.7315 - val_loss: 1.9367 - val_accuracy: 0.4307\n",
            "Epoch 38/50\n",
            "218/218 [==============================] - 29s 131ms/step - loss: 0.6664 - accuracy: 0.7349 - val_loss: 1.8435 - val_accuracy: 0.4167\n",
            "Epoch 39/50\n",
            "218/218 [==============================] - 29s 131ms/step - loss: 0.6532 - accuracy: 0.7415 - val_loss: 1.6718 - val_accuracy: 0.4573\n",
            "Epoch 40/50\n",
            "218/218 [==============================] - 29s 131ms/step - loss: 0.6277 - accuracy: 0.7517 - val_loss: 1.8106 - val_accuracy: 0.4453\n",
            "Epoch 41/50\n",
            "218/218 [==============================] - 29s 131ms/step - loss: 0.6292 - accuracy: 0.7555 - val_loss: 1.6536 - val_accuracy: 0.4527\n",
            "Epoch 42/50\n",
            "218/218 [==============================] - 28s 129ms/step - loss: 0.6095 - accuracy: 0.7621 - val_loss: 1.7624 - val_accuracy: 0.4547\n",
            "Epoch 43/50\n",
            "218/218 [==============================] - 28s 128ms/step - loss: 0.6184 - accuracy: 0.7628 - val_loss: 1.7668 - val_accuracy: 0.4340\n",
            "Epoch 44/50\n",
            "218/218 [==============================] - 29s 131ms/step - loss: 0.6001 - accuracy: 0.7645 - val_loss: 1.6532 - val_accuracy: 0.4473\n",
            "Epoch 45/50\n",
            "218/218 [==============================] - 28s 128ms/step - loss: 0.5787 - accuracy: 0.7730 - val_loss: 1.6836 - val_accuracy: 0.4633\n",
            "Epoch 46/50\n",
            "218/218 [==============================] - 28s 130ms/step - loss: 0.5645 - accuracy: 0.7776 - val_loss: 1.9072 - val_accuracy: 0.4540\n",
            "Epoch 47/50\n",
            "218/218 [==============================] - 28s 130ms/step - loss: 0.5492 - accuracy: 0.7892 - val_loss: 1.8744 - val_accuracy: 0.4500\n",
            "Epoch 48/50\n",
            "218/218 [==============================] - 28s 131ms/step - loss: 0.5407 - accuracy: 0.7895 - val_loss: 1.9388 - val_accuracy: 0.4633\n",
            "Epoch 49/50\n",
            "218/218 [==============================] - 28s 127ms/step - loss: 0.5358 - accuracy: 0.7934 - val_loss: 1.9989 - val_accuracy: 0.4367\n",
            "Epoch 50/50\n",
            "218/218 [==============================] - 28s 126ms/step - loss: 0.5072 - accuracy: 0.7990 - val_loss: 1.8926 - val_accuracy: 0.4533\n",
            "218/218 [==============================] - 10s 46ms/step - loss: 0.3970 - accuracy: 0.8473\n",
            "56/56 [==============================] - 2s 43ms/step - loss: 1.9283 - accuracy: 0.4407\n",
            "Epoch 1/50\n",
            "218/218 [==============================] - 37s 155ms/step - loss: 1.3839 - accuracy: 0.2828 - val_loss: 1.3628 - val_accuracy: 0.3113\n",
            "Epoch 2/50\n",
            "218/218 [==============================] - 33s 151ms/step - loss: 1.3609 - accuracy: 0.3141 - val_loss: 1.4104 - val_accuracy: 0.2967\n",
            "Epoch 3/50\n",
            "218/218 [==============================] - 33s 152ms/step - loss: 1.3424 - accuracy: 0.3432 - val_loss: 1.3993 - val_accuracy: 0.2960\n",
            "Epoch 4/50\n",
            "218/218 [==============================] - 33s 150ms/step - loss: 1.3307 - accuracy: 0.3537 - val_loss: 1.3952 - val_accuracy: 0.2913\n",
            "Epoch 5/50\n",
            "218/218 [==============================] - 33s 152ms/step - loss: 1.3139 - accuracy: 0.3747 - val_loss: 1.4123 - val_accuracy: 0.2793\n",
            "Epoch 6/50\n",
            "218/218 [==============================] - 33s 150ms/step - loss: 1.2888 - accuracy: 0.3905 - val_loss: 1.4429 - val_accuracy: 0.3660\n",
            "Epoch 7/50\n",
            "218/218 [==============================] - 33s 152ms/step - loss: 1.2820 - accuracy: 0.3954 - val_loss: 1.4299 - val_accuracy: 0.3473\n",
            "Epoch 8/50\n",
            "218/218 [==============================] - 33s 152ms/step - loss: 1.2550 - accuracy: 0.4260 - val_loss: 1.4111 - val_accuracy: 0.3233\n",
            "Epoch 9/50\n",
            "218/218 [==============================] - 33s 151ms/step - loss: 1.2422 - accuracy: 0.4394 - val_loss: 1.4657 - val_accuracy: 0.3340\n",
            "Epoch 10/50\n",
            "218/218 [==============================] - 33s 152ms/step - loss: 1.2010 - accuracy: 0.4570 - val_loss: 1.4463 - val_accuracy: 0.3580\n",
            "Epoch 11/50\n",
            "218/218 [==============================] - 33s 150ms/step - loss: 1.1842 - accuracy: 0.4675 - val_loss: 1.3775 - val_accuracy: 0.3387\n",
            "Epoch 12/50\n",
            "218/218 [==============================] - 33s 152ms/step - loss: 1.1585 - accuracy: 0.4882 - val_loss: 1.4735 - val_accuracy: 0.3833\n",
            "Epoch 13/50\n",
            "218/218 [==============================] - 33s 153ms/step - loss: 1.1322 - accuracy: 0.5079 - val_loss: 1.5012 - val_accuracy: 0.3613\n",
            "Epoch 14/50\n",
            "218/218 [==============================] - 33s 152ms/step - loss: 1.1085 - accuracy: 0.5220 - val_loss: 1.5740 - val_accuracy: 0.3373\n",
            "Epoch 15/50\n",
            "218/218 [==============================] - 36s 165ms/step - loss: 1.0876 - accuracy: 0.5402 - val_loss: 1.4206 - val_accuracy: 0.3840\n",
            "Epoch 16/50\n",
            "218/218 [==============================] - 33s 153ms/step - loss: 1.0569 - accuracy: 0.5532 - val_loss: 1.4728 - val_accuracy: 0.3707\n",
            "Epoch 17/50\n",
            "218/218 [==============================] - 34s 154ms/step - loss: 1.0545 - accuracy: 0.5552 - val_loss: 1.5179 - val_accuracy: 0.3727\n",
            "Epoch 18/50\n",
            "218/218 [==============================] - 33s 152ms/step - loss: 1.0214 - accuracy: 0.5721 - val_loss: 1.4827 - val_accuracy: 0.3653\n",
            "Epoch 19/50\n",
            "218/218 [==============================] - 33s 152ms/step - loss: 1.0052 - accuracy: 0.5803 - val_loss: 1.5146 - val_accuracy: 0.3920\n",
            "Epoch 20/50\n",
            "218/218 [==============================] - 33s 152ms/step - loss: 0.9719 - accuracy: 0.6017 - val_loss: 1.6148 - val_accuracy: 0.3640\n",
            "Epoch 21/50\n",
            "218/218 [==============================] - 33s 152ms/step - loss: 0.9575 - accuracy: 0.6056 - val_loss: 1.7096 - val_accuracy: 0.3193\n",
            "Epoch 22/50\n",
            "218/218 [==============================] - 33s 153ms/step - loss: 0.9286 - accuracy: 0.6161 - val_loss: 1.7035 - val_accuracy: 0.3800\n",
            "Epoch 23/50\n",
            "218/218 [==============================] - 33s 152ms/step - loss: 0.9184 - accuracy: 0.6236 - val_loss: 1.6918 - val_accuracy: 0.3833\n",
            "Epoch 24/50\n",
            "218/218 [==============================] - 33s 151ms/step - loss: 0.8871 - accuracy: 0.6379 - val_loss: 1.7401 - val_accuracy: 0.3913\n",
            "Epoch 25/50\n",
            "218/218 [==============================] - 33s 152ms/step - loss: 0.8792 - accuracy: 0.6458 - val_loss: 1.7207 - val_accuracy: 0.3807\n",
            "Epoch 26/50\n",
            "218/218 [==============================] - 33s 151ms/step - loss: 0.8617 - accuracy: 0.6510 - val_loss: 1.8422 - val_accuracy: 0.3713\n",
            "Epoch 27/50\n",
            "218/218 [==============================] - 33s 151ms/step - loss: 0.8318 - accuracy: 0.6585 - val_loss: 1.6565 - val_accuracy: 0.3913\n",
            "Epoch 28/50\n",
            "218/218 [==============================] - 33s 151ms/step - loss: 0.8145 - accuracy: 0.6700 - val_loss: 2.0326 - val_accuracy: 0.3933\n",
            "Epoch 29/50\n",
            "218/218 [==============================] - 33s 152ms/step - loss: 0.7989 - accuracy: 0.6772 - val_loss: 1.7192 - val_accuracy: 0.3600\n",
            "Epoch 30/50\n",
            "218/218 [==============================] - 33s 152ms/step - loss: 0.7791 - accuracy: 0.6876 - val_loss: 1.7877 - val_accuracy: 0.4000\n",
            "Epoch 31/50\n",
            "218/218 [==============================] - 33s 153ms/step - loss: 0.7726 - accuracy: 0.6928 - val_loss: 1.9676 - val_accuracy: 0.3420\n",
            "Epoch 32/50\n",
            "218/218 [==============================] - 33s 153ms/step - loss: 0.7475 - accuracy: 0.7026 - val_loss: 1.8804 - val_accuracy: 0.3633\n",
            "Epoch 33/50\n",
            "218/218 [==============================] - 33s 150ms/step - loss: 0.7546 - accuracy: 0.6937 - val_loss: 1.8655 - val_accuracy: 0.3960\n",
            "Epoch 34/50\n",
            "218/218 [==============================] - 33s 152ms/step - loss: 0.7286 - accuracy: 0.7046 - val_loss: 1.9154 - val_accuracy: 0.4047\n",
            "Epoch 35/50\n",
            "218/218 [==============================] - 33s 150ms/step - loss: 0.7136 - accuracy: 0.7178 - val_loss: 1.8007 - val_accuracy: 0.3993\n",
            "Epoch 36/50\n",
            "218/218 [==============================] - 33s 151ms/step - loss: 0.7233 - accuracy: 0.7115 - val_loss: 1.9393 - val_accuracy: 0.4000\n",
            "Epoch 37/50\n",
            "218/218 [==============================] - 33s 152ms/step - loss: 0.6921 - accuracy: 0.7320 - val_loss: 1.8542 - val_accuracy: 0.4047\n",
            "Epoch 38/50\n",
            "218/218 [==============================] - 33s 151ms/step - loss: 0.6750 - accuracy: 0.7372 - val_loss: 2.1138 - val_accuracy: 0.3807\n",
            "Epoch 39/50\n",
            "218/218 [==============================] - 33s 153ms/step - loss: 0.6428 - accuracy: 0.7457 - val_loss: 1.9313 - val_accuracy: 0.3867\n",
            "Epoch 40/50\n",
            "218/218 [==============================] - 33s 150ms/step - loss: 0.6480 - accuracy: 0.7405 - val_loss: 2.0573 - val_accuracy: 0.3947\n",
            "Epoch 41/50\n",
            "218/218 [==============================] - 33s 152ms/step - loss: 0.6373 - accuracy: 0.7523 - val_loss: 2.3003 - val_accuracy: 0.3707\n",
            "Epoch 42/50\n",
            "218/218 [==============================] - 33s 153ms/step - loss: 0.6225 - accuracy: 0.7532 - val_loss: 2.1892 - val_accuracy: 0.3800\n",
            "Epoch 43/50\n",
            "218/218 [==============================] - 33s 154ms/step - loss: 0.6204 - accuracy: 0.7524 - val_loss: 1.9638 - val_accuracy: 0.4127\n",
            "Epoch 44/50\n",
            "218/218 [==============================] - 33s 153ms/step - loss: 0.6070 - accuracy: 0.7631 - val_loss: 2.1624 - val_accuracy: 0.3920\n",
            "Epoch 45/50\n",
            "218/218 [==============================] - 33s 152ms/step - loss: 0.5924 - accuracy: 0.7662 - val_loss: 2.1806 - val_accuracy: 0.3740\n",
            "Epoch 46/50\n",
            "218/218 [==============================] - 33s 152ms/step - loss: 0.5834 - accuracy: 0.7714 - val_loss: 2.0954 - val_accuracy: 0.3973\n",
            "Epoch 47/50\n",
            "218/218 [==============================] - 33s 151ms/step - loss: 0.6063 - accuracy: 0.7647 - val_loss: 2.0407 - val_accuracy: 0.3793\n",
            "Epoch 48/50\n",
            "218/218 [==============================] - 34s 154ms/step - loss: 0.5783 - accuracy: 0.7759 - val_loss: 2.1761 - val_accuracy: 0.3873\n",
            "Epoch 49/50\n",
            "218/218 [==============================] - 33s 153ms/step - loss: 0.5593 - accuracy: 0.7833 - val_loss: 1.9812 - val_accuracy: 0.3980\n",
            "Epoch 50/50\n",
            "218/218 [==============================] - 33s 151ms/step - loss: 0.5518 - accuracy: 0.7862 - val_loss: 2.2327 - val_accuracy: 0.3900\n",
            "218/218 [==============================] - 12s 54ms/step - loss: 0.5350 - accuracy: 0.7993\n",
            "56/56 [==============================] - 3s 53ms/step - loss: 2.1747 - accuracy: 0.4035\n",
            "Epoch 1/50\n",
            "218/218 [==============================] - 45s 194ms/step - loss: 1.3858 - accuracy: 0.2780 - val_loss: 1.3883 - val_accuracy: 0.2947\n",
            "Epoch 2/50\n",
            "218/218 [==============================] - 39s 179ms/step - loss: 1.3693 - accuracy: 0.3014 - val_loss: 1.3896 - val_accuracy: 0.3053\n",
            "Epoch 3/50\n",
            "218/218 [==============================] - 41s 190ms/step - loss: 1.3565 - accuracy: 0.3154 - val_loss: 1.3875 - val_accuracy: 0.2753\n",
            "Epoch 4/50\n",
            "218/218 [==============================] - 39s 179ms/step - loss: 1.3463 - accuracy: 0.3286 - val_loss: 1.3740 - val_accuracy: 0.3073\n",
            "Epoch 5/50\n",
            "218/218 [==============================] - 39s 179ms/step - loss: 1.3392 - accuracy: 0.3438 - val_loss: 1.3983 - val_accuracy: 0.3060\n",
            "Epoch 6/50\n",
            "218/218 [==============================] - 42s 191ms/step - loss: 1.3230 - accuracy: 0.3579 - val_loss: 1.3687 - val_accuracy: 0.3293\n",
            "Epoch 7/50\n",
            "218/218 [==============================] - 39s 179ms/step - loss: 1.3139 - accuracy: 0.3710 - val_loss: 1.4438 - val_accuracy: 0.2987\n",
            "Epoch 8/50\n",
            "218/218 [==============================] - 42s 191ms/step - loss: 1.2951 - accuracy: 0.3875 - val_loss: 1.3818 - val_accuracy: 0.3680\n",
            "Epoch 9/50\n",
            "218/218 [==============================] - 39s 179ms/step - loss: 1.2712 - accuracy: 0.4111 - val_loss: 1.3830 - val_accuracy: 0.3380\n",
            "Epoch 10/50\n",
            "218/218 [==============================] - 42s 191ms/step - loss: 1.2632 - accuracy: 0.4135 - val_loss: 1.4119 - val_accuracy: 0.3453\n",
            "Epoch 11/50\n",
            "218/218 [==============================] - 39s 179ms/step - loss: 1.2449 - accuracy: 0.4254 - val_loss: 1.3713 - val_accuracy: 0.3307\n",
            "Epoch 12/50\n",
            "218/218 [==============================] - 41s 190ms/step - loss: 1.2189 - accuracy: 0.4491 - val_loss: 1.3503 - val_accuracy: 0.3527\n",
            "Epoch 13/50\n",
            "218/218 [==============================] - 39s 179ms/step - loss: 1.2011 - accuracy: 0.4536 - val_loss: 1.3881 - val_accuracy: 0.3600\n",
            "Epoch 14/50\n",
            "218/218 [==============================] - 42s 191ms/step - loss: 1.1782 - accuracy: 0.4782 - val_loss: 1.4265 - val_accuracy: 0.3553\n",
            "Epoch 15/50\n",
            "218/218 [==============================] - 39s 180ms/step - loss: 1.1516 - accuracy: 0.4928 - val_loss: 1.4788 - val_accuracy: 0.3520\n",
            "Epoch 16/50\n",
            "218/218 [==============================] - 42s 192ms/step - loss: 1.1337 - accuracy: 0.5009 - val_loss: 1.4112 - val_accuracy: 0.3580\n",
            "Epoch 17/50\n",
            "218/218 [==============================] - 39s 180ms/step - loss: 1.1106 - accuracy: 0.5204 - val_loss: 1.4877 - val_accuracy: 0.3753\n",
            "Epoch 18/50\n",
            "218/218 [==============================] - 39s 179ms/step - loss: 1.1003 - accuracy: 0.5194 - val_loss: 1.4264 - val_accuracy: 0.3807\n",
            "Epoch 19/50\n",
            "218/218 [==============================] - 39s 179ms/step - loss: 1.0848 - accuracy: 0.5274 - val_loss: 1.5119 - val_accuracy: 0.3600\n",
            "Epoch 20/50\n",
            "218/218 [==============================] - 42s 191ms/step - loss: 1.0531 - accuracy: 0.5524 - val_loss: 1.5478 - val_accuracy: 0.3860\n",
            "Epoch 21/50\n",
            "218/218 [==============================] - 42s 191ms/step - loss: 1.0285 - accuracy: 0.5716 - val_loss: 1.5148 - val_accuracy: 0.3593\n",
            "Epoch 22/50\n",
            "218/218 [==============================] - 42s 191ms/step - loss: 1.0177 - accuracy: 0.5661 - val_loss: 1.6057 - val_accuracy: 0.3680\n",
            "Epoch 23/50\n",
            "218/218 [==============================] - 41s 190ms/step - loss: 0.9951 - accuracy: 0.5842 - val_loss: 1.5212 - val_accuracy: 0.3927\n",
            "Epoch 24/50\n",
            "218/218 [==============================] - 42s 191ms/step - loss: 0.9889 - accuracy: 0.5823 - val_loss: 1.5237 - val_accuracy: 0.3827\n",
            "Epoch 25/50\n",
            "218/218 [==============================] - 42s 191ms/step - loss: 0.9606 - accuracy: 0.6007 - val_loss: 1.6128 - val_accuracy: 0.3633\n",
            "Epoch 26/50\n",
            "218/218 [==============================] - 39s 179ms/step - loss: 0.9532 - accuracy: 0.6063 - val_loss: 1.7353 - val_accuracy: 0.3787\n",
            "Epoch 27/50\n",
            "218/218 [==============================] - 42s 191ms/step - loss: 0.9412 - accuracy: 0.6057 - val_loss: 1.6480 - val_accuracy: 0.3840\n",
            "Epoch 28/50\n",
            "218/218 [==============================] - 42s 190ms/step - loss: 0.9178 - accuracy: 0.6197 - val_loss: 1.7200 - val_accuracy: 0.3940\n",
            "Epoch 29/50\n",
            "218/218 [==============================] - 42s 191ms/step - loss: 0.9093 - accuracy: 0.6263 - val_loss: 1.7555 - val_accuracy: 0.3807\n",
            "Epoch 30/50\n",
            "218/218 [==============================] - 42s 191ms/step - loss: 0.9003 - accuracy: 0.6287 - val_loss: 1.7355 - val_accuracy: 0.3813\n",
            "Epoch 31/50\n",
            "218/218 [==============================] - 42s 191ms/step - loss: 0.8664 - accuracy: 0.6486 - val_loss: 1.7233 - val_accuracy: 0.3687\n",
            "Epoch 32/50\n",
            "218/218 [==============================] - 42s 191ms/step - loss: 0.8449 - accuracy: 0.6559 - val_loss: 1.8612 - val_accuracy: 0.3747\n",
            "Epoch 33/50\n",
            "218/218 [==============================] - 42s 191ms/step - loss: 0.8518 - accuracy: 0.6514 - val_loss: 1.7721 - val_accuracy: 0.3847\n",
            "Epoch 34/50\n",
            "218/218 [==============================] - 39s 179ms/step - loss: 0.8265 - accuracy: 0.6644 - val_loss: 1.8759 - val_accuracy: 0.3800\n",
            "Epoch 35/50\n",
            "218/218 [==============================] - 39s 179ms/step - loss: 0.8060 - accuracy: 0.6773 - val_loss: 1.8906 - val_accuracy: 0.4007\n",
            "Epoch 36/50\n",
            "218/218 [==============================] - 42s 191ms/step - loss: 0.7982 - accuracy: 0.6787 - val_loss: 1.9994 - val_accuracy: 0.3753\n",
            "Epoch 37/50\n",
            "218/218 [==============================] - 42s 190ms/step - loss: 0.7924 - accuracy: 0.6774 - val_loss: 1.8055 - val_accuracy: 0.3887\n",
            "Epoch 38/50\n",
            "218/218 [==============================] - 39s 180ms/step - loss: 0.7655 - accuracy: 0.6901 - val_loss: 1.9074 - val_accuracy: 0.3773\n",
            "Epoch 39/50\n",
            "218/218 [==============================] - 39s 179ms/step - loss: 0.7633 - accuracy: 0.6868 - val_loss: 1.8791 - val_accuracy: 0.4027\n",
            "Epoch 40/50\n",
            "218/218 [==============================] - 42s 191ms/step - loss: 0.7432 - accuracy: 0.7030 - val_loss: 2.1930 - val_accuracy: 0.3827\n",
            "Epoch 41/50\n",
            "218/218 [==============================] - 42s 192ms/step - loss: 0.7466 - accuracy: 0.7040 - val_loss: 2.0758 - val_accuracy: 0.3673\n",
            "Epoch 42/50\n",
            "218/218 [==============================] - 39s 180ms/step - loss: 0.7224 - accuracy: 0.7151 - val_loss: 2.0819 - val_accuracy: 0.3867\n",
            "Epoch 43/50\n",
            "218/218 [==============================] - 42s 191ms/step - loss: 0.7336 - accuracy: 0.7093 - val_loss: 1.9992 - val_accuracy: 0.3787\n",
            "Epoch 44/50\n",
            "218/218 [==============================] - 42s 190ms/step - loss: 0.6937 - accuracy: 0.7270 - val_loss: 2.0378 - val_accuracy: 0.3940\n",
            "Epoch 45/50\n",
            "218/218 [==============================] - 42s 191ms/step - loss: 0.7175 - accuracy: 0.7149 - val_loss: 2.0984 - val_accuracy: 0.4020\n",
            "Epoch 46/50\n",
            "218/218 [==============================] - 39s 179ms/step - loss: 0.6757 - accuracy: 0.7319 - val_loss: 1.9988 - val_accuracy: 0.3833\n",
            "Epoch 47/50\n",
            "218/218 [==============================] - 42s 191ms/step - loss: 0.6885 - accuracy: 0.7279 - val_loss: 2.1468 - val_accuracy: 0.3767\n",
            "Epoch 48/50\n",
            "218/218 [==============================] - 41s 190ms/step - loss: 0.6541 - accuracy: 0.7450 - val_loss: 2.0758 - val_accuracy: 0.3907\n",
            "Epoch 49/50\n",
            "218/218 [==============================] - 42s 190ms/step - loss: 0.6699 - accuracy: 0.7359 - val_loss: 2.1110 - val_accuracy: 0.3993\n",
            "Epoch 50/50\n",
            "218/218 [==============================] - 39s 179ms/step - loss: 0.6255 - accuracy: 0.7509 - val_loss: 2.3360 - val_accuracy: 0.4000\n",
            "218/218 [==============================] - 14s 63ms/step - loss: 0.6917 - accuracy: 0.7471\n",
            "56/56 [==============================] - 3s 61ms/step - loss: 2.2338 - accuracy: 0.3736\n",
            "{'700': 0.7783045768737793, '800': 0.847270131111145, '900': 0.7992815971374512, '1000': 0.7471264600753784}\n",
            "{'700': 0.42945823073387146, '800': 0.44074490666389465, '900': 0.4034988582134247, '1000': 0.3735891580581665}\n"
          ]
        }
      ],
      "source": [
        "X_test = np.load(\"/content/drive/MyDrive/final/X_test.npy\")\n",
        "X_train_valid = np.load(\"/content/drive/MyDrive/final/X_train_valid.npy\")\n",
        "y_train_valid = np.load(\"/content/drive/MyDrive/final/y_train_valid.npy\")\n",
        "y_train_valid -= 769\n",
        "long_time_train_scores = {}\n",
        "long_time_test_scores = {}\n",
        "for i in range(700, 1100, 100):\n",
        "    y_test = np.load(\"/content/drive/MyDrive/final/y_test.npy\")\n",
        "    y_test -= 769\n",
        "    x_train, x_valid, x_test, y_train, y_valid, y_test = data_finalize(total_number=2115, takeout_sample=375, period=i, y_test=y_test)\n",
        "    num_classes = 4  \n",
        "    height = x_train.shape[1]\n",
        "    width = 1\n",
        "    channel = 22\n",
        "    input_shape = (height, width, channel)\n",
        "    # Create the ViT model\n",
        "    vit_classifier = create_vit_classifier(num_classes, height=height, width=width)\n",
        "\n",
        "    # Compile the model\n",
        "    vit_classifier.build(input_shape=(None, *input_shape))\n",
        "    vit_classifier.compile(optimizer=tfa.optimizers.AdamW(learning_rate=1e-3, weight_decay=1e-4),\n",
        "                           loss='categorical_crossentropy',\n",
        "                           metrics=['accuracy'])\n",
        "    epochs = 50  # Set the number of epochs you want to train for\n",
        "    batch_size = 32  # Set the batch size for training\n",
        "\n",
        "    history = vit_classifier.fit(x_train, y_train,\n",
        "                                 batch_size=batch_size,\n",
        "                                 epochs=epochs,\n",
        "                                 verbose=True,\n",
        "                                 validation_data=(x_valid, y_valid))\n",
        "    long_time_train_scores[str(i)] = vit_classifier.evaluate(x_train, y_train)[1]\n",
        "    long_time_test_scores[str(i)] = vit_classifier.evaluate(x_test, y_test)[1]\n",
        "print(long_time_train_scores)\n",
        "print(long_time_test_scores)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}